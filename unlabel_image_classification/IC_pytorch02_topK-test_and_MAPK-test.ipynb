{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5464,"status":"ok","timestamp":1642156200209,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"gOw7BjcGtBEc","outputId":"beac8fca-c323-45d9-b64f-284094c4239a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=b2cb70414bc23120cb6b2c56299c3d4d546716b2ea8997041709d9470cc366e5\n","  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1\n"]}],"source":["!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlc0b0ekv93y"},"outputs":[],"source":["#reference                           #https://keep-steady.tistory.com/35"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q00g7AtVubim"},"outputs":[],"source":["import numpy as np\n","import json\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import random\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4sXrKt2tZme"},"outputs":[],"source":["from efficientnet_pytorch import EfficientNet\n","model = EfficientNet.from_name('efficientnet-b0')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["ae742debf36e46b9959f80d17905c3bc","491ce6f0bbe94bc1a96bedff398c1156","bafb0098355b4ad685817835d3f0fbee","2f3f7be9fb7e4b32b73ab4d456cfbe95","5c683f3988b749f098f352813d2963ab","f2f601e9d16e4516972d594ded243a2d","e68a728b1a214015a1b498c86f015a96","b11419d2bacf42e5ae69f959f050d956","a311e4701afe437bab2297a05908ad40","7f7b1dff71d94d9c9698fb412991cfe7","81b4f8da046240d5ab6d3dd0c14196b3"]},"executionInfo":{"elapsed":696,"status":"ok","timestamp":1642156245468,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"EjRMSHIWtP-i","outputId":"c4c6cbff-36db-4341-84f2-84a5cf6d9242"},"outputs":[{"output_type":"stream","name":"stdout","text":["224\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae742debf36e46b9959f80d17905c3bc","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/20.4M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b0\n"]}],"source":["model_name = 'efficientnet-b0'  # b5\n","\n","image_size = EfficientNet.get_image_size(model_name)\n","print(image_size)\n","model = EfficientNet.from_pretrained(model_name, num_classes=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15828,"status":"ok","timestamp":1642156263760,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"jpuPjsZKtjYW","outputId":"fca8031d-9e5d-428a-918f-33263c4a959c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## 데이타 로드!!\n","batch_size  = 128\n","random_seed = 555\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","#google drive 연동\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","## make dataset\n","from torchvision import transforms, datasets\n","data_path = \"/content/drive/MyDrive/data/computer_vision_task/train\" # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n","president_dataset = datasets.ImageFolder(\n","                                data_path,\n","                                transforms.Compose([\n","                                    transforms.Resize((224, 224)),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","                                ]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J23gGDqauXM0"},"outputs":[],"source":["data_path = \"/content/drive/MyDrive/data/computer_vision_task/test\" # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n","tests_dataset = datasets.ImageFolder(\n","                                data_path,\n","                                transforms.Compose([\n","                                    transforms.Resize((224, 224)),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","                                ]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jlm2cerauiGT"},"outputs":[],"source":["## data split\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Subset\n","train_idx, tmp_idx = train_test_split(list(range(len(president_dataset))), test_size=0.2, random_state=random_seed)\n","datasets = {}\n","datasets['train'] = Subset(president_dataset, train_idx)\n","tmp_dataset       = Subset(president_dataset, tmp_idx)\n","\n","val_idx, test_idx = train_test_split(list(range(len(tmp_dataset))), test_size=0.5, random_state=random_seed)\n","datasets['valid'] = Subset(tmp_dataset, val_idx)\n","datasets['test']  = Subset(tmp_dataset, test_idx)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pXAejLyZXBR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1642156282261,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"bv5I50kYuoep","outputId":"df84e719-9a44-4c5e-85b0-0837aac18fd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["batch_size : 128,  tvt : 4 / 1 / 1\n"]}],"source":["\n","## data loader 선언\n","dataloaders, batch_num = {}, {}\n","dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n","                                              batch_size=batch_size, shuffle=True,\n","                                              num_workers=4)\n","dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n","                                              batch_size=batch_size, shuffle=False,\n","                                              num_workers=4)\n","dataloaders['test']  = torch.utils.data.DataLoader(datasets['test'],\n","                                              batch_size=batch_size, shuffle=False,\n","                                              num_workers=4)\n","batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n","print('batch_size : %d,  tvt : %d / %d / %d' % (batch_size, batch_num['train'], batch_num['valid'], batch_num['test']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"no2ed1RLZa_j"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQNaq0HHZpUR"},"outputs":[],"source":["# ## 데이타 체크\n","# import torchvision\n","# def imshow(inp, title=None):\n","#     \"\"\"Imshow for Tensor.\"\"\"\n","#     inp = inp.numpy().transpose((1, 2, 0))\n","#     mean = np.array([0.485, 0.456, 0.406])\n","#     std = np.array([0.229, 0.224, 0.225])\n","#     inp = std * inp + mean\n","#     inp = np.clip(inp, 0, 1)\n","#     plt.imshow(inp)\n","#     if title is not None:\n","#         plt.title(title)\n","#     plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","# num_show_img = 5\n","\n","# class_names = {}\n","# for cls_num in range(50): \n","#   class_names[str(cls_num)] = str(cls_num)\n"," \n","\n","# # train check\n","# inputs, classes = next(iter(dataloaders['train']))\n","# out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","# imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","# # valid check\n","# inputs, classes = next(iter(dataloaders['valid']))\n","# out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","# imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","# # test check\n","# inputs, classes = next(iter(dataloaders['test']))\n","# out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","# imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])"]},{"cell_type":"code","source":["## 데이타 체크\n","import torchvision\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","num_show_img = 5\n","\n","class_names = {}\n","for cls_num in range(50): \n","  class_names[str(cls_num)] = str(cls_num)\n"," \n","\n","# train check\n","inputs, classes = next(iter(dataloaders['train']))\n","out1 = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","#imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","# valid check\n","inputs, classes = next(iter(dataloaders['valid']))\n","out2 = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","#imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","# test check\n","inputs, classes = next(iter(dataloaders['test']))\n","out3 = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n","#imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])"],"metadata":{"id":"YbNt6zh40Qek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imshow(out1, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","#imshow(out2, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n","#imshow(out3, title=[class_names[str(int(x))] for x in classes[:num_show_img]])"],"metadata":{"id":"riSo2d5d0R0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGNrLg1xvJlY"},"outputs":[],"source":["import math\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n","    \n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'valid']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n","            \n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    #torch.max(outputs, 2) IndexError: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n","                    print(\"checking process in train models!! ___________________ outpusts : \", outputs, \" length of outputs!! : \", len(outputs), \" shape of outputs!!! : \", outputs.shape) \n","                    #outputs는 현재 형태는 batch size X label(50)\n","\n","                    print(\"checking process in train models!! ___________________ preds : \", preds, \" shape of preds : \", preds.shape)\n","                    #preds는 128개 배치에 대한 예측값 128개\n","                    \n","                    #torch.max는 shape는 일단 없넹\n","                    #tormax = torch.max(outputs, 1)\n","                    #rint(\"checking process in train models!! ___________________ torch.max(outputs, 1) : \", tormax ,\" length of torch.max : \", len(tormax ) )\n","                    \n","                    false_list, preds_list = torch.sort(outputs,  descending=True)  #/** additional part **/#\n","\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                #기존: \n","                #running_corrects += torch.sum(preds == labels.data) \n","                #num_cnt += len(labels)\n","\n","                #dcg 적용: 아래 #----------------------------------------------------------------------------\n","                #topKval = 3 #test로 top3로\n","                topKval = 5 #test로 top5로\n","                for iii in range(topKval):\n","                  indices = torch.tensor([ iii ], device=\"cuda:0\")\n","                  predTopK = torch.index_select(preds_list, 1, indices)\n","                  predTopK = torch.reshape( predTopK, (-1, ) )\n","\n","                  print(\"iii is %d      divison by zero???  : \"%(iii), math.log(2, iii+2 ) )\n","                  \n","                  #running_corrects += torch.sum(   (predTopK == labels.data) / math.log(2, iii+2 )   ) # DCG 적용\n","                  running_corrects += torch.sum(   (predTopK == labels.data) /  (iii+1)    ) # MAP@K 적용\n","                  \n","                num_cnt += len(labels)\n","                #dcg 적용: 위 #----------------------------------------------------------------------------\n","                \n","            if phase == 'train':\n","                scheduler.step()\n","            \n","            epoch_loss = float(running_loss / num_cnt)\n","            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n","            \n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                valid_loss.append(epoch_loss)\n","                valid_acc.append(epoch_acc)\n","            print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n","           \n","            # deep copy the model\n","            if phase == 'valid' and epoch_acc > best_acc:\n","                best_idx = epoch\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n","                torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/image_model_210114_1.pt\")\n","                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    #torch.save(model.state_dict(), \"/content/drive/MyDrive/model/image_class/president_model.pt\")\n","    torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/image_model_210114_1.pt\")\n","    print('model saved')\n","    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTNrhnlQXFUU"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WM84f2psXFWc"},"outputs":[],"source":["#-------------------------------아래 쫙 torch 형태 테스트---------------------------------_#"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cmGdX4TXFYb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1642055615921,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"aZTsMujN_cTR","outputId":"d17ba09c-cd44-480f-bf85-9f29cb994365"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.6101, 1.5238, 0.8179])\n","tensor([2.6101, 1.5238, 0.8179])\n","tensor([0.3368, 0.9035, 0.9918])\n"]}],"source":["b = torch.randn(3)\n","print(b)\n","\n","b2 = b\n","c = torch.rand(3)\n","print(b2)\n","print(c)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1642055733492,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"3IS4TfL6JSXg","outputId":"ee5b3262-22ee-4e11-f7e0-1468f230623b"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.0000, 0.0000, 2.6101],\n","        [0.0000, 1.5238, 0.0000],\n","        [0.8179, 0.0000, 0.0000]])\n"]}],"source":["d = torch.tensor([     [0,0,2.6101], [0,1.5238,0], [0.8179,0,0]               ]  )\n","print(d)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1642053239171,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"D9Qxvlq__cVm","outputId":"6084b7e6-adf8-4a07-ae64-0d9be8f32db3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.2976, 0.9933, 0.5625]])\n"]}],"source":["a = torch.randn(1, 3)\n","print(a)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1642054109302,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"HbtbuXxe_cX-","outputId":"ea656721-00cd-4b6b-bff6-029d3c5fe23a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.9933)\n","'''''''''''''''''''''''''''''''''''''''''\n","torch.return_types.max(\n","values=tensor([0.9933]),\n","indices=tensor([1]))\n","-----------==================-------------\n","torch.return_types.sort(\n","values=tensor([[0.9933, 0.5625, 0.2976]]),\n","indices=tensor([[1, 2, 0]]))\n"]}],"source":["print(torch.max(a) )\n","print(\"'''''''''''''''''''''''''''''''''''''''''\")\n","print(torch.max(a, 1) )\n","\n","print(\"-----------==================-------------\")\n","\n","print( torch.sort(a, descending=True) )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1642056582710,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"lQ0ZT_RVMq1q","outputId":"bb5e6b60-53f2-48bf-cb53-6823eb6c3a54"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.3985,  1.0277,  0.3146, -0.3213],\n","        [ 0.6226, -0.4492,  0.6144,  1.0075],\n","        [ 1.9314,  1.8235,  0.0220,  0.5228]])\n"]}],"source":["x = torch.randn(3, 4)\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1642057718922,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"sO6DU091RE82","outputId":"0eb09aea-ab82-4994-b7a6-6708b78c0c6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.3985,  1.0277,  0.3146, -0.3213],\n","        [ 0.6226, -0.4492,  0.6144,  1.0075],\n","        [ 1.9314,  1.8235,  0.0220,  0.5228]])\n"]}],"source":["print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1642057272938,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"cvXT1lttPYF6","outputId":"343f5cf4-e375-4f34-fc44-585832038274"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.return_types.max(\n","values=tensor([1.0277, 1.0075, 1.9314]),\n","indices=tensor([1, 3, 0]))\n"]}],"source":["print(torch.max(x, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1642057431461,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"wWXRCemdPzlo","outputId":"c55655d2-cfa2-4ecd-e8ad-a3d2da615feb"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.0277, 1.0075, 1.9314])\n","========\n","tensor([1, 3, 0])\n"]}],"source":["aaa, bbb = torch.max(x, 1)\n","print(aaa)\n","print(\"========\")\n","print(bbb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1642058241296,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"9Tl_vrkZQMf7","outputId":"07f602cc-4e08-4215-fa7b-4eb88379982d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.return_types.sort(\n","values=tensor([[ 1.0277,  0.3985,  0.3146, -0.3213],\n","        [ 1.0075,  0.6226,  0.6144, -0.4492],\n","        [ 1.9314,  1.8235,  0.5228,  0.0220]]),\n","indices=tensor([[1, 0, 2, 3],\n","        [3, 0, 2, 1],\n","        [0, 1, 3, 2]]))\n","tensor([[1, 0, 2, 3],\n","        [3, 0, 2, 1],\n","        [0, 1, 3, 2]])\n","-----------------\n","tensor([[1],\n","        [3],\n","        [0]])\n","=================\n","tensor([1, 3, 0])\n"]}],"source":["x_sorted = torch.sort(x, descending=True)\n","print(x_sorted)\n","valval, indind = torch.sort(x, descending=True)\n","print(indind)\n","\n","print(\"-----------------\")\n","indices = torch.tensor([0])\n","indind2 = torch.index_select(indind, 1, indices)\n","print( indind2 )\n","\n","print(\"=================\")\n","print( torch.reshape( indind2, (-1, )) )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wr69m6RbQMjW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEzRWqW9QMlt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1642057144153,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"keEeE-BXOvH0","outputId":"82ed9aef-94e8-4932-a4c4-9366e37ecdac"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.3985,  1.0277,  0.3146, -0.3213],\n","        [ 0.6226, -0.4492,  0.6144,  1.0075],\n","        [ 1.9314,  1.8235,  0.0220,  0.5228]])\n"]}],"source":["_, _x = torch.max(x, 1)\n","print( x )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1642056872679,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"9DA20zmkMq4D","outputId":"09eae5ab-afc2-490b-8aa5-bd2367537c0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1.0277,  0.3146],\n","        [-0.4492,  0.6144],\n","        [ 1.8235,  0.0220]])\n"]}],"source":["indices = torch.tensor([1, 2])\n","print( torch.index_select(x, 1, indices) )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSN7lIcQMq54"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1642055830016,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"Ud6BUEULHsxx","outputId":"5f991ac2-d348-4009-fede-316af7e076df"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["print( '1' in ['1',2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KO7wTyQKABJ2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0tLl-yuXvvy4"},"outputs":[],"source":["# torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3TIFSY4vwQw"},"outputs":[],"source":["# torch.save(model.state_dict(), \"/content/drive/MyDrive/model/image_class/president_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"meht38ZnvwUB"},"outputs":[],"source":["#왜인지 에러가 나서..\n","device = torch.device(\"cuda:0\")        #(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n","\n","model = model.to(device)\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer_ft = optim.SGD(model.parameters(), \n","                         lr = 0.05,\n","                         momentum=0.9,\n","                         weight_decay=1e-4)\n","\n","lmbda = lambda epoch: 0.98739\n","exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1618683,"status":"ok","timestamp":1642062097685,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"_5JkBXSYvwoe","outputId":"fca4748c-1260-4d28-9f57-e1ed2de4accd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","         -9.9006e-02, -1.1735e+00,  9.8145e+00, -1.6163e+00,  8.7189e-01,\n","          2.9891e-01,  2.6770e+00,  1.4307e+00, -1.7364e+00, -4.9709e-01,\n","         -5.7856e-01, -1.8622e+00, -6.3784e-01, -5.3142e-01, -1.8507e+00,\n","         -1.5862e+00,  6.0231e-01,  1.0152e-01, -2.5244e+00, -2.5960e+00,\n","         -2.8232e+00, -2.7962e-01, -9.3234e-01,  2.5114e+00, -1.2830e+00,\n","         -1.4625e+00,  8.9957e-01,  2.8753e+00, -5.2554e-01, -3.9312e-01,\n","         -3.6028e-01, -9.4621e-01,  7.2604e-01, -1.3134e+00,  1.7702e+00,\n","          2.4868e+00,  1.3857e+00,  1.0128e+00,  1.7518e-01, -4.6425e-01,\n","          1.4405e+00,  1.1395e+00, -1.5109e+00,  2.2407e-01,  4.8384e-01],\n","        [-3.6090e+00,  2.5116e+00, -1.6759e+00, -1.1448e-01,  2.3201e-01,\n","         -2.7117e-01, -1.3284e+00, -2.6166e+00,  5.2167e+00, -1.0913e+00,\n","         -8.3567e-01, -5.4246e-01, -2.0901e+00,  1.1738e+01, -4.8454e-03,\n","          2.2566e+00,  5.2934e-01, -1.0784e+00, -7.4098e-02,  8.7589e-01,\n","          9.1171e-01, -3.5778e-01, -1.2900e+00,  4.2616e+00, -1.2227e+00,\n","         -2.2798e+00, -1.2689e+00, -3.2054e+00, -1.1835e+00,  9.3402e-01,\n","         -2.5124e+00,  3.5060e+00,  3.4142e+00,  3.6614e+00,  4.0376e+00,\n","         -1.5103e+00, -1.9264e+00,  2.1627e+00, -1.2043e+00, -1.5958e+00,\n","         -1.2921e+00, -1.1052e+00, -1.8389e+00,  3.3341e+00, -4.8078e-01,\n","         -7.4276e-01, -8.2726e-01, -3.6529e+00, -2.3931e+00, -1.6712e-01],\n","        [ 4.0082e+00, -3.4596e+00,  3.9036e+00,  1.1005e+00, -2.5727e+00,\n","          1.9132e+00, -3.1849e+00, -3.0466e+00, -4.9495e-01, -7.4811e-01,\n","          1.3691e+00,  4.2661e+00, -2.1330e+00, -2.8490e+00, -9.8726e-01,\n","         -3.2864e+00,  1.2775e+01,  6.1503e-02, -2.7711e+00, -2.2461e+00,\n","          1.9907e+00, -2.6059e+00, -1.3672e+00, -7.5333e-01,  6.1221e-01,\n","          1.0382e+00,  3.0502e+00, -2.0182e+00, -1.8670e+00, -3.5487e-01,\n","          3.3367e+00, -2.3098e+00,  1.2810e-02,  1.2386e+00, -2.4139e+00,\n","          2.8865e+00, -9.6787e-01, -1.7234e+00,  4.6887e+00, -6.4216e-01,\n","          2.6187e-01, -7.7230e-01, -1.2518e+00,  2.0785e-01,  2.1066e+00,\n","         -3.8956e+00,  7.8582e-01,  5.4506e-02,  4.6146e-01,  3.4650e-01],\n","        [-1.2342e+00, -2.8514e+00, -5.1276e-01, -2.5662e+00, -1.7781e+00,\n","          1.4186e+00,  4.1690e-01, -1.1322e+00, -1.9309e+00, -5.2355e-01,\n","          2.7258e-02, -6.0090e-02,  3.7257e+00,  1.1533e-01,  1.3745e+01,\n","          4.5879e-01, -3.0085e+00,  7.4040e-01, -7.0897e-01, -2.9634e+00,\n","          9.8012e-01, -5.4999e-02,  3.6201e+00, -7.1708e-01, -9.6251e-01,\n","          5.9975e-01,  1.0752e+00,  9.9020e-01, -1.6424e+00, -1.4846e+00,\n","         -7.3737e-01,  9.4015e-02,  3.3273e+00, -1.9641e+00, -2.2878e+00,\n","          2.4169e+00, -5.4701e-01, -1.9517e+00,  5.6296e-01, -2.2443e-01,\n","          1.3848e+00, -2.3941e-01, -1.6197e+00,  5.3302e-01,  2.0865e+00,\n","         -2.8084e+00, -1.5232e+00,  4.6806e-01, -9.8036e-01, -1.2808e+00],\n","        [-2.8448e+00, -3.3554e+00, -3.6635e-01, -2.7828e+00, -4.8750e-02,\n","          2.1885e+00,  6.2371e-01,  4.4801e-01, -8.7619e-01, -5.4492e-01,\n","          1.9529e-01,  5.6340e-01,  2.6742e+00, -1.5630e+00, -1.8919e+00,\n","         -3.0101e-01, -7.2585e-01,  1.6930e+00,  1.8413e+00, -7.4619e-01,\n","         -5.1322e-01,  2.7783e-01, -3.0092e+00, -3.1844e+00, -2.2452e+00,\n","         -1.7080e+00, -3.9813e-01,  7.5550e-01,  1.1365e+01,  1.1207e+00,\n","          1.5833e+00,  5.7233e-01,  1.1029e+00, -1.8994e+00, -5.1046e-01,\n","          3.8101e-01, -6.4284e-01,  1.4302e+00, -2.0377e+00, -1.0678e+00,\n","          3.1925e+00,  6.6934e+00, -4.7909e-01, -1.8395e+00, -2.5156e-01,\n","          2.5905e+00,  4.8828e-01, -3.4972e+00,  9.3169e-02, -2.1106e-01],\n","        [ 1.0372e+01,  1.1286e+00, -5.8514e-01, -1.9485e+00, -1.6510e+00,\n","          2.5722e+00,  2.3302e+00, -2.9506e+00,  2.1246e+00, -2.8447e+00,\n","          1.4526e+00, -3.1652e-01, -1.1645e+00, -2.9880e+00, -2.5286e+00,\n","         -1.5349e+00, -1.1531e-02,  2.0778e+00, -4.3487e+00, -1.7530e+00,\n","          2.5172e+00, -2.3660e+00, -1.7159e+00,  4.7828e-01, -1.6172e+00,\n","         -1.9199e+00, -1.0376e+00, -2.1739e-01, -3.2613e+00,  1.3047e-01,\n","          3.1329e-04, -2.9541e+00, -2.0022e+00, -1.7638e-01, -2.1772e-02,\n","          8.2490e-01,  5.5684e+00,  2.4299e+00,  1.4113e+00, -5.8212e-01,\n","         -5.6626e-01, -1.2038e+00,  3.5814e+00,  5.6252e+00,  1.8562e+00,\n","         -3.0679e+00,  4.4532e-01,  3.6888e-01,  3.9864e+00,  7.5137e-01],\n","        [-2.5067e+00, -1.9025e+00,  2.4378e+00, -2.5619e+00, -6.9522e-01,\n","          3.1810e+00, -6.2906e-01, -5.2978e-01, -1.6772e+00,  8.1047e-01,\n","          5.9606e-01,  1.4907e+00,  9.0070e-01, -3.5313e+00, -1.0736e+00,\n","         -8.9533e-01, -1.6248e+00,  5.0087e-01,  2.6429e+00, -9.4888e-04,\n","         -2.8809e+00,  1.5086e+00, -2.2704e-01, -2.8073e+00, -9.9910e-01,\n","         -1.5589e+00, -6.1717e-01,  1.0408e+01,  2.1657e+00,  7.1820e-01,\n","          4.6027e-01,  4.2881e-01,  2.9116e-01, -1.7688e+00,  2.7278e-01,\n","         -2.1441e-01, -1.2441e+00,  8.7247e-01, -2.6569e-01, -1.7259e+00,\n","          8.6370e-01,  3.8255e+00, -1.0027e+00, -1.3438e+00,  1.5430e+00,\n","         -9.1854e-02,  1.7906e-01, -6.1391e-01,  1.1807e+00,  2.1526e-01],\n","        [-2.4817e+00,  1.2017e+00, -2.2274e+00, -1.3125e+00,  2.1188e+00,\n","         -3.0270e-01, -7.3311e-01, -1.6223e+00, -2.3582e-01,  6.5697e-01,\n","         -1.3760e+00,  6.0715e-01,  3.8097e-01,  4.5822e-01, -2.7757e+00,\n","          4.8827e+00, -3.7495e+00, -2.4150e-01, -5.5368e-01, -1.3799e+00,\n","          1.4457e+00, -6.4002e-01, -1.4185e+00,  1.8991e+00, -8.7664e-01,\n","         -7.0982e-01, -3.1789e+00, -2.4804e+00, -2.2285e-01,  1.1948e+01,\n","         -2.7256e+00,  8.7420e-01,  2.8954e+00, -2.3255e+00,  2.4040e+00,\n","         -2.7237e+00,  2.0118e-01,  1.8071e+00, -3.1410e-01, -1.2502e+00,\n","          4.5066e-01,  1.7963e+00, -1.2103e+00,  1.5587e+00, -7.1303e-02,\n","          2.9174e+00, -1.0887e+00, -2.7575e+00, -2.0726e+00,  4.7920e+00],\n","        [ 1.8754e+00, -3.3439e+00,  2.6830e+00, -4.5244e-02, -3.1891e+00,\n","         -1.3177e+00,  3.5726e+00, -3.0962e+00,  1.7994e+00, -2.4021e+00,\n","         -2.0999e+00,  2.8757e+00,  4.9617e-01, -6.9829e-01, -2.4369e-01,\n","         -2.5389e+00,  4.7849e-01,  1.0135e+00, -2.4760e+00,  3.1885e+00,\n","         -1.3200e-01,  1.1540e+00,  1.0139e+00, -2.7760e+00,  1.0358e+00,\n","         -6.1917e-01, -2.0766e-01,  1.4636e+00, -4.6942e+00, -1.5037e+00,\n","          6.3903e-01, -2.0168e+00, -9.9365e-02, -1.9158e+00, -1.7340e+00,\n","          3.8286e+00, -3.2858e-02, -4.3562e+00,  1.2648e+01,  3.5533e+00,\n","         -3.3853e+00,  1.7182e+00, -1.7378e+00,  2.3368e+00,  4.5789e-01,\n","         -3.6049e+00, -2.0592e+00,  2.4316e+00,  2.8016e+00,  1.2158e-01],\n","        [ 3.0680e+00,  4.6202e+00,  7.1269e-01,  3.1366e+00, -2.4325e-01,\n","         -1.2907e+00, -1.9263e+00, -3.4575e+00, -1.5581e+00,  9.0737e-01,\n","         -5.6672e-01, -1.8571e+00, -1.6929e+00, -9.4471e-01, -2.8962e+00,\n","         -4.7590e-01,  1.6061e+00, -1.5838e+00, -1.3856e+00,  1.7097e+00,\n","          3.1807e-01, -2.0230e+00, -5.0790e-01, -1.4843e-01,  1.0806e+01,\n","         -1.9835e+00, -1.0527e+00, -3.8832e+00, -2.9608e-01,  1.0583e+00,\n","          2.0072e+00, -2.9380e-01,  1.2070e+00, -3.6543e-01,  4.9612e-01,\n","         -9.3435e-01,  2.3163e-01,  3.2471e+00,  1.1936e+00,  6.4816e-01,\n","          1.7433e+00, -1.9029e+00, -1.8098e+00, -5.3400e-01, -2.4168e+00,\n","         -2.8115e+00,  3.4427e+00,  9.0476e-01, -7.5910e-01, -7.5942e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([31,  3, 24, 25, 25, 21,  7, 13, 16, 14, 28,  0, 27, 29, 38, 24],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 7.7129e-01,  1.0878e+01, -5.4373e-01,  ..., -1.7016e+00,\n","         -2.3108e+00,  2.6231e+00],\n","        [-1.2277e-02,  4.8975e+00, -3.6730e-01,  ..., -7.5040e-01,\n","         -7.1143e-01,  3.3176e+00],\n","        [ 5.9558e+00, -3.5559e+00,  1.6054e+00,  ...,  6.1901e+00,\n","          1.1341e+00, -1.5281e+00],\n","        ...,\n","        [ 2.1094e+00, -2.0646e-01, -9.3958e-01,  ..., -2.0923e+00,\n","          5.0735e-01, -6.0307e-01],\n","        [ 1.8273e+00,  1.6292e+01,  1.0301e+00,  ..., -1.5714e+00,\n","         -3.3964e+00,  1.6751e+00],\n","        [ 1.1015e+00, -4.2779e+00,  3.9571e+00,  ..., -5.1797e-01,\n","          2.2376e+00, -5.8540e-01]], device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 21, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.4\n","Epoch 380/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.8439,  3.7155, -2.1607,  ..., -3.5420, -2.4862,  3.5239],\n","        [ 0.3440,  0.6980, -0.2836,  ..., -0.9150, -0.3110,  0.6660],\n","        [-0.6809,  2.4386, -1.4857,  ..., -2.2964, -1.3089,  4.8179],\n","        ...,\n","        [-3.1228, -2.5547, -2.8036,  ..., -3.2035, -0.1842,  2.2686],\n","        [-2.3034, -1.0507,  1.3736,  ...,  1.2378, -2.0447, -2.1792],\n","        [ 0.5899, -1.0755, -0.3937,  ..., -0.9663, -1.2824,  0.0774]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([23, 43, 23, 30, 46, 49, 16, 23,  1, 46,  4,  2,  2, 31, 38, 30, 14, 19,\n","        27, 13, 34,  4, 28, 20, 46,  7,  6, 31, 22, 36, 19,  8, 12, 42, 21, 17,\n","         6, 15, 14,  1, 24, 48, 29, 45, 18, 30, 20, 23, 23, 11,  0, 21,  9, 26,\n","         5, 11,  6, 35, 32, 19, 22, 26, 30, 48, 25, 48, 14, 32,  3, 20, 46, 42,\n","        47, 22, 18, 10, 29, 45, 45, 40, 32,  4,  0, 16, 27, 18, 27, 11, 25, 28,\n","        14, 34, 28, 12, 41, 22, 36,  1, 16, 22, 49, 46, 33,  1, 26, 39, 30, 29,\n","        22, 45, 30, 29, 20,  3, 25, 18, 16, 27,  4,  2, 23, 40, 10,  4, 33, 41,\n","         9, 14], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.3081, -1.0204,  0.1998,  ...,  0.8905, -0.7347,  1.9938],\n","        [ 0.8984,  0.6427, -0.3472,  ..., -1.6770, -1.2401,  2.0136],\n","        [ 2.6769, -2.7876,  1.4266,  ...,  1.8979, -0.2499, -0.2950],\n","        ...,\n","        [ 0.2171, -1.8738,  0.2685,  ...,  0.5473,  2.7714, -1.9833],\n","        [-1.6135, -2.8313,  1.2449,  ..., -2.2357,  0.0111, -0.1043],\n","        [ 3.2559, -3.0721,  3.6486,  ...,  3.6627, -0.5869, -0.5300]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20, 36, 25, 28, 24, 37, 13, 13, 24, 34, 28, 43, 48, 19, 43, 36,  9, 33,\n","        44, 41, 30, 24,  8,  8,  3, 29, 11, 29, 39, 35, 33,  7, 11, 10,  1, 34,\n","         8,  1, 43, 16, 13, 44, 39, 48, 31, 11, 40, 48, 42, 32, 43,  5,  3, 40,\n","        40, 49, 37, 24,  3,  2, 12,  2, 17, 32, 48, 44,  8, 45,  5, 41, 15, 30,\n","        10, 12, 26, 20,  3, 17,  9, 23, 29, 36, 36, 35, 14, 30, 24, 43, 14, 15,\n","         9, 49, 12, 17, 40, 17, 49,  8, 26, 42,  7, 27, 41, 17, 27, 27, 18, 35,\n","         9, 10, 37, 49, 31, 15, 36, 33, 41,  1, 31,  1, 24, 37, 20, 21, 16, 17,\n","        44, 35], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.0102, -2.9894, -0.8939,  ..., -1.3945, -0.5636, -0.4580],\n","        [ 2.4207, -1.0945,  0.9960,  ..., -0.0079,  2.2540, -0.3862],\n","        [-1.0822,  4.3867, -1.0433,  ..., -2.5889, -2.4826,  1.5862],\n","        ...,\n","        [ 3.1070,  0.7819,  0.4685,  ...,  0.5256, -0.9901,  1.5393],\n","        [-2.4243, -1.7685, -1.9842,  ..., -1.0924, -0.4462, -0.8981],\n","        [ 0.1231,  0.5181,  0.6542,  ...,  2.6969, -0.5486, -1.8384]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([14, 30, 34,  4, 31, 25, 11, 10,  5, 35, 27,  9, 47, 20,  3, 19, 49, 38,\n","        21, 47,  0, 16, 20, 17, 21, 44, 33, 12,  5, 28, 10, 42, 15, 16,  0, 28,\n","        45, 38, 11, 46,  6, 26, 32,  9, 38, 16, 37, 40, 17,  0, 41, 12, 29, 13,\n","         2, 18, 31, 42, 47, 35, 45, 19, 31, 29, 14, 25,  1,  2, 15,  3,  4, 47,\n","         9, 26, 17, 24, 10,  8,  7,  9, 37, 37,  0,  2, 32,  5, 24,  6,  7, 35,\n","        15, 25, 18,  4, 31, 21, 33, 27, 49, 13,  6, 34, 37, 32, 22,  8, 38,  7,\n","         2,  0, 27, 39, 26, 39,  3, 44, 42, 41, 40, 46, 13,  6,  7, 47, 22, 36,\n","         7, 19], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.6596e+00, -1.2834e+00,  6.5129e+00,  4.3706e+00, -2.5904e+00,\n","          2.7920e+00, -1.7929e+00, -3.3366e+00, -1.4587e+00, -8.4259e-02,\n","         -2.4942e+00,  2.0090e+00, -3.2668e+00, -3.1136e+00, -9.8997e-01,\n","         -2.0417e+00,  1.6206e+01, -1.0164e+00,  2.1681e-01,  2.0027e-01,\n","          6.3460e-01, -1.5987e+00, -3.6049e+00, -1.8527e+00,  1.6984e+00,\n","          2.2185e-01,  5.4572e+00, -1.0483e+00, -3.0605e+00, -2.1515e+00,\n","          4.3159e+00, -1.1414e+00, -6.6949e-01,  4.7611e+00, -1.1077e+00,\n","          2.9939e+00, -3.4999e+00,  1.8446e-02,  1.9341e+00, -1.8300e+00,\n","         -1.1122e+00, -1.6301e+00, -3.9392e+00,  7.1411e-03,  2.8576e-01,\n","         -2.8171e+00,  3.3611e+00,  4.7644e-01, -1.7110e+00, -3.0275e-01],\n","        [-2.6145e-01, -1.0973e+00,  2.8067e+00,  7.5338e-01,  1.6984e-01,\n","         -1.7787e+00, -7.4764e-01, -1.3822e+00, -3.2719e+00,  7.1823e-01,\n","         -1.5759e+00,  1.8069e+00, -3.3621e+00, -1.2602e+00, -1.2801e+00,\n","         -1.5753e+00,  6.5714e-01,  1.3621e+00, -5.6363e-01, -6.0253e-01,\n","          1.8550e+00, -1.3455e+00,  3.6232e+00, -1.3199e+00,  3.6208e+00,\n","          1.0947e+01, -4.4845e-01, -2.7425e+00, -2.0634e+00,  3.5785e+00,\n","          8.2407e-01, -6.9648e-01,  3.0440e+00, -9.3197e-03, -2.3645e+00,\n","          3.2841e+00, -1.2912e+00, -2.0031e+00,  2.7803e-01,  1.6800e+00,\n","         -1.9828e+00, -1.3554e+00, -3.8333e+00, -4.0024e-01,  5.4982e-01,\n","         -1.0008e+00, -8.6571e-01,  1.9558e+00, -6.9932e-01,  4.1499e-01],\n","        [-1.0926e-01, -3.2725e-02,  2.9866e+00, -3.7544e-01, -1.5971e+00,\n","         -9.1285e-01, -2.3782e+00, -2.3961e+00, -2.9660e-01,  9.3496e-01,\n","         -1.0304e+00,  2.9922e+00, -1.7827e+00, -3.3156e-01, -2.1167e+00,\n","         -2.3694e+00,  2.2713e+00,  8.8812e-01,  1.9788e+00,  4.9202e-01,\n","         -6.8703e-01,  3.2847e+00, -1.0964e+00, -2.2930e+00,  1.7208e+00,\n","          3.0714e-01,  1.6071e-01, -5.1228e-01, -2.2102e-01,  1.8945e+00,\n","          5.6815e-01, -8.0524e-01,  1.3428e+00, -1.6471e+00, -3.0196e+00,\n","         -1.6679e-01, -1.0899e+00, -1.4763e+00,  1.1463e+01, -1.2919e+00,\n","         -3.6386e-01, -6.6368e-01, -2.7650e-01, -1.1233e+00,  1.6764e+00,\n","         -3.2667e+00,  1.8407e+00, -4.0134e-01, -1.3018e+00,  9.2090e-01],\n","        [-1.6305e+00, -6.5652e-01,  3.0916e+00, -1.5680e+00, -6.7371e-02,\n","          1.1924e+01,  1.4142e-01, -2.0864e+00,  4.7984e-01,  2.2700e-01,\n","          1.0357e+00,  2.1922e+00, -2.1498e+00, -1.5906e+00, -1.4321e+00,\n","          1.2511e-01, -1.0538e+00, -2.4272e-01, -2.5401e-01, -1.2745e+00,\n","          8.8313e-01,  4.7727e-02, -3.5118e+00, -1.2576e+00, -2.7225e+00,\n","         -2.3025e+00,  3.5609e+00,  2.7302e+00, -2.1206e+00,  2.3668e+00,\n","         -9.9163e-01,  3.6922e-01, -8.6012e-01,  1.1297e+00,  1.3158e+00,\n","         -2.0106e+00, -5.7161e-03,  1.5348e-01, -2.0572e+00, -1.3108e+00,\n","          7.9382e-01, -7.3957e-01, -4.8424e-01,  2.5549e+00,  1.8808e+00,\n","         -1.4898e+00, -1.9932e+00, -1.1025e+00,  1.4545e+00,  1.2998e+00],\n","        [ 8.2793e-01,  1.7614e+00,  1.8434e-01,  2.8500e+00, -1.5269e+00,\n","         -6.4720e-01,  2.2270e+00, -2.0808e+00, -2.0006e+00,  6.3286e-01,\n","         -1.8590e+00,  2.0939e+00, -3.5086e+00, -1.2345e+00, -1.1045e+00,\n","         -1.4814e+00, -2.2939e+00,  1.1198e+00,  8.7845e-01,  3.7899e+00,\n","          1.5990e+00, -1.3303e+00, -1.4879e+00, -1.6319e+00,  3.5043e+00,\n","          2.6125e+00, -1.3043e+00, -2.3084e+00, -2.4837e+00,  2.1707e+00,\n","          1.8332e+00, -1.9920e+00, -9.7124e-01, -1.9713e+00, -1.7642e+00,\n","          6.7782e-01, -5.6091e-01, -2.2056e+00,  1.9896e+00,  1.8815e+00,\n","         -6.7840e-01, -6.4805e-01, -1.3113e+00, -2.8679e-01, -9.0871e-01,\n","         -2.4884e+00, -5.8608e-01,  1.1207e+01,  6.3485e-01, -1.1027e+00],\n","        [ 1.0839e+01,  8.5328e-01,  1.4740e+00, -8.7774e-01, -7.6197e-01,\n","          2.1485e-01,  1.7747e+00, -3.5412e+00,  7.3293e-01, -2.4648e+00,\n","          9.5121e-01, -4.1495e-01, -7.5781e-01, -3.6340e+00, -2.4785e+00,\n","         -3.3189e+00,  8.7355e-01,  1.1726e+00, -3.3167e+00, -1.2869e+00,\n","          2.6359e+00, -1.8036e+00, -1.3433e+00, -7.8763e-01,  1.2145e+00,\n","         -8.5508e-01, -3.9719e-01,  1.4607e+00, -3.3324e+00, -3.9055e-01,\n","          1.1769e+00, -1.4118e+00, -1.0882e+00, -2.9911e+00, -1.6953e+00,\n","         -7.8283e-02,  5.1686e+00,  2.4479e+00,  1.4543e+00,  3.0501e-01,\n","         -6.9077e-02, -1.5062e+00,  3.0627e+00,  2.9752e+00,  8.5496e-01,\n","         -3.6523e+00, -2.6178e-01,  1.5185e-01,  3.4585e+00,  4.0656e-01],\n","        [-1.0341e+00, -1.7205e+00,  1.3131e+00, -1.3011e+00,  1.9045e+00,\n","         -2.6868e+00, -1.5789e+00, -1.4577e+00,  3.3464e-01,  3.3518e+00,\n","         -4.6294e-01, -1.9836e+00,  9.9704e+00, -2.1793e+00, -1.9771e-01,\n","         -1.6041e+00, -2.2501e+00, -1.4546e+00,  1.3458e+00, -2.1105e+00,\n","          3.4717e-01,  2.2843e+00,  3.7149e+00, -5.3502e-01, -1.2769e+00,\n","         -1.3823e+00, -2.4552e+00, -2.1192e-02,  1.7495e+00, -5.7741e-01,\n","         -8.6833e-01,  1.3012e+00,  1.0050e+00, -3.2250e+00, -1.2656e+00,\n","          1.4956e-01, -7.1703e-01,  2.1671e+00,  1.5344e+00, -5.6141e-01,\n","          4.1349e+00,  3.1893e+00,  3.6798e-01, -1.0322e+00, -1.6636e+00,\n","          8.2825e-01,  3.4341e-01, -1.9338e+00, -3.3152e-01, -6.5644e-01],\n","        [-3.3606e+00, -3.4665e+00, -1.7267e+00, -3.2924e+00,  4.5116e+00,\n","          8.5934e-02, -2.5776e+00,  2.6538e+00, -8.7331e-01,  2.9004e+00,\n","          4.9025e-01,  2.0937e+00,  2.3015e+00, -2.5960e+00, -2.4745e+00,\n","         -2.4175e+00, -2.1058e+00, -6.2149e-01,  6.1150e-02, -2.6314e+00,\n","         -5.2153e-01,  8.4495e-02, -7.9386e-01, -2.6091e+00, -2.1100e+00,\n","         -1.0753e+00, -5.8374e-01, -7.2968e-01,  3.1989e+00,  3.2887e+00,\n","         -1.1892e+00,  3.4771e+00,  5.3286e+00, -2.9280e+00, -6.9617e-01,\n","          2.6075e-01, -8.6423e-02,  2.3344e+00, -9.5606e-01, -3.7549e-01,\n","          3.9792e+00,  1.3840e+01, -2.7129e+00, -3.5238e+00,  5.6768e-01,\n","          5.5949e+00, -1.2844e+00, -4.1876e+00, -8.8711e-01,  1.4847e+00],\n","        [-2.3490e+00, -7.5730e-02, -1.5834e+00,  3.2527e-01,  1.0691e+00,\n","          5.3580e-01, -1.4907e+00, -1.1372e+00, -7.5801e-01, -9.3527e-01,\n","         -2.5531e+00, -1.3287e+00, -1.2340e+00,  1.8826e+00,  9.4294e-01,\n","          1.4269e+01,  5.0629e-01, -2.7322e+00, -1.5404e+00, -2.1926e+00,\n","         -5.4832e-01, -7.6111e-01, -1.4561e+00,  5.4602e+00, -2.2234e-01,\n","         -2.2385e+00, -2.4123e+00,  8.6296e-01, -1.1529e+00,  4.5838e+00,\n","         -2.1121e+00,  3.2756e+00,  1.9694e+00, -2.5862e+00,  1.2720e+00,\n","         -2.0637e+00,  1.0960e-01,  1.4491e+00, -1.3778e+00, -1.8474e+00,\n","          1.1036e+00,  2.4466e-01, -2.4203e+00,  1.4664e+00,  2.0786e-01,\n","         -2.4753e+00, -8.4865e-01, -2.3237e+00, -2.5922e+00,  5.0282e+00],\n","        [ 2.8435e+00,  2.7231e+00,  1.5339e+00,  4.1172e+00, -3.5567e+00,\n","         -6.7770e-01,  3.3126e+00, -4.8686e+00, -2.9534e-01, -1.7271e+00,\n","         -3.3227e+00, -1.9989e+00, -2.6437e+00,  9.6388e-01, -1.6243e+00,\n","         -4.0242e-01,  6.9443e-01,  1.4055e+00,  2.3577e+00,  1.2088e+01,\n","         -6.6891e-01, -1.7411e+00,  1.0363e+00,  1.1872e-01,  3.9789e+00,\n","          1.4341e+00,  1.3257e+00, -2.4061e-01, -4.0810e+00, -1.4484e-01,\n","          3.2857e+00, -1.1597e+00,  3.8347e-01, -2.5376e-01, -8.2830e-01,\n","          5.9862e-01, -2.9981e+00, -1.9207e+00,  3.3436e+00,  1.3045e+00,\n","         -1.9691e+00, -3.7201e+00, -3.7647e+00,  1.3202e+00, -1.1312e+00,\n","         -3.1026e+00,  4.8800e-01, -9.5707e-01, -1.5690e+00, -1.8599e+00],\n","        [-3.3133e+00,  3.1726e-01, -1.3490e+00, -1.0411e+00, -1.5170e+00,\n","         -2.1531e+00,  8.6686e-01, -3.3162e+00,  5.7983e+00, -1.9071e+00,\n","         -2.1169e+00, -2.0778e+00, -2.3209e+00,  1.3360e+01,  7.9190e-01,\n","          9.3671e-01, -4.2352e-01, -1.1769e+00,  7.4103e-01,  1.8430e+00,\n","          1.6572e+00,  2.4960e-01, -9.6620e-01,  4.5121e+00, -1.0950e+00,\n","         -1.3582e+00, -1.9057e+00, -2.2579e+00, -1.2983e+00,  1.0074e+00,\n","         -1.9209e+00,  4.2605e+00,  2.9709e+00,  2.6677e+00,  4.4787e+00,\n","         -2.4610e+00, -1.8365e+00,  1.1993e+00, -4.9718e-01, -1.6217e+00,\n","         -1.9097e+00, -1.1759e+00, -2.8236e+00,  4.0749e+00,  5.9142e-01,\n","         -1.6672e+00, -1.2025e+00, -3.4810e+00, -2.2650e+00,  1.0486e+00],\n","        [ 8.4248e-01,  2.5951e+00,  6.0384e-01, -3.2220e-02,  4.8443e-01,\n","          3.9001e-01, -1.5916e+00, -2.7737e+00,  1.6797e+00, -1.5117e+00,\n","          8.9609e-01, -1.0564e+00,  7.7713e-01, -1.8209e-01,  1.4464e+00,\n","         -8.1729e-01, -1.0335e+00, -2.0761e+00,  2.1728e-01, -2.9016e+00,\n","          3.1138e+00, -7.9014e-01, -1.7223e+00,  1.5127e+00,  9.7387e-01,\n","         -2.7454e+00, -2.0435e+00, -1.7936e+00, -1.2656e+00,  9.4252e-01,\n","          3.1621e-01,  2.1926e+00,  1.9610e+00, -1.4883e+00,  1.0225e+00,\n","         -1.5389e+00,  1.1242e+01,  1.8032e-01,  4.3389e-01, -2.6295e+00,\n","          4.9595e-01, -1.0534e-01,  1.0205e+00,  2.2354e+00,  2.8942e+00,\n","         -2.9917e+00, -7.9796e-02, -2.2154e+00, -2.4871e+00,  1.7639e+00],\n","        [-2.7670e+00, -2.4636e+00, -9.9341e-01, -1.7089e+00,  7.1969e-01,\n","          9.6451e-01, -2.5698e-01,  3.0836e+00, -1.8301e+00,  4.2937e-02,\n","         -2.5733e-02, -8.8372e-01,  3.8330e+00, -1.3770e+00, -1.2508e+00,\n","         -1.1473e+00, -1.0927e+00,  9.0102e-01,  2.2718e+00, -3.5429e-01,\n","          5.4697e-01,  1.8971e+00, -2.4489e-01, -1.0370e+00, -1.5913e+00,\n","         -1.4583e+00, -9.6711e-01, -1.4052e-01,  1.4800e+01, -1.2461e-01,\n","          1.9375e+00,  2.5609e+00,  1.3487e+00, -1.3172e+00, -1.2247e+00,\n","         -6.3222e-01, -1.9047e+00,  1.3615e+00, -1.9032e+00, -4.2320e-01,\n","          1.8872e+00,  4.6656e+00, -5.8594e-01, -2.2294e+00, -5.5871e-01,\n","          3.8842e-02, -1.7491e-02, -3.8699e+00, -1.7910e+00, -1.9157e+00],\n","        [-5.2927e-01, -6.6774e-01,  1.5834e+00, -1.1019e+00, -3.4361e-01,\n","         -4.4695e-01, -6.6256e-03, -9.8476e-01,  1.0808e-02, -5.2950e-02,\n","          1.3419e+01, -1.4320e-01, -6.7772e-01, -9.6121e-01, -1.4597e+00,\n","         -1.9858e+00, -8.9752e-01,  6.1134e+00, -1.4532e+00, -1.1593e+00,\n","          2.2935e-01, -1.5419e+00, -6.9185e-01, -1.1740e+00, -1.6957e+00,\n","         -2.0692e+00, -4.0145e-01, -2.3174e+00, -5.8032e-01, -1.1268e+00,\n","          7.6808e-01, -1.0931e+00,  3.4268e-01,  1.5396e+00, -4.2780e-01,\n","         -9.3340e-01, -3.7280e-01,  7.1403e-02, -1.5000e+00, -1.2163e+00,\n","         -2.0896e-01, -1.1919e+00,  4.8002e+00,  1.3134e+00,  2.0467e+00,\n","         -1.2113e+00,  3.9608e+00, -2.9788e+00,  3.5113e+00, -1.7867e+00],\n","        [ 3.8321e+00, -1.9546e+00, -5.1648e-01,  1.4419e+00, -3.0085e+00,\n","          7.6076e-01,  1.2335e+00, -1.8673e+00, -1.0211e+00, -5.5082e-01,\n","         -9.1699e-01,  4.3792e+00, -2.7627e+00, -2.1812e+00,  4.1114e-01,\n","         -1.1117e+00, -2.1474e-01, -1.3214e+00, -1.3230e+00,  9.8526e-01,\n","          1.4559e+00,  2.1529e-01, -7.5584e-01, -2.1864e+00,  3.5920e+00,\n","          1.5891e+00, -2.9112e-01,  1.0272e+00, -2.6514e+00, -6.8166e-01,\n","          4.2873e-01, -1.9705e+00, -9.2261e-01, -1.4858e+00, -1.3777e+00,\n","          2.6725e+00, -1.9051e+00, -2.3670e+00,  4.1491e+00,  2.7377e+00,\n","         -1.9958e+00,  9.7914e-01, -8.2659e-01, -1.2036e+00, -1.5045e+00,\n","         -3.0517e+00, -1.3567e+00,  9.6030e+00,  2.3791e+00, -1.6277e-01],\n","        [ 6.4084e-01, -8.7467e-01,  4.8860e-01,  5.9642e-02,  1.0202e-01,\n","         -8.8269e-01,  2.1341e-01,  1.3974e-01, -9.9521e-01,  1.2708e+00,\n","         -1.3083e+00, -6.8188e-02,  1.0420e+01, -4.0176e+00,  4.9405e-01,\n","         -2.7072e+00, -3.1630e+00, -2.1835e-01, -1.3019e+00, -2.8644e-01,\n","         -2.0733e+00,  1.1757e+00,  2.5253e+00, -3.0892e+00, -2.2115e-01,\n","         -1.1335e+00, -4.8702e-01,  2.3199e+00,  4.7825e-01,  3.1081e-01,\n","         -3.6305e-01, -1.4041e+00,  2.1160e-01, -2.2533e+00, -3.0887e-01,\n","          1.2950e+00, -1.3767e+00,  6.7222e-01,  1.4795e+00,  1.9909e+00,\n","          2.2971e+00,  2.7103e-01,  1.4933e+00, -9.0561e-01,  4.5349e-01,\n","          1.9916e+00,  4.7860e-01, -1.7182e+00,  5.5564e-01, -2.4121e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([16, 25, 38,  5, 47,  0, 12, 41, 15, 19, 13, 36, 28, 10, 47, 12],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7623, 10.8786, -0.5475,  ..., -1.7084, -2.3107,  2.6435],\n","        [-0.0215,  4.8978, -0.3700,  ..., -0.7540, -0.7096,  3.3264],\n","        [ 5.9782, -3.5567,  1.5947,  ...,  6.1879,  1.1409, -1.5279],\n","        ...,\n","        [ 2.1120, -0.2062, -0.9431,  ..., -2.0974,  0.5066, -0.5985],\n","        [ 1.8253, 16.3242,  1.0346,  ..., -1.5806, -3.4015,  1.6852],\n","        [ 1.0908, -4.2692,  3.9408,  ..., -0.5167,  2.2279, -0.5787]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 21, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.4\n","Epoch 381/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.3724,  3.6342,  0.0992,  ..., -1.0357, -2.8167,  0.5179],\n","        [-0.4931,  3.5524, -0.2659,  ..., -3.1204, -1.0886,  3.2126],\n","        [-1.0920, -1.1136,  0.7581,  ..., -1.7265, -0.2826, -2.0994],\n","        ...,\n","        [-2.5538, -0.1212,  1.5940,  ...,  0.9301, -1.0413, -1.2970],\n","        [-3.0342, -2.2593, 17.9028,  ..., -2.2840, -1.5480, -0.3193],\n","        [ 0.2564, -0.8712,  0.4115,  ...,  0.1268,  1.6118, -1.7902]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([18, 37, 33, 11,  7, 38, 15, 32,  7, 30, 10, 15, 44, 39, 33, 40,  8, 33,\n","        12, 45, 40, 32, 13,  0, 35, 48, 33, 17,  9, 17, 37,  9, 29, 15, 46,  0,\n","         6, 28, 43,  5, 28, 46, 20, 32,  9, 30, 49, 39, 40, 48, 42,  9, 29, 23,\n","         5, 10, 35, 38, 37, 22, 15, 15,  1, 41, 11, 28, 12, 27, 38, 38, 19, 12,\n","        14, 32,  8, 10, 16, 45, 35,  6, 41,  9, 25,  4, 10, 36,  3, 48, 19, 37,\n","        23, 25, 14, 27, 29, 47,  2, 12,  0,  5, 27, 35, 41,  6, 34, 24, 27, 49,\n","        28, 45, 13, 12, 47, 43, 11, 16,  1, 47, 43, 39, 21, 39, 49, 28, 32, 18,\n","         2, 17], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.2383, -0.5957,  2.7820,  ..., -0.6618, -2.0448,  1.5056],\n","        [-2.4836, -1.5658, -1.2660,  ..., -3.1408, -1.4428,  0.1175],\n","        [ 0.8196, -0.2931,  1.3488,  ..., -1.2361,  2.0505, -2.1594],\n","        ...,\n","        [-2.4375,  0.0464,  0.5628,  ..., -3.7513, -2.5995,  3.1024],\n","        [ 2.3401,  1.1031,  0.0698,  ..., 15.4007, -0.9901, -1.8217],\n","        [-1.9660, -0.2151, -0.8730,  ...,  0.9353, -0.8477, -1.6692]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([21, 28, 17, 34,  0, 24, 11, 43, 38, 20, 34, 49, 11,  2, 12, 40, 16, 44,\n","        35,  5, 15, 30,  4,  0,  2, 23, 48, 36, 14, 42,  3, 17, 17,  3,  3, 13,\n","        25, 36, 18, 30,  1,  3,  3, 23, 17, 29, 28, 20, 27, 40, 26,  4, 26,  6,\n","        22, 33, 19, 27, 46,  3,  7, 14, 25, 17, 30, 37, 16, 36, 30, 46, 40, 19,\n","        24, 19, 44, 44, 32, 41, 36, 22, 31, 47, 33, 46, 12, 22, 38,  6, 20,  7,\n","        49, 29, 48,  2, 24, 16, 23, 25, 24, 44, 19, 31, 34, 43, 28, 14, 41, 17,\n","        18, 40, 46, 40,  1, 33, 22, 17, 22, 20, 30, 15, 14, 34, 10,  2,  5,  4,\n","        47, 21], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.1424,  1.1249,  1.5857,  ..., -2.4122, -0.1869,  0.1395],\n","        [ 4.2998, -0.3273,  2.1520,  ...,  2.4087, -0.7602, -0.5487],\n","        [ 0.2655, -1.4798,  1.8967,  ...,  0.6674,  1.0022, -0.4324],\n","        ...,\n","        [-0.4703, -2.4772,  1.7829,  ..., -2.5900, -0.7109, -2.8535],\n","        [ 1.7187, -2.0544,  1.3559,  ...,  4.3907, -0.1491, -1.1639],\n","        [ 0.5911, -0.8208,  1.2344,  ...,  2.0550,  2.1229,  0.1571]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([46,  3, 26, 41, 21,  4, 35, 27, 11, 41, 35,  8, 45, 34, 39, 42, 24, 31,\n","        29, 29, 22, 30, 24, 20, 20, 10,  0, 45, 29, 37,  1,  2, 49,  8,  9, 37,\n","        16, 19,  8, 43, 31, 26, 31, 21, 23, 45,  7,  9, 30, 27,  3, 25, 24, 16,\n","        41,  0, 26,  6, 25,  7, 36, 27,  1, 36, 44,  9, 24, 16,  8, 31, 14, 48,\n","        45, 20, 27, 13, 13, 13, 14, 23, 13, 31, 47, 26, 13, 49, 47, 41, 32, 12,\n","         4, 36,  1, 42,  2,  8, 26, 42,  4, 31,  7, 48,  8, 16,  9, 36, 15, 18,\n","        26, 31, 10, 21, 22, 18,  2,  1, 11, 29,  4, 18,  9,  7, 42, 30, 35, 12,\n","        25,  5], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.1722e+00,  1.0050e+00, -1.1022e+00, -1.3565e+00,  1.2959e+00,\n","          3.8433e-01, -3.4008e-01, -2.3373e+00,  2.9028e+00, -1.6354e+00,\n","         -4.1246e+00,  1.6846e+00, -9.0455e-01,  4.3835e-01, -9.2181e-01,\n","          4.0410e+00,  1.1418e+00, -3.4219e+00, -2.4454e+00, -2.7174e+00,\n","          6.7287e-01,  2.1997e-01, -2.4950e+00,  3.0329e+00, -1.3216e+00,\n","         -2.9156e+00, -1.0827e+00, -7.3069e-01, -7.6751e-01,  5.7150e+00,\n","         -1.4653e+00, -1.7987e+00,  5.6468e-02, -5.5637e-01,  2.2308e+00,\n","          3.0859e-01,  1.4899e+00,  1.2765e+00,  1.6446e+00, -2.1767e+00,\n","         -9.7592e-01,  2.7141e+00, -3.2203e+00,  2.4198e+00,  8.9393e-02,\n","         -1.4537e+00, -6.5754e-01, -2.2141e+00, -2.9472e+00,  1.3328e+01],\n","        [-2.9689e+00, -1.0678e+00,  1.7961e+00, -3.2633e-01, -4.1324e-01,\n","          1.2276e+01, -1.9997e+00, -1.3071e+00, -3.6970e+00,  8.0112e-01,\n","         -8.0653e-01,  8.3689e-01, -1.0580e+00, -3.1073e+00, -1.8107e+00,\n","          1.6108e+00,  7.0509e-01, -7.8166e-01,  9.8192e-02, -2.1265e+00,\n","          8.4330e-01,  1.1010e-01, -4.3806e+00, -2.2962e+00, -1.2274e+00,\n","         -2.5310e+00,  4.1122e+00,  2.6814e+00, -3.3059e-01,  3.1873e+00,\n","         -1.1812e+00,  2.1216e+00, -4.5939e-01,  9.1781e-01,  3.0155e+00,\n","         -1.7777e+00, -1.8825e+00, -1.0127e-01,  4.3455e-01, -2.0276e+00,\n","          2.1900e+00,  1.0941e+00, -2.7458e+00, -5.6252e-01,  1.0023e+00,\n","         -1.8951e+00, -4.5321e-01,  5.7344e-01,  1.8250e+00,  1.3870e+00],\n","        [ 2.5021e+00, -1.1609e+00, -3.5630e-01, -1.5445e+00,  2.9924e-01,\n","         -5.4039e-01, -1.4085e+00, -9.3486e-01,  1.9514e+00,  8.2346e-01,\n","          1.2841e+00, -1.6434e-01,  2.3348e+00, -2.4790e+00, -1.6594e+00,\n","         -1.7095e+00, -1.1603e+00,  2.9279e-02, -2.5057e+00, -1.0015e+00,\n","          5.8080e-01, -1.2995e-01,  1.1978e-01, -7.0579e-01, -1.7296e+00,\n","         -1.9167e+00, -7.6782e-01, -5.5802e-01,  8.7046e-01, -4.3010e-01,\n","          4.1594e-01, -9.1838e-01, -1.4756e+00, -2.2639e+00, -8.0467e-01,\n","         -8.9031e-01,  1.7352e+00,  3.2490e+00,  6.2417e-01, -1.4402e+00,\n","          1.4752e+00,  3.4011e-01,  1.1210e+01,  9.0726e-01,  1.7711e+00,\n","         -2.0112e+00,  1.3327e+00, -9.2978e-01,  3.5816e+00, -3.3585e-01],\n","        [ 1.4077e+01, -1.9106e+00, -1.7598e+00,  2.9580e+00, -4.3229e+00,\n","         -1.3460e+00, -2.9690e-01, -2.9776e+00,  1.0748e+00, -1.9136e+00,\n","         -2.7919e+00, -2.2806e+00, -4.6252e-01, -3.2439e-01, -7.4907e-02,\n","         -2.5311e+00,  3.4154e+00, -8.0315e-01, -2.3816e+00,  5.9806e-01,\n","          1.4915e+00, -2.6765e+00,  4.0412e+00,  7.0761e-01,  2.4891e+00,\n","          3.9216e+00,  8.3444e-01, -5.8011e-01, -2.8125e+00, -5.4105e-01,\n","          1.4623e+00, -2.8344e+00, -5.2839e-01, -2.9804e+00, -2.1741e+00,\n","          1.0577e+00, -2.4340e-01, -9.8503e-01,  4.0274e+00,  1.7783e+00,\n","         -1.3635e-01,  1.0154e-01, -3.0316e+00,  1.2962e+00, -1.8303e+00,\n","         -1.9266e+00, -9.4539e-01,  3.3864e+00,  2.5937e+00, -1.3669e+00],\n","        [ 3.1531e-01, -1.2662e+00,  3.3404e+00, -5.1695e-01, -1.3996e+00,\n","         -1.8212e-01,  1.2905e+01, -1.6535e+00,  4.4518e-01, -3.5531e+00,\n","         -1.4271e+00, -1.6434e-02, -1.1100e+00,  7.2983e-01, -1.1441e+00,\n","         -6.7786e-01, -3.1078e-01,  1.4826e+00, -2.2038e+00,  1.5731e+00,\n","          9.4874e-01, -1.4165e+00, -1.5316e+00, -1.1836e+00,  9.2976e-01,\n","         -1.5299e+00,  5.8576e-01, -7.2079e-01, -1.7334e+00, -1.2106e+00,\n","          1.5967e+00, -1.9154e+00, -1.6222e+00,  4.0757e+00, -4.7665e-01,\n","          4.5103e+00,  1.5197e+00, -2.9461e+00,  1.4355e-01,  1.5938e+00,\n","         -2.6391e+00, -5.2880e-01, -1.6753e+00,  2.2811e+00, -3.9606e-01,\n","         -1.8654e+00, -7.2315e-01,  3.2602e-01,  7.2499e-01, -6.3895e-01],\n","        [-1.1128e+00, -3.6949e+00,  3.6098e+00, -2.4755e+00,  6.3712e-01,\n","         -2.9190e-01, -1.2322e+00,  8.3104e-02, -2.2758e+00, -2.5352e-01,\n","         -1.1088e+00,  1.2336e+01, -8.8092e-01, -2.7198e+00, -2.7739e+00,\n","         -2.2420e+00,  2.4819e+00, -3.9219e-01, -1.9074e-01,  2.0062e+00,\n","         -1.6908e+00,  1.5745e+00, -1.4737e+00, -4.0177e+00,  1.7866e+00,\n","          3.8239e+00, -1.0135e+00,  1.3187e+00, -9.4086e-02,  1.6556e+00,\n","          5.3461e-01, -1.1400e-01,  1.2235e+00, -2.3986e+00, -2.9731e+00,\n","         -1.0743e-02, -1.3508e+00, -3.7520e+00,  5.3456e+00,  3.5235e+00,\n","         -1.3665e+00,  1.2354e+00, -1.5378e+00, -3.0020e+00, -7.4429e-01,\n","          1.0886e+00, -1.5138e+00,  2.9318e+00, -1.3473e+00,  1.5695e-01],\n","        [-2.4130e+00, -1.6394e+00,  9.4514e-01, -1.1795e+00,  6.2347e-01,\n","         -9.4696e-01, -1.8912e+00,  6.5862e-01, -2.0031e-01,  9.6097e-01,\n","         -1.0498e+00, -4.1245e-02,  2.2938e-01,  1.6387e+00,  1.4834e+00,\n","         -4.3211e-01,  1.1680e+00,  7.6815e-01,  1.7091e+00, -2.0232e+00,\n","         -4.0450e-01,  8.2736e-01, -1.4066e+00, -3.4881e-01, -1.0447e+00,\n","          1.6344e+00, -1.0621e+00,  1.1315e+00,  5.1626e-01, -4.2631e-02,\n","         -2.4970e+00,  2.1552e+00,  1.0505e+01,  1.3054e+00, -1.0859e+00,\n","         -1.4205e-02, -2.8666e+00,  1.1892e-02, -7.1607e-02, -7.7193e-01,\n","          5.1837e-01, -7.9574e-01, -1.5623e+00, -2.8174e-01,  1.2925e+00,\n","         -5.7872e-01,  8.9605e-02, -2.8651e+00, -1.0750e+00, -1.1644e+00],\n","        [-5.1923e-01, -1.0427e+00,  1.3063e+00, -7.1893e-01, -5.6647e-01,\n","         -1.1182e-02, -2.7390e-01, -9.3090e-01, -7.3676e-01,  4.0174e-01,\n","          1.2662e+01, -4.4709e-01, -5.8332e-02, -2.2920e+00, -1.5280e+00,\n","         -2.0289e+00, -1.4886e+00,  6.4352e+00, -8.9849e-01, -1.1007e+00,\n","         -1.7875e+00, -9.3122e-01, -2.8774e-01, -1.4239e+00, -1.5625e+00,\n","         -1.5693e+00, -9.3069e-02, -5.1987e-01,  1.6427e-01, -1.5870e+00,\n","          1.5868e+00, -1.3671e+00, -4.8069e-01,  1.4136e+00, -1.7001e+00,\n","          3.6011e-01, -1.2287e+00, -1.3605e+00,  8.2999e-02, -8.1373e-01,\n","          2.6602e-01, -8.0431e-01,  4.6951e+00,  1.0157e+00,  2.3095e+00,\n","         -4.7533e-01,  3.1589e+00, -2.2584e+00,  3.6054e+00, -2.3391e+00],\n","        [ 3.1324e+00,  1.3094e+01, -1.1975e+00,  3.0632e+00,  8.1772e-01,\n","         -7.9936e-01, -8.3766e-01, -1.2846e+00,  3.2240e+00, -7.9522e-01,\n","         -1.3034e+00, -2.4232e+00, -1.6146e+00,  3.9521e-01, -3.1373e+00,\n","         -1.3688e-02, -2.1226e+00, -7.2430e-01, -1.8730e+00, -6.0903e-01,\n","          5.2374e-01, -1.7175e+00, -5.4392e-01,  2.2648e+00,  1.4612e+00,\n","         -3.6863e+00, -2.2953e+00, -4.6434e+00, -1.6258e+00,  5.3268e-01,\n","         -1.9215e+00,  1.9027e+00,  2.5237e-01, -1.2815e-01,  4.0414e+00,\n","         -3.7091e+00,  2.4777e+00,  2.6499e+00, -1.4230e-01, -3.0732e+00,\n","          1.1642e+00, -4.9816e-01,  1.3285e+00,  3.2571e+00, -4.2945e-02,\n","         -1.2272e+00,  2.7816e+00, -2.3326e+00, -1.7858e+00,  2.6460e-01],\n","        [ 4.4332e-01, -1.4870e-01,  1.7420e+00,  4.0651e+00, -1.9067e+00,\n","          1.3441e-01,  2.2020e+00, -2.2510e+00,  2.9611e-01,  3.6998e-01,\n","         -2.9036e+00, -1.0597e+00, -2.0267e+00,  1.5002e+00, -2.1977e+00,\n","         -8.7498e-01,  1.9750e+00,  6.4748e-01,  2.0362e+00,  1.0879e+01,\n","         -2.1421e+00, -1.3765e+00, -7.4828e-01, -1.6549e+00,  2.9988e+00,\n","          1.2871e+00,  5.5495e-01, -6.2654e-01, -1.5555e+00,  2.4418e+00,\n","          1.3817e+00, -8.7412e-02, -7.6610e-01,  1.5371e+00, -6.3449e-01,\n","         -9.8199e-01, -1.8309e+00, -7.6898e-01,  8.8595e-01,  4.0871e-01,\n","         -2.1224e+00, -1.7636e+00, -3.0188e+00, -6.0340e-01,  5.2479e-01,\n","         -1.5581e+00,  4.8477e-01, -4.1483e-01, -1.3495e+00, -2.3837e+00],\n","        [-8.0307e-01,  5.7201e-01,  5.0887e-01, -1.3172e+00,  2.3585e-01,\n","         -1.0543e+00, -6.7142e-01, -2.5421e+00,  4.3166e-01,  9.9029e-01,\n","         -2.5513e+00,  8.8652e-01, -5.6186e-01,  2.8090e+00, -8.3938e-01,\n","         -2.7055e-01, -1.7924e+00, -1.5760e+00,  2.8504e+00, -1.8851e+00,\n","          1.0780e+01,  1.8909e+00, -1.0740e+00,  1.3640e+00,  2.0765e+00,\n","         -2.2696e-01, -2.9163e+00, -1.3872e+00, -1.9373e+00,  1.0521e+00,\n","          5.5279e-01, -6.9477e-01,  4.9573e-01, -2.5663e+00,  1.0219e+00,\n","          2.2367e-01,  2.2018e+00, -1.4787e+00,  1.0035e+00, -1.2772e+00,\n","          2.4236e-01,  8.9982e-01, -1.1874e+00,  2.8501e+00, -8.0668e-01,\n","         -1.7681e+00, -1.7089e+00, -3.8108e-02, -1.9847e+00,  2.9090e+00],\n","        [-8.5121e-01, -3.3999e+00, -1.4538e+00, -2.0635e+00, -1.5697e+00,\n","          6.0352e-01, -1.4537e+00,  3.7088e-01, -1.6005e+00,  6.8235e-01,\n","         -7.2289e-01, -1.3473e+00,  2.7565e+00,  5.5782e-01,  8.6993e+00,\n","         -7.4721e-02, -2.0977e+00,  6.2092e-01,  1.6702e-02, -2.1733e+00,\n","          7.7533e-01,  4.1891e-01,  4.1267e+00, -1.2499e+00, -1.6835e-02,\n","          1.0931e+00,  6.0524e-01,  3.3543e-01,  5.8716e-01,  5.8037e-01,\n","         -1.1273e+00,  1.8139e+00,  4.5367e+00, -1.6901e+00, -2.5144e+00,\n","          1.4009e+00, -2.5236e-01, -1.2359e+00, -3.9817e-02, -1.4978e-01,\n","          2.5496e-01,  1.2963e+00, -2.1821e+00,  8.9300e-01,  3.8527e+00,\n","         -1.3650e+00, -1.9332e+00, -5.7427e-01, -1.1006e+00, -1.3879e+00],\n","        [ 6.6723e-01,  1.1874e+00,  4.5508e-02,  4.0556e+00, -1.1024e+00,\n","         -1.5770e+00, -1.3140e-01, -1.9327e+00, -2.5742e+00,  1.4140e+00,\n","         -2.5050e+00,  2.6166e+00, -1.8451e+00, -1.7699e+00, -2.2114e+00,\n","         -8.2099e-01, -1.9230e+00, -1.0692e+00,  1.0782e+00,  3.1787e+00,\n","         -9.1107e-02, -2.5395e-01, -1.4049e+00, -1.5689e+00,  4.8486e+00,\n","          3.7876e+00, -2.5237e+00, -1.1931e+00, -1.5259e+00,  3.1037e+00,\n","          2.5439e+00, -1.7552e+00,  2.9908e-01, -2.3443e+00, -1.0077e+00,\n","          7.1915e-01, -6.0844e-01, -2.3424e+00,  2.2552e+00,  1.1649e+00,\n","         -7.8744e-01, -2.3623e-01, -2.8313e+00, -1.3556e+00, -1.8487e+00,\n","         -2.1835e+00,  4.8940e-01,  1.1361e+01, -5.9660e-01, -1.6122e+00],\n","        [ 1.9903e+00, -2.0013e+00,  3.1752e+00,  2.4426e+00, -2.5798e+00,\n","         -3.6063e-01, -2.2032e+00, -1.4873e+00, -1.2691e+00, -1.0236e+00,\n","         -2.3823e+00,  4.6982e-01, -7.9305e-01, -1.8739e+00, -1.1370e+00,\n","         -2.8238e+00,  1.0621e+01,  1.1434e+00,  2.0322e+00,  1.5006e+00,\n","         -2.4069e+00,  3.3284e-01,  2.2390e-01, -1.4549e+00,  6.5587e-01,\n","          2.1122e+00,  3.6106e+00,  1.2346e+00, -9.4693e-01, -9.1639e-01,\n","          4.4401e+00, -5.7496e-01,  1.2711e+00,  8.1046e-02, -2.9129e+00,\n","          3.3401e-01, -1.9960e+00, -7.8489e-01,  2.9240e+00,  1.0810e+00,\n","         -5.2678e-02, -1.2839e+00, -3.0331e+00, -1.2482e+00, -1.2681e+00,\n","          7.8264e-02,  1.0021e+00, -2.0727e+00, -8.9888e-01, -1.3334e+00],\n","        [-2.0805e+00,  8.8657e-01, -6.4774e-01, -4.9823e-01,  3.1926e+00,\n","         -6.5299e-01, -2.8458e+00, -2.1173e+00,  2.0674e+00,  7.2139e-01,\n","         -2.0477e+00, -2.7543e+00,  2.8405e+00, -7.8566e-01, -2.6391e-01,\n","          8.2055e-01, -7.9363e-01, -3.8820e+00,  5.8462e-01, -1.4197e+00,\n","          4.6772e-01,  1.0335e+00, -1.0476e+00,  2.7039e+00, -4.8497e-01,\n","         -3.2015e+00, -1.4467e+00, -1.2539e+00,  1.8820e+00,  4.6537e-01,\n","          1.0432e+00,  3.0574e+00,  1.5345e-01, -1.6569e+00,  2.1106e+00,\n","         -2.2942e+00,  6.6579e-01,  1.0249e+01, -1.0257e+00, -1.5731e+00,\n","          4.2887e+00,  3.5772e+00, -1.6610e+00, -3.9807e-01, -7.1137e-01,\n","         -7.7860e-01, -1.3806e-01, -3.8477e+00, -1.9288e+00,  1.8729e+00],\n","        [-1.4823e+00, -2.3053e+00,  2.9023e+00, -2.0856e+00, -6.4481e-01,\n","          1.4281e+00, -1.3601e+00, -1.1498e+00, -1.8416e+00,  2.3449e+00,\n","          8.3452e+00,  1.0288e+00,  3.4283e+00, -2.1013e+00,  4.3479e-01,\n","          1.2556e-01, -1.1640e+00,  3.0067e-01, -2.0758e+00, -2.4417e+00,\n","          4.6319e-01,  1.0413e+00,  3.9090e-01, -2.1157e+00, -5.2333e-01,\n","         -6.0868e-01, -5.1178e-01, -1.2617e-01,  2.3355e+00, -4.4506e-01,\n","         -1.6277e+00,  2.7441e+00,  1.4453e+00, -5.5225e-01, -1.5681e+00,\n","          1.8874e+00, -7.7594e-01,  6.2399e-01, -1.3354e+00, -1.0194e+00,\n","          6.4219e-02,  1.2080e+00,  2.5086e-01,  3.6230e-02,  1.0924e+00,\n","         -9.9157e-01,  2.3907e-01, -1.0609e+00, -6.1252e-01, -1.4542e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([49,  5, 42,  0,  6, 11, 32, 10,  1, 19, 20, 14, 47, 16, 37, 10],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7526, 10.8646, -0.5550,  ..., -1.7123, -2.3077,  2.6299],\n","        [-0.0313,  4.8926, -0.3701,  ..., -0.7528, -0.7100,  3.3161],\n","        [ 5.9533, -3.5493,  1.5942,  ...,  6.1704,  1.1385, -1.5339],\n","        ...,\n","        [ 2.1133, -0.2057, -0.9491,  ..., -2.1029,  0.5076, -0.5965],\n","        [ 1.8116, 16.3091,  1.0355,  ..., -1.5838, -3.4035,  1.6769],\n","        [ 1.0787, -4.2720,  3.9366,  ..., -0.5230,  2.2227, -0.5894]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 382/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-8.1851e-01,  7.3421e-01, -2.4486e+00,  ...,  2.5308e-01,\n","         -2.1332e+00,  3.5271e+00],\n","        [-8.1181e-02,  3.6239e+00, -8.6352e-01,  ..., -4.3956e-01,\n","         -3.0451e-01, -1.0643e-01],\n","        [-2.3267e+00,  4.3039e-03,  2.4171e-01,  ..., -1.1052e-01,\n","         -2.1071e-01, -7.1570e-01],\n","        ...,\n","        [ 1.7290e+00,  9.2869e-01, -3.2167e-01,  ..., -7.5735e-02,\n","         -9.6822e-01,  1.0036e+00],\n","        [ 1.4897e+01, -2.2754e+00, -1.3254e+00,  ...,  4.4317e+00,\n","          3.9797e+00, -8.4483e-01],\n","        [-4.7162e-03,  5.2132e+00, -1.6465e+00,  ...,  8.7918e-01,\n","         -1.5968e+00,  1.2695e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([15,  7, 21, 45, 30,  2, 42,  0, 19,  2, 37, 11,  5, 22, 18, 30, 10, 36,\n","         3, 36, 27, 40, 17, 47, 27, 30,  2, 36, 14, 48, 42, 47, 26, 20, 22,  2,\n","        30,  9, 27, 41, 13, 14,  8, 14, 12, 26, 20, 41,  9, 24, 37, 20, 38, 28,\n","        23, 36, 44, 21, 15, 42, 40, 22,  8,  5, 35, 16, 18, 32, 30, 28, 24,  6,\n","        43, 44, 21, 15, 27, 37, 33, 17,  6, 28, 45, 24, 34, 28, 12, 30, 30, 30,\n","        49, 23, 33, 16, 22, 19, 45, 45, 33, 31, 44, 33,  0,  7,  3, 46,  1, 49,\n","        17, 45, 43, 11, 35, 39,  3,  5, 49, 13,  1, 33,  0,  3, 36, 17, 41, 36,\n","         0, 34], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.5091, -2.7753, -0.3077,  ...,  0.4798, -1.3798, -1.0480],\n","        [ 2.3591, 13.0159, -1.0175,  ..., -0.4401, -3.5321,  1.7215],\n","        [ 3.9132, -3.7521,  2.0351,  ...,  2.3760, -0.6321, -2.6684],\n","        ...,\n","        [-2.0907,  0.9155,  0.4343,  ..., -3.8821, -3.0644,  3.1203],\n","        [ 0.4568, -1.4435,  0.5253,  ...,  3.6994, -0.8899, -1.4495],\n","        [ 3.9777, -3.2404,  1.1606,  ...,  0.3180, 12.7185, -1.0997]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([14,  1, 25, 26, 17, 46, 48, 10, 17, 22, 29, 44,  7,  8, 35, 31, 48, 46,\n","        21,  5, 47, 14,  9, 31, 16, 27, 43, 38, 12, 37,  8,  6,  8, 26,  7, 34,\n","        13, 15, 43, 23, 16,  2, 48,  9, 34, 35,  2, 20, 35, 18, 27, 31, 35,  0,\n","        32, 35, 13, 34, 46, 47, 36,  7, 29,  6, 27, 46, 43, 28,  1,  5,  6, 48,\n","         3, 26, 37, 38, 20, 31, 16, 24,  3, 44, 14, 38,  1, 11,  8, 40, 33, 20,\n","         4, 10, 25, 14, 12, 29, 16, 42,  1, 23, 16,  4, 29, 17, 27, 42, 11,  9,\n","        19, 41, 10,  6,  4, 10, 48, 29,  5, 15,  3, 42, 31, 19, 20, 49, 26,  4,\n","        25, 48], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 6.0040,  2.4749,  3.7073,  ...,  1.3608, -0.8967,  0.6095],\n","        [-2.1089,  0.6591,  0.3672,  ..., -2.8884, -2.1622,  2.7890],\n","        [-1.1612,  0.7496,  2.5884,  ..., -0.9652,  0.7946,  0.4428],\n","        ...,\n","        [ 0.8981, -0.1078,  0.3458,  ..., -1.4105,  3.7400, -1.2586],\n","        [-0.6251,  1.2250,  2.9917,  ..., -2.6004, -2.2626,  6.6469],\n","        [ 1.6334, 14.6553,  0.6038,  ..., -0.8849, -2.9930, -1.6780]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([24,  4, 40,  9, 15, 22, 32,  3, 38, 38, 13, 42,  2,  8, 19, 28,  5, 12,\n","        14, 44, 20, 11, 10, 25, 37, 41, 24, 24, 17,  1, 47, 24, 35, 41, 46, 45,\n","        21, 46, 22, 49, 25, 12,  9,  3, 34, 39, 32,  9, 31, 17, 43, 26, 33, 40,\n","        29, 39, 37, 31, 11, 14, 41, 15, 25, 41,  9,  0, 25, 47, 18, 23,  2, 12,\n","        20, 19, 13, 30, 15, 40,  4, 27,  8, 17, 28,  7,  7, 18, 49, 29, 11, 11,\n","        30, 45, 21, 49, 40, 41, 19, 32, 27, 32, 31,  6, 28, 40, 10, 29, 13, 39,\n","        23, 16,  4, 32, 18,  1, 16, 10, 19, 24, 39, 47, 36,  4,  2, 18, 13, 10,\n","        29,  1], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.7038e-01, -1.8630e+00,  6.1004e+00,  1.1719e+00, -2.0156e+00,\n","          2.8513e-01, -1.6293e+00, -2.5420e+00, -1.1201e+00, -1.1310e-01,\n","          7.9721e-01,  1.6912e+00, -2.2274e+00, -2.0153e+00, -1.2666e+00,\n","         -2.1736e+00,  1.0381e+01,  1.3498e+00,  9.7838e-01,  2.5544e+00,\n","         -2.2518e+00,  3.2248e-03, -2.7786e+00, -3.7167e+00,  4.6220e-01,\n","          3.7080e-01,  2.3085e+00,  1.4215e+00, -8.6869e-01, -3.9958e-01,\n","          4.6680e+00, -1.0721e-01,  4.1794e-01,  4.5949e-01, -2.6213e+00,\n","          4.7322e-01, -2.5244e+00,  3.0628e-01,  2.4619e+00, -5.8796e-01,\n","         -8.2278e-02, -1.1769e+00, -2.0869e+00, -4.3665e-01, -5.3713e-01,\n","         -1.6214e+00,  3.3054e+00, -2.7309e+00,  6.8582e-02, -8.6079e-01],\n","        [-1.6010e+00, -2.6440e+00,  1.6742e+00, -1.2139e+00, -1.2076e+00,\n","          7.9352e-01, -7.0950e-01, -7.5567e-01, -6.5587e-01,  9.8956e-01,\n","          2.1202e+00,  6.8219e-01,  9.8452e+00, -2.1328e+00,  2.1135e+00,\n","          3.5795e-01, -1.9401e+00,  1.0918e+00, -2.7132e-01, -1.4577e+00,\n","         -3.9714e-01,  1.0580e+00,  1.6270e+00, -2.9947e+00, -2.6909e-01,\n","         -7.8517e-01, -4.4051e-02,  1.2143e+00,  3.3832e+00, -8.8299e-01,\n","          4.0740e-01,  1.0279e+00,  2.1091e+00, -1.8492e+00, -2.4069e+00,\n","          2.7537e+00, -7.6697e-01, -1.0465e+00, -4.8073e-01, -1.5003e+00,\n","          2.3131e+00,  4.4342e-01, -4.4496e-02, -1.1677e+00,  1.0152e+00,\n","         -6.0390e-01,  2.6727e-01, -2.6140e+00, -7.6102e-01, -2.4063e+00],\n","        [ 1.0625e+01,  6.0489e-01,  6.8816e-01, -6.9891e-01, -2.1471e+00,\n","          1.9955e+00,  1.7968e+00, -3.8592e+00,  1.4391e-01, -3.2096e+00,\n","          1.3668e+00,  2.0582e-01, -2.6394e+00, -2.6056e+00, -2.9467e+00,\n","         -8.3368e-01,  2.2659e+00,  1.4788e+00, -3.5693e+00, -6.9993e-01,\n","          4.0571e+00, -1.8399e+00, -2.2411e+00, -1.0972e+00,  9.8413e-01,\n","         -1.4785e+00, -9.5496e-01, -3.6229e-01, -2.3674e+00, -1.7857e-01,\n","          2.0122e+00, -2.4463e+00, -1.9713e+00, -1.4313e+00,  3.5849e-01,\n","         -3.2615e-01,  3.7564e+00,  1.4921e+00,  1.0955e+00, -1.1179e+00,\n","         -6.5636e-01, -2.5511e+00,  2.7862e+00,  5.5226e+00,  5.5494e-01,\n","         -3.1465e+00,  2.2492e+00,  8.4841e-01,  3.7228e+00, -3.1922e-01],\n","        [-8.6527e-02, -2.1527e+00,  1.4698e+00,  3.3675e-01, -3.0850e+00,\n","          3.0166e+00,  2.3401e+00, -1.3727e+00, -2.1918e-01, -6.5519e-01,\n","          1.7856e+00, -8.3013e-01, -2.8722e+00, -1.0126e+00, -7.7849e-01,\n","         -2.7321e+00,  1.9276e-02,  3.2377e+00,  9.0997e-01, -5.0492e-01,\n","         -1.3817e+00, -8.9438e-01, -3.1873e+00, -6.6188e-02, -1.5214e+00,\n","         -1.5156e+00,  1.0710e+01, -2.4880e-01, -3.4331e+00,  1.5863e+00,\n","          8.5215e-01, -9.6934e-01, -5.0792e-01,  6.4211e+00, -4.3531e-01,\n","          1.0047e+00, -2.5110e+00, -8.7848e-01, -5.3138e-02, -1.3256e+00,\n","         -2.3412e+00, -2.1669e+00,  1.0842e+00,  4.8712e-01,  4.4676e+00,\n","         -3.0383e+00, -3.6114e-01, -5.8820e-01,  4.1478e+00, -8.0160e-01],\n","        [-5.8049e-01,  1.9411e+00, -5.3044e-01, -4.2911e-01,  1.4930e+00,\n","         -6.8532e-01,  8.3203e-02, -3.0819e+00,  5.6146e+00, -2.4137e+00,\n","         -1.2187e+00, -2.0013e+00, -1.5115e+00,  3.7574e+00,  7.0391e-01,\n","          7.9705e-01, -3.1741e-01, -2.5004e+00,  1.0303e+00, -1.5147e+00,\n","          2.7817e+00, -8.2703e-01, -9.4231e-01,  1.2019e+01, -9.1835e-01,\n","         -1.7760e+00, -1.8650e+00, -1.9697e+00, -1.8209e+00,  5.2483e-01,\n","         -9.1791e-01,  1.2565e+00, -1.2818e-02, -7.1520e-01,  1.4173e+00,\n","         -1.9028e+00,  1.2993e+00,  3.0940e+00, -1.6604e-01, -1.9146e+00,\n","         -1.6087e-01,  2.7319e-01, -1.7878e+00,  2.5822e+00, -1.2876e-01,\n","         -1.7222e+00, -2.4795e+00, -2.4379e+00, -1.0794e+00,  3.6158e+00],\n","        [ 1.1497e+01, -5.1779e-01, -3.8130e-01,  4.0147e+00, -3.2302e+00,\n","         -9.2376e-01,  5.9547e-01, -2.8116e+00,  4.0840e-01, -1.2939e+00,\n","         -8.6846e-01, -4.9824e-02, -1.2209e+00, -5.5470e-01, -5.3358e-01,\n","         -2.5141e+00,  2.8202e+00, -4.9311e-02, -1.9888e+00,  1.0556e+00,\n","          2.9246e-01, -1.1091e+00,  2.1748e+00, -1.6339e+00,  2.1723e+00,\n","          1.7289e+00,  5.7177e-01, -1.3857e+00, -1.6435e+00, -8.6827e-01,\n","          1.1955e-01, -2.4452e+00, -1.4430e+00, -6.3427e-01, -1.4060e+00,\n","          1.3801e+00, -1.0444e+00, -1.7412e+00,  5.3134e+00,  2.6913e+00,\n","         -6.7750e-01, -1.7034e+00, -1.1654e-01,  4.3653e-01, -1.2925e+00,\n","         -2.5857e+00,  2.7152e-01,  2.0408e+00,  9.9777e-02, -2.6280e+00],\n","        [-3.7145e+00, -1.5888e+00,  1.8096e+00, -5.6398e-01, -3.4747e-01,\n","          3.6984e+00, -2.1150e+00, -2.0257e+00, -2.9033e+00,  1.5095e+01,\n","          1.5658e+00,  5.6737e-01,  4.7093e-01, -2.6901e+00, -2.3462e+00,\n","         -1.0381e+00, -1.2161e+00, -9.9959e-01,  4.6511e+00, -7.8733e-01,\n","          7.4553e-01,  1.4431e+00, -1.5246e+00, -2.0363e+00,  2.6926e+00,\n","         -5.3022e-01, -6.7819e-01,  9.5308e-01,  1.2029e-01,  2.0292e+00,\n","         -1.4694e+00,  4.2928e+00,  3.4603e-01, -1.2601e+00, -8.6513e-01,\n","         -2.9733e+00, -1.9375e+00, -1.0159e+00,  5.8168e-01, -3.7797e+00,\n","         -1.9303e-02,  4.8091e+00, -1.7743e+00, -2.4833e+00,  2.6180e+00,\n","         -2.1726e-03,  4.5956e-01, -1.1570e+00, -2.2024e+00, -1.6104e+00],\n","        [-4.2630e-01, -1.5479e+00,  8.3169e-01,  3.7402e+00, -2.0237e+00,\n","          1.2012e+00,  3.6787e+00, -2.6831e+00, -2.0363e+00, -1.2090e+00,\n","         -9.1433e-01,  3.8251e+00, -3.0039e+00, -1.3985e+00, -2.0462e+00,\n","         -7.6563e-01, -5.8295e-01,  9.6154e-01,  1.3964e-01,  2.4134e+00,\n","          7.2811e-01, -7.8156e-01, -1.9234e+00, -2.8465e+00,  4.9712e-01,\n","          3.1590e+00, -1.0152e+00, -1.1231e-01, -3.4888e+00,  7.5444e-01,\n","          2.1975e+00, -1.7142e+00, -5.6074e-01, -3.9290e-01, -2.3244e+00,\n","          2.0462e+00, -1.3268e+00, -3.5538e+00,  3.2793e+00,  3.5286e+00,\n","         -2.6420e+00,  2.1441e-01, -1.1953e+00, -5.1153e-02, -1.1995e+00,\n","         -2.7278e+00, -1.8877e+00,  1.3967e+01,  6.1204e-01, -1.8069e+00],\n","        [-6.9355e-01, -8.0445e-01, -9.2022e-01, -1.6430e+00,  1.5507e+00,\n","         -8.8140e-01, -1.1566e+00, -5.0126e-02, -3.9213e-01, -1.2036e-01,\n","         -1.4439e+00,  1.5929e+00, -1.7560e+00,  7.0534e-01, -6.1312e-01,\n","         -2.1171e+00, -2.2755e-01,  9.7841e-01, -2.6434e-01,  3.2054e-01,\n","          1.7564e+00,  1.7308e+00,  2.3288e+00, -1.7666e+00,  1.2109e+00,\n","          5.5063e-01, -1.0213e+00, -2.4907e+00,  4.5779e-02,  2.3473e-01,\n","         -1.5017e+00,  2.5779e+00,  9.7242e+00, -1.0559e+00, -5.0012e-01,\n","         -1.7216e+00, -7.5430e-01, -6.9135e-01,  5.7826e-01,  1.3991e+00,\n","          2.3760e+00, -2.0460e-01, -1.7768e+00,  8.3112e-01,  4.9637e-01,\n","          9.7152e-01, -2.5781e-01, -1.3670e+00, -1.5497e+00, -1.1789e+00],\n","        [-2.3709e+00,  3.1083e-01, -1.7693e-01, -1.5096e+00, -1.5108e+00,\n","         -4.1674e-02, -1.0266e+00,  1.1484e+01, -1.4861e+00,  2.0485e-01,\n","         -1.0711e+00,  2.1060e+00, -3.4203e-01, -1.5957e+00,  1.0157e-01,\n","         -1.0094e+00, -1.4174e+00,  2.8920e-01,  3.3419e+00, -1.0043e+00,\n","         -1.2560e+00,  2.9064e+00, -2.2252e+00, -3.1940e+00, -1.8408e+00,\n","         -1.8445e+00,  5.5963e-01, -9.7220e-02,  4.2458e+00,  3.6351e-02,\n","         -2.0329e+00,  1.3893e+00,  1.0551e+00, -1.0710e+00, -9.9865e-02,\n","         -2.6324e-01, -1.1777e+00, -2.9166e-01, -8.4528e-01,  9.1426e-01,\n","          1.7833e+00,  2.9487e+00,  2.7899e-01, -1.6271e+00, -9.5662e-01,\n","          2.5272e+00,  1.3537e+00, -1.0222e+00, -7.1073e-01, -9.0419e-02],\n","        [-2.8331e+00,  4.5236e+00, -2.1718e+00, -1.1095e+00,  1.9841e+00,\n","          4.8453e-01, -9.9317e-01, -2.2871e+00,  3.3324e+00, -1.3683e+00,\n","         -2.0805e+00, -2.7906e+00, -7.5169e-01,  1.2446e+00, -1.2558e+00,\n","          2.1288e+00, -1.0888e+00, -4.1780e+00,  1.7582e+00, -1.2199e+00,\n","         -3.7510e-02,  1.1924e+00, -2.3661e+00,  4.0470e+00, -1.6416e+00,\n","         -4.1329e+00, -2.0762e+00,  5.9176e-01, -4.6956e-01,  2.3648e+00,\n","         -1.0819e+00,  3.5353e+00,  1.0264e+00,  3.2384e-01,  6.1731e+00,\n","         -2.9767e+00,  7.3565e-01,  1.3230e+01, -2.3174e+00, -3.0204e+00,\n","          3.0279e+00,  2.3023e+00, -1.6849e+00, -2.4383e-01,  5.2628e-02,\n","         -1.4808e+00,  7.6564e-01, -3.7018e+00, -2.2500e+00,  1.6404e+00],\n","        [ 2.6703e+00,  1.7292e-01,  4.0948e-01,  2.0325e+00, -1.0036e+00,\n","         -1.2160e+00, -8.6217e-01, -2.5577e+00, -1.8210e+00, -2.5578e-01,\n","         -1.6824e+00, -2.2502e+00,  1.4708e+00, -3.6044e-01,  1.9051e+00,\n","         -1.4269e+00, -8.7097e-02,  2.1755e-01, -1.2466e+00,  1.1259e+00,\n","          1.1541e+00, -4.1723e-01,  1.0398e+01, -4.2441e-01,  3.3950e+00,\n","          1.8800e+00, -1.3209e+00, -2.8628e+00, -1.2229e+00, -7.5220e-01,\n","          6.5235e-01, -4.6806e-01,  2.8856e+00, -1.2292e+00, -2.3100e+00,\n","          8.8347e-01, -1.6778e+00, -7.6465e-01,  2.3534e+00,  1.0046e+00,\n","          1.7889e+00,  2.3541e-01, -2.7601e+00, -8.9352e-01, -1.4660e+00,\n","         -1.0315e+00, -4.1496e-01, -4.7961e-01, -1.0285e+00, -3.4603e+00],\n","        [-2.6780e+00, -8.1272e-01,  3.3539e+00,  3.9157e-01,  6.7368e-01,\n","         -1.4804e+00,  5.1214e-01, -2.0083e+00, -1.9090e+00, -7.5445e-01,\n","         -1.1913e+00,  2.7783e+00, -2.9170e+00,  3.6035e-01, -1.6874e+00,\n","         -1.2148e+00,  8.6975e-01,  1.3679e+00, -8.5751e-01,  1.6505e+00,\n","          7.3006e-01, -2.2039e+00, -7.2558e-02, -1.2106e+00,  3.2695e+00,\n","          9.3997e+00, -9.5802e-01, -2.6652e+00, -6.1393e-01,  3.5748e+00,\n","          1.4275e+00, -1.0110e+00,  1.0769e+00,  2.5293e+00, -1.5654e+00,\n","          2.6140e+00, -1.9947e+00, -2.7091e+00,  2.3990e-01,  1.5504e+00,\n","         -2.1382e+00, -3.5852e-01, -3.8690e+00,  5.9932e-01,  6.7626e-01,\n","         -1.4387e+00, -5.7510e-01,  1.3287e+00, -1.0264e+00, -5.1768e-02],\n","        [ 2.4749e-01, -2.1114e+00,  8.4949e-01, -1.3158e+00,  1.6000e+00,\n","         -1.1828e+00, -4.9884e-01, -1.1857e+00, -9.6698e-01,  7.7015e-01,\n","         -5.1023e-01,  6.2482e-02,  1.1043e+01, -3.1761e+00, -9.4819e-01,\n","         -1.6030e+00, -2.9687e+00, -9.9043e-01, -9.0029e-01, -9.4862e-04,\n","         -1.6893e+00,  4.9216e-01,  1.6114e+00, -2.4784e+00, -7.1878e-01,\n","         -1.0546e+00, -1.5282e+00,  3.3880e+00,  2.7631e+00,  7.1793e-01,\n","          1.2760e+00, -4.6402e-01, -2.7552e-01, -2.3115e+00, -9.7219e-01,\n","          1.8741e+00, -1.2296e+00,  9.0095e-01,  1.3091e+00,  1.3555e+00,\n","          1.7355e+00,  2.8471e+00,  6.9970e-01, -1.3034e+00,  9.3355e-02,\n","          1.6501e+00,  2.5947e-01, -2.0238e+00,  3.4914e-01, -2.6813e+00],\n","        [-3.1437e+00,  2.0842e+00, -1.7407e+00, -1.7197e+00,  2.4519e+00,\n","          1.6694e+00, -2.4626e+00, -3.1768e+00,  1.0091e+00, -2.0911e+00,\n","         -2.4391e+00,  2.5014e+00, -2.7746e+00,  2.8305e+00, -4.7556e-01,\n","          5.1397e+00, -5.4024e-01, -3.5453e+00, -1.3540e+00, -1.2422e+00,\n","          2.6929e+00,  3.2698e-01, -3.6306e+00,  2.6529e+00, -7.2250e-01,\n","         -2.7125e+00, -1.6383e+00, -1.2679e+00, -8.9682e-01,  5.4671e+00,\n","         -3.0372e-01,  1.9757e+00,  6.2365e-01, -2.2193e+00,  2.7643e+00,\n","         -2.2530e+00,  1.3169e-01,  9.9112e-01,  1.0010e+00, -2.3294e+00,\n","          2.4660e+00,  1.7353e+00, -3.1327e+00,  7.6734e-01, -2.6288e-01,\n","         -5.7435e-01, -2.8409e-01, -3.1147e+00, -2.8771e+00,  1.3778e+01],\n","        [ 2.8857e-01,  9.5414e-01,  3.7506e-01, -9.5902e-01, -2.5295e-01,\n","          5.7226e-01,  5.5052e-01, -2.6145e+00,  2.4400e+00, -2.2943e+00,\n","          3.3687e+00, -6.5685e-01, -5.6904e-01,  1.7420e+00, -5.2321e-01,\n","         -5.5356e-01, -2.5323e+00,  2.3922e+00, -1.8262e+00, -7.6991e-01,\n","          2.6515e+00, -1.7947e+00, -1.8596e+00, -4.7227e-01, -3.0931e-01,\n","         -3.2314e+00, -2.3064e+00, -1.3366e+00, -5.2985e-01,  4.4103e-02,\n","         -2.0166e+00,  8.5605e-01,  2.5535e-01, -1.6690e+00, -4.1932e-01,\n","         -1.0917e+00,  1.0112e+01, -4.8217e-01,  1.3764e+00, -1.3374e+00,\n","         -1.3591e+00,  9.3561e-01,  4.5221e+00,  5.3521e+00,  3.1788e+00,\n","         -2.4497e+00, -4.8694e-01, -1.0755e+00,  4.2774e-01,  1.3688e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([16, 12,  0, 26, 23,  0,  9, 47, 32,  7, 37, 22, 25, 12, 49, 36],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7496, 10.8753, -0.5521,  ..., -1.7161, -2.3101,  2.6268],\n","        [-0.0403,  4.8917, -0.3670,  ..., -0.7565, -0.7096,  3.3120],\n","        [ 5.9458, -3.5509,  1.5984,  ...,  6.1745,  1.1395, -1.5365],\n","        ...,\n","        [ 2.1042, -0.2069, -0.9445,  ..., -2.1046,  0.5083, -0.6004],\n","        [ 1.7978, 16.3021,  1.0359,  ..., -1.5864, -3.4030,  1.6582],\n","        [ 1.0591, -4.2653,  3.9380,  ..., -0.5257,  2.2111, -0.5892]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 383/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.4154, -0.6496, -1.0604,  ..., -1.0008, -1.0262, -0.3947],\n","        [-1.3419, -0.5939,  0.8826,  ..., -1.3589, -2.0545, -1.0839],\n","        [-1.9774, -0.3222,  2.9163,  ..., -1.9710,  0.7632,  2.0113],\n","        ...,\n","        [-1.4678, -3.1740, 16.6555,  ..., -1.3305,  1.3677, -1.4707],\n","        [-2.2292,  2.3111, -0.0890,  ..., -3.4850, -1.8742, 15.5291],\n","        [-1.1144,  0.6677, -0.8901,  ..., -0.6490, -0.6834, -0.8460]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([45, 31, 29, 10, 23,  1,  8, 19, 32, 15,  7, 41, 17, 11, 38,  3, 46, 43,\n","        44,  8, 24, 16, 34, 33, 38, 11, 41, 16,  7, 11, 29, 43, 48, 20, 31, 37,\n","         3, 32, 13,  9, 31, 47, 40, 42, 32, 17,  9, 21,  9, 27, 36, 15, 47, 20,\n","         3, 46,  7, 49, 28, 41, 25, 13, 29, 16, 19, 26,  8, 22, 26,  7, 49, 29,\n","        19, 33, 24, 16, 27, 44, 41, 34, 40, 28, 28, 44, 15, 10,  4,  5, 40, 32,\n","        13,  4,  0, 14, 27, 25, 34,  5,  4, 18, 22, 23, 43, 37,  9,  1, 45,  0,\n","        17, 20, 19, 18, 12, 47,  6, 35, 13, 29, 21,  1,  4, 30, 44, 38, 45,  2,\n","        49,  7], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.6751, -2.9986, -0.8110,  ..., -0.3208, -1.2792, -0.2173],\n","        [-1.9130, -0.9257,  0.3851,  ..., -0.5657, -1.1917, -1.0112],\n","        [ 1.5682, -2.8426,  2.8376,  ...,  0.3848,  1.1777, -1.4247],\n","        ...,\n","        [-1.3235, -0.5443,  0.2031,  ...,  0.3930, -0.9437, -0.6585],\n","        [-0.3951, -0.8795,  1.2743,  ..., -0.1112,  0.9384,  0.0683],\n","        [16.2103,  0.8709,  0.2102,  ...,  1.2911,  4.2173, -0.1440]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([14,  9, 35,  2, 12, 45, 36,  9, 23, 36, 24, 10, 11, 30, 47,  4, 24, 38,\n","        41, 47, 14,  6, 42,  5, 36, 13,  8, 29, 26, 48,  7, 16, 13, 46, 38, 21,\n","        10, 42, 27, 33, 10,  4,  6, 40, 37,  2, 30, 14, 37, 31, 16, 29, 21, 18,\n","        31, 27, 30,  9, 36,  8, 43, 33, 10, 18,  9, 49, 25, 22, 10, 20, 48, 11,\n","        34,  5, 10, 16, 27, 27, 24,  2, 25, 35,  9, 46, 35,  1, 38, 48,  2, 21,\n","        37, 39,  4, 41, 34,  3, 19, 15, 22, 16, 17,  2, 43, 11,  6, 19, 30, 49,\n","         6, 15,  3, 49, 42, 47, 11, 32, 33, 27, 45, 41,  2, 24,  2, 18, 44, 18,\n","         5,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.3469e+00, -2.3428e-01, -5.9410e-01,  ...,  5.2568e-01,\n","         -6.0051e-04,  3.8593e+00],\n","        [ 1.4747e+01, -4.3315e-01,  3.4513e+00,  ..., -1.3966e+00,\n","          4.0620e+00,  1.8027e-01],\n","        [ 1.5621e-01, -2.0290e+00,  5.2074e-01,  ...,  3.5899e+00,\n","          4.7145e-01, -7.1769e-01],\n","        ...,\n","        [-5.9132e-01, -2.4431e+00,  1.5059e+00,  ..., -2.0860e+00,\n","         -3.8546e-01, -2.3735e+00],\n","        [ 5.5554e+00, -4.5149e+00,  1.2591e+00,  ...,  5.5413e+00,\n","          4.3295e-01, -2.8731e+00],\n","        [-4.2053e-01, -1.1513e+00,  2.1699e+00,  ...,  4.7804e-01,\n","          4.9965e-01, -5.1419e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([29,  0, 25, 22, 31, 14, 19, 36, 23,  3, 12, 31, 49, 28, 39, 12,  0, 43,\n","        36, 37, 14, 37,  2, 30, 15, 28, 36, 26, 23, 40, 10,  8, 35, 23, 42, 40,\n","        39, 12, 11, 18,  5, 16, 41, 20, 30, 15,  3, 49,  1, 42, 26, 27, 20, 45,\n","         0, 20, 41, 37, 14, 47, 17, 21,  1, 35, 20, 32,  3,  8,  8, 36, 12, 30,\n","        25, 31, 32, 44, 48, 12, 14, 46, 47, 28,  5, 40, 40, 14, 39, 33,  0, 25,\n","        48, 15, 45, 22, 29,  6, 42, 35,  7, 12, 46, 24,  1,  1, 22, 28, 22, 31,\n","        39, 46, 23, 13, 17, 17, 26,  9,  0, 32,  7,  4, 33, 30,  3, 27, 48, 12,\n","        25, 26], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.9808e+00,  7.3723e-01,  1.7703e+00,  5.6391e+00, -1.9667e+00,\n","         -6.9026e-01,  2.5099e+00, -3.6861e+00, -2.4788e-01, -1.9625e+00,\n","         -2.9712e+00,  1.0943e+00, -1.4892e+00,  1.8932e+00, -2.7243e+00,\n","         -2.4330e-01,  1.0476e+00, -1.1368e-01,  8.5504e-01,  1.1439e+01,\n","         -2.0570e+00, -3.5400e-01, -1.4277e-02, -8.4182e-01,  3.7025e+00,\n","          1.1699e+00, -1.2883e-02, -1.1369e+00, -3.0105e+00,  6.1174e-01,\n","          2.3845e+00, -1.1470e+00, -2.1511e-01,  4.7451e-01, -1.1580e+00,\n","          4.5271e-01, -2.5206e+00, -2.3120e+00,  5.0481e+00,  4.3424e+00,\n","         -3.5799e+00, -1.3871e+00, -3.4439e+00, -4.1135e-02, -2.0381e+00,\n","         -1.8344e+00, -5.7017e-01,  3.7604e-01, -1.3985e+00, -1.8092e+00],\n","        [ 1.2068e+00, -1.2182e+00, -9.6329e-01, -2.1431e+00, -3.1919e-01,\n","          9.2656e-02,  7.4450e+00, -3.9961e-01,  8.8955e-01, -1.4646e+00,\n","         -2.2866e+00,  8.8854e-01,  5.3038e-01, -2.9907e-01, -6.6233e-01,\n","          6.6737e-01, -2.1370e+00, -2.2847e-01, -5.7337e-01,  1.4897e+00,\n","          1.0761e-01,  7.5147e-01,  6.2225e-01, -1.5662e+00, -5.9541e-01,\n","          6.7539e-01, -1.2186e+00,  3.9254e-01, -1.1345e+00,  1.9281e+00,\n","         -7.9050e-01, -1.9724e+00,  9.8047e-02,  9.6792e-02, -6.9672e-01,\n","          2.0558e+00,  1.5107e-01, -2.0269e+00,  3.5231e-01,  2.4733e+00,\n","         -4.0544e-01,  1.8221e+00, -8.4242e-01,  4.8100e-01, -8.0215e-01,\n","          7.1470e-01, -3.1998e+00,  2.8172e+00,  1.2079e+00, -7.0386e-01],\n","        [ 4.3938e-01, -1.6688e+00,  2.1782e+00,  3.8552e-01, -1.6492e+00,\n","          1.3014e+00, -1.9143e+00, -1.9421e+00, -2.5583e+00, -8.9084e-01,\n","          1.2244e+00,  3.5974e+00,  2.7178e+00, -3.1379e+00, -1.5727e+00,\n","         -2.6576e+00,  9.5725e-01, -1.9878e+00,  1.0577e+00,  2.4022e-02,\n","         -3.5669e-01,  2.0287e-02, -5.0130e-01, -2.7394e+00, -1.6609e+00,\n","         -1.1989e+00, -1.3270e+00,  1.7383e+00,  1.9678e+00, -1.4128e+00,\n","          1.3737e+01, -1.6381e+00, -5.8667e-01, -3.2320e+00, -1.4658e+00,\n","          1.4409e-01, -1.1695e+00,  7.4903e-01,  2.0224e+00, -2.3347e+00,\n","          2.8685e+00,  9.3817e-02, -9.9071e-02, -6.9579e-02,  4.8836e-01,\n","         -7.3671e-01,  3.9189e+00,  2.0815e-01,  5.9898e-01, -7.2792e-01],\n","        [ 1.2217e+00,  4.3808e-01,  5.8455e+00,  3.1740e+00, -1.5752e+00,\n","          3.4825e-01, -4.1530e+00, -4.6934e+00, -2.4232e+00,  5.7682e+00,\n","         -3.4924e+00, -1.8354e-01, -8.3016e-01, -4.5993e+00, -2.8466e+00,\n","         -2.0784e-01,  3.0908e+00, -2.3863e+00,  8.2594e-01,  1.0193e-01,\n","          7.5206e-01,  1.0645e+00,  4.5468e-01, -2.6875e+00,  1.1450e+01,\n","          2.7807e+00, -1.5153e-01, -9.4978e-01, -2.8014e+00,  3.2518e+00,\n","          7.5760e-01, -6.3090e-01,  5.1910e-01, -4.0713e-01, -4.2796e-01,\n","         -2.3963e+00, -3.5137e+00,  6.3148e-01,  3.7047e+00, -8.1427e-01,\n","          1.6065e+00, -7.8209e-01, -4.3044e+00, -2.9107e+00, -8.7463e-01,\n","         -1.5038e+00,  3.6061e+00,  1.0085e+00, -1.4541e+00,  8.3927e-01],\n","        [ 6.0585e-01, -6.1983e-01,  3.6975e-01, -2.6111e+00,  2.2631e+00,\n","          1.9628e+00, -1.5341e+00, -2.8369e+00,  1.7710e+00, -2.3604e+00,\n","         -7.2656e-01,  1.2820e+00, -5.4515e-01,  7.4138e-01,  1.2879e+00,\n","          1.6409e-01, -2.2866e+00, -2.8284e+00, -2.0239e+00, -4.5749e+00,\n","          1.4945e+01, -3.1910e-01, -2.0412e+00,  4.3629e+00, -3.3286e+00,\n","         -6.1025e-01, -4.5256e+00, -1.5669e+00, -2.0580e+00,  1.3524e+00,\n","         -2.5055e+00,  2.8482e+00,  1.3997e+00, -1.9660e+00, -7.1729e-01,\n","         -1.9458e+00,  6.2588e+00,  1.6195e+00, -5.2695e-01, -8.0751e-01,\n","          1.0373e+00,  1.0536e+00,  2.0109e-01,  6.4796e+00,  1.9044e-01,\n","         -4.5030e+00, -1.5721e+00, -7.8701e-01,  1.6332e+00,  2.5203e+00],\n","        [-1.0076e+00,  3.8741e+00, -1.6767e+00, -7.6913e-01,  7.4082e-01,\n","          1.2344e+00, -1.2268e-01,  3.3040e-01,  3.6616e+00, -1.4943e+00,\n","         -2.4905e+00, -4.0815e-01, -8.3157e-01,  5.4691e-01, -8.5962e-01,\n","          2.5025e-01, -4.7144e-01, -3.1456e+00, -2.8391e-02, -1.6103e+00,\n","          2.6227e-01,  6.1083e-01, -2.4282e+00, -8.9962e-03, -1.3496e+00,\n","         -4.3072e+00, -4.7641e-01, -6.8741e-01, -1.8183e+00,  1.9180e+00,\n","         -2.2130e+00,  1.7697e+00,  1.4787e+00,  1.7519e+00,  1.1318e+01,\n","         -2.2116e+00,  9.8728e-01,  6.0363e+00, -1.3138e+00, -3.0131e+00,\n","          1.7687e+00,  2.6606e+00, -2.8162e+00,  2.0740e+00,  3.8106e-02,\n","         -1.6078e+00, -9.7661e-02, -2.3128e+00, -2.6196e+00,  2.7550e+00],\n","        [ 2.2580e-01, -2.0396e+00,  1.6661e+00, -2.3630e+00, -1.3710e+00,\n","          5.0841e-01,  1.5545e+00, -3.1591e-01, -1.2878e+00, -1.2320e+00,\n","         -1.2723e-01,  1.7857e+00,  2.3167e+00, -1.7789e+00,  3.3996e+00,\n","         -4.0106e-01,  7.4420e-01, -1.3409e+00, -6.4206e-01, -1.3267e+00,\n","          7.6843e-01,  3.5487e-01,  6.4754e-01, -8.9820e-01,  2.5301e-01,\n","         -4.9852e-01, -5.8162e-01,  1.8831e+00, -1.4224e+00, -2.3358e+00,\n","          7.4914e-02, -1.0328e+00,  1.1294e+00,  1.0063e-01, -1.0433e+00,\n","          9.1422e+00, -4.8540e-01, -1.9613e+00, -1.1639e-03, -4.2227e-01,\n","         -2.1784e-01, -5.2084e-01, -1.7778e+00,  8.4277e-01, -3.0717e-01,\n","         -1.0329e+00, -9.1023e-01,  2.0661e+00, -1.7537e+00,  6.5279e-01],\n","        [-1.4531e+00, -8.1485e-02, -1.4816e+00,  6.1639e-01, -1.0809e+00,\n","         -6.6161e-01,  8.9527e-02, -3.5241e+00,  5.8112e+00, -2.7768e+00,\n","         -2.8630e+00, -1.1483e+00, -2.5018e+00,  1.3189e+01, -2.1243e-01,\n","          2.6041e+00,  2.7120e-01, -1.8424e+00, -9.2820e-01,  2.5740e+00,\n","          2.5047e+00,  4.4571e-01, -4.1451e-01,  5.5471e+00,  3.2032e-01,\n","         -4.2091e-01, -1.4566e+00, -2.5789e+00, -3.1714e+00,  1.5788e+00,\n","         -1.9381e+00,  2.8678e+00,  3.4221e+00,  1.3233e+00,  1.2115e+00,\n","         -2.0796e+00, -5.4957e-01, -8.2067e-01,  6.3918e-01, -6.2001e-01,\n","         -1.5233e+00, -1.6645e+00, -2.4753e+00,  4.5699e+00,  6.6436e-01,\n","         -1.9334e+00, -3.5755e+00, -2.2010e+00, -3.0097e+00,  1.7378e+00],\n","        [ 2.4818e+00, -3.2249e+00,  3.3801e+00, -1.7054e+00, -1.7578e+00,\n","          1.1329e+00, -2.1345e+00, -1.4106e+00, -3.8460e-01, -1.3772e+00,\n","         -6.4040e-01,  5.2332e+00, -1.2766e+00, -2.4787e+00,  1.7993e+00,\n","         -1.6238e+00,  9.5540e+00, -1.4524e+00, -2.8246e+00, -3.2050e+00,\n","          7.0155e-01, -6.7357e-01, -1.1824e-01, -8.3940e-01,  1.1390e+00,\n","          2.9278e+00,  5.6197e-01,  1.9233e-01, -2.2583e+00,  1.1874e-01,\n","         -3.4827e-01,  4.7091e-02,  2.8269e+00,  2.9528e-01, -2.5994e+00,\n","          1.7704e+00,  6.6300e-01, -2.7611e+00,  3.4351e+00,  9.1542e-01,\n","          2.4012e-01,  3.9935e-01, -1.2751e+00, -1.1958e+00,  1.4899e+00,\n","         -2.9641e+00, -1.3826e+00,  1.8978e+00, -1.4824e+00,  1.4018e+00],\n","        [ 1.8818e+00, -1.7408e+00,  6.2754e-01,  2.9202e+00, -2.0709e+00,\n","          1.3443e+00, -1.4010e+00, -2.0928e+00, -1.3282e+00,  2.1814e+00,\n","         -4.6232e-01,  7.2097e-01, -1.8422e+00, -1.6019e+00,  2.8658e-01,\n","         -2.6585e-01,  1.2684e+00, -1.5536e+00,  1.9885e+00,  2.0660e+00,\n","         -1.2206e+00,  2.0241e-01,  2.8276e-01, -1.4821e+00,  8.8693e+00,\n","          2.1159e+00,  4.7678e-01,  2.8025e+00, -1.8014e+00,  1.8082e-01,\n","         -8.0811e-01,  2.2385e+00,  5.3513e-01, -2.5389e+00, -1.7425e+00,\n","         -2.1697e+00, -1.2811e+00, -8.5247e-01,  6.8941e-01,  1.2821e+00,\n","          1.4435e+00, -1.0496e+00, -3.0986e+00, -1.6080e+00, -4.3908e-01,\n","         -2.3669e+00, -1.4887e+00,  2.3010e+00, -1.7958e-01, -1.6844e+00],\n","        [-1.9720e-01, -2.4075e+00,  5.6396e-01, -1.2357e+00,  1.5627e-01,\n","         -6.0933e-01,  1.7961e-01, -7.1394e-01, -7.7469e-01,  1.8987e-01,\n","          5.0685e+00, -3.7439e-01,  6.4397e-01, -6.9473e-01, -1.1207e+00,\n","         -1.5913e+00, -1.1000e+00,  9.1213e+00, -8.2015e-01,  1.8823e-01,\n","         -3.8579e-01, -3.7742e-01,  5.9217e-01, -1.8681e+00, -1.2384e+00,\n","         -1.3879e-02, -1.9670e+00, -6.2985e-01, -1.0413e-02, -1.0676e+00,\n","          2.7134e-01, -2.6910e-02,  1.0517e+00, -1.2501e+00, -2.3957e+00,\n","         -5.0652e-01,  4.0494e-01, -1.1290e+00,  2.4142e-01,  4.6113e-01,\n","          2.8717e-01, -4.3258e-01,  3.1414e+00,  5.9630e-01,  1.2369e+00,\n","         -3.1376e-01,  1.1535e+00, -6.1858e-01,  1.8792e+00, -1.7646e+00],\n","        [-3.5689e+00, -2.8282e+00, -8.9906e-02, -2.5919e+00,  1.4383e+00,\n","          8.7906e-01, -2.9602e+00,  1.3925e+00, -2.9127e+00,  3.7391e+00,\n","         -1.1561e-01,  2.2747e+00,  3.3126e+00, -2.0353e+00, -1.9902e+00,\n","          7.7421e-01, -7.0326e-01, -1.3888e+00,  2.4015e+00, -1.2997e+00,\n","         -2.1136e+00,  1.4658e+00, -1.4481e+00, -2.8310e+00, -1.0031e+00,\n","         -9.7208e-01, -1.2934e+00,  1.0554e+00,  1.3546e+01,  2.2576e+00,\n","          3.7984e-01,  3.2586e+00,  9.4812e-01, -2.4721e+00, -1.5070e+00,\n","         -2.0214e+00, -2.3073e+00,  2.6215e+00, -5.4494e-01, -1.3464e+00,\n","          3.4096e+00,  7.7910e+00, -1.1579e+00, -4.0714e+00, -1.1484e+00,\n","          1.9081e+00,  4.8305e-01, -3.4585e+00, -2.6200e+00,  6.3530e-01],\n","        [ 1.7016e+00,  1.1583e+01, -4.0055e-01,  1.5695e+00,  1.7285e+00,\n","         -2.0052e+00, -1.1828e+00, -3.9500e-01,  2.9092e+00, -7.9302e-01,\n","         -1.4034e+00, -3.6330e+00,  2.1202e+00, -1.4984e+00, -1.3964e+00,\n","          2.6599e-01, -2.1483e+00, -4.0409e+00,  6.9177e-01, -1.6916e+00,\n","         -9.8574e-01, -9.8841e-01, -1.1729e-01,  2.9765e+00, -1.8229e-01,\n","         -3.1888e+00, -2.5678e+00, -1.4309e+00, -3.2356e-01,  5.9897e-01,\n","         -1.7873e+00,  9.2921e-02,  6.9696e-01, -9.4043e-01,  2.3012e+00,\n","         -2.6630e+00,  6.1867e-01,  6.0213e+00, -2.4744e-01, -1.5086e+00,\n","          2.3686e+00, -6.8252e-01,  9.0684e-01,  1.7048e+00, -1.0887e+00,\n","         -9.0945e-01,  1.6186e+00, -2.7163e+00, -9.5561e-01,  1.6176e+00],\n","        [-6.5208e-01, -1.6235e+00,  1.3542e+00, -2.7451e-01, -4.1767e-01,\n","         -9.9666e-01, -4.7598e-02, -4.9846e-01, -9.2551e-01,  1.1736e+00,\n","          5.3241e+00, -2.9879e-01,  2.1299e-01, -1.2632e+00, -9.6606e-01,\n","         -1.9773e+00, -1.1537e+00,  7.2903e+00, -2.8582e-01, -1.3579e+00,\n","         -1.9665e-01, -1.4906e+00, -4.1178e-02, -1.2829e+00, -1.7702e+00,\n","         -4.6672e-01, -8.9565e-01, -1.8131e+00, -3.7977e-02,  2.1759e-01,\n","         -9.1912e-01, -1.9585e-01, -1.2509e-02, -4.4347e-01, -1.7321e+00,\n","         -8.1235e-01,  1.3791e+00, -1.0406e+00,  8.4795e-01, -1.6201e-01,\n","         -8.0714e-01, -6.6463e-01,  4.3914e+00,  3.6044e-01,  3.5991e+00,\n","         -1.3722e+00,  1.8924e+00,  1.0390e-01,  2.1996e+00, -5.8843e-01],\n","        [-1.7500e+00, -2.2443e+00, -3.9427e-01, -1.3230e+00, -5.2170e-01,\n","          1.6598e-01, -7.2971e-02, -7.9123e-01, -1.2059e+00,  2.7124e+00,\n","          4.5795e+00, -3.3661e-01,  1.2572e-01, -1.6603e+00, -1.8038e+00,\n","         -9.9142e-01, -1.9299e+00,  1.0380e+01,  2.3334e-01, -6.1419e-01,\n","         -1.3156e+00, -8.2794e-01, -3.9264e-01, -2.1831e+00, -1.1725e+00,\n","          1.1474e+00, -4.6241e-01, -9.5307e-01, -4.0743e-01,  1.6362e+00,\n","         -1.2569e-02, -1.6253e-02,  2.8239e+00, -9.8845e-01, -2.0815e+00,\n","         -1.0691e-01,  3.0335e-01, -1.6128e+00, -4.3003e-01, -6.4881e-03,\n","          4.0669e-01,  4.4381e-01,  1.7469e+00, -4.3048e-01,  4.2395e+00,\n","          4.7707e-01,  1.2270e+00, -1.4043e-01,  1.1839e+00, -1.9178e+00],\n","        [ 1.2098e+00, -1.5149e+00,  2.3663e+00,  3.0005e-01, -1.5163e+00,\n","          4.7759e+00,  2.1400e+00, -7.3404e-01, -2.8144e-01, -1.5001e+00,\n","          3.0529e-01,  2.8666e-01, -2.4765e+00, -1.9375e+00, -5.6360e-01,\n","         -3.0596e+00, -3.3103e-01, -7.7967e-02, -7.1522e-01, -1.5235e+00,\n","          3.1982e-02, -7.2129e-01, -3.0584e+00, -1.3470e+00, -2.7172e+00,\n","         -1.2735e+00,  1.2113e+01,  1.1256e+00, -3.6643e+00,  2.5896e+00,\n","         -2.0640e+00, -1.7385e+00, -1.6032e+00,  4.3892e+00, -1.2142e+00,\n","          2.1518e+00, -9.6015e-01, -6.4346e-01,  7.0078e-01, -1.3951e+00,\n","         -1.4360e+00,  3.5099e-02, -8.0098e-01,  2.0911e+00,  3.3140e+00,\n","         -2.4516e+00, -5.2308e-01,  7.5022e-01,  3.4838e+00,  7.2954e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([19,  6, 30, 24, 20, 34, 35, 13, 16, 24, 17, 28,  1, 17, 17, 26],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7430, 10.8653, -0.5560,  ..., -1.7160, -2.3117,  2.6455],\n","        [-0.0402,  4.8972, -0.3700,  ..., -0.7583, -0.7066,  3.3196],\n","        [ 5.9181, -3.5513,  1.6061,  ...,  6.1662,  1.1363, -1.5401],\n","        ...,\n","        [ 2.1102, -0.2036, -0.9446,  ..., -2.1066,  0.5045, -0.5955],\n","        [ 1.7933, 16.2775,  1.0390,  ..., -1.5869, -3.4030,  1.6703],\n","        [ 1.0381, -4.2657,  3.9407,  ..., -0.5407,  2.2052, -0.5807]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 384/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.0875, -0.9242, -0.5005,  ..., -2.3946,  0.4374,  1.4180],\n","        [ 0.2760, -1.7036, -0.5031,  ..., -0.9509,  0.2005, -0.5061],\n","        [ 0.9135, -0.6505,  2.3255,  ...,  1.4433, -0.0518, -1.7048],\n","        ...,\n","        [ 3.1157,  1.2850,  1.0817,  ...,  2.5135,  0.0373, -1.1548],\n","        [-1.2343, -3.1245, -1.8206,  ..., -0.9529,  3.7656, -0.3051],\n","        [15.3021, -0.1420, -1.7323,  ...,  1.5552, -0.0232, -2.6770]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20, 14, 38, 18, 47, 30, 46, 24, 31, 29, 19, 44, 24,  8, 35, 33,  3, 30,\n","        39, 23,  9,  3, 26,  1, 25, 45,  5, 31, 27, 19, 43, 19, 19, 40, 24, 26,\n","        26, 28,  6, 29, 20, 12, 16,  9, 27,  2,  7, 46, 30, 18,  2, 27, 22, 10,\n","        31, 13, 21, 39, 26, 15, 30, 45, 12, 48, 37, 44,  6, 29, 26, 46, 14, 31,\n","         3, 45, 41, 23, 47,  9,  7, 10,  7, 31, 36, 34, 15, 28,  7,  3,  0,  8,\n","        30, 11,  5,  9,  2, 28, 41, 16, 17, 15, 35, 38, 15, 41, 33, 43,  2, 49,\n","        46, 28, 23,  5,  9, 43, 47, 30, 22, 34, 44, 21, 29, 40,  2, 20, 22,  3,\n","        41,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1831, -1.9434,  1.3069,  ..., -0.9266,  0.0785, -0.3299],\n","        [ 2.3019, -0.4218, -0.1577,  ..., -1.1865,  2.5504, -1.2112],\n","        [-2.0623, -3.3603, -1.5705,  ..., -1.4340,  1.4845, -0.5832],\n","        ...,\n","        [ 6.2518, -3.7488, -0.6309,  ..., 12.9480,  1.4652, -1.4335],\n","        [ 0.3615, -1.3519,  0.9254,  ..., -0.6785,  1.6989, -2.0104],\n","        [-2.5824, -3.0786, -0.3652,  ..., -3.9200, -1.2079, -0.3915]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([27, 42, 41, 48, 49, 42, 33,  0, 10, 11, 47,  8, 39, 24, 49,  2, 12, 32,\n","        49,  7,  5,  0, 30, 20, 33, 11, 42, 37, 44, 11, 46, 27, 20, 22, 32, 37,\n","         2, 19, 24, 13, 18, 32,  6,  9, 31, 19, 21,  3, 27, 35,  0,  5, 20,  9,\n","         2, 19, 47, 25, 12,  8, 29, 13, 15, 16, 10, 13, 22, 36,  1,  4, 32, 29,\n","        17, 25,  1, 45, 43, 49, 34, 37,  6, 18, 12,  7, 11, 18,  8, 32,  0, 27,\n","        35, 14,  1, 16, 37,  9,  8, 15, 25, 10, 34, 40,  6, 24, 25, 35, 17, 20,\n","        38, 25, 31, 14, 36, 21, 15, 33, 10,  7, 26, 42, 36, 23,  1, 17, 24, 47,\n","        17, 28], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.9777,  1.2863, -1.8311,  ..., -0.0378, -3.2010,  1.1426],\n","        [ 1.9103, -3.5388,  4.9282,  ...,  0.9270,  0.3014, -2.5422],\n","        [-1.2301, -1.2142,  1.6932,  ...,  1.8400, -1.8596, -1.5882],\n","        ...,\n","        [-1.8988, -2.0836,  1.0479,  ...,  0.0567, -2.2674,  0.1051],\n","        [-0.0093,  0.5972,  0.4695,  ...,  0.0495, -2.4420, -1.0324],\n","        [ 2.0161, -0.6703,  1.8703,  ..., -0.4056,  2.3974, -0.4425]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([13, 35,  9, 25, 36, 41, 16, 34, 28, 48, 24, 37,  3, 12, 12, 39, 16, 16,\n","        17, 40, 11, 10, 22, 40, 29, 23, 12, 27, 17,  1, 48, 49, 49,  8, 16, 33,\n","        20,  6, 13, 30, 47,  9, 48, 19, 13, 35,  2, 42, 30,  4, 37, 40, 36, 41,\n","         4, 38, 23, 36, 48, 32, 33,  5, 21, 16,  3, 49, 26, 45, 29,  0,  1, 35,\n","        41, 31, 36,  7,  8, 10, 18, 43, 22, 18, 28,  1, 34, 42,  5, 46, 40,  0,\n","        38, 44,  4, 11, 21, 38, 14,  1, 14, 13, 48, 22, 14, 14, 28, 16, 23, 41,\n","         6,  3,  4, 45, 32,  4, 36, 30, 17, 40, 25, 43, 39,  4, 44, 15, 32, 14,\n","        31, 20], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.2874e+00,  2.5141e+00,  2.4676e+00,  1.5330e+00, -1.0533e+00,\n","         -1.5587e+00, -2.6572e+00, -1.0686e+00, -5.3933e-01, -1.1878e+00,\n","          3.5592e-01,  2.2214e-01, -8.7407e-01, -1.5693e+00, -2.7873e+00,\n","         -2.0719e+00,  3.2611e+00,  3.2561e-01, -1.8123e-01,  2.3612e+00,\n","          7.1886e-01, -2.2660e+00, -1.2204e+00, -3.2882e+00,  1.1422e+00,\n","         -1.3563e+00, -4.6917e-01, -2.6853e+00,  1.3311e+00,  3.4418e-01,\n","          3.0449e+00, -2.7623e+00, -7.1848e-01, -4.3343e-02,  7.8459e-01,\n","          9.3322e-03, -1.0016e+00,  2.1447e+00,  1.0210e+00, -1.3626e+00,\n","          1.2234e+00, -7.6775e-01,  1.6159e-01, -2.6992e-01, -7.3506e-01,\n","         -2.6952e+00,  1.2428e+01, -2.3036e+00, -1.5798e-01, -3.2390e-01],\n","        [-1.6873e+00, -2.6360e+00,  2.6510e-01, -2.0261e+00, -2.0084e+00,\n","          4.2735e-01, -5.5219e-01,  5.6355e-01, -1.9664e-01,  7.1617e-01,\n","          3.9906e-01, -7.4074e-01,  9.2464e+00, -9.6351e-01,  5.0091e+00,\n","          6.4050e-01, -1.5732e+00,  1.1263e-01,  6.8199e-02, -1.4848e+00,\n","          6.6148e-02,  8.6974e-01,  2.4478e+00, -1.3771e+00, -7.3241e-01,\n","         -8.1052e-01,  1.4823e-01,  3.9632e-02,  4.4024e+00, -9.5827e-01,\n","         -7.7837e-01,  1.5631e+00,  3.0365e+00, -2.0903e+00, -2.3762e+00,\n","          2.6519e+00, -1.1170e+00,  6.2124e-01, -4.3282e-01, -1.2149e+00,\n","          2.0087e+00,  9.1386e-01, -1.1731e+00, -7.8072e-02,  2.1496e+00,\n","         -2.0623e+00, -1.6094e+00, -3.0455e+00, -1.1967e+00, -1.1162e+00],\n","        [-1.8587e+00, -1.1256e+00, -1.4010e+00, -1.4479e+00,  1.7733e+00,\n","         -1.5426e+00, -1.0361e+00,  1.1198e+00,  5.3767e-01,  1.3665e+00,\n","         -1.6744e+00,  7.9105e-01,  1.9434e+00, -1.7109e-02, -2.1850e+00,\n","         -2.2134e+00, -8.5913e-01, -9.2866e-02,  1.5887e+00,  3.0468e-01,\n","         -1.7701e+00,  8.0191e-01,  1.4333e+00, -1.9869e+00, -7.0772e-01,\n","         -2.0186e-01, -1.1339e-01, -1.9239e+00,  7.8487e-01, -5.4945e-03,\n","          1.0347e+00,  1.5160e+00,  4.4954e+00, -9.4959e-01, -4.5105e-01,\n","         -2.0263e+00, -1.6099e+00, -2.3170e-01, -6.6097e-01,  1.7119e+00,\n","          3.1954e+00,  1.8282e+00, -1.8897e+00, -1.5431e+00, -3.0147e-01,\n","          1.2509e+01, -1.2953e+00, -2.4880e+00, -1.1462e+00, -9.2127e-01],\n","        [-2.1847e+00,  7.9186e-01, -1.5926e+00, -3.7589e-01,  1.5457e-01,\n","          2.3482e+00,  2.0264e+00, -3.6075e+00,  1.0609e+00, -2.8888e-01,\n","         -2.2382e+00, -1.7563e+00, -1.5781e+00,  4.7797e+00, -6.5743e-01,\n","          6.8830e+00, -6.0924e-01, -2.1916e+00,  9.6053e-01, -4.6345e-02,\n","          2.2534e+00,  1.0363e+00, -9.8378e-01,  4.8995e+00,  1.9925e-01,\n","          5.7381e-01, -1.0567e+00, -3.2535e+00, -2.3028e+00,  1.1702e+01,\n","         -3.3204e+00,  5.6777e-01,  2.1991e+00,  3.0567e-01,  1.1507e+00,\n","         -1.2550e+00, -9.7169e-01,  1.3636e-01, -2.4488e-01, -2.4078e+00,\n","         -1.3990e+00,  1.3925e+00, -5.5114e+00,  1.2011e+00,  2.4218e-01,\n","         -1.4361e+00, -3.7532e+00, -1.4642e+00, -4.1387e+00,  4.5532e+00],\n","        [-5.1579e-01, -2.0716e+00, -1.8788e-01, -4.7886e-01, -2.4314e+00,\n","         -4.4259e-01,  1.6850e+00, -2.0142e+00, -9.0269e-01,  9.8907e-01,\n","          3.2478e+00, -1.3736e+00, -7.4299e-01, -3.4236e-02, -1.4563e+00,\n","         -1.2124e+00, -1.5895e+00,  1.2539e+01,  8.5551e-01,  6.4306e-01,\n","          2.1047e-01, -1.6708e+00, -1.0903e+00, -8.4464e-01, -5.4696e-01,\n","          8.6515e-01, -6.0061e-01, -1.3430e+00, -8.7017e-01,  1.7277e-01,\n","          2.0233e+00, -3.1276e-02,  1.3282e+00, -1.0477e+00, -2.0611e+00,\n","          1.0203e-01,  8.5463e-01, -2.0321e+00,  4.3415e-01, -6.6022e-01,\n","         -1.0093e-01, -3.0856e-01,  1.2937e+00,  3.2734e-03,  2.8994e+00,\n","         -8.9785e-01,  1.6648e-01,  4.2665e-01,  1.3565e+00, -1.6633e+00],\n","        [ 5.2546e+00,  1.1088e+00,  4.0592e+00,  5.6335e+00, -4.2844e+00,\n","         -3.3129e-01,  1.8276e-01, -4.5243e+00, -3.5295e-01,  1.5037e+00,\n","         -4.0919e+00, -3.7780e-01, -3.4551e+00, -2.3542e-01, -1.9421e+00,\n","         -2.1439e+00,  5.2274e+00, -1.7625e+00,  1.5072e+00,  3.6776e+00,\n","          2.6609e+00, -3.9617e-01,  9.6455e-01, -6.8941e-01,  1.2930e+01,\n","          2.5707e+00,  2.7559e-02, -4.4577e+00, -2.4932e+00, -8.7501e-01,\n","          1.4288e+00, -8.4446e-01,  4.1055e-01,  7.3386e-01, -6.8652e-01,\n","          2.7646e-01, -2.5402e+00, -1.9739e+00,  4.0511e+00,  1.5418e-01,\n","         -2.6137e+00, -5.6649e-01, -5.3623e+00, -6.8596e-01, -1.9802e+00,\n","         -3.6989e+00, -7.6222e-01,  2.5625e+00, -1.1646e+00, -2.2155e-01],\n","        [ 2.6736e-01, -1.0584e+00,  2.6303e+00, -8.4925e-01, -7.0390e-01,\n","          5.7346e-01, -1.5702e-01, -1.6719e+00, -7.7988e-01, -1.2603e-01,\n","          1.0296e+01,  1.0273e+00, -7.1156e-01, -1.2379e+00, -1.2447e+00,\n","         -1.5755e+00,  6.5485e-01,  9.0634e-01, -2.3583e+00, -1.7900e+00,\n","          1.6895e+00, -1.6122e+00, -8.9953e-01, -2.3482e-01, -8.5006e-01,\n","         -1.9803e+00, -1.4193e+00, -2.1875e+00,  1.8492e-01, -1.1960e+00,\n","          1.3748e+00,  7.1611e-01, -8.8280e-01,  7.0999e-01, -7.6975e-03,\n","         -1.7594e-01,  1.3916e+00, -2.3489e-01, -2.2546e-01, -6.2421e-01,\n","         -3.9385e-01, -2.1582e-01,  1.4136e+00,  2.8244e+00,  8.2774e-01,\n","         -2.2537e+00,  2.3517e+00, -9.3444e-01,  2.7509e+00, -5.0106e-01],\n","        [-7.7509e-01,  2.3786e+00,  1.0393e+00,  2.2256e-01,  1.2429e+01,\n","         -3.8698e-01, -8.4925e-01, -1.2486e+00, -8.6237e-01,  1.8618e+00,\n","         -1.6014e+00, -1.7451e+00,  1.0277e+00, -2.6534e+00, -1.4562e+00,\n","          2.0938e-02, -1.7953e+00, -3.9200e+00,  1.5601e-01, -1.8127e+00,\n","          1.6777e+00,  1.6623e-01,  1.2636e+00,  1.0862e+00, -8.4228e-02,\n","         -1.8413e-01, -2.7224e+00, -1.9877e+00,  7.9630e-01,  4.7954e-01,\n","         -1.6851e+00,  2.5358e+00,  1.1757e+00, -3.4451e+00, -7.5106e-01,\n","          4.5712e-02,  3.5413e+00,  1.4451e+00,  2.9294e-01, -5.0512e-01,\n","          1.3420e+00,  2.9924e+00, -1.3798e+00, -8.0758e-01, -2.5698e-01,\n","         -2.6729e-01, -1.3520e+00, -2.2458e+00, -1.6089e+00,  2.2814e+00],\n","        [-2.2549e-01,  4.5539e+00, -1.6704e+00,  1.5615e-01,  1.7362e+00,\n","          4.2150e-01, -3.4090e+00, -2.0391e+00,  5.2934e+00,  1.2594e-01,\n","         -7.6814e-01, -3.4193e+00,  1.1377e-01,  9.7224e-01, -1.6365e+00,\n","          1.6876e+00, -5.8061e-01, -5.8678e+00, -1.6515e+00, -2.2388e+00,\n","          8.1790e-01, -3.1675e-02, -2.4660e+00,  5.7746e+00, -2.0108e+00,\n","         -4.5002e+00, -1.4760e+00, -2.6990e+00,  6.7533e-01,  1.4897e+00,\n","         -9.1011e-01,  4.8608e+00, -3.8636e-01, -1.8392e+00,  4.7374e+00,\n","         -3.8082e+00,  1.8379e+00,  1.3052e+01, -2.4007e+00, -4.1858e+00,\n","          3.4365e+00,  1.5904e+00, -5.5558e-01,  2.3896e+00, -9.3912e-02,\n","         -2.8851e+00,  1.0028e+00, -5.1819e+00, -2.5077e+00,  5.3250e+00],\n","        [ 8.1171e-01, -1.6495e+00,  1.2077e+00, -1.2466e+00, -2.8345e+00,\n","          1.4188e+00, -1.2594e+00,  1.5625e-01, -1.2621e+00,  1.4721e+00,\n","         -3.2092e+00, -1.0497e+00,  8.7176e-01, -2.8461e+00,  1.5553e+00,\n","          5.2088e-01,  1.1329e+00, -2.1653e+00,  2.5546e+00, -1.0303e+00,\n","         -2.5881e-01,  9.9187e-01,  1.1693e+00, -1.5685e+00, -5.7179e-02,\n","         -1.7675e-01, -1.1997e+00,  1.1649e+01, -2.2960e+00,  5.0899e-01,\n","         -1.6713e+00,  2.3823e+00,  1.4907e+00, -2.9848e+00, -2.3191e-01,\n","          2.5634e+00, -5.5085e-01, -1.0844e+00,  4.5739e-01, -2.0319e-01,\n","          9.6538e-01,  2.2765e+00, -2.6913e+00, -1.0331e+00,  2.5710e-02,\n","         -3.0729e+00, -1.7709e+00, -6.7679e-02,  1.4048e+00, -3.6484e-02],\n","        [ 4.0910e-01, -3.1587e+00,  5.2650e+00, -2.8743e+00, -2.1497e+00,\n","          1.2291e+00,  5.7096e-01, -6.0477e-01, -2.5252e+00, -1.5269e+00,\n","          1.4875e+00,  1.2872e+01,  1.0193e+00, -1.5834e+00,  5.6005e-03,\n","         -2.6949e+00,  2.2048e+00, -4.9406e-01,  1.7914e-01, -5.6120e-02,\n","          2.1966e-01,  3.9429e+00, -2.0408e-01, -3.5914e+00, -4.3130e-01,\n","          8.5431e-01, -2.5004e+00,  6.0487e-02,  2.7034e-01, -8.4012e-01,\n","          3.3102e+00, -2.2422e+00,  6.0745e-01, -1.4195e+00, -2.7672e+00,\n","         -4.7967e-01, -1.4204e+00, -3.1686e+00,  5.6029e+00,  1.7500e+00,\n","          1.1328e+00, -9.4922e-01, -7.4509e-01, -2.2763e-01, -7.0419e-01,\n","         -1.2929e+00, -8.9248e-02,  7.0461e-01, -1.6370e+00, -1.3952e+00],\n","        [ 1.7321e+00, -2.8162e+00, -1.7615e-01, -1.3065e+00, -3.0294e+00,\n","          9.5771e-01, -6.3473e-02, -1.5371e+00, -1.9127e+00,  3.8293e-01,\n","         -2.6560e+00,  3.2401e+00,  7.1083e-01, -2.7205e+00,  7.7968e-01,\n","          9.2673e-02,  1.1066e-01, -9.4460e-01, -1.1767e+00, -1.6042e+00,\n","         -5.3962e-01,  3.8142e-01, -8.3827e-01, -3.3243e+00, -8.1024e-01,\n","          2.4252e+00, -1.5007e+00,  1.2526e+01, -9.8088e-01, -9.6855e-02,\n","         -1.6675e+00, -1.8384e+00, -4.7223e-01, -1.9655e+00, -1.5589e+00,\n","          3.2590e+00,  1.2464e-01, -1.6745e+00,  2.6224e+00,  2.3433e+00,\n","          6.8808e-01,  3.8704e+00, -8.9230e-01,  7.5875e-01,  3.3149e-01,\n","         -2.7596e+00, -1.2809e+00,  2.4473e+00,  2.2532e+00, -7.6231e-01],\n","        [ 7.8456e-01, -1.2020e+00,  1.2413e+00,  1.0825e+00, -8.1023e-01,\n","         -1.6455e+00,  1.1473e+00, -1.3135e+00, -9.1759e-01, -2.0318e+00,\n","          1.2271e+00, -5.8845e-01, -1.7399e+00,  4.2847e-01, -2.5983e+00,\n","         -1.9348e+00,  1.4921e+00,  9.6019e+00, -1.9029e+00,  2.8077e+00,\n","          1.0167e+00, -1.5934e+00,  4.5152e-01, -6.7707e-01,  7.1595e-01,\n","          1.7962e+00, -1.1379e+00, -3.1725e+00, -9.2080e-01, -5.2336e-01,\n","          2.4640e+00, -1.9950e-01,  3.5682e-01,  1.5100e-01, -2.3725e+00,\n","          1.1089e-01,  8.8800e-02, -2.1350e+00,  1.0180e+00,  3.1816e+00,\n","         -1.4459e+00, -1.8959e+00,  4.4706e-01,  1.4336e+00,  5.8530e-01,\n","         -1.8303e+00,  1.0292e+00, -1.1404e+00,  1.5813e+00, -1.3877e+00],\n","        [ 1.0000e+00,  7.2839e-01, -7.5906e-01,  3.7957e+00, -1.1914e+00,\n","         -7.9110e-01,  9.6220e-01, -1.6644e+00, -1.8910e+00,  2.1838e-01,\n","         -2.7447e+00,  1.6568e+00, -2.6873e+00,  5.3628e-02, -8.7071e-01,\n","         -5.3331e-01, -2.2239e+00, -4.8827e-01,  1.5451e+00,  3.1830e+00,\n","          1.3302e+00, -5.7490e-01, -1.0932e+00, -9.7988e-01,  2.7901e+00,\n","          4.1048e+00, -1.2251e+00, -2.5515e+00, -2.2333e+00,  2.0105e+00,\n","          1.2819e+00, -1.2592e+00,  4.2185e-01, -1.5062e+00, -4.0330e-01,\n","          2.7587e-01, -2.1548e-01, -2.3923e+00,  2.8714e+00,  1.6377e+00,\n","         -6.7564e-01, -1.0608e+00, -2.2731e+00, -1.0703e-01, -1.1879e+00,\n","         -2.4164e+00, -2.3137e+00,  1.1270e+01, -6.6243e-01, -1.0945e+00],\n","        [ 1.4317e+00, -2.7198e-01, -5.2204e-01, -6.9673e-01,  2.7603e-01,\n","         -3.8903e-01, -1.3567e+00, -4.4072e-01,  3.4273e+00, -7.0261e-01,\n","          2.2811e+00, -8.8606e-01,  3.5192e-01,  4.4579e-01, -3.3432e-01,\n","         -8.6085e-01, -1.5822e+00,  3.1482e-01, -9.7025e-01, -8.7176e-01,\n","          1.8669e+00,  6.6039e-01, -3.5163e-01, -3.0380e-01, -1.9796e+00,\n","         -1.8270e+00, -7.2864e-01, -2.2668e+00,  1.5641e-01, -9.9217e-01,\n","         -1.0305e+00, -2.2717e-01, -6.4868e-01, -9.3217e-01, -7.9197e-01,\n","         -2.1493e+00,  7.2984e-01,  2.2669e+00, -6.5050e-01, -1.0058e+00,\n","          7.3059e-01, -1.4705e+00,  1.2441e+01,  2.9229e+00,  1.1468e+00,\n","         -2.4095e+00,  1.2646e+00, -1.7739e+00,  1.8105e+00, -7.4993e-01],\n","        [-4.8598e-01, -1.4459e+00,  3.2532e+00, -5.6684e-01, -2.1628e+00,\n","          6.6011e+00,  4.1766e-01,  6.5956e-02, -1.2310e+00, -8.4925e-01,\n","         -1.3161e+00,  6.1617e-01, -3.3759e+00, -2.3014e+00, -7.2040e-01,\n","         -1.6959e+00,  1.3964e+00, -8.1289e-01,  6.6154e-01, -2.0962e+00,\n","         -8.9142e-01, -2.2285e-01, -4.6310e+00, -1.2435e+00, -1.5798e+00,\n","         -2.4145e+00,  1.4613e+01,  8.4643e-01, -3.4327e+00,  3.4055e+00,\n","         -1.8976e+00, -4.1780e-01,  5.4761e-01,  6.6192e+00,  9.5667e-01,\n","          1.0600e+00, -2.2762e+00,  1.0318e-01,  6.2339e-01, -1.6908e+00,\n","         -1.6565e+00,  2.0771e-02, -2.3533e+00,  1.9214e+00,  3.4903e+00,\n","         -2.4768e+00, -2.0743e+00, -6.2089e-01,  1.3405e+00,  2.5316e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([46, 12, 45, 29, 17, 24, 10,  4, 37, 27, 11, 27, 17, 47, 42, 26],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7345, 10.8447, -0.5565,  ..., -1.7156, -2.3140,  2.6534],\n","        [-0.0457,  4.8886, -0.3725,  ..., -0.7604, -0.7102,  3.3201],\n","        [ 5.9227, -3.5413,  1.5973,  ...,  6.1664,  1.1244, -1.5320],\n","        ...,\n","        [ 2.1172, -0.2009, -0.9455,  ..., -2.1100,  0.5007, -0.5919],\n","        [ 1.7846, 16.2501,  1.0372,  ..., -1.5877, -3.4015,  1.6683],\n","        [ 1.0357, -4.2645,  3.9510,  ..., -0.5525,  2.1831, -0.5647]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 385/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-8.7290e-02,  4.0998e-01,  1.4646e+01,  ..., -5.3535e-03,\n","         -1.4198e+00, -1.1769e+00],\n","        [ 1.6072e+01, -8.1831e-01, -9.5741e-01,  ...,  4.2646e+00,\n","          2.1537e+00, -1.4224e+00],\n","        [ 2.9399e+00,  4.9263e-01, -3.8335e-01,  ..., -7.7479e-01,\n","          4.5432e-01,  1.2501e+00],\n","        ...,\n","        [-1.6647e+00, -2.6957e+00,  1.4191e+01,  ..., -1.9263e+00,\n","          1.9734e+00,  1.0487e+00],\n","        [-2.3868e+00, -2.1997e+00, -1.6375e+00,  ..., -2.2027e+00,\n","         -2.2307e+00,  8.5270e-01],\n","        [ 1.5831e+01,  2.8936e-01, -2.2032e+00,  ...,  2.6773e+00,\n","          2.2182e+00, -1.5957e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 2,  0, 36, 46,  4, 46, 21, 35, 30, 46, 26, 48, 13, 34, 41, 18, 33, 21,\n","        13, 42,  7, 32,  7, 30, 35,  5,  4, 13, 36, 26, 17, 44, 13,  8, 47, 49,\n","        42,  5, 26, 22,  1, 47, 47, 11, 28, 37, 47,  2,  9, 22, 13, 29, 26, 20,\n","        12, 45, 12,  5, 22, 39, 17, 40, 15, 42,  8,  4, 39, 22,  2, 41, 43, 46,\n","         0,  1, 16, 24, 23, 40, 33, 23,  1, 49, 14, 31, 11, 32, 35, 24, 10,  5,\n","        26, 40, 16, 41, 11,  7, 10, 13, 34,  6,  0, 29, 38, 41, 14, 14, 14, 46,\n","        25, 34, 37, 45, 12, 13, 19, 33, 20,  1,  1, 12, 43,  9, 19, 17, 16,  2,\n","        45,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0798,  0.3634, -0.9233,  ...,  0.5732, -0.1801, -0.9234],\n","        [-1.3923, -0.2433, -1.4553,  ..., -2.8978, -2.0493,  0.8380],\n","        [ 1.9708, -0.6894,  3.3286,  ..., -0.3536, -2.8636, -0.8727],\n","        ...,\n","        [-2.2716,  3.0024, -1.4866,  ..., -4.0333, -2.4707,  2.2697],\n","        [-2.9438,  0.1096,  0.0887,  ..., -2.6215, -3.5649, -0.7976],\n","        [ 0.1591, -1.0239,  0.6504,  ..., -1.5058,  1.8952, -1.6993]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7, 28, 16, 27, 38, 41, 39, 41, 48, 34, 14, 12, 48,  6, 48, 36, 45,  5,\n","        21, 40, 29, 27,  3, 28, 36, 45, 25, 42, 30, 49, 14, 40, 29, 27,  3, 34,\n","        46, 11, 24,  2, 20, 21,  7, 22, 18, 23,  3, 31, 38, 20,  0, 10, 43, 38,\n","         7, 20, 39, 10,  9, 45, 31, 31,  8,  6, 29, 39, 25,  6, 24, 40,  4, 47,\n","        32, 35, 15,  3, 49, 43, 14, 35, 35, 13, 30,  9, 20, 21, 24, 42, 19, 38,\n","        17,  3,  9, 31, 40,  0, 10, 25, 24, 18,  9, 27, 36, 11, 18, 41, 36, 44,\n","        26, 15, 25, 16, 27, 49, 28, 24, 27, 31, 37, 19, 47, 10, 25, 15,  5, 37,\n","        31, 10], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.4262, -2.6622, -0.9749,  ..., -0.6432, -1.0650,  0.4054],\n","        [ 3.3324, -3.2368,  4.6933,  ..., -0.3798, -1.1239,  0.3216],\n","        [-0.8067, -2.0439,  1.2220,  ..., -1.5633, -0.8282, -1.0075],\n","        ...,\n","        [-1.1181, -2.0993, -1.6295,  ..., -3.8263, -1.2761, -1.6370],\n","        [ 0.5547, -1.7311,  4.3383,  ..., -1.0489, -0.9620, -2.2685],\n","        [ 0.6378, -0.2649,  1.9415,  ..., -2.9960,  2.9804, -2.5875]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([14, 16, 12, 30,  4, 28,  1, 17, 22, 29,  8, 23, 41, 33, 32, 17,  4, 31,\n","        37,  4,  7,  3, 23,  8, 27, 44,  1, 49, 18, 17,  6, 28, 41, 27, 35,  9,\n","        48, 35, 49, 21, 10, 36,  8, 45, 16, 15,  5, 30, 22, 37,  1, 38, 19, 16,\n","        46, 40, 29, 17, 11, 37, 22, 30,  0,  0,  9, 42, 43, 32,  2, 23, 33,  9,\n","        25, 32, 24, 32, 14, 26, 20,  7, 17, 27, 15,  8, 20, 18,  2, 47, 32, 11,\n","        36,  1, 31, 23, 30,  2, 16, 19, 25, 27,  3, 26, 29, 37, 43, 44, 29,  6,\n","        44, 47, 18, 12, 19, 44,  3, 11, 33, 15, 42,  4, 19, 33, 24, 48, 20, 28,\n","        30, 10], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-7.3861e-01, -1.2754e+00,  1.1998e+01,  7.7607e-01,  3.3605e-01,\n","          2.0735e+00, -1.4946e+00, -4.3861e+00, -2.0742e+00,  9.9861e-01,\n","          1.3258e+00,  8.3455e-01, -3.5605e+00, -8.7516e-01, -1.1505e+00,\n","         -2.4425e+00,  1.6387e+00, -1.0343e+00, -5.5875e-02,  3.5489e+00,\n","         -7.4815e-01,  6.5764e-01, -6.7001e-01, -2.8870e+00,  2.0753e+00,\n","          2.2556e+00,  3.1858e+00,  3.0763e-01, -2.5051e+00,  6.2658e-01,\n","         -6.3311e-02,  7.1944e-01,  4.2133e-01,  1.8652e+00, -2.7198e+00,\n","         -2.7731e+00, -2.9078e+00, -2.0971e-01,  1.9142e+00, -1.0933e+00,\n","          1.7524e-02, -2.9838e+00, -1.4467e+00,  1.2893e+00,  8.8575e-02,\n","         -2.4770e+00,  1.4840e+00,  1.0805e-01, -9.0180e-01, -1.5717e+00],\n","        [-1.3029e+00,  5.0867e+00, -5.6098e-01, -1.4539e+00, -1.0371e+00,\n","          9.0981e-01, -5.2976e-01, -7.9554e-01,  2.4565e+00, -1.5533e+00,\n","         -2.0596e+00, -8.4997e-01, -1.5522e+00,  1.5730e+00, -3.9253e-01,\n","         -1.7459e-02,  1.0469e-01, -3.1700e+00,  1.7266e+00, -9.3504e-02,\n","          3.0514e-02, -9.0938e-01, -1.2549e+00,  4.1040e-01, -6.1596e-01,\n","         -3.1156e+00,  5.4566e-04, -5.2419e-01, -1.9298e+00,  1.4510e+00,\n","         -9.7316e-01,  2.8754e+00,  1.8511e+00,  2.8544e+00,  1.0856e+01,\n","         -1.8574e+00,  5.1016e-01,  3.8801e+00, -1.2470e+00, -2.7790e+00,\n","         -4.3497e-01,  4.0949e-01, -3.4344e+00,  2.0104e+00,  1.1458e+00,\n","         -1.2212e+00,  4.3434e-01, -3.0377e+00, -3.6948e+00,  1.1657e+00],\n","        [-3.2177e+00, -4.8899e-01,  6.1563e-01, -9.3476e-01,  1.6097e+00,\n","          1.4241e-01, -2.0640e+00,  1.8263e-01, -3.1823e+00,  1.0675e+01,\n","         -2.5622e-01,  2.1693e+00, -7.8967e-01, -2.6260e+00, -2.4959e+00,\n","         -1.8651e+00, -1.1899e+00,  3.7148e-01,  3.3783e+00,  1.1389e+00,\n","          1.4999e-01,  8.4518e-01, -2.8213e-01, -2.6980e+00,  2.1330e+00,\n","          1.7690e+00, -2.0331e+00, -9.9532e-01,  1.3854e+00,  1.8124e+00,\n","         -1.7059e+00,  1.9011e+00,  2.1196e+00, -1.7019e+00, -5.3296e-01,\n","         -2.3263e+00, -2.5015e+00, -8.7863e-01,  5.1974e-01, -1.2205e+00,\n","          3.4644e-01,  4.3146e+00, -1.1879e+00, -2.3426e+00,  1.4957e+00,\n","          2.1127e+00,  1.7027e+00, -9.7315e-02, -1.4992e+00, -1.9737e+00],\n","        [-8.8690e-01,  9.7360e-02, -2.0937e+00, -7.2243e-01, -1.3563e-01,\n","          3.8521e-01, -8.1313e-01, -1.1529e+00, -1.2675e+00, -2.2478e+00,\n","         -1.9518e+00, -8.1465e-01, -1.5676e+00,  3.0589e+00,  8.9159e-01,\n","          1.2055e+01, -4.0772e-01, -2.2630e+00, -9.4890e-01, -1.1355e-01,\n","          5.2773e-01,  1.6699e-02, -1.0001e+00,  2.9831e+00,  1.3383e-01,\n","         -4.8058e-01, -2.5348e+00,  1.1213e+00, -4.0808e-01,  4.8838e+00,\n","         -2.4325e+00,  8.1342e-01,  9.9849e-01, -9.3405e-01, -4.5600e-01,\n","         -9.8924e-01,  3.5629e-01,  5.8203e-01, -4.9068e-01, -1.0378e+00,\n","          6.0097e-01,  2.1557e-01, -2.3576e+00,  1.6548e+00, -3.9248e-01,\n","         -1.0130e+00, -1.2498e+00,  1.1739e-01, -2.2953e+00,  3.7451e+00],\n","        [-7.9596e-01, -2.4605e+00,  8.6929e-01, -1.6973e+00, -1.4222e+00,\n","          3.1181e-01, -4.4153e-01,  3.1033e-01, -1.9873e+00,  1.2302e+00,\n","          1.8888e+00,  9.9966e-01,  9.4129e+00, -2.2726e+00,  5.1459e+00,\n","         -1.1004e+00, -2.1684e+00, -1.9756e-02, -1.2635e+00, -2.1169e+00,\n","         -8.5787e-02,  1.1905e+00,  4.0348e+00, -2.8844e+00, -3.4839e-01,\n","         -1.4574e-01,  1.1280e-01,  3.8952e-01,  8.1887e-01, -1.1781e+00,\n","         -1.1807e+00,  7.8313e-02,  3.5577e+00, -2.6376e+00, -2.3343e+00,\n","          2.3819e+00, -7.3940e-01, -5.4088e-02,  8.0799e-01,  2.5143e-01,\n","          2.0410e+00,  7.0388e-02,  5.2305e-02, -1.9520e-01,  1.4684e+00,\n","         -9.7269e-01, -5.8188e-01, -2.2093e+00,  1.0041e-01, -2.6862e+00],\n","        [ 6.3793e+00, -2.8706e+00,  2.9009e+00,  5.7644e-01, -2.7180e+00,\n","          2.6746e-01, -3.1718e+00, -1.8447e+00, -2.5120e+00, -1.1838e+00,\n","         -4.8706e-01,  5.8206e+00, -2.8448e+00, -2.4983e+00,  9.5865e-01,\n","         -2.4785e+00,  1.2537e+01, -1.7374e+00, -2.2280e+00, -2.4648e+00,\n","          1.3249e+00, -1.4946e+00, -1.0632e+00, -1.5000e+00,  3.6714e+00,\n","          4.6139e+00,  4.5138e-01, -4.7877e-01, -1.4980e+00, -7.6805e-01,\n","          5.1276e-01, -1.3835e+00,  3.0159e-01, -2.5823e-01, -3.1953e+00,\n","          4.9161e+00,  1.5498e-01, -2.7369e+00,  4.9176e+00,  2.1008e+00,\n","         -1.8402e+00, -1.2911e+00, -1.6059e+00, -1.1345e+00,  4.2423e-01,\n","         -3.3621e+00, -3.4113e-01,  3.6449e+00, -1.7535e+00,  9.1687e-01],\n","        [ 1.7383e+00, -1.2274e+00,  6.9913e-01, -6.9123e-01,  1.2252e+00,\n","         -1.7104e+00, -8.8817e-01, -7.2988e-01, -9.6347e-01,  1.5164e+00,\n","         -1.2930e+00, -3.2215e-01,  1.1199e+01, -3.9888e+00, -5.9189e-01,\n","         -2.7310e+00, -3.4301e+00, -1.6919e+00, -2.0901e-01,  1.6609e-01,\n","         -7.9932e-01,  2.3367e-01,  3.1193e+00, -2.5552e+00, -4.3244e-02,\n","         -7.3620e-01, -8.5310e-01,  3.9319e+00,  9.6817e-01, -4.9153e-01,\n","         -1.3565e+00, -6.3716e-01,  9.2148e-01, -3.4437e+00, -1.4242e+00,\n","          2.1644e+00, -1.1818e+00,  9.9456e-01,  2.4659e+00,  1.8856e+00,\n","          1.2216e+00,  2.5211e+00,  6.4909e-01, -7.5443e-01, -7.2882e-01,\n","          1.9948e+00, -3.5530e-01, -1.1410e+00, -3.0162e-01, -2.2118e+00],\n","        [ 4.1860e+00,  6.9811e-01,  6.6787e-01,  1.3361e+01, -1.5996e+00,\n","         -8.1937e-01,  3.2736e-01, -3.1343e+00, -5.5859e-01, -4.3458e-01,\n","         -1.7563e+00, -1.2706e+00, -2.5737e+00, -1.2636e-01, -2.2143e+00,\n","         -2.2002e+00,  2.5909e+00, -1.2660e+00, -6.7318e-01,  5.8545e+00,\n","          2.7258e-01, -1.3226e+00, -1.0918e+00,  2.1516e-02,  3.3403e+00,\n","          1.5577e+00,  1.4084e+00, -2.7403e+00, -2.5645e+00, -5.0578e-01,\n","          3.3148e+00, -1.5259e+00, -1.3858e+00,  3.6524e-01, -1.8894e+00,\n","         -4.6944e-01, -2.6839e+00, -6.4510e-02,  2.3991e+00,  3.6525e+00,\n","         -2.4384e+00, -1.8343e+00, -2.1326e+00, -3.5213e-01, -2.4368e+00,\n","         -2.4923e+00,  1.6073e+00,  2.7348e+00, -6.9683e-03, -2.5146e+00],\n","        [ 3.0693e+00, -1.8789e-01, -1.1454e+00, -6.8464e-02, -1.2184e+00,\n","          1.3321e+00, -2.8996e+00, -1.3595e+00,  1.2240e+00, -9.5936e-01,\n","          3.7487e+00, -1.7309e-02, -1.4763e+00, -3.7683e+00, -2.0895e+00,\n","         -2.8289e+00,  5.4205e-03,  7.9757e-01, -2.6879e+00, -2.4436e+00,\n","          9.4628e-01, -6.3403e-01, -4.5313e-01,  5.2013e-01, -9.8629e-01,\n","         -7.7863e-01,  8.7225e-01,  1.7817e+00, -2.1607e+00,  2.8767e-01,\n","         -4.2846e-01, -1.3262e+00,  3.1028e-01, -1.1619e+00, -1.2339e+00,\n","         -2.5713e+00, -5.7883e-01,  1.5295e+00,  1.4421e+00,  1.8754e+00,\n","          2.0688e+00,  8.4280e-01,  3.5446e+00,  1.0750e+00,  6.5486e-01,\n","         -2.6551e+00,  7.3019e-01, -1.4081e+00,  1.2855e+01, -1.4935e+00],\n","        [-2.9274e+00, -2.6826e+00, -1.4488e+00, -1.5575e+00,  1.9589e-01,\n","         -1.5464e-01, -1.1312e+00,  3.1951e+00, -2.2279e+00,  9.3841e-03,\n","         -1.2019e-01, -2.7741e-01,  3.6185e+00, -8.0252e-01, -1.8776e+00,\n","         -2.9312e-01, -9.4892e-01, -9.8365e-02,  3.1642e+00, -7.6020e-01,\n","         -8.3590e-01,  1.7545e+00, -4.6559e-01, -7.3319e-01, -1.4495e+00,\n","         -1.3819e+00, -1.5680e+00, -3.3254e-02,  1.4234e+01, -1.0119e-01,\n","          2.2981e+00,  1.8869e+00,  1.9458e+00, -1.9658e+00, -1.2703e+00,\n","         -1.1417e+00, -1.5671e+00,  2.0272e+00, -1.1439e+00, -6.2950e-01,\n","          2.2538e+00,  5.9356e+00, -7.7808e-01, -2.8323e+00, -1.1746e+00,\n","          1.5560e+00,  1.2606e-01, -3.3232e+00, -2.8202e+00, -8.5900e-01],\n","        [ 1.7125e+00,  3.9680e-02, -3.5966e-01, -1.6005e+00,  8.3398e-01,\n","         -8.2526e-01, -2.2000e+00, -3.7866e+00, -1.0098e+00,  2.8397e-02,\n","         -3.6351e-01,  3.6831e-01, -9.0685e-01, -7.2664e-01, -1.6828e+00,\n","          2.6584e-01, -1.2956e+00,  4.6853e-01,  2.7305e-01, -2.1152e+00,\n","          3.1517e+00,  3.5591e-01, -6.9418e-01,  1.2016e+00,  2.3063e+00,\n","         -1.0974e+00, -1.3561e+00, -1.2308e+00, -2.0037e+00,  1.5138e+00,\n","          1.6123e+00,  2.3543e+00,  1.8879e+00, -3.7927e+00, -1.0196e+00,\n","         -1.0480e+00,  9.0242e+00,  5.2818e-01,  5.0400e-01, -1.4381e+00,\n","          9.0990e-01,  1.0020e+00,  1.5808e+00,  5.1216e-01,  1.5516e+00,\n","         -3.1452e+00, -1.1829e-01,  1.0560e+00, -1.1996e+00,  2.2683e+00],\n","        [-1.1796e+00, -1.3243e+00, -2.0876e-01, -7.2413e-01, -2.1484e+00,\n","          4.3733e-02, -9.6767e-02, -1.5655e+00, -7.5480e-01,  5.1196e-01,\n","          5.8867e+00, -1.0456e+00, -1.7306e+00, -1.9525e-01, -1.3146e+00,\n","         -1.8006e+00, -2.1973e+00,  1.2775e+01,  8.5300e-01,  9.5234e-01,\n","         -6.3242e-01, -1.8469e+00, -8.5335e-01, -1.0752e+00, -3.8963e-01,\n","          8.7775e-01, -4.6946e-01, -9.5315e-01, -1.6995e+00,  9.6223e-01,\n","          6.4260e-01, -3.3246e-01,  1.2365e+00, -1.0343e-01, -1.8337e+00,\n","         -1.0550e+00, -7.8139e-01, -1.5322e+00, -1.5467e-01, -5.8320e-01,\n","         -1.2046e+00, -1.4684e+00,  3.6172e+00,  6.8343e-01,  4.0720e+00,\n","         -3.2218e-01,  1.4436e+00,  1.8794e-02,  2.0295e+00, -1.9946e+00],\n","        [ 2.8558e+00,  3.2447e-01,  3.6170e-01,  1.0708e+00, -1.1684e+00,\n","         -3.3293e-01,  1.8525e-02, -3.5316e+00, -1.6685e+00, -2.2385e+00,\n","         -1.9995e+00,  7.9205e-01, -2.1946e+00, -9.4338e-01, -2.1423e+00,\n","         -2.0781e+00,  1.1542e+00,  2.9218e-01, -1.2929e-01,  3.8460e+00,\n","          1.5534e+00, -2.4497e-01, -2.0026e-01, -1.9538e+00,  1.4924e+00,\n","          1.1784e+00, -1.6849e+00, -6.3587e-01, -1.7118e+00,  4.5546e-01,\n","          1.1797e+01, -1.2246e+00, -1.0371e+00, -3.5052e+00, -1.8880e+00,\n","          1.2616e+00, -1.1743e+00,  3.5736e-02,  2.6052e+00, -8.2394e-02,\n","          3.4927e+00,  6.2480e-01, -2.7336e+00, -5.0432e-01, -1.2221e+00,\n","         -9.7207e-01,  1.3811e+00,  2.4993e+00,  4.5028e-01, -1.7391e-01],\n","        [ 1.3168e+00,  1.6971e+00, -8.2175e-01, -1.9324e+00, -1.6069e+00,\n","          1.1982e+00,  5.8557e-01, -2.4591e+00,  1.0677e+01, -1.9876e+00,\n","         -1.6311e+00, -6.4126e-01, -5.9287e-01,  6.0007e+00, -1.6442e+00,\n","         -2.1745e-01, -2.2403e-01, -2.5269e+00, -1.2601e+00,  7.7797e-01,\n","          2.8155e+00,  1.2513e+00, -7.6430e-01,  3.3233e+00, -1.1870e+00,\n","         -2.4270e+00, -1.4569e+00, -2.1900e+00, -2.7106e+00, -1.7785e-01,\n","         -2.5458e+00, -6.4706e-01, -7.0366e-01,  1.1602e+00,  2.3962e+00,\n","         -1.6804e+00,  9.5331e-01,  1.7516e+00,  6.9158e-01, -2.4163e+00,\n","          1.0333e+00, -1.2396e-01,  9.4054e-01,  5.0406e+00,  6.5778e-01,\n","         -1.5869e+00, -1.9255e+00, -1.8828e+00, -1.2275e+00,  2.1203e+00],\n","        [-2.7783e+00,  3.6435e+00, -7.8068e-01, -2.5013e+00,  4.6104e+00,\n","         -1.2069e+00, -2.5246e+00, -6.8349e-01,  4.3310e+00, -1.4482e+00,\n","         -2.2995e+00,  3.7448e-01, -2.3935e+00,  2.3788e+00, -1.2664e+00,\n","         -5.5616e-01, -1.5404e+00, -4.0239e+00, -1.0704e+00, -2.4736e+00,\n","          1.1730e+00, -2.7967e-01, -4.4849e+00,  3.6546e+00, -1.0243e+00,\n","         -3.1627e+00, -1.3111e+00, -1.6489e+00, -1.0862e+00,  3.2702e+00,\n","         -2.8536e+00,  2.4806e+00,  1.5685e+00, -1.0745e+00,  3.7508e+00,\n","         -1.7675e+00,  2.0616e+00,  4.8419e+00,  3.6946e-01, -2.0128e+00,\n","          9.4282e-01,  2.2640e+00, -1.7981e+00,  1.6653e+00,  1.1899e+00,\n","         -1.0439e+00, -8.3613e-01, -3.2762e+00, -1.9399e+00,  1.1855e+01],\n","        [ 3.7423e-01, -1.5075e+00,  3.7166e+00, -1.3602e+00, -2.0145e+00,\n","          1.3194e+00,  1.4579e+01, -1.4129e+00, -1.1779e+00, -3.4933e+00,\n","         -8.2041e-01,  1.0963e+00, -1.3458e+00, -6.9256e-01, -1.2930e+00,\n","         -1.2369e+00, -2.9981e-01,  2.1913e+00, -1.2911e+00,  1.3755e+00,\n","          1.0365e+00, -9.2876e-01, -1.7631e+00, -2.2691e+00,  5.0335e-03,\n","         -7.8583e-01,  2.5120e+00, -1.2127e-01, -1.4451e+00, -1.0149e+00,\n","          4.3441e-02, -2.6857e+00, -1.4013e+00,  5.5978e+00, -1.2056e+00,\n","          5.4477e+00,  4.7202e-01, -3.3617e+00,  5.2468e-01,  8.1960e-01,\n","         -3.0940e+00, -6.9694e-01, -1.1277e+00,  2.5187e+00, -4.3119e-01,\n","         -2.2679e+00, -1.0361e+00,  1.1121e+00,  3.5305e-01, -4.6898e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 2, 34,  9, 15, 12, 16, 12,  3, 48, 28, 36, 17, 30,  8, 49,  6],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7368, 10.8423, -0.5598,  ..., -1.7112, -2.3172,  2.6474],\n","        [-0.0444,  4.9099, -0.3711,  ..., -0.7606, -0.7184,  3.3269],\n","        [ 5.9204, -3.5430,  1.5878,  ...,  6.1737,  1.1193, -1.5356],\n","        ...,\n","        [ 2.1184, -0.1971, -0.9437,  ..., -2.1143,  0.4991, -0.5942],\n","        [ 1.7882, 16.2648,  1.0386,  ..., -1.5870, -3.4037,  1.6554],\n","        [ 1.0372, -4.2653,  3.9508,  ..., -0.5462,  2.1707, -0.5658]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 386/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.4336, -0.2478,  2.0100,  ...,  1.1859,  0.0141, -1.3641],\n","        [-2.2840, -1.8160,  5.7745,  ..., -2.5398, -0.4483, -1.5138],\n","        [-2.2434, -0.1782,  0.2163,  ..., -3.7237, -2.4784,  4.7289],\n","        ...,\n","        [ 0.0250, -2.6865,  2.7627,  ..., -0.6296,  1.0405, -0.8797],\n","        [-1.4297,  0.3012, -1.8535,  ..., -0.8655, -1.6638,  2.9473],\n","        [-3.0152, -3.3799, -1.2537,  ..., -0.6459, -0.6808, -0.8625]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([21, 33,  4, 41, 24, 24, 25, 17,  1,  7, 32, 17, 10, 16, 36, 42, 14, 20,\n","        37,  8,  0, 42, 45, 48, 13, 28, 32, 33, 47, 14, 47, 47, 30, 28, 38, 20,\n","        28,  8, 46, 48,  4, 31,  1,  0,  9, 29, 34, 44, 23, 46, 25, 31, 47, 37,\n","        15, 47, 44, 45,  1, 40, 31, 29, 26, 29, 36, 13, 39,  1, 36, 14, 35, 26,\n","        46, 33, 31,  6, 11, 41, 48, 34, 38,  7, 40, 47, 36,  5,  7, 30, 13, 22,\n","        30, 39, 20, 20, 45,  8, 23,  8, 23, 29, 38, 18, 25, 49, 21, 35, 26, 32,\n","        12, 17, 34, 16, 18,  2, 14, 48, 27, 20, 27,  3,  5, 10, 40, 18,  0, 10,\n","        15, 41], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.2500, -0.9714,  1.0756,  ..., -0.0568,  1.7927,  0.0052],\n","        [ 0.9838,  1.2262, -2.9759,  ..., -3.0835,  0.4496,  3.6793],\n","        [-1.8382, -1.7799, -0.8644,  ..., -0.8611,  0.0963,  0.6324],\n","        ...,\n","        [ 1.1436, -2.7847,  2.6736,  ...,  3.1491, -1.5688, -0.1768],\n","        [-0.3634,  2.6429, -0.0568,  ..., -0.9027, -0.7873, -0.0601],\n","        [-2.2501, -1.1946, -1.0091,  ..., -0.7124, -1.1260, -0.5217]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20,  8, 41, 24, 30, 16, 42, 38, 14, 30, 20, 15,  9,  8, 12, 49, 40, 11,\n","        36,  0, 19,  4, 40,  8, 32, 25, 19, 45, 42, 37,  2, 19, 10,  4, 42, 16,\n","         7, 44,  3,  3,  9,  9, 27,  3, 11, 12, 14, 21, 49, 22,  2, 24, 15, 18,\n","        21, 35, 21,  1, 31,  3,  6,  3, 45,  5, 16, 23, 19,  3,  8, 41,  2,  6,\n","        17, 38, 32, 16, 27, 19, 39, 33, 24, 15, 35,  1,  4, 37, 14,  6, 29, 12,\n","         2, 26, 11, 36, 22, 23, 26, 31,  0, 12, 44, 17, 25,  1, 19, 17, 46, 29,\n","        15, 17,  7, 10,  1,  6, 22,  9, 22, 28, 43, 13,  1,  3,  6, 27, 40, 35,\n","        34,  7], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.1169,  2.8828,  0.0965,  ..., -0.9570,  0.7349,  2.8538],\n","        [-2.5369,  1.6107, -0.1401,  ..., -1.5261, -1.9094, -3.0773],\n","        [-1.7295,  3.6580, -0.9402,  ..., -1.1682, -2.5182, 14.9840],\n","        ...,\n","        [ 2.7045,  2.3763,  0.6469,  ..., -1.5154,  2.0289,  1.5926],\n","        [-0.3228,  0.8497, -0.3658,  ...,  0.4344, -0.9559,  3.3418],\n","        [-0.5119, -1.8750, -1.1412,  ..., -4.1067, -1.4335, -1.5769]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([43, 18, 49,  9,  9,  2,  7, 12, 29, 16,  4, 48,  6, 40, 24, 29, 16, 44,\n","        29, 30, 21, 46, 41,  5, 19, 25, 24, 41, 33,  4, 35, 13, 17, 13, 30, 13,\n","        40, 18, 36,  0, 41, 26, 33, 49, 27, 37, 27, 46,  9, 15, 43, 13, 41, 11,\n","        30, 22, 24, 34, 35, 10, 15,  5, 24, 45, 23, 49, 10, 44, 46,  0, 12, 28,\n","        27, 45, 33, 49, 31, 16, 39,  9, 30, 14, 22,  2, 11, 34, 17, 38, 36, 19,\n","        42, 32, 32, 48, 26, 47, 31, 37, 43, 18,  5,  4, 16, 28, 49, 37, 10, 28,\n","         2, 25, 25, 11, 20,  0, 30, 12, 47, 32, 48, 37, 31,  9, 36, 42,  3, 43,\n","        20, 28], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 5.4129e-01, -7.7907e-01,  4.5280e-01, -3.2541e-01, -5.5769e-01,\n","         -3.1667e-03, -4.6477e-01, -1.1413e+00, -8.8204e-01,  8.5318e-01,\n","          1.3237e+01, -1.0325e+00, -7.7347e-01, -1.5895e+00, -1.4270e+00,\n","         -1.9501e+00, -1.2597e+00,  4.1405e+00,  8.4146e-02, -1.2593e+00,\n","         -1.8037e-01, -4.0253e-01, -4.8542e-01, -2.0302e+00, -1.8419e+00,\n","         -1.4813e+00, -4.7834e-01, -1.3262e+00,  4.6128e-01, -1.3262e+00,\n","          8.6980e-01, -8.4362e-01,  6.0135e-02,  1.4421e+00, -1.3916e+00,\n","         -1.5186e+00, -1.6031e+00, -5.6318e-01, -1.1767e+00, -1.7114e+00,\n","          2.7928e-01,  1.9899e-02,  4.7649e+00,  8.9036e-01,  1.8342e+00,\n","         -6.5205e-01,  4.1451e+00, -1.9206e+00,  2.9059e+00, -2.1056e+00],\n","        [ 1.4667e+00,  1.9877e+00, -3.8672e-02, -7.7312e-01, -2.0255e+00,\n","          8.0809e-01,  1.0024e+00, -4.2122e+00,  5.5647e+00, -4.9162e+00,\n","         -3.7185e-01, -1.7204e-01, -1.5720e+00,  6.5980e+00, -2.7010e+00,\n","          1.2011e+00,  1.8874e+00,  1.6676e+00, -2.9502e+00,  3.3992e-01,\n","          5.4012e+00, -2.4783e+00, -4.0439e-01,  2.4426e+00, -1.2229e+00,\n","         -1.2064e-01, -4.0365e+00, -5.8976e+00, -1.8589e+00,  2.0372e+00,\n","          1.9311e-01, -1.0800e+00,  7.0419e-01,  4.5090e-01,  5.9004e-01,\n","         -1.6007e+00,  6.7334e-01,  9.1986e-01, -5.0295e-01, -2.3955e+00,\n","         -6.0721e-01, -3.3822e+00,  2.2326e+00,  1.3039e+01,  2.0718e+00,\n","         -3.0774e+00, -6.7662e-01, -2.0602e+00, -5.0075e-01,  1.9949e-01],\n","        [ 3.3271e+00,  2.3949e-01, -8.4032e-01,  3.2371e+00, -1.1734e+00,\n","         -1.2224e+00, -1.5406e+00, -2.8266e+00, -1.1051e+00,  1.1416e+00,\n","         -2.8842e+00, -1.5347e+00,  2.3611e-01,  3.5555e-01,  4.1994e-01,\n","         -2.2851e-01,  2.2157e+00, -1.0042e+00, -7.7514e-01,  2.1494e+00,\n","          4.1637e-01, -1.1604e-01,  8.8355e+00, -2.5714e-01,  5.2551e+00,\n","          2.7229e+00, -1.8228e+00, -4.2588e+00, -1.1673e+00,  8.3348e-01,\n","          2.0485e+00, -9.2789e-01,  3.4147e+00, -2.5178e+00, -2.5983e+00,\n","         -1.1979e+00, -1.9385e+00, -6.3988e-01,  3.4547e+00,  7.7329e-01,\n","          1.3974e+00, -3.7405e-01, -3.9384e+00, -1.7961e+00, -1.7900e+00,\n","         -9.4252e-01, -3.2509e-01,  1.8815e+00, -2.3563e+00, -1.4170e+00],\n","        [-1.3368e+00, -2.2112e+00, -5.0557e-01, -2.6325e+00, -2.0758e+00,\n","          1.0052e+00, -2.0498e-01, -1.1861e+00,  5.9972e-01, -7.2949e-02,\n","         -6.0030e-01, -9.5890e-01,  2.2088e+00,  9.3895e-01,  1.2988e+01,\n","         -2.1979e-02, -2.0869e+00, -4.1875e-01,  3.4055e-01, -1.9895e+00,\n","          9.0046e-01,  3.3521e-01,  1.6300e+00, -2.0141e-01, -3.6226e-01,\n","         -7.9810e-02, -6.6668e-01,  1.2367e+00, -1.9752e-01, -4.6821e-01,\n","         -1.0528e+00,  1.4148e+00,  1.4860e+00, -6.6355e-01, -1.2964e+00,\n","          1.3058e+00,  7.7408e-02,  3.1934e-02,  3.1945e-01, -1.4677e+00,\n","          8.7696e-01,  4.9755e-01, -1.5466e+00,  1.7758e+00,  3.4872e+00,\n","         -3.2300e+00, -1.0770e+00, -7.1884e-01, -1.0480e+00, -2.2766e-01],\n","        [-8.3652e-01, -1.1201e+00,  3.1198e+00,  1.0091e+00, -1.4393e+00,\n","          3.4760e+00, -1.3519e+00, -2.0645e+00, -1.7463e+00,  1.9850e+00,\n","         -2.4969e+00, -2.0135e+00, -2.7913e+00,  1.5014e+00, -1.8362e+00,\n","          4.6949e-01,  8.3170e-01, -7.1018e-01,  4.7030e+00,  3.1013e+00,\n","         -7.4689e-01,  1.1930e-01, -4.1986e+00, -1.9758e+00,  2.2324e+00,\n","         -1.0066e+00,  1.3569e+01,  1.5442e+00, -4.0550e+00,  2.7352e+00,\n","          9.9144e-01,  4.7354e+00,  2.9009e-01,  2.2751e+00, -1.0655e+00,\n","          8.7349e-02, -3.7854e+00, -1.1381e+00, -1.2359e+00, -2.3515e+00,\n","          2.5343e-01, -3.3473e+00, -2.5717e+00, -2.5058e+00,  1.5388e+00,\n","         -1.3636e+00, -1.2900e+00, -1.0468e+00, -2.2655e-01,  6.9638e-01],\n","        [-6.7035e-01, -3.3480e+00,  9.0712e-02,  2.4403e+00,  5.1236e-02,\n","         -1.8659e+00, -2.8353e-01,  7.1956e-01, -1.0456e+00, -1.7467e-01,\n","         -2.2449e+00,  7.3549e-01, -8.5335e-03, -1.0104e+00, -2.6593e+00,\n","         -3.1358e+00,  7.6585e-01,  1.8337e+00, -7.6279e-01,  1.0923e+00,\n","         -1.1765e+00,  1.3630e+00,  1.9253e+00, -1.9789e+00,  6.4676e-01,\n","          1.4996e+00, -9.5493e-01, -3.2791e+00,  1.2364e+00, -6.7188e-01,\n","          3.3430e-01,  9.7841e-01,  2.2601e+00, -1.3099e+00, -2.1346e+00,\n","         -1.1514e+00, -1.5812e+00, -1.0706e+00,  2.7487e+00,  1.2827e+01,\n","          1.3858e-02,  1.6784e+00, -1.4606e+00, -1.9831e+00, -4.3609e-01,\n","          3.0951e+00, -1.3200e+00, -5.0590e-01,  1.1823e+00, -3.0428e+00],\n","        [ 6.4257e-01,  1.9210e-01,  1.0534e+01,  2.9129e+00, -5.3534e-02,\n","         -1.2257e+00,  1.6445e-01, -3.2425e+00, -1.1341e+00, -1.6332e-01,\n","         -1.3498e+00,  9.8353e-01, -1.3207e+00, -2.6295e+00, -1.9140e+00,\n","         -1.3243e+00,  3.3610e+00, -1.5057e+00, -3.3873e-01,  1.3545e+00,\n","          1.6712e+00, -4.2746e-01, -1.4986e+00, -9.6321e-01,  4.1617e+00,\n","         -1.0876e+00, -4.0333e-02, -1.2024e+00, -1.6912e+00, -3.2070e-01,\n","          3.4733e+00, -2.1564e-01, -1.9574e+00,  6.3367e-02,  7.4581e-02,\n","         -1.5398e+00,  2.9047e-01, -5.1211e-01,  2.1618e+00,  3.4957e-01,\n","          2.3370e-01, -8.0140e-01, -1.8883e+00,  2.1283e-01, -1.7678e+00,\n","         -2.9477e+00,  2.4784e+00, -2.5866e+00,  9.5638e-01, -1.1131e-01],\n","        [-5.2327e-01,  2.4317e+00, -1.9041e+00, -1.7566e-01,  1.2817e+00,\n","         -1.1972e+00, -9.7456e-01, -3.1051e+00,  7.4850e+00, -2.0435e+00,\n","         -2.3924e+00, -2.0598e+00, -1.8216e+00,  3.6559e+00, -5.6350e-01,\n","          5.5740e-01, -2.6008e-01, -3.4972e+00, -8.7107e-01, -2.0279e+00,\n","          3.3110e+00, -8.1638e-01, -2.1095e+00,  1.1679e+01, -1.0315e+00,\n","         -2.0400e+00, -8.8591e-01, -3.4742e+00, -2.3545e+00,  1.4648e+00,\n","         -1.6739e+00,  3.1553e+00,  2.9804e-01,  2.5466e-01,  2.5467e+00,\n","         -2.5148e+00,  3.5012e+00,  5.1041e+00, -7.6421e-01, -2.4245e+00,\n","          4.3344e-01, -2.8829e-01, -1.8273e+00,  1.8972e+00,  1.2319e+00,\n","         -1.8236e+00, -2.2771e+00, -2.6228e+00, -1.4830e+00,  4.4486e+00],\n","        [ 5.0843e+00, -2.0203e+00,  1.7414e-01, -1.4174e+00, -1.6123e+00,\n","         -1.9167e+00,  4.0240e+00, -3.0327e+00, -3.3053e-01, -1.3429e+00,\n","         -2.2665e+00,  9.8441e-01,  1.1240e+00, -1.2484e+00, -1.1354e+00,\n","         -1.9859e+00,  1.0086e+00, -6.6878e-02, -2.8018e+00, -8.7564e-01,\n","          1.8892e+00, -2.0106e+00,  2.8185e+00, -2.2146e+00,  3.1804e+00,\n","          4.9379e+00, -1.9899e+00,  7.7928e-01, -1.8538e+00, -6.6508e-01,\n","          1.1679e-01, -2.2244e+00,  1.1191e+00, -3.6728e-01, -1.9885e+00,\n","          1.0352e+01,  3.5035e+00, -2.5058e+00,  1.9159e+00,  2.6238e+00,\n","         -3.4392e+00,  1.9009e+00, -1.6516e+00, -1.2906e-01,  3.7874e-01,\n","         -1.9462e+00, -2.6102e+00,  2.8276e+00, -1.0983e+00, -5.8208e-01],\n","        [-7.6384e-01,  3.7958e-01,  2.0737e+00, -3.9905e-01,  4.7013e-01,\n","          1.2521e+01, -9.2568e-01, -2.3787e+00, -2.9171e+00,  5.6749e-01,\n","          1.8731e-01,  1.3858e+00, -3.2885e+00, -4.0929e+00, -3.5132e+00,\n","          9.7126e-01,  1.0779e+00, -2.9707e+00, -1.5730e-01, -3.1598e+00,\n","          3.4722e+00,  3.4543e-01, -5.4088e+00, -2.2327e+00, -1.4491e+00,\n","         -2.7787e+00,  2.1793e+00, -6.5056e-02, -8.0953e-01,  4.9475e+00,\n","         -2.4593e+00,  3.1379e+00, -9.6737e-02,  1.0353e+00,  5.1590e+00,\n","         -2.6928e+00, -3.3750e-01,  1.5373e+00,  4.4801e-01, -2.9742e+00,\n","          2.2644e+00,  2.2492e+00, -2.3762e+00, -9.9198e-01,  8.2236e-01,\n","         -2.0754e+00,  8.1822e-01,  1.7068e+00,  7.7237e-01,  2.4892e+00],\n","        [-2.6074e-01, -2.1124e+00,  1.2464e+00, -1.6464e+00, -1.4959e+00,\n","          1.6635e+00, -1.3980e+00, -1.7051e+00,  1.7441e-01, -2.2184e-01,\n","         -1.8329e+00, -2.6687e-01,  2.9127e-01, -1.9814e+00,  2.4157e-02,\n","          1.6440e+00,  6.3266e-01, -1.5513e+00,  1.0060e+00, -2.1068e-01,\n","         -2.0089e+00,  1.2784e+00, -2.1474e+00, -7.3467e-01, -8.9114e-01,\n","         -3.9091e-01,  4.4646e-01,  1.0376e+01,  3.8094e-01,  4.0564e-01,\n","         -8.0813e-01,  5.4464e-01,  2.4564e-01, -2.1153e+00, -2.7109e-01,\n","          4.0587e-01, -3.0682e-01,  8.1179e-01,  1.4621e+00, -9.5939e-01,\n","          6.5596e-01,  4.0312e+00, -2.0178e+00, -5.5332e-01,  4.8690e-01,\n","         -2.0950e+00, -1.1055e+00,  3.8825e-01,  3.2292e-01,  1.7345e+00],\n","        [ 1.2823e+00,  1.1709e+00,  2.0247e+00, -1.0615e-01, -1.6245e+00,\n","          3.4734e-01, -5.3514e-01, -2.9139e+00,  4.8538e-02,  1.7558e+00,\n","         -1.5382e+00,  3.5302e-01,  1.1101e-01, -2.9297e+00, -9.2248e-01,\n","         -9.4779e-01,  1.8814e+00, -1.9322e+00,  3.7993e-01,  5.8832e-01,\n","         -2.3718e+00,  6.1987e-03, -1.5754e+00, -8.1918e-01,  1.7097e+00,\n","         -1.0926e+00, -7.2243e-01,  8.7137e+00, -9.3305e-01, -7.6778e-01,\n","          1.3676e+00, -2.2373e-01, -8.6958e-01, -1.3142e+00,  1.9382e+00,\n","         -5.7982e-02,  5.9383e-01,  1.7031e+00,  9.0482e-01, -2.1289e+00,\n","          9.7631e-01,  1.8340e+00, -1.1474e+00, -9.0607e-02, -2.5020e-01,\n","         -2.3427e+00,  1.1166e+00,  5.3579e-01, -1.6551e-01,  5.1749e-01],\n","        [-6.3180e-01,  1.1899e+00, -1.7167e+00, -2.8325e-01,  1.5642e+00,\n","          3.4129e-01, -6.0123e-01,  1.1337e+01, -9.8402e-01,  7.8052e-01,\n","         -1.4034e+00, -2.5748e-01,  3.4056e-01, -2.3045e+00, -1.2337e+00,\n","         -1.6212e+00,  1.6235e-01, -7.0888e-01,  1.6053e+00, -1.3458e+00,\n","         -1.4790e+00,  2.0784e+00, -4.7615e-01, -3.3303e+00, -1.4480e+00,\n","         -1.9529e+00,  9.8642e-01, -1.4746e+00,  2.4509e+00, -7.5507e-01,\n","         -2.0669e+00,  1.8286e-02,  2.4673e+00, -3.5723e-01,  7.3292e-01,\n","         -5.3814e-01, -2.0200e+00,  2.2796e+00, -1.0057e+00, -2.6735e-01,\n","          2.3325e+00,  1.6659e+00,  3.7968e-01, -1.2112e+00, -7.1692e-01,\n","          2.2237e+00,  1.6978e+00, -1.2736e+00, -5.2681e-01,  9.5867e-04],\n","        [ 3.5269e-01, -6.0941e-01,  1.7260e+00, -1.0046e+00,  6.7124e-01,\n","          5.5921e-04, -9.5125e-01, -3.4939e+00, -1.0044e+00, -8.4557e-01,\n","          3.3073e-01,  1.5176e+01, -1.8029e+00, -7.6301e-01, -1.7174e+00,\n","          1.0437e-01,  5.0345e-01, -2.5619e+00, -1.1800e+00,  2.1150e+00,\n","          4.1206e-01,  1.6246e+00, -4.8628e+00, -3.0683e+00,  1.6235e+00,\n","          9.4863e-01, -3.3857e+00, -3.0789e+00, -6.4518e-01,  7.2787e+00,\n","          6.3131e-01, -2.2110e+00,  1.3494e+00, -2.6130e+00, -1.9010e+00,\n","         -5.7558e-01, -3.5426e-01, -2.5828e+00,  6.3106e+00,  7.3387e-01,\n","         -1.8917e+00,  6.3161e-01, -1.5914e+00, -7.1235e-01,  7.3314e-01,\n","         -2.0709e+00,  2.7785e-01,  2.8311e+00, -2.1318e+00,  3.2689e+00],\n","        [-3.8559e-01, -1.2740e+00,  1.8384e-01, -4.9916e-01, -1.2574e+00,\n","         -1.4162e+00,  1.2570e+00, -1.9323e+00, -2.0772e+00,  8.1282e-01,\n","          4.4223e+00, -7.9183e-01, -1.1326e+00, -6.4317e-01, -1.6686e+00,\n","         -1.6877e+00, -2.0240e+00,  1.3067e+01,  1.8561e-01,  9.6460e-01,\n","          1.3639e+00, -1.2958e+00, -7.6961e-01, -2.1969e+00, -1.2064e+00,\n","          1.0797e+00, -1.1708e+00, -1.6862e+00, -7.9108e-02,  1.3015e-01,\n","          9.7755e-01, -5.3532e-01,  6.6225e-01, -1.5910e+00, -2.2172e+00,\n","         -7.8805e-01,  1.5231e-01, -1.3420e+00,  4.8253e-01, -8.0565e-01,\n","         -3.3077e-01, -1.1171e+00,  3.7264e+00,  4.9068e-01,  2.6620e+00,\n","         -1.3600e+00,  1.4056e+00,  9.4167e-01,  1.7122e+00, -1.6938e+00],\n","        [-4.7103e-01, -6.1140e-01, -5.5310e-01, -8.0222e-01,  1.5632e+00,\n","         -2.7931e+00, -4.4814e-01, -4.8049e-01, -8.9287e-01,  2.6025e+00,\n","         -1.7611e+00, -8.3323e-01,  1.1011e+01, -1.4517e+00, -1.4800e+00,\n","         -5.3032e-01, -3.0044e+00, -1.5119e+00, -1.9127e-01,  8.8536e-01,\n","         -6.8803e-01,  3.2126e-01,  2.2241e+00, -1.1396e+00, -2.5386e-01,\n","         -9.3974e-01, -1.9619e+00, -9.7173e-01,  4.8747e+00,  8.3831e-01,\n","         -8.7071e-02,  9.1764e-01,  2.8185e+00, -3.4568e+00, -1.3421e+00,\n","          6.1995e-01, -4.7068e-01,  1.4161e+00,  9.0200e-01, -1.2875e+00,\n","          1.5407e+00,  3.5377e+00, -9.3981e-01, -7.7977e-01, -1.2555e+00,\n","          2.8152e+00,  5.1509e-01, -2.2885e+00, -2.1577e+00, -1.1240e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([10, 43, 22, 14, 26, 39,  2, 23, 35,  5, 27, 27,  7, 11, 17, 12],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7307, 10.8501, -0.5647,  ..., -1.7150, -2.3194,  2.6557],\n","        [-0.0419,  4.9303, -0.3748,  ..., -0.7586, -0.7246,  3.3273],\n","        [ 5.9154, -3.5371,  1.5796,  ...,  6.1837,  1.1237, -1.5340],\n","        ...,\n","        [ 2.1244, -0.1988, -0.9466,  ..., -2.1198,  0.4970, -0.5889],\n","        [ 1.7768, 16.2660,  1.0393,  ..., -1.5854, -3.4108,  1.6565],\n","        [ 1.0514, -4.2534,  3.9293,  ..., -0.5402,  2.1713, -0.5539]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 387/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7668,  1.6283,  0.6193,  ..., -3.3484, -0.7713, -0.0989],\n","        [ 3.7281, -2.5326, -1.3788,  ...,  0.9214, 12.3854, -0.5721],\n","        [-0.8701,  0.4706,  0.7365,  ...,  0.6280, -0.7858,  0.3470],\n","        ...,\n","        [ 5.1805, -3.0505,  3.4239,  ..., -0.7429, -0.3392, -0.5003],\n","        [-2.7131, -0.5932,  0.2622,  ..., -2.9144, -1.8618,  2.9069],\n","        [-1.5927, -2.0040,  0.4631,  ..., -0.1392, -2.2269,  0.7314]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([46, 48, 21, 24, 47, 17,  2, 35, 15,  3, 30, 45, 37, 17, 10,  9, 14, 43,\n","        46,  4,  2, 25, 21, 37, 45,  2, 25, 30, 35, 13, 21, 42,  0, 42, 12, 34,\n","        41, 28, 26, 32, 26, 34, 27,  3, 36,  3, 49, 14, 21, 46, 14, 46,  8, 28,\n","         8, 12, 21, 38, 36,  2, 37, 15,  0,  9, 10,  5,  8,  2, 29, 12, 28, 42,\n","        12, 33, 38, 49,  6, 16, 29, 26,  3,  7, 47,  5,  6, 41, 35, 43, 11, 39,\n","        22, 12, 35,  8, 23, 28, 41, 38, 29,  5,  8, 11, 12, 25, 19,  1, 26, 36,\n","        10,  2, 36, 43, 33, 16, 17, 44, 20, 13, 16, 32,  7, 29, 25, 27,  3, 16,\n","         4, 14], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.9749,  4.3631,  2.7734,  ...,  1.6681, -1.7336, -1.2643],\n","        [ 1.9918,  0.2632,  1.7975,  ...,  1.1678,  1.5031,  3.3838],\n","        [-1.6565,  1.5461, -2.5361,  ..., -4.0071, -0.5624,  2.7813],\n","        ...,\n","        [-1.5977, -0.3844, -1.4807,  ...,  0.1898, -1.7566,  2.5798],\n","        [-2.1000,  2.0311, -1.5382,  ..., -2.7602, -2.4536,  3.5381],\n","        [15.0681, -0.7694, -1.4221,  ...,  2.0365,  0.4928, -2.9066]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 3, 20,  8, 29, 16, 45, 39, 17, 14, 49,  7, 15, 38, 48, 43, 13, 11, 36,\n","        31, 46, 26, 10, 41, 32,  2,  1,  4,  8, 42, 14, 45, 27, 13, 33, 41,  5,\n","        44, 32, 47,  6, 49, 42, 24, 20, 48, 15, 27,  7, 24, 34, 16, 20,  5, 38,\n","        27, 31, 20,  0, 32, 25, 44, 40,  1, 35, 14, 31, 19, 20, 37, 12, 22, 22,\n","        29, 37,  0, 42, 19, 23, 16, 27, 14, 49, 12,  9, 30, 28, 13, 31,  0, 42,\n","        19, 25, 40, 40, 24, 43, 26, 49,  4, 20,  8,  6, 17, 27, 16,  6, 44, 49,\n","        41, 23, 31, 13, 41,  4, 10, 39, 10, 40, 30, 30, 40, 18,  1, 35, 11, 15,\n","        23,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.5611, -4.8418,  0.2255,  ...,  1.9239,  2.8932, -3.0897],\n","        [ 1.3898, -2.0702,  0.3308,  ..., -1.5371,  0.5857, -3.0285],\n","        [ 1.5547,  1.3879,  0.9715,  ..., 11.4283, -0.1008, -0.8903],\n","        ...,\n","        [-0.2614, -2.2591,  2.7096,  ...,  0.5912,  0.1225, -0.9048],\n","        [-0.0228, -0.5730,  1.3654,  ..., -1.9763,  3.1236, -1.8994],\n","        [-1.6499, -0.5843,  2.9117,  ...,  0.6272, -1.1569, -0.4355]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([39, 22, 47, 45, 24, 24,  0, 32, 17, 47,  1, 48, 11, 37, 19, 18,  4, 26,\n","         3, 22, 47, 10, 46, 30, 48, 25, 17, 30,  1, 41, 36, 26, 48,  2, 21, 43,\n","        19, 28, 29,  9, 13, 44, 32, 17,  0, 19, 27, 47, 22,  5, 16, 16, 19,  4,\n","        31, 28,  3, 34, 49, 33, 22, 24, 36, 23, 14, 18,  9,  7, 38, 29, 39, 24,\n","        47, 15,  9, 31, 44, 24, 33, 17, 41, 18, 15, 15, 30, 22, 27,  9, 13,  3,\n","         6,  6,  5, 17, 18, 29, 45, 34, 11,  7, 28,  1, 37, 18, 31, 46, 35, 33,\n","        10, 37, 12,  7, 23, 45,  2, 40, 30,  4, 36,  1, 40, 20, 36,  9, 48, 30,\n","        10, 27], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.9176e+00, -1.2739e+00,  8.9616e-01,  6.3166e-01,  1.8142e+00,\n","          1.1795e+00, -8.6330e-01, -1.5408e+00, -2.2173e+00,  8.5923e+00,\n","          2.0174e+00, -1.4655e-01,  1.5711e+00, -2.4807e+00, -2.8869e+00,\n","         -1.8096e+00, -1.1006e+00,  2.9048e+00, -6.8155e-01,  2.0240e+00,\n","         -1.0890e+00, -5.0046e-01,  6.3152e-02, -3.2264e+00,  5.0879e-01,\n","          4.9908e-01, -5.0801e-01, -8.6796e-01,  2.3897e+00,  1.5232e+00,\n","          1.7299e+00,  1.7917e+00,  4.8320e-01, -1.1851e+00, -1.8130e+00,\n","         -2.5023e+00, -1.8461e+00, -1.3711e+00,  9.1143e-01, -1.1841e+00,\n","          1.0573e+00,  2.1804e+00, -9.5631e-02, -1.9230e+00,  1.4510e+00,\n","          2.7269e-01,  8.1580e-01, -7.9445e-01, -1.7611e-01, -1.5443e+00],\n","        [ 2.7910e+00, -2.6423e+00,  1.4071e+00, -2.4192e+00, -4.1993e+00,\n","          2.5814e-01, -1.2329e+00, -8.2653e-01, -1.7219e+00, -2.1367e+00,\n","          1.3543e+00,  1.3049e+01, -6.4245e-03, -1.6828e+00, -2.8873e+00,\n","         -3.4427e+00,  3.1289e+00,  1.0945e+00, -1.3668e+00, -5.0927e-01,\n","         -1.4590e+00,  3.5479e+00, -1.9849e+00, -4.4137e+00,  2.4941e-01,\n","          3.2444e-01,  3.2146e-01, -1.4157e+00,  1.9019e+00, -2.4460e-01,\n","          2.0864e+00, -2.2061e+00, -1.2994e+00, -3.5247e+00, -3.7152e+00,\n","         -7.8107e-01, -9.7735e-01, -3.8558e+00,  1.0252e+01,  4.6456e+00,\n","         -5.5862e-03,  2.3191e+00,  2.3725e+00, -6.1751e-01,  4.1430e-01,\n","         -7.0717e-01, -6.9965e-01,  3.3640e-01,  2.0426e+00, -6.4720e-01],\n","        [ 2.9614e+00, -3.4623e+00,  3.4352e+00, -2.3212e+00, -2.6430e+00,\n","         -1.6709e+00,  4.2658e+00, -2.6663e+00, -1.2417e+00, -2.6603e+00,\n","         -4.9776e-01,  3.1625e+00,  3.5145e+00, -2.2177e+00,  2.0157e+00,\n","         -2.9803e+00,  2.8676e+00,  7.3262e-01, -3.0453e+00, -3.2693e-01,\n","          7.5927e-01, -1.2623e+00,  1.4046e+00, -2.5456e+00,  2.2039e+00,\n","          4.7447e-01, -2.8794e-01,  1.3762e+00, -1.6201e+00, -2.7553e+00,\n","          1.9968e+00, -2.4293e+00,  1.5428e-01, -3.6821e-01, -2.1435e+00,\n","          1.3711e+01,  1.0347e+00, -3.6900e+00,  3.8179e+00,  9.1627e-01,\n","         -2.7501e+00,  5.1211e-01, -2.3337e+00,  1.8985e-01,  9.7920e-01,\n","         -2.9183e+00, -8.7885e-01,  2.5335e+00, -1.5154e+00, -4.6452e-01],\n","        [ 1.8662e+00, -3.5335e+00,  7.7235e-01, -1.7703e+00, -2.5803e+00,\n","          1.4619e+00,  1.1120e+00, -3.6001e+00, -1.3910e+00, -1.5252e+00,\n","         -1.4631e+00, -8.5714e-02,  8.6135e-01,  6.0086e-01,  1.9567e-01,\n","         -1.6528e+00, -6.3337e-01,  1.8937e+00,  2.0414e-01, -7.7055e-01,\n","          9.6133e+00, -8.2089e-01,  2.8380e-01,  1.0568e-01,  4.2139e-01,\n","          9.4907e-01, -2.1241e+00,  1.7522e+00, -9.8786e-01,  5.7010e-01,\n","          1.8859e+00, -7.8643e-01, -4.4652e-01, -2.8301e+00, -2.2646e+00,\n","          1.0818e+00,  4.5904e+00, -6.2734e-01,  1.0740e+00,  6.4602e-01,\n","         -5.3552e-01,  1.3637e+00, -9.9785e-01,  2.4389e+00,  3.1892e-01,\n","         -3.0410e+00, -1.7142e+00,  7.0449e-01,  1.2794e+00, -1.8695e-01],\n","        [-7.8292e-01,  5.2641e-01,  6.1933e-01, -6.1549e-01,  1.7878e+00,\n","         -1.7099e+00, -6.1040e-01, -1.5355e+00,  1.2573e+00,  1.6775e+00,\n","          2.9003e-01, -2.6989e+00,  3.9047e-01,  2.0350e-03, -4.8266e-01,\n","         -2.7060e+00, -5.7308e-01, -1.3495e-02,  8.8127e+00,  8.1759e-01,\n","          8.9555e-01,  2.6131e+00, -1.2424e+00,  3.0274e-01,  1.6541e+00,\n","         -9.7999e-01,  2.0650e-02, -5.0358e-01, -3.8708e-01, -1.3322e+00,\n","          9.0552e-01,  1.4915e-01, -7.2285e-01, -2.2158e+00, -9.7210e-01,\n","         -2.0762e+00, -8.1899e-01,  1.5097e+00,  1.8147e-01, -1.6321e+00,\n","          4.4634e-01,  1.0565e+00,  1.9691e+00, -1.3519e+00,  1.0657e+00,\n","         -2.1522e-01,  8.7041e-01, -6.7156e-01, -5.2793e-01, -6.0570e-01],\n","        [-1.2423e+00,  2.1766e+00, -2.0084e+00, -1.1977e-02,  2.5731e+00,\n","         -1.8302e+00, -6.9124e-01, -3.3607e+00,  6.3282e+00, -3.1812e+00,\n","         -2.4133e+00, -2.9125e+00, -5.8144e-01,  4.9141e+00, -7.4630e-01,\n","          2.3459e+00,  6.8311e-01, -2.7517e+00, -7.9325e-01,  1.4399e-01,\n","          1.4063e+00,  1.0817e+00, -5.2185e-01,  1.0850e+01, -1.0922e+00,\n","         -2.7804e+00, -1.8695e+00, -2.7334e+00, -1.9521e-01,  1.5577e+00,\n","         -4.4471e-01,  2.3279e+00, -6.7350e-02, -7.6839e-01,  3.1616e+00,\n","         -3.1654e+00, -5.8154e-02,  5.8376e+00, -1.0287e+00, -2.7292e+00,\n","         -2.8655e-01,  1.4231e+00, -2.0828e+00,  2.2547e+00, -1.7516e+00,\n","         -1.4155e+00, -2.3235e+00, -3.7209e+00, -2.2971e+00,  4.5026e+00],\n","        [-1.6426e+00, -2.2629e+00, -1.6307e-01, -1.0995e+00,  3.0163e-02,\n","          1.4776e+00, -1.8648e+00, -7.3138e-01, -1.0548e+00,  1.4087e+00,\n","          1.6736e+00, -6.9221e-02, -8.4887e-01,  1.5236e+00,  7.1393e-01,\n","         -7.9287e-01,  2.0783e-01,  2.1032e+00,  2.1435e+00, -6.0776e-01,\n","         -5.6962e-01,  1.5333e-01, -1.7411e+00, -2.1435e+00, -2.0532e+00,\n","          5.6528e-01, -1.2659e+00,  9.8267e-01,  9.0465e-02,  8.2904e-01,\n","         -1.5589e+00,  2.0731e+00,  1.1339e+01,  1.2041e+00, -1.0650e+00,\n","          1.2156e-01, -3.1279e+00,  4.5712e-01,  2.1969e-01, -1.5891e+00,\n","         -1.4471e+00, -3.2647e-01, -1.0508e+00,  1.8508e-01,  3.2352e+00,\n","         -4.0932e-01,  7.8760e-01, -2.7055e+00, -9.9206e-01, -2.0315e+00],\n","        [-1.5511e-01, -1.6681e+00,  3.8577e+00,  2.8492e-01, -2.0416e+00,\n","          2.8722e+00,  4.0942e+00, -1.4698e+00, -1.0061e+00, -2.6030e+00,\n","          7.6327e-02, -1.6221e+00, -1.5158e+00, -2.2345e-01, -1.0093e+00,\n","         -1.8952e+00,  2.7063e+00,  2.3793e+00, -1.5629e+00, -4.0881e-01,\n","         -6.5294e-01, -1.4952e+00, -1.8454e+00, -1.2475e+00,  4.3842e-01,\n","         -1.2718e+00,  5.8881e+00, -1.0422e+00, -1.9225e+00, -3.7980e-01,\n","          4.1030e-01, -2.0647e+00, -1.6910e-01,  1.3797e+01, -8.2079e-01,\n","          1.1901e+00, -1.1315e+00, -1.5396e+00, -7.7313e-01,  3.2580e-01,\n","         -1.3638e+00, -1.9503e+00, -1.9042e-01,  1.5349e+00, -2.4261e-01,\n","         -1.3167e+00, -5.9384e-02, -8.2806e-01,  1.0829e+00, -1.7967e+00],\n","        [ 3.7089e+00,  1.1762e+01,  2.8268e-01,  1.9473e+00,  2.4349e-01,\n","          1.4828e-01, -1.6434e-01, -2.9864e+00,  1.1314e+00, -2.2332e+00,\n","         -3.1416e+00, -3.0395e+00, -5.1776e-01, -3.6674e-01, -1.8078e+00,\n","          1.3952e+00, -1.1419e+00, -3.7313e+00,  3.6161e-01,  1.1452e+00,\n","         -8.6471e-01,  1.3826e+00, -6.8175e-01,  1.3764e+00,  1.4040e+00,\n","         -2.9445e+00, -9.3680e-01, -5.0130e-01, -2.6102e+00,  1.4188e+00,\n","          2.1543e+00, -1.7028e+00, -1.7231e+00, -1.3645e+00,  3.3150e+00,\n","         -1.9943e+00,  5.7283e-01,  3.9071e+00,  8.5305e-01, -3.3268e+00,\n","          1.5801e+00, -1.0109e+00, -2.2684e+00,  1.3151e+00, -9.0336e-01,\n","         -1.4343e+00,  1.2607e+00, -6.7015e-01, -2.6473e+00,  1.0935e+00],\n","        [-2.0011e+00, -1.1944e+00,  2.5871e+00,  1.8698e+00, -5.0012e-01,\n","          4.3051e-01, -4.8502e-01, -9.7439e-01, -2.1988e+00,  3.2995e-02,\n","          7.2455e-01,  9.4997e+00, -1.1030e+00, -5.8422e-01, -1.3295e+00,\n","         -1.7056e+00, -2.1048e+00,  1.0170e+00,  9.3217e-01,  3.2064e+00,\n","         -7.6706e-01,  6.3146e-01, -2.5751e+00, -3.3828e+00, -3.3907e-01,\n","          1.3447e+00,  2.4944e-01,  7.1508e-01, -8.5801e-01,  3.9696e+00,\n","         -2.2660e-01, -4.8973e-01,  6.8766e-01, -1.0876e-01, -2.2734e+00,\n","         -7.4637e-01, -1.9223e+00, -2.6656e+00,  1.2578e+00,  1.2663e+00,\n","         -6.3888e-01,  9.6551e-01, -6.2551e-01, -5.0383e-01, -2.7356e-02,\n","          8.1945e-01,  4.7518e-01,  9.8633e-01, -6.8185e-01, -1.2645e+00],\n","        [ 4.4118e-01,  5.2827e-01, -1.2837e+00, -7.5088e-01, -7.4448e-01,\n","         -2.4994e-01, -2.3048e-01,  1.1477e+01, -2.0970e+00, -7.4232e-01,\n","         -6.2499e-01,  1.4397e+00,  3.2246e-01, -1.0411e+00,  5.2093e-01,\n","          1.7957e-01, -9.1783e-01, -2.7649e-02,  2.7252e-01, -1.2526e+00,\n","         -1.9354e+00,  1.9569e+00,  4.7328e-01, -1.9748e+00, -1.3860e+00,\n","         -1.1243e+00,  6.0486e-01, -1.1526e-02,  1.8480e+00, -1.6136e-01,\n","         -9.4910e-01, -7.2028e-01,  1.8835e+00, -6.9551e-01, -1.0951e+00,\n","          1.0557e+00, -1.3487e+00, -7.2571e-01, -6.2367e-01,  1.6777e+00,\n","         -4.7719e-02,  3.6317e-01,  6.0370e-01, -2.0611e-01, -8.8054e-01,\n","          6.0362e-01,  3.7682e-01, -7.7482e-01, -1.9484e-01, -6.2654e-01],\n","        [ 8.6241e-01, -2.1382e-01,  2.6885e+00, -5.4766e-01, -1.2287e+00,\n","         -1.2368e-01, -2.0149e+00, -1.6940e+00,  9.1465e-01, -7.8517e-01,\n","          3.0033e-02, -3.7411e+00,  2.0306e+00, -2.4459e+00,  3.0941e+00,\n","          1.0012e+00, -2.6788e+00, -3.3292e-01, -2.4731e+00, -2.5380e+00,\n","          2.8449e+00, -1.1243e+00,  3.2777e+00, -3.8425e-01, -1.1514e+00,\n","         -1.9250e+00, -4.5679e-01,  3.5557e-01, -2.1162e+00, -4.9022e-01,\n","         -9.6934e-01,  5.5442e-01,  2.8122e+00, -4.0531e+00, -2.1487e+00,\n","         -1.4851e+00,  9.3634e-01,  1.1919e+00,  2.2158e+00, -2.1118e+00,\n","          1.1779e+01, -1.4187e+00, -4.1200e-01,  1.6240e+00,  5.9513e-01,\n","         -2.6245e+00,  1.1449e+00, -6.0427e-01,  2.6679e+00,  2.0205e+00],\n","        [ 2.8575e+00,  2.5653e+00, -2.3036e+00,  4.5263e-01, -3.5580e+00,\n","          3.4682e+00, -1.9274e-01, -3.6702e+00,  2.6222e+00, -3.3035e+00,\n","         -9.9442e-01, -1.8717e+00, -2.4903e+00, -3.7477e-01, -1.4206e-01,\n","          1.5075e+00,  1.1178e+00, -2.5645e+00, -1.3537e+00, -2.4016e+00,\n","          1.1651e+00, -1.3670e+00, -6.7783e-01,  1.6099e-01,  9.7355e-01,\n","         -2.2533e+00, -2.4563e-01,  1.7933e+00, -1.3729e+00,  1.2990e+00,\n","         -5.0727e-01, -5.8772e-01, -3.8548e-01, -1.3348e+00,  9.0533e+00,\n","          4.3914e-01,  2.9589e+00,  2.1309e+00,  1.2211e+00, -2.0273e+00,\n","         -1.0216e+00,  6.8174e-01, -8.3810e-01,  3.3355e+00,  8.1468e-01,\n","         -4.3031e+00, -1.3511e-01,  1.2220e+00,  5.4856e-01,  1.2886e+00],\n","        [ 1.3864e-01, -1.7317e+00,  6.1185e-01,  1.1772e+00,  2.1404e-01,\n","         -1.3389e+00, -2.0455e+00, -1.3721e+00, -2.9477e+00,  7.6952e+00,\n","          1.3224e+00, -1.8759e+00,  4.0093e-01, -2.0689e+00, -1.9887e+00,\n","         -1.2543e-01, -4.5080e-01,  1.9943e+00,  6.2238e-01,  1.0218e+00,\n","         -2.4937e-01, -2.6301e-01, -2.2113e-01, -2.0198e+00,  2.0657e+00,\n","         -1.5687e+00, -1.4215e+00, -1.9214e-01,  4.1471e-01,  1.6156e+00,\n","         -5.6139e-01,  2.3530e+00, -1.0121e+00, -3.1530e+00, -2.6516e+00,\n","         -1.7660e+00, -1.2108e+00,  3.6086e+00, -1.0854e-01, -3.8637e-01,\n","          1.1080e-01,  1.6888e+00,  2.7066e+00, -1.2255e+00,  6.6237e-01,\n","         -6.5610e-01,  1.5471e+00,  1.1835e+00,  1.1121e+00,  4.8948e-01],\n","        [ 1.5985e+00, -2.8100e+00,  2.6939e+00,  2.3926e+00, -3.7993e-01,\n","         -8.2467e-01, -3.1709e-01, -3.3446e+00, -3.5584e+00, -1.6833e+00,\n","         -2.2112e+00, -3.6735e-01, -3.0273e+00, -1.3128e+00, -1.3773e+00,\n","         -1.8031e+00,  3.2431e+00,  1.9301e+00, -1.5873e+00,  1.5068e+00,\n","          1.4063e+00, -3.1526e+00,  3.8919e+00, -1.0740e+00,  4.9048e+00,\n","          1.5569e+01, -2.0492e-01, -3.5925e+00, -2.1358e+00,  3.5308e+00,\n","          1.6145e+00, -2.2115e+00,  2.0875e+00, -3.2611e-01, -4.3761e+00,\n","          3.1661e+00, -9.6707e-01, -3.0816e+00,  4.1827e-01,  3.3311e+00,\n","         -4.2257e+00, -5.9014e-01, -4.0606e+00, -5.6036e-01,  6.8882e-01,\n","         -2.4095e+00, -1.9666e+00,  5.1527e+00,  6.7022e-01, -9.2804e-01],\n","        [-2.7548e+00, -1.3116e+00,  2.8200e-01, -3.4245e-01,  2.8087e+00,\n","          1.5250e+00, -1.3968e+00, -2.5587e+00,  2.9668e+00,  5.7563e-01,\n","          1.3358e+00,  5.2467e-01,  1.0667e+00, -4.4476e-01, -1.5618e+00,\n","          3.6941e-01, -5.2716e-01, -2.2020e+00, -2.5183e-01, -6.9326e-01,\n","          6.5179e-01, -9.2101e-01, -3.6314e+00,  1.2429e+00, -5.1020e-01,\n","         -2.8562e+00, -1.1200e+00, -9.2632e-01,  1.1836e+00,  2.6525e+00,\n","         -1.3894e+00,  9.9149e+00,  1.3734e+00, -1.2408e+00,  2.3594e+00,\n","         -3.1008e+00,  8.0662e-01,  4.5884e-02, -2.6043e-02, -1.1743e+00,\n","         -1.3924e-01,  3.1791e+00, -1.5530e+00,  6.1731e-01,  1.5599e+00,\n","         -3.0258e-01, -2.1292e-01, -4.0693e+00, -1.5231e+00,  3.0138e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 9, 11, 35, 20, 18, 23, 32, 33,  1, 11,  7, 40, 34,  9, 25, 31],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7428, 10.8300, -0.5653,  ..., -1.7111, -2.3085,  2.6459],\n","        [-0.0369,  4.9203, -0.3804,  ..., -0.7588, -0.7228,  3.3308],\n","        [ 5.9277, -3.5435,  1.5908,  ...,  6.1821,  1.1298, -1.5381],\n","        ...,\n","        [ 2.1289, -0.2030, -0.9495,  ..., -2.1188,  0.5012, -0.5912],\n","        [ 1.7870, 16.2530,  1.0376,  ..., -1.5877, -3.4071,  1.6601],\n","        [ 1.0691, -4.2661,  3.9300,  ..., -0.5388,  2.1849, -0.5528]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 388/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.4733, -0.9137,  1.6690,  ...,  3.4217, -0.5369, -2.4626],\n","        [-1.5999, -0.5540, -0.6569,  ..., -0.4836, -0.2101, -0.7289],\n","        [-0.5424, -0.6595,  1.3458,  ..., -1.0772,  0.4745, -1.0926],\n","        ...,\n","        [ 3.2945, -0.5432,  1.6021,  ...,  0.6167,  2.6814,  2.4167],\n","        [ 2.2034,  0.8635,  2.5904,  ...,  2.1323,  0.2196, -2.2993],\n","        [ 5.0048, -4.5322,  1.2882,  ...,  4.3208,  1.2917, -2.3272]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([19,  7, 33, 27, 20,  4,  2, 49, 13,  1, 37, 37, 34, 29, 32, 32, 22, 31,\n","        25, 41, 19, 31, 30, 23, 43,  1, 26, 41, 45, 49, 13, 36, 44, 33, 14,  4,\n","         8, 41, 22, 20,  0, 30, 16, 13, 30, 15, 24, 34, 45,  7, 42, 27,  7, 15,\n","         5,  7, 22, 29,  3, 31, 49, 27,  1,  8, 17, 23, 47, 27, 30, 20, 47, 28,\n","        33,  4, 31, 15,  9, 13, 45, 27, 37, 21, 31, 23, 47,  9, 17, 17,  6, 36,\n","        43, 40, 12, 46, 17, 41, 18, 29, 37,  6, 10, 33, 21, 32, 14, 41, 29, 10,\n","        45, 32, 33, 28, 49, 18, 11, 16,  0, 28, 21, 18, 10,  2,  2, 29,  6, 20,\n","         3, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.0838, -1.6758,  1.0737,  ...,  4.4499, -0.4061, -1.3465],\n","        [ 3.6522, -2.4088,  5.3315,  ...,  1.9566, -1.4708,  1.9363],\n","        [-0.6643,  0.7834, -1.3320,  ..., -3.9403,  0.3109,  3.6955],\n","        ...,\n","        [ 0.7444, -3.1750,  2.5899,  ...,  3.2239,  0.0414, -2.1324],\n","        [-0.9175, -1.7538, -0.4667,  ..., -0.2456,  2.0683, -1.9012],\n","        [ 2.2237,  2.3745,  2.2408,  ..., -1.7403, -0.1774, -0.1813]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([25, 16,  8,  1, 40, 48, 25,  1, 29, 19,  9, 13, 40,  2,  7, 17, 36, 11,\n","        41, 24, 15, 14, 14,  9, 35,  0, 16, 39, 24,  8, 48, 19, 35, 40, 22, 24,\n","         3, 13, 37, 23,  3, 26, 44, 12, 12, 31, 49, 41, 30, 33, 43, 40, 11, 30,\n","        13, 45,  9,  5, 42, 28, 10, 42, 46, 45, 47, 39,  6, 20, 12, 43, 29, 47,\n","        49, 27, 15,  6,  0, 10,  5,  1,  1, 47, 42, 47, 40, 12, 36,  1, 46, 22,\n","         2, 27, 26, 10, 16, 26, 40, 35, 12,  3, 41, 46, 35, 39, 30, 48, 44, 20,\n","        28, 38, 38, 10, 20, 23, 19,  8, 25, 48, 16, 14, 21, 39, 30, 32, 36, 39,\n","        17, 46], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.4250,  0.6045, -2.2291,  ..., -3.2531,  0.0401,  2.3601],\n","        [-1.9195,  0.9924,  0.2337,  ..., -0.4184, -1.5949, -0.6815],\n","        [-0.8705, -2.0670, -2.0482,  ..., -0.7495, -0.8669, -0.7385],\n","        ...,\n","        [-2.9435,  0.9321, -0.7807,  ..., -1.4681, -3.2098, -0.2861],\n","        [-2.3686, -0.1300,  0.7251,  ..., -3.5518, -1.6694,  2.4391],\n","        [ 2.1104, -2.9313,  1.8168,  ...,  2.0072, -1.2073, -1.3231]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 18, 32, 34, 30, 17, 48, 23, 11,  7, 35, 12, 24, 10,  6, 13, 10, 40,\n","        18, 37, 14,  2, 28, 42,  3, 20, 28,  2,  9, 36,  4, 36,  7, 42,  7, 11,\n","         3, 48, 44, 22, 36, 31, 44, 28, 17,  0,  5, 38, 31,  0, 30, 34, 45, 14,\n","        38, 19,  8, 21, 17, 43, 19, 41,  9,  2, 11, 34, 34,  9, 24,  3, 29,  4,\n","        15, 24, 25,  9, 35,  4, 25, 46, 43,  6, 14, 32, 22, 16, 35, 46, 18,  8,\n","        22, 33, 37, 47, 49, 17,  0,  1, 26, 15, 26,  0, 24, 38,  4, 21,  5, 42,\n","        12, 16, 36, 24, 29, 38, 19, 25, 14, 44, 37,  9, 15,  5, 32, 20,  3, 31,\n","         4, 35], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.5095e+00, -1.3834e+00,  6.3483e-01, -1.0406e-01, -3.0589e+00,\n","          2.2068e+00,  2.8300e+00, -1.4595e+00,  1.6436e+00, -2.7661e+00,\n","         -1.4175e+00, -8.6445e-01,  5.9064e-01, -5.1912e-02,  1.9551e+00,\n","         -3.1630e+00, -7.2423e-01,  2.4509e+00,  1.8181e-01, -4.1981e-01,\n","         -1.6083e-01,  7.5212e-01, -1.3127e+00, -2.4165e+00, -1.2782e+00,\n","         -1.2789e+00,  9.8022e+00, -1.1922e+00, -3.3410e+00,  1.5173e+00,\n","         -1.6781e+00, -1.2199e+00,  1.0223e+00,  2.2797e+00, -1.6243e+00,\n","          1.4471e+00, -3.7233e-01, -1.6545e+00,  2.3999e+00, -1.1563e+00,\n","         -2.4252e-01, -8.0500e-01,  1.0262e-01,  2.8742e+00,  4.3298e+00,\n","         -2.3414e+00, -1.6703e+00, -5.4885e-01,  8.3230e-01,  3.7263e-02],\n","        [ 2.4066e+00,  1.2874e+00, -3.2040e-01, -3.8597e-01,  3.7718e-01,\n","         -1.5669e+00, -7.0136e-01, -5.4669e-01,  1.1244e+00, -7.3252e-02,\n","          2.6395e+00, -2.7914e+00,  1.0589e+00, -2.3937e+00, -2.2502e+00,\n","         -2.3598e+00, -1.4651e+00,  2.2164e+00, -3.1731e+00, -1.1793e+00,\n","          6.9383e-01, -1.2817e+00,  7.2049e-01,  4.1944e-01, -9.0846e-01,\n","         -1.6517e+00, -1.0293e+00, -1.6726e+00,  4.1066e-01,  4.7046e-01,\n","         -2.3630e-01, -4.8885e-01, -5.5175e-01, -8.8364e-01, -3.2609e-01,\n","         -1.1467e+00, -1.6333e-01,  3.9878e+00, -1.1570e-01,  8.9731e-01,\n","          2.3141e+00,  7.1501e-01,  4.0306e+00,  5.7949e-01,  1.8211e-01,\n","         -1.0645e+00,  1.2593e+00, -2.3616e+00,  7.1534e+00, -2.6292e-01],\n","        [-1.1198e+00,  2.4560e+00, -3.7575e-01, -1.2249e-01,  4.6647e+00,\n","          4.5387e-02, -2.1883e+00, -2.3134e+00,  3.4790e-01,  1.2717e-01,\n","         -2.7411e+00, -1.0665e+00, -2.6443e+00, -3.5297e-01, -2.3636e+00,\n","          5.9316e+00, -8.0946e-01, -3.8898e+00, -3.6359e+00, -2.4413e+00,\n","          6.8802e-01, -2.3492e-01, -1.9906e+00,  2.0169e+00,  6.4073e-01,\n","         -1.3127e+00, -2.7360e+00, -2.0291e+00,  3.3069e-01,  5.7994e+00,\n","         -1.3732e+00,  8.8778e-01,  1.8569e+00, -3.1602e+00,  3.3508e+00,\n","         -2.1139e+00,  1.8029e+00,  2.0842e+00,  1.3988e-01, -2.4464e+00,\n","          1.4122e+00,  1.1470e+00, -2.1083e+00,  2.1002e+00,  8.7894e-02,\n","         -5.8630e-01, -2.6800e-01, -1.6108e+00, -2.9494e+00,  1.3605e+01],\n","        [ 2.8152e+00, -1.6193e+00,  2.4911e+00,  2.5564e+00, -1.8161e+00,\n","         -9.0644e-01, -1.3610e+00, -1.5038e+00, -6.5222e-01, -7.2137e-01,\n","         -5.9088e-01, -3.5944e-01, -1.9004e+00, -1.2853e+00, -1.0594e+00,\n","         -2.5680e+00,  1.1248e+01,  1.4776e+00,  6.9565e-01,  3.6351e+00,\n","         -1.6893e+00, -1.7753e+00, -7.8499e-01, -2.6275e+00,  1.2217e+00,\n","          2.4658e+00,  2.6554e+00, -1.0448e+00, -1.2369e+00, -1.8355e+00,\n","          5.3926e+00, -9.4113e-01,  9.7790e-01,  1.7854e-01, -2.8469e+00,\n","          1.7760e+00, -1.1427e+00, -2.6623e-01,  2.3229e+00,  4.6506e-01,\n","         -9.2225e-01, -1.1553e+00, -2.5379e+00, -7.1644e-01, -2.8111e-01,\n","         -7.1594e-01,  1.8627e+00, -1.4099e+00, -9.2281e-01, -4.8438e-01],\n","        [-2.0588e+00,  2.3502e+00, -1.4909e+00, -8.9174e-01,  2.9678e+00,\n","         -3.2097e+00,  4.2356e-04, -2.9374e+00,  5.8280e+00, -2.9514e+00,\n","         -2.4779e+00, -2.8357e+00, -1.9899e+00,  8.0106e+00,  3.8826e-01,\n","          1.2292e+00, -1.3312e+00, -1.7693e+00,  5.6634e-01,  6.7503e-01,\n","          4.7067e+00,  1.5721e-01,  8.7764e-01,  1.3029e+01, -1.4116e-01,\n","         -1.1333e+00, -3.4902e+00, -4.2798e+00, -1.9540e+00,  2.0322e+00,\n","         -9.8676e-01,  4.1692e+00,  1.3620e+00, -1.2745e+00,  1.6672e+00,\n","         -3.3678e+00,  1.4742e-01,  3.5854e+00, -2.9279e-01, -9.6266e-01,\n","         -1.3875e+00, -3.2191e-02, -1.5611e+00,  3.2062e+00, -9.5214e-01,\n","         -1.5226e+00, -3.6723e+00, -2.8285e+00, -1.9093e+00,  1.7851e+00],\n","        [ 2.4622e+00, -2.1719e+00,  1.7504e-01, -2.1805e+00, -1.6180e-01,\n","          5.5054e-01, -9.8866e-01, -1.3733e+00, -2.2931e+00, -6.0290e-02,\n","          2.1582e+00,  8.4462e+00, -3.3637e-01, -2.0228e+00, -2.2854e+00,\n","         -1.9509e+00,  1.4902e+00,  4.5909e-01, -3.1729e+00, -4.1090e+00,\n","          2.7330e+00, -1.3120e+00, -5.6800e-01, -3.1390e+00,  8.5230e-01,\n","          1.5647e+00, -4.0207e+00, -2.5837e+00,  1.5216e+00,  3.1735e+00,\n","          1.1284e-01, -1.4112e+00,  3.5141e+00,  7.5932e-01, -8.4049e-01,\n","          1.8924e+00,  2.4340e+00, -7.7066e-01,  1.1938e+00, -4.6229e-01,\n","         -1.2650e+00,  2.6572e+00,  6.9841e-02,  1.9803e+00,  2.5315e+00,\n","         -1.8090e+00,  4.3621e-01, -8.0316e-01,  3.5915e-01,  2.1301e-01],\n","        [-9.4473e-01, -1.5569e+00, -4.1830e-01, -9.6158e-01,  3.1929e-01,\n","         -1.3517e+00, -8.2435e-01, -6.0524e-01, -1.0355e+00,  2.6248e+00,\n","          1.1055e+00, -1.3459e+00,  1.1544e+01, -1.5136e+00,  2.8407e+00,\n","         -7.8015e-01, -3.0273e+00,  9.7130e-01, -9.7145e-02, -8.0534e-01,\n","          8.5299e-01,  1.1031e+00,  4.0049e+00, -2.1879e+00,  1.0669e-01,\n","         -2.4267e-01, -1.6594e+00, -2.2831e+00,  3.0967e+00, -8.8339e-01,\n","          1.6573e-01,  8.5272e-01,  3.7822e+00, -2.9198e+00, -2.4331e+00,\n","          1.9221e+00, -1.0866e+00, -9.6658e-02, -2.7284e-01, -7.2532e-01,\n","          3.2811e+00,  5.0668e-01,  1.2318e-01, -9.6985e-01,  3.5345e-01,\n","         -3.8007e-02,  4.7983e-01, -2.6096e+00, -1.3268e+00, -2.6087e+00],\n","        [-1.5393e+00,  3.9270e+00, -1.0787e+00, -4.3186e-01, -8.2517e-01,\n","         -2.0496e+00, -3.2713e-01,  2.5902e+00, -4.5488e-01,  1.4736e+00,\n","         -2.4813e+00, -9.9882e-01, -3.4290e-01,  7.1382e-01, -8.7023e-01,\n","          3.5141e-01, -1.9966e+00, -5.1388e-01,  1.0312e+01,  8.7073e-01,\n","         -3.9722e-01,  3.3558e+00, -1.8933e+00, -3.4259e-01, -1.2850e-01,\n","         -1.4841e+00, -1.9096e+00, -3.7833e-01,  1.2308e+00,  1.1169e+00,\n","         -1.5469e+00, -4.8439e-01,  2.8614e+00, -1.5292e+00,  7.2077e-01,\n","         -1.6638e+00, -9.6435e-01,  1.3201e+00, -1.0857e-01, -1.4462e+00,\n","         -2.8620e-01,  1.9076e+00, -1.6026e+00, -2.5295e+00, -1.7827e+00,\n","          9.6480e-01,  9.9251e-01, -1.1720e+00, -2.8289e+00,  3.5727e-01],\n","        [ 2.1186e+00, -1.2627e+00, -3.6198e-01, -1.4110e+00, -3.3093e+00,\n","         -4.5254e-01,  4.2512e-01, -2.3178e+00, -1.3131e+00, -4.5854e-01,\n","         -1.6179e+00,  1.9889e+00,  2.0700e+00, -2.3197e+00, -6.8668e-01,\n","         -7.5129e-01, -1.5722e+00, -3.4414e-01, -1.2908e+00,  6.9673e-01,\n","          9.6726e-01,  1.5769e+00, -6.8623e-01, -2.5544e+00, -6.4230e-01,\n","          8.3315e-01, -2.8697e+00,  1.0462e+01, -7.3203e-01,  3.9370e-01,\n","         -6.5539e-02, -2.5494e+00, -1.8933e+00, -2.9148e+00, -1.5828e+00,\n","          3.3568e+00,  9.1145e-02,  1.3388e+00,  2.9434e+00,  1.9743e+00,\n","          1.4584e+00,  2.7447e+00,  1.9178e+00,  2.7673e-02, -7.1084e-01,\n","         -2.1127e+00,  2.9890e-01,  3.1515e+00,  1.2729e+00, -2.7351e+00],\n","        [ 2.7738e-01, -1.4392e-02,  9.9416e-01,  1.4243e-01,  3.9316e-01,\n","          1.1150e+01,  8.7179e-01, -1.0015e+00,  1.4338e+00, -1.9650e+00,\n","          1.5009e+00,  1.0356e+00, -2.9588e+00,  1.1103e-01, -1.4268e+00,\n","          1.9220e+00, -1.1318e+00, -4.6424e-01, -2.6841e+00, -2.1275e+00,\n","          5.9775e+00, -7.8144e-01, -4.0638e+00, -1.0887e+00, -2.3984e+00,\n","         -2.4542e+00, -2.0304e-01, -3.4855e+00, -9.1057e-01,  3.6325e+00,\n","         -1.3847e+00, -7.2551e-01,  7.2342e-01,  2.6289e+00,  2.7228e+00,\n","         -1.1898e+00,  5.5082e-01,  7.4990e-01, -4.7827e-01, -2.9453e+00,\n","          7.2306e-01,  3.5341e-01, -1.5763e+00,  4.7123e+00,  1.0778e+00,\n","         -1.7287e+00, -2.0561e-02, -6.8007e-01, -3.2202e-01, -3.6055e-01],\n","        [-9.5537e-01, -2.8748e+00,  8.2480e-01, -1.8779e+00, -7.0125e-01,\n","         -2.8897e-01, -8.6891e-01, -9.5303e-01, -1.9050e+00,  1.0889e+00,\n","         -7.3027e-02,  1.7895e+00,  6.0890e-01, -2.5350e+00,  1.6322e+00,\n","          1.3952e+00,  7.3156e-01, -1.3805e+00, -4.8153e-01, -1.1949e+00,\n","         -1.7023e+00,  8.3470e-01,  4.0223e-01, -1.9384e+00, -4.1591e-01,\n","          4.7141e-01, -8.4880e-01,  1.0014e+01, -5.6933e-01, -2.1734e-01,\n","         -2.0101e+00,  2.2172e+00, -6.5911e-01, -1.6724e+00, -1.6579e-01,\n","          2.2775e-01, -1.0163e+00, -9.5706e-01,  1.3478e+00,  2.9033e-01,\n","         -2.1912e-01,  3.8501e+00, -6.8942e-01, -1.0108e+00, -9.9247e-02,\n","         -6.3879e-01, -6.7805e-01,  1.4563e+00,  6.8727e-01, -1.1618e+00],\n","        [-1.3841e+00, -2.6901e-01,  9.8182e+00,  9.2999e-01,  1.8744e-01,\n","         -1.4032e+00,  2.1759e+00, -2.2292e+00, -1.6514e+00, -1.6674e-01,\n","          1.8253e+00,  3.6611e-01, -7.6750e-01,  1.3267e-01, -9.7168e-01,\n","         -1.3910e+00, -1.3798e+00,  1.2526e+00,  4.8185e-01,  7.4816e-01,\n","          4.1961e+00, -1.0443e+00, -1.7604e+00, -4.4403e-01,  3.5366e+00,\n","         -4.6763e-01, -1.4019e+00, -2.8613e+00, -8.6767e-01, -1.1645e+00,\n","          1.5772e+00,  1.7500e+00, -2.1895e-02,  1.7084e-01, -1.5249e+00,\n","          5.8246e-01,  8.9127e-01, -2.4194e+00, -1.8870e-01,  1.5441e+00,\n","         -1.2255e+00, -1.5389e+00, -1.2185e+00,  8.6329e-01, -1.7102e-02,\n","         -1.7341e+00,  4.2876e-01, -1.1217e+00, -1.0256e+00, -1.1959e+00],\n","        [ 1.6985e+00, -4.9743e-01,  1.0563e+00,  5.6730e+00, -6.0220e-01,\n","         -5.7914e-01, -1.1719e+00, -3.0165e+00, -7.4189e-01,  3.0971e-01,\n","         -2.3436e+00,  8.5187e-01, -4.6476e+00,  5.4569e-01, -2.0457e+00,\n","         -7.5292e-01,  8.4335e+00, -5.6091e-01, -1.0419e+00,  4.8011e+00,\n","         -9.6770e-01, -1.3758e+00, -6.7499e-01, -1.2278e+00,  5.0612e+00,\n","          4.7822e+00, -1.1971e+00, -3.1804e+00, -1.2386e+00, -5.5974e-02,\n","          2.5740e+00, -3.7010e-01, -4.4137e-01, -6.4663e-01, -1.3253e+00,\n","          2.5460e-01, -1.5970e+00, -1.1654e+00,  2.5415e+00,  2.3083e+00,\n","         -1.5657e+00, -7.3075e-01, -2.5407e+00, -1.4568e+00, -1.7837e+00,\n","         -2.7269e+00,  1.6730e+00,  4.6314e+00, -2.0803e+00, -1.0082e+00],\n","        [-1.0939e+00, -2.8631e+00,  7.5734e-01, -2.1485e+00, -7.7432e-01,\n","          2.0525e+00, -1.1873e+00,  2.3341e-01, -8.8909e-01,  2.5497e+00,\n","          6.6465e-01, -3.7997e-01,  1.4379e+00, -2.1624e+00, -4.0538e-03,\n","         -9.0726e-01, -1.5033e+00, -4.5406e-01,  1.8226e+00, -3.6595e-01,\n","         -1.7320e+00,  6.4537e-01,  2.0793e+00, -1.1797e+00,  1.3833e+00,\n","         -4.8112e-02, -1.6029e+00,  7.6536e+00,  1.4597e+00, -4.4039e-03,\n","         -1.6353e-01,  3.3030e+00,  1.0186e+00, -2.2083e+00, -8.5422e-01,\n","         -3.7548e-01, -6.6940e-01,  1.0196e+00, -1.2381e+00, -1.8109e+00,\n","          2.0080e+00,  2.9211e+00, -1.1948e+00, -1.2283e+00,  8.1712e-01,\n","         -7.1579e-01, -1.5802e+00, -7.3914e-01, -8.2313e-02,  1.4363e-02],\n","        [ 2.8033e+00,  1.4263e+00,  4.6653e-01,  4.2725e+00, -1.9901e+00,\n","          2.1900e+00,  1.9341e+00, -2.5360e+00, -8.6788e-01,  9.8450e-01,\n","          2.9512e-02, -3.2187e+00, -1.3604e+00, -1.3634e+00, -2.0462e+00,\n","         -2.3060e+00,  1.9282e-01,  1.0802e+00, -6.0507e-02, -4.9919e-01,\n","         -1.4553e+00, -9.4503e-01, -1.3451e+00, -1.9662e+00,  2.2994e+00,\n","         -1.6180e+00,  1.0351e+01, -2.8336e+00, -2.8928e+00,  1.3671e+00,\n","          2.1502e+00, -4.4855e-01, -4.1362e-01,  4.6645e+00,  1.2282e-02,\n","         -1.1944e-01, -2.0701e+00, -1.4577e+00,  4.5703e-01, -1.5707e+00,\n","         -5.3481e-01, -2.5325e+00, -1.1599e+00, -5.1797e-02,  1.8911e+00,\n","         -2.0200e+00,  2.5982e+00,  3.8760e-01, -3.2095e-01, -6.6195e-01],\n","        [ 9.8228e-02, -3.0466e+00,  1.7358e+00, -2.2276e+00, -3.9745e-01,\n","         -3.3519e-01, -2.1579e+00, -8.0958e-01, -2.2504e+00,  1.1665e+00,\n","          1.2980e+00,  1.0679e+01, -1.4266e+00, -2.1418e+00, -8.4134e-01,\n","         -2.6766e+00,  2.1873e+00, -7.9634e-01,  1.4371e+00,  8.2644e-01,\n","          7.0355e-02,  1.8243e+00, -9.0545e-01, -3.2135e+00,  1.2684e+00,\n","          1.8083e+00, -1.3023e+00, -2.9843e+00,  2.5358e-01, -1.8341e-01,\n","          1.7717e+00, -3.6798e-01,  8.4709e-01, -2.1215e+00, -2.9804e+00,\n","         -6.4692e-01, -1.1275e+00, -2.5842e+00,  5.5246e+00,  2.7295e+00,\n","         -4.5621e-01,  9.2840e-01,  4.6483e-01, -2.2100e+00, -4.8969e-01,\n","         -2.9461e-01, -7.9403e-01,  3.4999e+00,  1.8467e-01, -2.3671e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([26, 48, 49, 16, 23, 11, 12, 18, 27,  5, 27,  2, 16, 27, 26, 11],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7454, 10.8414, -0.5666,  ..., -1.7150, -2.3072,  2.6272],\n","        [-0.0367,  4.9204, -0.3802,  ..., -0.7658, -0.7249,  3.3267],\n","        [ 5.9340, -3.5356,  1.5653,  ...,  6.1830,  1.1201, -1.5449],\n","        ...,\n","        [ 2.1268, -0.1973, -0.9470,  ..., -2.1220,  0.4978, -0.5928],\n","        [ 1.7710, 16.2158,  1.0309,  ..., -1.5906, -3.4052,  1.6474],\n","        [ 1.0642, -4.2529,  3.8982,  ..., -0.5372,  2.1793, -0.5494]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 389/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.3489,  1.3894,  0.5011,  ..., -3.1926,  0.9590,  1.5821],\n","        [ 2.8419, -1.3155,  3.0675,  ...,  0.1130, -1.6873, -0.3111],\n","        [-0.5992, -0.2205,  2.3716,  ...,  0.9022, -0.7105, -0.3656],\n","        ...,\n","        [-2.2956,  0.9874, -0.5791,  ..., -1.6085, -1.2957, -3.0356],\n","        [-0.5323,  0.4045, -0.4527,  ..., -0.4443, -2.0458, -1.3257],\n","        [ 2.4646, -0.9161, -0.6617,  ...,  1.1187,  0.3008,  2.5061]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20, 16, 27, 40,  1, 28, 29, 23, 35, 22, 39, 22, 18,  5,  9,  6, 48,  2,\n","         4, 10, 27, 13, 28, 35, 42, 21,  5,  6,  9, 37, 30, 40,  7, 10, 49, 43,\n","        12,  2, 26, 38, 29, 23, 16, 32, 23, 30, 21, 11, 41, 46, 22, 36, 31,  5,\n","        33, 25,  6, 15,  7, 26, 30, 44,  7, 35, 19, 14, 18, 19, 13, 19, 41, 12,\n","         5,  9, 33, 25, 36, 16, 24, 42, 14,  9, 13, 16, 30,  3, 45, 35, 12, 20,\n","        45, 37, 36,  9, 31, 29, 48, 37,  8, 25, 13, 27,  0, 33, 30, 32, 46, 29,\n","        32, 20,  2, 47, 33, 30, 47,  4, 40, 22, 45,  7, 22, 27, 41,  1, 27, 18,\n","        31, 20], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.2734, -2.2025,  2.2363,  ...,  2.7274, -2.0277,  0.4987],\n","        [-0.3031, -0.9563,  0.4312,  ...,  2.9573, -0.0372, -2.3149],\n","        [ 0.5763, -1.0505,  1.0268,  ..., -1.9597,  3.0183, -1.5767],\n","        ...,\n","        [-0.0712, -2.7753,  1.7047,  ..., -2.1009,  0.6583, -2.0848],\n","        [-1.2615, -1.3910, -0.7834,  ..., -1.8899, -0.9648,  1.3846],\n","        [ 3.4022, 15.9395,  0.7228,  ..., -0.7233, -1.9429,  0.1621]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([35, 19, 10, 23, 13, 22, 14, 44, 31, 32, 17, 31,  9, 28, 15,  4, 41,  3,\n","        31, 15, 34,  9, 45, 15,  1, 16, 37, 12, 24,  8, 27,  0, 33, 36, 27,  7,\n","        14,  3, 10, 11, 13, 45, 11, 37, 21, 10, 36, 16, 16, 43,  7, 20,  1, 22,\n","        14,  7, 31, 40, 23, 46,  4, 27, 23, 40, 49, 11, 10, 39, 28, 38, 41, 12,\n","        26,  2, 46, 25, 29, 18, 15, 19, 39, 24, 27, 42, 17, 17, 30, 32, 35,  2,\n","        13,  3, 11, 14,  0,  1, 37,  7,  4, 46, 16, 20, 15,  0, 46, 38,  0, 41,\n","        49, 33, 11, 20, 18,  1, 25, 48, 24, 47, 20, 42, 15, 19, 35, 24, 34, 12,\n","        44,  1], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0278, -0.0725, -1.1291,  ..., -3.8086, -0.1793,  1.2788],\n","        [ 0.7466,  0.1658,  0.8762,  ..., 11.9461, -0.7719, -1.1898],\n","        [-0.9552, -0.6431, -0.7988,  ..., -0.8025, -1.4165, -0.8900],\n","        ...,\n","        [-2.7069,  2.0903, -0.3298,  ..., -1.7698, -3.2329, 14.4243],\n","        [-1.6328,  0.4000, -1.7425,  ..., -3.5393, -3.1907, 14.6792],\n","        [11.7468,  0.2489, -1.6437,  ...,  0.2238, -0.6065, -2.1367]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 47, 45, 14, 23,  2, 24, 29,  2, 10, 37,  3, 28, 38, 47, 40, 17, 34,\n","        24, 26,  3,  3, 27, 16,  6, 46, 36, 11, 17,  8,  5, 44, 30, 17, 42, 39,\n","        28, 15,  2, 19, 26, 44, 44,  8, 43, 22, 42,  9, 10, 13,  6,  3, 32, 32,\n","         3, 21, 48, 41, 21, 37, 25, 24, 42, 41, 20, 48, 48, 17, 25, 39, 24, 12,\n","         8, 12, 17, 43, 45, 16,  0,  4, 26, 32, 31, 38, 47,  5, 29,  1, 14, 49,\n","         8, 29, 48, 30, 43,  5, 17, 49, 12, 36, 17, 40,  1, 21, 30, 36, 43, 34,\n","        47, 28, 25, 36, 47, 49, 18, 35,  4, 11, 26, 41, 26, 34, 38,  9,  4, 49,\n","        49,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.9567e+00,  3.1801e+00, -1.6077e-01,  2.4185e-01, -1.5922e+00,\n","         -1.6330e+00, -2.1220e+00, -8.5355e-01, -1.4036e+00,  1.4960e+00,\n","         -2.6368e+00,  1.2500e+00,  3.4552e-01,  3.2319e-01, -3.4483e-01,\n","          3.5775e-01, -1.0632e+00, -2.1070e-01,  1.1581e+01,  1.1159e+00,\n","         -1.3021e+00,  4.6087e+00, -1.1303e+00,  4.2174e-02,  1.7205e-01,\n","         -3.0931e-01, -1.5814e+00,  3.6251e+00, -1.3363e-01,  8.8654e-01,\n","          4.5563e-01, -6.0022e-01,  1.6610e+00, -2.0087e+00, -1.5934e-01,\n","         -2.4223e+00, -2.0134e+00,  1.7109e-01,  1.7405e+00, -1.0384e+00,\n","          1.5912e-01,  7.1006e-01, -9.5480e-01, -2.4303e+00, -6.0284e-01,\n","          2.2005e-01,  3.8077e-01, -2.2989e+00, -2.1225e+00, -9.1230e-01],\n","        [-3.8490e-01, -9.2239e-01,  2.3641e-01,  9.8809e-01,  1.3522e+00,\n","          8.6620e-01, -3.4223e+00, -6.3569e-01, -2.7864e+00,  1.0023e+01,\n","         -6.9319e-01,  5.1573e-01,  2.0835e+00, -3.1833e+00, -9.3609e-01,\n","         -3.2440e-01,  3.3223e-01, -1.3215e+00,  2.0578e+00, -8.2927e-01,\n","         -6.0632e-02, -6.2225e-01,  6.4277e-01, -2.0782e+00,  2.1707e+00,\n","         -1.2512e-01, -5.9728e-01,  1.2588e-01,  1.6078e+00,  1.7123e+00,\n","          1.1439e-02,  6.8821e-02,  1.2334e+00, -2.4970e+00, -1.8434e+00,\n","         -6.4725e-01, -1.0404e+00,  2.2835e+00,  7.2200e-02, -2.0444e+00,\n","          1.0964e+00,  2.7782e+00, -7.1709e-01, -2.6642e+00,  8.8152e-01,\n","          2.2851e-01,  1.7917e+00,  1.5641e-01, -1.8417e+00, -5.7441e-02],\n","        [-1.8393e+00, -1.8786e+00,  1.3898e-01, -2.2911e+00, -1.4116e+00,\n","          1.7185e+00, -8.4868e-01, -9.5216e-01, -1.8924e+00, -1.2890e+00,\n","         -2.7287e-01,  6.7584e-01,  2.1590e+00,  9.5240e-01,  1.0937e+01,\n","          2.1860e+00, -2.6646e+00, -9.1682e-01,  1.8785e-01, -1.7325e+00,\n","          1.7030e+00,  1.3556e+00,  9.9268e-01,  5.3593e-01, -8.4009e-01,\n","         -1.2095e+00,  3.4367e-01,  5.7392e+00, -1.6472e+00, -1.8802e-01,\n","         -1.6743e+00,  8.6107e-01,  1.7832e+00, -2.7796e+00, -1.0821e+00,\n","          8.0515e-01, -3.5442e-01, -4.3639e-01,  6.9279e-01, -7.0008e-01,\n","          1.2409e+00,  1.0457e+00, -2.3001e+00,  1.4999e+00,  5.7355e-01,\n","         -3.8972e+00, -1.4465e+00,  2.0087e-01, -1.8276e+00,  1.2762e+00],\n","        [ 3.4269e-01, -1.3243e+00,  5.3033e-01, -1.4767e+00, -1.8052e+00,\n","          1.5127e+00,  1.7804e+00, -1.5693e+00,  1.3247e+00, -1.9014e+00,\n","         -1.3399e-01, -2.4085e-01, -5.2539e-01,  2.6588e+00, -7.2733e-01,\n","         -1.0328e+00,  2.2319e+00, -4.8353e-03, -8.1679e-01, -1.0261e+00,\n","         -4.8686e-01,  2.6635e-02, -4.5547e-01,  6.9041e-01, -1.3220e+00,\n","          2.8220e-01,  3.0083e+00,  1.9119e-01, -1.8423e+00, -2.6664e-01,\n","         -5.1260e-01, -1.4884e+00,  5.0044e-01,  9.9157e+00, -4.1097e-01,\n","          2.9027e+00, -8.3457e-01, -9.3647e-01, -6.2555e-01, -1.3290e-01,\n","         -2.4769e+00, -1.5627e+00, -1.0637e+00,  4.0429e+00,  1.4675e+00,\n","         -1.1694e+00, -1.0156e+00, -1.0240e+00, -9.8359e-01, -1.3369e+00],\n","        [-2.9918e+00,  5.3297e-01, -9.4864e-01, -1.7668e+00,  4.1843e+00,\n","         -8.9841e-01, -4.6057e+00, -1.7897e+00, -3.9064e-01,  4.2624e+00,\n","         -1.9573e-02, -1.1001e+00,  6.2989e-01,  2.6020e-01, -6.9275e-01,\n","         -1.8187e+00, -1.7624e-02, -2.4260e+00,  2.8012e+00, -2.9708e+00,\n","          3.5890e+00,  1.9348e+00, -1.5049e+00,  1.3994e+00,  2.0178e+00,\n","         -2.5476e+00, -1.4972e+00, -3.6227e+00, -9.8131e-01,  1.8669e-01,\n","         -1.4898e+00,  1.2945e+01,  4.1423e+00, -4.0633e+00,  4.8104e-01,\n","         -3.3686e+00,  3.0716e+00,  4.1912e+00, -8.1112e-01, -1.6825e+00,\n","          2.9654e+00,  3.8018e+00, -1.3699e+00, -1.9839e+00,  1.0333e+00,\n","          2.2887e-01, -1.7776e+00, -2.8238e+00, -2.3242e+00, -5.9508e-05],\n","        [ 8.0241e-02,  6.2325e+00, -5.0639e-01,  7.3321e-02,  5.3291e-01,\n","          1.5779e+00, -1.9449e+00, -8.5096e-01, -6.1570e-02, -5.7680e-01,\n","         -1.9040e+00, -1.5128e+00, -1.1579e+00, -1.3564e+00, -1.3948e+00,\n","          2.2828e+00, -8.6640e-01, -2.7110e+00, -4.4273e-01, -1.9570e+00,\n","          9.3649e-01, -1.1594e+00, -9.0556e-01, -2.0763e-01,  2.8933e-01,\n","         -2.6100e+00, -3.0407e-01, -1.1515e+00, -1.1754e+00,  1.1984e+00,\n","          4.4323e-01,  6.6127e-01, -2.9226e-01, -2.9771e-01,  1.1295e+01,\n","         -1.1462e+00, -7.3697e-01,  3.5380e+00, -1.3561e+00, -3.0703e+00,\n","          9.8976e-01,  1.8807e-01, -1.6954e+00,  2.1402e+00, -1.2640e+00,\n","         -4.6752e-01,  1.6951e+00, -1.1504e+00, -1.0486e+00,  1.7127e+00],\n","        [ 2.1583e-01, -1.5726e-01,  5.0294e-01, -6.2056e-01,  4.1535e-01,\n","         -7.9504e-01, -1.2623e+00, -3.5832e-01, -7.9641e-01, -8.3507e-01,\n","          1.2509e+01,  1.8215e-01,  3.4828e-01, -1.1638e+00, -1.2072e+00,\n","         -2.0580e+00, -1.1121e+00,  3.9334e+00, -1.7794e+00, -1.5177e+00,\n","          4.3007e-01, -1.1509e+00,  4.2048e-01, -1.2811e+00, -1.4329e+00,\n","         -1.4305e+00, -8.3431e-01, -1.4161e+00, -6.7530e-01, -1.3014e+00,\n","          2.9249e-02, -1.5888e+00,  1.4839e+00,  9.0537e-01, -1.0555e+00,\n","         -5.6274e-01, -3.0751e-01, -3.2104e-01, -7.4782e-01,  5.6245e-01,\n","         -3.7028e-01, -7.2349e-01,  4.3272e+00,  1.9305e+00,  9.5813e-01,\n","         -4.8204e-01,  2.3499e+00, -1.9629e+00,  4.2118e+00, -2.3315e+00],\n","        [ 1.1217e-01,  1.2051e+00,  1.4282e+00,  4.8149e+00, -1.8454e+00,\n","         -1.4710e+00,  1.6265e+00, -4.3691e+00, -4.6362e-01, -7.9125e-01,\n","         -3.9527e+00, -1.8759e+00, -1.6498e+00,  1.0395e+00, -2.7369e+00,\n","         -1.0306e+00,  1.9630e-01,  4.9780e-01,  7.0419e-01,  1.3677e+01,\n","         -5.2869e-01,  1.3433e-01,  9.8337e-01, -4.6634e-01,  5.5050e+00,\n","          1.2558e-01, -1.0593e+00, -2.0235e+00, -2.3710e+00,  1.7270e-01,\n","          3.1334e+00, -2.4688e-01, -2.0138e-01, -7.2957e-02, -8.2802e-01,\n","         -9.6220e-01, -1.4808e+00, -2.3145e+00,  4.5152e+00,  3.8713e+00,\n","         -3.8636e+00, -2.9011e-01, -3.1859e+00,  2.3908e-01, -9.2031e-01,\n","         -9.0567e-01, -3.1064e-01,  7.3526e-01, -1.4725e+00, -2.3715e+00],\n","        [-1.5076e+00, -1.3908e+00, -2.1018e+00, -9.6357e-01, -1.0432e+00,\n","          3.1284e-01, -3.1355e+00,  7.8428e-01,  2.7799e-01,  1.4532e+00,\n","         -1.9465e+00,  8.7016e-01,  2.0094e+00, -6.2710e-01, -8.5612e-01,\n","          6.4062e-02, -4.7706e-01,  1.2938e+00, -8.1519e-01, -1.2969e+00,\n","         -2.0482e+00, -1.3928e+00, -3.9971e-02, -2.4022e+00,  2.8678e-01,\n","          3.6515e-01, -2.9469e-01, -1.1894e+00,  2.4239e+00,  2.5114e+00,\n","          6.9572e-01, -3.7249e-01,  4.2266e+00, -2.8255e+00, -2.1379e+00,\n","         -3.4682e+00, -1.4763e+00,  1.1449e+00,  7.1822e-01,  4.7321e-01,\n","          1.1346e+01,  1.8574e+00, -8.3105e-01, -5.0775e-01,  1.2814e+00,\n","          3.2754e+00,  4.6924e-01, -1.5347e+00, -1.4069e-01,  1.1482e+00],\n","        [ 7.4782e-01,  2.0560e+00, -2.3750e+00, -8.2710e-01,  1.1958e-01,\n","         -1.2853e+00, -9.5580e-01, -2.4234e+00,  1.3907e+01, -3.2826e+00,\n","         -1.7003e+00, -2.4820e+00,  5.2450e-01,  4.7652e+00, -9.2763e-01,\n","         -8.6573e-01,  1.2640e-01, -2.8650e+00, -2.8928e+00, -6.4586e-02,\n","          7.2414e-01, -7.8682e-02, -1.9508e-01,  5.5226e+00,  1.7248e-01,\n","         -2.9137e+00, -2.2297e+00, -2.0920e+00, -2.1653e+00, -1.1648e+00,\n","         -2.0775e+00,  1.8661e-02, -4.2326e-01, -8.1247e-01,  2.6126e+00,\n","         -1.8232e+00,  2.7393e+00,  5.3930e+00,  4.5063e-01, -1.0206e+00,\n","          1.9333e-02,  7.5404e-01,  1.2952e+00,  3.9652e+00, -5.7417e-01,\n","         -2.3952e+00, -1.1291e+00, -2.4370e+00, -1.5114e-01,  2.3684e+00],\n","        [ 2.3973e+00, -1.4406e+00,  4.7297e+00,  1.3387e+00, -1.6063e+00,\n","          1.7669e+00,  1.0933e+01, -2.3134e+00, -2.6028e+00, -2.5547e+00,\n","          4.1219e-01,  2.7648e-02,  4.5823e-01, -1.9287e+00, -9.6131e-01,\n","         -2.4668e+00,  8.7564e-01,  2.0000e+00, -2.5049e+00, -4.5265e-01,\n","          2.0820e+00, -1.6753e+00, -8.9796e-01, -1.4676e+00, -2.6385e-01,\n","         -5.5636e-01,  3.3153e+00, -1.1259e+00, -2.8777e+00, -1.7885e+00,\n","          7.7638e-01, -2.4957e+00, -2.1299e+00,  3.4970e+00, -2.0577e+00,\n","          6.7888e+00,  1.4110e+00, -3.0886e+00,  1.5881e+00,  4.4247e-01,\n","         -2.5163e+00, -7.1388e-01, -1.7409e+00,  6.4187e-01, -4.9270e-01,\n","         -3.6081e+00, -5.6947e-01,  2.2056e+00,  5.6098e-01, -1.1171e+00],\n","        [-2.6148e+00, -1.4314e+00, -1.0427e+00,  1.8138e+00, -2.1105e+00,\n","          2.7248e+00, -3.5775e+00, -2.7125e+00, -2.7759e+00,  8.1638e-01,\n","         -2.3703e+00,  2.1202e+00, -4.5850e+00, -9.1308e-01, -1.6413e+00,\n","          2.5905e+00,  3.6385e-01,  1.8253e+00, -2.5268e-02,  3.0351e+00,\n","         -2.1968e-01, -4.9410e-01, -3.3596e+00, -1.3725e+00,  1.6875e+00,\n","          2.1045e+00, -3.1688e-01, -1.2793e+00, -1.4458e+00,  1.1263e+01,\n","          2.0145e+00,  1.1569e+00,  1.7033e+00, -3.5524e+00,  2.7566e-02,\n","         -2.7806e+00, -1.8105e+00, -6.3663e-01,  1.1575e+00, -8.7840e-01,\n","          5.3022e-01, -4.2038e-01, -2.3026e+00, -4.0575e-01,  5.0904e+00,\n","         -4.8988e-01, -3.4674e-01,  1.7370e+00, -2.6623e-02,  3.6281e+00],\n","        [-4.1773e-01, -1.2670e+00,  1.1411e+01, -1.3568e-03,  1.5387e+00,\n","         -1.6798e-01,  2.7785e-02, -2.0007e+00, -3.4065e+00, -3.6298e-01,\n","          9.9089e-01,  2.4498e+00,  9.1357e-01, -2.5687e+00, -1.4188e+00,\n","         -2.8224e-01,  5.1354e-01, -1.5666e+00, -6.5349e-02, -4.2732e-01,\n","          2.8052e+00,  2.6015e-01,  1.4620e+00, -1.3322e+00,  2.5510e+00,\n","          9.3924e-01, -1.8172e+00, -3.6729e-01,  2.6292e-01, -4.4874e-01,\n","         -4.4303e-02,  2.1835e+00,  2.4572e-01, -1.7273e+00, -1.8300e+00,\n","          4.7321e-01,  1.3886e-01, -1.9325e+00,  2.3286e+00,  6.1222e-01,\n","          2.7118e-01, -1.3580e+00, -1.6641e+00, -1.0622e+00, -1.1449e+00,\n","         -8.6190e-01, -3.7748e-01, -1.8094e+00, -1.5751e+00,  1.0393e-01],\n","        [ 2.8309e+00, -3.5342e+00,  3.3216e+00,  8.3880e-01, -2.3480e+00,\n","          6.6287e-01,  1.0427e+01, -3.0989e+00, -1.4264e+00, -4.1247e+00,\n","         -1.3055e+00,  1.6143e+00, -9.4870e-01, -1.3598e-01, -2.9173e+00,\n","         -2.1429e+00,  3.1843e+00,  3.4559e+00, -2.7298e+00,  2.1605e+00,\n","          1.4545e+00, -2.4412e+00, -1.2021e+00, -1.2118e+00,  4.4040e-01,\n","          5.4397e+00,  1.0268e+00,  1.2793e-01, -3.4312e+00, -4.3798e-01,\n","          3.8307e+00, -2.9526e+00, -1.1558e+00,  1.2968e+00, -3.9405e+00,\n","          7.9166e+00,  9.3268e-02, -4.0914e+00,  6.8063e-01,  2.8082e+00,\n","         -4.1140e+00,  9.2800e-01, -3.1862e+00,  1.3042e+00,  1.7772e-01,\n","         -3.0786e+00, -3.2532e+00,  3.5416e+00,  1.1693e+00, -6.5082e-01],\n","        [-1.9740e+00, -3.1455e+00,  9.7149e-01, -3.2135e+00,  1.8329e+00,\n","          9.5011e-01, -2.1318e+00,  1.6599e+00, -1.6026e+00,  4.5218e-01,\n","          5.2356e-01,  2.2018e+00,  3.6674e+00, -2.5551e+00, -1.2224e+00,\n","         -1.6002e+00, -1.3327e+00, -5.5568e-01, -2.3292e-01, -1.8082e+00,\n","         -1.3042e+00,  2.9334e-01, -5.7280e-01, -1.4874e+00, -6.1266e-01,\n","         -8.6879e-01, -5.8704e-01,  1.9510e+00,  1.0478e+01,  1.5854e+00,\n","         -5.0214e-01,  1.4628e+00,  3.9123e-01, -2.9766e+00, -1.4773e+00,\n","          8.6931e-01,  1.5277e-02,  1.6754e+00,  5.4730e-01,  2.6964e-01,\n","         -6.4677e-02,  5.3831e+00,  7.7254e-01, -2.4505e+00,  5.0026e-01,\n","         -1.4444e-03, -8.8895e-01, -2.2300e+00,  2.7214e-02,  3.0596e+00],\n","        [ 1.5450e+01, -6.3695e-01, -8.3301e-01,  2.5600e-01, -5.1016e+00,\n","          1.1801e+00, -1.5900e+00, -2.7890e+00,  7.9114e-02, -2.9058e+00,\n","          8.2791e-01,  2.7106e+00, -2.1380e+00, -3.0700e+00, -2.8563e+00,\n","         -2.9455e+00,  6.7127e+00,  2.5221e+00, -4.2794e+00, -1.6504e+00,\n","          3.1273e+00, -1.8782e+00, -3.4732e-01, -2.7400e+00,  4.2026e-01,\n","          3.1985e+00,  1.0516e+00, -3.2413e+00, -2.0190e+00, -1.6145e-01,\n","          1.2978e+00, -4.3858e+00, -9.6881e-01, -6.6240e-01, -2.5893e+00,\n","         -5.5850e-01, -1.3832e+00,  6.8661e-02,  5.1643e+00, -1.0333e+00,\n","         -7.5539e-01, -8.7807e-01,  3.3024e+00,  1.5262e+00,  5.3969e-02,\n","         -4.1656e+00,  4.9916e+00,  2.8453e+00,  4.1707e+00, -1.1448e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([18,  9, 14, 33, 31, 34, 10, 19, 40,  8,  6, 29,  2,  6, 28,  0],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7431, 10.8407, -0.5745,  ..., -1.7151, -2.3092,  2.6285],\n","        [-0.0415,  4.9201, -0.3827,  ..., -0.7740, -0.7258,  3.3440],\n","        [ 5.9374, -3.5366,  1.5504,  ...,  6.1989,  1.1198, -1.5470],\n","        ...,\n","        [ 2.1224, -0.1993, -0.9477,  ..., -2.1194,  0.4975, -0.5937],\n","        [ 1.7654, 16.1791,  1.0228,  ..., -1.5898, -3.3950,  1.6405],\n","        [ 1.0600, -4.2565,  3.8826,  ..., -0.5305,  2.1933, -0.5542]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 390/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.5333, -0.3452, -0.4597,  ..., -0.5317, -3.6661,  4.3234],\n","        [-2.2744,  1.2758,  1.5923,  ..., -3.6749, -3.3046,  4.1956],\n","        [-2.7896, -2.3476,  0.8017,  ..., -3.5055, -1.7847, -0.2129],\n","        ...,\n","        [-2.9502, -2.6339, -1.0675,  ..., -0.3031, -0.6085,  0.0440],\n","        [-1.0045, -0.6702,  0.2229,  ..., -1.0082,  0.0560,  0.9596],\n","        [ 0.4787, -1.8904,  1.2776,  ...,  3.6798,  0.0269, -0.6434]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([29,  4, 28, 27, 42, 40,  3, 36, 22, 19, 32, 24, 41, 33, 14, 26,  1, 48,\n","        13, 42, 21, 46, 12, 10, 46, 14, 39,  4, 22, 22, 36, 12,  6, 40, 36, 41,\n","        12, 31, 26, 20, 46, 47, 34,  3, 24, 28,  5, 45,  2, 17, 12,  9,  3, 37,\n","        35, 26, 38, 46, 27,  9, 46, 40, 47, 29, 15, 36, 38, 13, 24,  0, 26, 49,\n","        19, 13, 25, 12, 28, 13, 18,  9, 41, 30, 23,  8, 30,  8, 23,  7, 37, 16,\n","        35, 20, 44, 29, 27, 29, 14, 18,  8, 36, 22, 39, 21, 45, 38, 31, 36, 39,\n","        35,  9,  4, 43, 41, 12, 48, 30,  1, 20, 43,  7, 28, 23,  8, 35, 23, 41,\n","         7, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.2291e+00,  4.9146e-02,  2.1980e-01,  ..., -1.3989e+00,\n","         -2.3527e+00,  1.9224e+00],\n","        [ 6.8874e-01, -1.4007e-02,  2.4628e+00,  ...,  1.6455e+00,\n","         -4.2613e-01, -1.9675e+00],\n","        [-2.2333e+00, -1.2253e+00, -6.8952e-01,  ..., -1.3666e-01,\n","         -8.4575e-01, -1.6005e+00],\n","        ...,\n","        [ 1.5038e+01,  3.7933e-02,  1.9755e+00,  ..., -9.5396e-01,\n","          8.3753e+00, -1.3189e+00],\n","        [ 7.0076e-01, -1.0316e+00,  5.3625e-01,  ..., -6.0621e-02,\n","          7.7023e-01, -2.8061e+00],\n","        [ 1.0665e+00,  1.0010e+00,  2.7211e+00,  ..., -2.4183e+00,\n","         -8.8546e-01, -1.7712e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 4, 19,  7, 25, 18, 30, 32, 13, 47,  3, 20,  2, 43, 26,  5, 37, 18, 27,\n","        29, 43,  6,  5,  7, 26, 16, 11, 18,  6, 44,  1,  8, 28, 26, 33, 32, 33,\n","        41, 10, 20, 35, 21, 10, 16, 33, 23, 19,  4,  5, 49, 34, 42,  4,  8, 17,\n","        30, 14, 22, 16, 27, 40, 49, 11, 14, 41, 10, 49, 14, 24, 44, 28, 19, 37,\n","         8, 18, 13, 24, 21,  1, 40,  0,  2, 32, 22, 21, 13, 24,  1, 45, 49,  3,\n","        26, 15,  9, 10, 31, 45, 14, 19,  0,  2, 47, 16,  9, 15, 16, 32,  2, 40,\n","        37, 49, 30, 28, 25,  6, 28, 44, 15, 29, 27,  3, 19, 34, 31, 38, 17,  0,\n","        17, 46], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.2311e+00,  4.4080e+00, -9.4018e-01,  ..., -1.8957e+00,\n","         -2.8709e+00,  2.7858e+00],\n","        [ 5.2640e-01, -3.9250e-01, -1.2478e+00,  ..., -1.2505e+00,\n","          1.5099e+00, -6.0434e-01],\n","        [-2.5528e+00, -1.0999e+00,  3.3810e+00,  ...,  6.8099e-02,\n","         -1.2355e+00,  2.9716e-01],\n","        ...,\n","        [-1.5679e+00,  2.6292e+00, -1.4751e+00,  ..., -4.3366e+00,\n","         -2.2414e+00,  2.2519e+00],\n","        [-2.8950e+00, -3.4934e+00,  1.4607e+01,  ..., -1.8469e+00,\n","          4.5632e-01,  7.9221e-01],\n","        [ 3.1610e+00, -2.0839e+00,  5.3940e+00,  ...,  1.1151e+00,\n","         -1.1261e+00,  9.0867e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 42, 11, 16, 46, 47, 27, 31,  1, 17, 37,  6, 33, 42, 13, 19, 45, 30,\n","         5,  9, 38, 29, 17, 15, 24, 27, 33,  2, 11, 15, 10, 34,  1, 42,  5, 21,\n","         9, 39, 25, 41, 43, 15, 48,  0, 32, 35, 40,  7,  7, 34,  3, 17, 31, 47,\n","        20, 35, 32, 22, 22, 49, 25, 31,  3, 10,  1,  9, 30, 39,  2, 31, 36, 45,\n","        27, 25,  4, 20, 47,  0, 14, 32, 36, 41, 44, 33, 48, 12,  0, 43,  6,  2,\n","        48, 11, 18, 35,  4, 30, 17, 15, 36, 17, 23, 12, 20, 27, 40, 49, 25, 10,\n","        29, 47, 10,  6, 37, 30, 45,  3, 12,  9,  1, 31,  8, 16, 42, 23, 17, 37,\n","         2, 16], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-5.2027e-01, -2.0208e+00,  1.0128e+00, -2.0970e+00,  1.6287e-01,\n","          1.1155e+00,  8.6054e-01, -6.7643e-01, -2.1349e+00,  1.7841e+00,\n","         -2.8794e-01,  7.3986e+00,  2.4606e-01, -2.0167e+00, -2.5719e+00,\n","         -2.1937e-01,  4.3625e-01, -8.8713e-03, -1.2650e+00, -2.6935e+00,\n","          6.1875e-01,  1.5425e-01, -1.4808e+00, -3.4988e+00, -9.8907e-01,\n","          5.0430e-02, -2.0074e+00, -6.1047e-01,  1.2327e+00,  2.5752e+00,\n","         -1.2354e+00, -1.8932e+00,  1.5276e+00,  2.1209e+00,  3.1418e-01,\n","          1.6562e+00,  8.0054e-01, -3.7283e-01,  2.0404e-01, -4.9813e-01,\n","         -1.0832e+00,  3.4312e+00,  1.4726e-01,  7.4238e-01,  7.8272e-01,\n","         -4.4213e-01,  1.0054e+00, -1.2173e-01, -1.3496e+00,  3.0789e-01],\n","        [-1.5570e+00, -9.1726e-01, -1.2924e-01, -2.6071e+00, -1.4136e+00,\n","         -1.1916e-02, -8.0850e-01, -7.6385e-01,  2.9131e-01, -1.0965e+00,\n","         -6.5656e-01, -1.8968e+00,  3.6033e+00, -1.7655e-01,  1.0514e+01,\n","         -8.2335e-01, -1.7438e+00, -5.7141e-01, -1.0396e+00, -1.7875e+00,\n","          2.4383e+00, -4.4963e-01,  2.1555e+00,  1.9259e+00, -1.2774e+00,\n","          2.8714e-01, -8.0527e-01, -2.6554e-02,  2.0818e-02, -1.5715e+00,\n","         -9.5843e-01,  6.7892e-01,  2.4562e+00, -1.8211e+00, -7.1513e-01,\n","          2.1215e+00,  8.2798e-02,  2.0949e+00, -5.1358e-01, -5.4307e-01,\n","          2.8026e+00, -1.6578e+00, -5.8495e-01,  2.2880e+00,  1.5701e+00,\n","         -3.1322e+00, -1.9632e-01, -1.2935e+00, -1.2193e+00,  4.3601e-01],\n","        [ 8.6869e-01,  1.2226e+00,  5.0382e+00,  1.0403e-01, -5.3483e-01,\n","         -2.1234e+00,  1.0147e+00, -5.4890e+00,  2.9725e+00, -1.6252e+00,\n","         -1.8885e-01, -3.0549e+00,  8.6321e-01, -7.0597e-01, -1.0656e+00,\n","         -3.3188e+00, -2.0442e-01,  1.3260e+00, -1.5100e+00,  9.4095e-01,\n","          2.4477e+00, -8.9177e-02,  1.9584e+00,  2.1795e+00,  1.1652e+00,\n","         -2.1157e+00, -1.3812e+00,  9.4386e-01, -2.6947e+00, -8.4170e-01,\n","          1.1847e+00,  2.6630e-01,  1.1304e+00, -2.2350e+00, -7.0633e-01,\n","          7.2091e-01,  1.5583e+00, -1.2491e+00,  7.5594e+00,  2.9692e-01,\n","         -1.3982e+00,  1.1643e+00, -1.2582e+00,  3.6924e+00,  9.2008e-01,\n","         -2.3387e+00, -7.7071e-01, -4.5200e-01, -8.8033e-01,  2.7364e-01],\n","        [-1.1234e+00, -2.5797e-01, -4.8440e-01,  1.7049e+00, -7.5064e-01,\n","          8.9735e+00,  6.6413e-01, -3.7868e+00,  7.4932e-01,  9.4228e-01,\n","          4.3856e-01, -2.1376e-01, -6.4558e-01,  1.0151e+00, -5.5019e-01,\n","          1.7716e+00, -2.0616e-01, -1.0782e+00, -2.9167e-01,  3.2428e-01,\n","         -4.6186e-01,  5.2557e-02, -2.7512e+00,  2.5155e-01, -2.1433e+00,\n","         -3.5392e+00,  1.8035e+00,  7.2579e-01,  3.0063e-01,  1.1453e+00,\n","         -4.4861e-02,  3.7516e+00,  7.2937e-01,  2.4629e+00,  2.2055e+00,\n","         -7.6692e-02, -7.6618e-01,  2.5987e+00, -1.5339e+00, -2.9635e+00,\n","          1.8520e-01,  5.3936e-01, -1.7115e+00,  9.0706e-01,  1.4373e+00,\n","         -2.1071e+00, -9.5184e-01, -2.3714e+00, -3.2168e+00, -3.5982e-01],\n","        [ 6.4027e-01, -2.3773e+00,  6.1091e-01, -1.5236e+00, -3.1448e-01,\n","         -5.2711e-01, -6.2596e-01, -1.5449e+00,  1.3097e+00,  4.6578e-01,\n","          6.6505e+00, -2.2135e+00,  3.1132e-01, -2.7272e+00, -1.7334e+00,\n","         -1.1281e+00, -1.9882e+00,  2.7579e+00, -2.2633e+00, -1.8043e+00,\n","         -5.5438e-01, -1.4185e+00,  1.1956e+00, -2.4912e-01, -2.2655e+00,\n","         -1.5468e+00,  8.5325e-02,  6.2704e-01, -1.0654e+00, -1.1350e+00,\n","         -1.4510e+00, -1.1963e-01,  6.2432e-01, -9.5886e-01, -8.6098e-01,\n","         -5.5642e-01, -3.5515e-01,  4.5668e-01,  3.6457e-01,  2.3201e+00,\n","          6.9364e-01,  2.6071e+00,  3.5433e+00,  7.8176e-01, -3.9948e-01,\n","         -1.5671e+00, -2.8720e-01, -1.3557e+00,  1.1577e+01, -1.3912e+00],\n","        [ 2.8304e+00, -2.3771e+00,  2.5913e+00,  4.5933e+00, -1.2393e+00,\n","         -6.4260e-02,  1.3155e-01, -2.6471e+00, -8.1625e-01, -2.6397e+00,\n","         -1.8833e+00,  1.6171e-01, -2.5190e+00, -8.0595e-01, -1.3414e+00,\n","         -1.2093e+00,  1.2187e+01, -1.0717e+00, -1.3872e+00,  1.9527e+00,\n","          5.1347e-01, -1.1657e+00, -1.2040e+00,  1.2349e-01,  5.1260e-01,\n","          3.3853e+00,  2.3470e+00, -6.2051e-01, -2.3907e+00, -3.3227e-01,\n","          2.9675e+00, -1.0724e+00,  2.4096e-01,  2.4135e+00, -1.5621e+00,\n","          1.8339e+00, -2.5421e+00, -2.3939e-01,  2.1877e+00,  1.1026e+00,\n","         -2.1870e+00, -1.4464e+00, -2.7774e+00, -4.9587e-01, -1.2416e+00,\n","         -2.9592e+00,  7.8600e-01,  2.1885e+00, -1.1897e+00,  4.2336e-01],\n","        [ 1.0801e+01, -3.7469e-01, -9.7643e-01,  3.4991e+00, -2.4955e+00,\n","         -1.9782e+00,  9.9791e-01, -2.6344e+00,  2.1645e+00, -2.5926e+00,\n","         -2.3508e+00, -1.2285e+00,  5.3964e-01, -3.8697e-02, -5.2777e-01,\n","         -2.3285e+00,  3.0228e+00,  2.7050e-01, -2.8900e+00, -2.6838e-01,\n","          2.6110e-01, -1.6839e+00,  4.3887e+00,  4.7502e-01,  7.2795e-01,\n","          3.9474e+00, -1.0595e-01, -2.3447e+00, -1.8445e+00, -5.3471e-01,\n","          3.3412e-01, -3.5086e+00,  2.8482e-01, -4.4751e-01, -1.8866e+00,\n","          1.7871e+00, -6.1088e-01, -1.0543e+00,  3.9768e+00,  2.6378e+00,\n","         -1.1691e+00, -8.1049e-01, -4.8144e-01,  1.8764e+00, -7.3998e-01,\n","         -1.8773e+00, -8.0389e-01,  1.2954e+00, -6.0506e-01, -1.5251e+00],\n","        [-1.5098e+00,  1.1787e+00,  1.1177e+00, -1.1774e+00,  2.7291e+00,\n","          2.5959e-02,  7.3572e-02, -3.2950e+00,  7.5650e-01,  1.7032e+00,\n","         -1.8823e+00,  5.3360e-01, -7.7173e-01,  4.4581e+00, -2.1573e+00,\n","         -8.0083e-01, -1.6908e+00, -9.7191e-01,  3.7752e+00, -1.1736e+00,\n","          1.0615e+01,  7.1820e-01, -2.3339e+00,  2.4253e+00, -8.6450e-01,\n","         -1.0135e+00, -2.2501e+00, -3.2602e+00, -2.1409e+00,  1.9179e+00,\n","          4.1145e-01,  2.4182e+00,  3.5643e-01, -2.8050e+00,  1.3123e-01,\n","         -2.9082e+00,  1.6456e+00,  3.3903e-01,  2.0648e-01, -2.7024e+00,\n","          4.2690e-01,  5.2372e-01,  3.5289e-01,  2.1273e+00, -1.0742e+00,\n","         -9.4163e-01, -1.1397e+00, -5.4991e-01, -2.1520e+00,  3.1996e+00],\n","        [-1.9217e+00,  3.3076e-01, -7.6357e-01, -3.8678e-01,  8.7370e-02,\n","         -7.9864e-01, -8.5091e-02,  9.2166e+00, -3.4434e-01,  6.2635e-01,\n","         -1.2501e+00, -2.0646e-01,  8.3456e-01, -1.0469e+00, -3.9321e-01,\n","         -9.9125e-01, -6.3872e-01, -6.8086e-01,  2.8092e+00, -6.0407e-01,\n","         -1.7337e+00,  2.3496e+00, -9.2686e-01, -1.8938e+00, -2.0932e+00,\n","         -1.6299e+00,  1.4690e+00, -2.1509e-01,  3.0861e+00, -1.7504e-01,\n","         -1.7227e+00,  7.7407e-01,  1.5875e+00, -6.1270e-01, -4.4945e-01,\n","         -3.1942e-01, -1.4639e+00,  9.9088e-01, -1.4867e+00, -3.9014e-01,\n","          9.3727e-01,  1.8281e+00,  8.9225e-01, -1.5800e+00, -6.0698e-01,\n","          2.1630e+00,  7.9382e-01, -7.8474e-01, -9.9966e-01, -4.0748e-01],\n","        [ 3.9663e-01, -2.3155e+00,  2.4704e+00, -3.1969e+00, -1.7665e+00,\n","         -4.5310e-01, -1.0810e+00,  8.5755e-01, -1.3930e+00, -3.6443e-01,\n","          3.2925e-01,  1.1180e+01,  2.7687e+00, -1.2866e+00, -2.0794e+00,\n","         -2.6461e+00,  1.4190e+00,  3.3630e-04, -9.5775e-01, -2.2330e+00,\n","          9.4613e-02,  3.2402e+00, -9.1026e-01, -3.4633e+00,  1.2220e-01,\n","         -1.8758e-01, -1.0514e+00, -1.1267e+00,  4.0444e+00,  3.0737e-01,\n","          1.5063e+00, -4.3078e-01,  3.2934e-01, -2.5739e+00, -2.6968e+00,\n","         -1.8754e-01, -3.0497e-01, -2.2032e+00,  5.3151e+00,  2.3776e+00,\n","          1.9359e-01,  1.7133e+00,  1.2552e+00, -1.2038e+00, -1.1929e+00,\n","         -1.2346e+00,  1.1770e-01, -4.9807e-01, -6.7836e-01,  5.9236e-01],\n","        [ 1.2652e+00,  1.2219e+00,  2.0712e+00,  4.7173e+00, -1.3738e+00,\n","         -4.6510e-01, -3.9502e-01, -3.5555e+00, -1.9603e+00,  1.9853e+00,\n","         -1.1475e+00, -1.9288e+00, -2.6930e+00, -4.7820e-01, -9.4606e-01,\n","          6.6452e-01,  5.3992e-01, -1.2269e+00,  2.1652e+00,  4.9488e+00,\n","         -7.7310e-01, -1.0465e+00,  1.2611e-01, -5.6721e-01,  1.0931e+01,\n","          7.5620e-01,  1.4558e-01, -6.0114e-01, -2.0115e+00, -6.6405e-02,\n","          2.5136e+00,  1.6814e+00, -1.6571e-01, -1.8519e+00, -4.4908e-01,\n","         -1.5311e+00, -1.0623e+00,  1.4550e+00,  1.4128e-01, -1.5420e+00,\n","          2.5226e+00, -1.4833e+00, -3.8642e+00, -1.7274e+00, -2.6472e+00,\n","         -2.4039e+00,  2.0109e-01,  1.6729e+00, -1.6134e+00, -8.8070e-01],\n","        [-2.1223e+00,  1.2134e+00, -1.1847e+00, -2.0822e+00,  3.2741e-01,\n","         -9.8554e-02, -5.1276e-02, -6.4189e-01,  1.2852e+00,  3.0391e-01,\n","         -1.7411e+00, -1.7530e+00,  2.9371e+00, -4.8707e-01, -1.2454e+00,\n","          3.1943e+00, -1.8822e+00,  1.6415e+00,  3.4069e-01,  9.5467e-02,\n","         -3.0667e+00, -8.1090e-01, -1.9229e+00,  3.7056e-01, -2.1401e-02,\n","         -1.7687e-01, -2.1005e+00, -6.0778e-01, -1.2466e-01,  3.0419e+00,\n","         -6.0748e-01,  2.5292e-01,  2.1245e+00, -1.4181e+00, -1.3878e+00,\n","          1.0594e+00,  4.8899e+00,  2.0124e+00, -2.0217e-01, -1.5547e+00,\n","          1.1003e+00,  3.1485e-03, -1.3635e+00, -1.1729e+00,  9.8595e+00,\n","         -1.5188e+00,  3.7709e-01, -3.5534e+00, -2.5493e+00,  2.2431e+00],\n","        [-1.8728e+00, -3.2548e+00,  3.1337e+00, -1.8077e+00,  9.7826e-01,\n","          2.8360e-01, -8.0759e-03, -5.6947e-01, -1.8414e+00,  2.5922e-01,\n","         -2.4150e-03,  9.3475e+00, -2.8582e-01, -2.4576e+00, -3.0288e+00,\n","         -1.9235e+00, -1.2201e-01,  2.2755e-01,  1.2360e+00,  2.7930e+00,\n","         -2.4881e+00,  2.3699e+00, -1.9841e+00, -3.5477e+00,  5.4618e-01,\n","          3.1625e+00, -7.6120e-01,  3.1990e+00,  7.4216e-01,  2.3615e+00,\n","          1.1206e+00,  5.4671e-01,  2.1338e-01, -1.3933e+00, -2.7896e+00,\n","         -8.7156e-01, -2.1492e+00, -2.1414e+00,  2.2658e+00,  1.9179e+00,\n","         -1.0375e+00,  1.9268e+00, -6.1747e-01, -1.9476e+00, -1.6239e+00,\n","          1.8422e+00, -1.0021e+00,  2.0492e+00, -1.5164e+00,  7.6802e-02],\n","        [-3.3484e+00, -4.9759e-01, -1.3483e+00, -1.5858e+00,  5.3642e-01,\n","          2.1130e+00, -1.7108e+00, -2.4346e+00, -6.5993e-01,  9.0269e-01,\n","         -8.1408e-01, -5.3742e-01, -1.9077e+00, -2.1380e-02, -1.0418e+00,\n","          3.7340e+00, -1.8177e+00, -7.3559e-01,  1.3283e+00, -9.7389e-01,\n","          6.1812e-01,  5.7756e-01, -3.5467e+00, -5.3507e-02, -1.4413e+00,\n","         -1.9549e+00,  1.6529e-01,  1.2204e-02,  1.2853e-01,  7.5586e+00,\n","         -1.6689e+00,  3.1997e+00,  1.8145e+00, -3.3090e-01,  3.7161e+00,\n","         -2.5646e+00, -1.1784e+00,  1.6241e+00, -1.4455e+00, -2.6686e+00,\n","          2.3866e+00,  2.0049e+00, -9.0234e-02,  5.8221e-01,  1.5287e+00,\n","          1.1999e+00,  1.0929e+00, -2.0984e+00, -2.2199e+00,  3.4221e+00],\n","        [ 2.5371e+00,  5.7429e+00,  7.5163e-01,  5.0509e+00, -1.0146e+00,\n","         -2.1859e+00, -1.5270e+00, -3.5511e+00, -8.5498e-01,  1.2661e+00,\n","         -2.1812e+00, -2.7403e+00, -1.8762e-01, -6.6030e-01, -2.3726e+00,\n","         -1.3690e+00, -3.8257e-01, -2.3134e-01,  9.8998e-01,  2.6963e+00,\n","         -1.3242e+00, -1.8314e+00,  4.6682e-01, -3.4796e-01,  1.0277e+01,\n","         -2.9460e-01, -2.1179e-01, -2.1816e+00, -8.4380e-01,  1.0419e+00,\n","          2.0123e+00,  6.0570e-01,  3.1684e-01, -1.6048e+00,  4.7948e-01,\n","         -9.1027e-01, -4.4122e-01,  1.3220e+00,  1.3108e-01, -1.6750e+00,\n","          1.2592e+00, -2.3144e+00, -2.8905e+00, -1.0778e+00, -1.0762e+00,\n","         -1.4010e+00,  2.9308e+00,  9.6412e-01, -1.9233e+00, -7.0983e-01],\n","        [ 1.5890e+00, -1.9249e+00,  5.0845e-01, -9.5488e-01, -5.3768e-01,\n","          1.1152e+00, -2.6183e-01, -1.6541e+00,  2.2458e-01,  3.2851e-01,\n","          6.2900e+00, -2.7238e+00, -1.5720e+00, -9.5243e-01, -1.6599e+00,\n","         -2.1654e+00, -1.1403e+00,  3.0885e+00, -8.2885e-01, -1.5848e+00,\n","          3.4101e+00, -8.1570e-01, -1.9280e+00,  1.7144e-02, -2.6600e+00,\n","         -2.2686e+00,  2.2409e+00, -5.8220e-01, -2.2341e+00, -1.3665e+00,\n","          1.0669e+00, -8.3302e-01, -1.0471e+00,  8.5902e-01, -8.9292e-01,\n","         -9.3950e-01, -1.7441e+00,  1.2051e+00, -5.8212e-01,  1.4208e-01,\n","          3.3624e-01,  7.2259e-01,  2.5530e+00,  1.7782e+00,  6.7703e-01,\n","         -2.3685e+00,  1.0406e+00, -3.6287e-01,  1.0817e+01, -7.5929e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([11, 14, 38,  5, 48, 16,  0, 20,  7, 11, 24, 44, 11, 29, 24, 48],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7274, 10.8443, -0.5706,  ..., -1.7199, -2.3150,  2.6393],\n","        [-0.0527,  4.9028, -0.3768,  ..., -0.7695, -0.7342,  3.3412],\n","        [ 5.9222, -3.5321,  1.5479,  ...,  6.1956,  1.1128, -1.5505],\n","        ...,\n","        [ 2.1136, -0.2002, -0.9475,  ..., -2.1168,  0.4901, -0.5948],\n","        [ 1.7558, 16.1787,  1.0258,  ..., -1.5932, -3.3960,  1.6461],\n","        [ 1.0490, -4.2459,  3.8926,  ..., -0.5384,  2.1688, -0.5568]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 391/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8621,  1.3933, -0.6403,  ..., -3.0594, -1.5479,  3.3107],\n","        [-2.2569, -1.1490,  1.9977,  ...,  0.3216, -2.6771, -0.8786],\n","        [ 2.2053, -3.7088, -0.4188,  ...,  2.0737,  2.7107, -3.0333],\n","        ...,\n","        [ 4.1489, -2.9373, -0.0282,  ..., 16.9326,  0.2334, -1.0993],\n","        [-1.1061,  0.5449, -1.6806,  ..., -2.7087,  1.1030,  2.3543],\n","        [-2.2202, -2.7408, -1.3139,  ..., -3.3176, -1.7215,  0.8148]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([37,  9, 39,  8, 44,  6, 40, 11, 14, 46, 36,  3,  9,  2,  9, 39, 41,  8,\n","        27, 10,  8, 37,  1, 47, 20, 30, 28,  7, 17,  2, 25, 24, 14, 16,  7, 42,\n","        29, 40, 13, 35, 19, 48,  2, 14, 34, 26,  1, 30,  6, 49, 32, 26, 21,  0,\n","        25, 36,  8, 21, 15, 12, 22, 29, 25, 32, 38,  8, 32,  7, 43, 26, 18,  3,\n","        25, 28, 17, 34, 38,  5, 24,  9,  6,  1, 30, 47,  9, 13, 20, 16,  0, 10,\n","         2, 26, 25, 30, 18, 20, 31, 19, 11, 40, 37, 45, 21,  6, 22, 12, 27, 35,\n","        16, 14,  2, 21,  5, 39, 12, 29, 48,  7,  9, 41, 48, 18, 42,  1, 20, 47,\n","        40, 28], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.0152, -1.7200,  0.9142,  ...,  2.1033,  0.4571, -1.3172],\n","        [-1.2200, -1.6797, -1.3860,  ...,  0.2802, -1.8416,  0.1316],\n","        [-0.0743,  0.7983, -1.1010,  ..., -1.7203, -2.0434,  1.4565],\n","        ...,\n","        [-2.5365, -3.2479, -0.1377,  ..., -4.0634, -1.5480, -2.0115],\n","        [ 0.2022, -1.8469,  3.0043,  ...,  0.4457,  1.4442,  0.0925],\n","        [-2.6392, -3.2654, -1.6549,  ..., -0.1943, -0.5514,  1.1606]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([27, 32, 13, 35, 18,  3,  9,  4, 14, 10, 33,  8, 23,  5,  9, 16, 17, 43,\n","        16, 12, 40,  3, 49, 31,  1, 25,  3,  4,  4, 40, 36, 24, 17,  7, 16, 17,\n","         0, 30, 30, 10, 27, 38,  9, 35, 28,  4, 16,  6, 37, 12, 17,  6,  8, 21,\n","        23, 22, 22, 28, 30, 26, 11,  2, 39, 15,  7, 41, 33, 24,  4, 35, 16, 10,\n","        10,  4, 32,  1, 37, 20,  3, 48, 47, 26,  5, 22, 42, 30, 49, 10, 13, 28,\n","        27, 18, 44, 45, 49, 20,  2,  0, 38, 31, 35, 12, 37, 45,  2,  5, 25, 13,\n","        48, 31, 11, 20, 15, 23, 10, 34, 33, 27, 48, 46, 21, 31, 28, 25, 19, 28,\n","        26, 41], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.1268, -2.9216,  3.0001,  ...,  4.1269, -0.6388, -0.9582],\n","        [-1.0943, -1.5765,  2.3089,  ...,  0.6256,  0.9233,  0.1796],\n","        [-2.5099,  1.9810, -0.8571,  ..., -1.9669, -3.5157,  3.0063],\n","        ...,\n","        [-3.3357, -4.4832,  0.4620,  ..., -2.6583,  3.1921,  1.5059],\n","        [-0.6496, -1.7284,  0.3335,  ..., -1.2552, -0.2354, -1.4140],\n","        [ 5.0092,  2.9205, -0.4192,  ...,  4.2267, -1.3061, -0.6221]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([11,  5, 15,  4, 22, 46, 40, 40, 14, 11, 22, 29, 47, 15,  0, 29,  0, 13,\n","        35, 32, 13, 42, 36, 49, 43, 19, 44, 17,  1, 46, 42, 49,  1, 33, 36, 34,\n","        45, 14, 16, 32, 15, 24, 37, 30, 14, 22, 27, 17, 29, 44, 23, 23, 36, 35,\n","         2, 33,  4,  3,  6,  0, 26, 24, 19, 24, 49, 41, 34, 19, 17, 10, 12, 36,\n","        13, 33, 36, 32, 46, 46, 29, 31, 47, 31, 30, 19, 20, 20,  0, 47, 33, 41,\n","        15,  7, 23, 24, 27, 15, 36, 43, 38, 49, 43, 45, 17, 23, 42, 46, 31, 41,\n","        48, 11,  1,  7, 42, 31,  5, 45, 29,  8, 44, 38, 43,  3, 41, 47, 41, 44,\n","        12, 24], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.2346e+00,  5.2171e-01,  1.1076e+00,  2.5218e+00, -3.5842e+00,\n","          8.9567e-01,  4.6251e+00, -4.7453e+00,  2.2380e+00, -1.5073e+00,\n","         -1.5079e+00, -2.3713e+00, -4.5280e+00,  3.9165e+00, -3.1432e+00,\n","         -1.0169e+00,  1.4094e+00,  2.1300e+00, -2.1710e-01,  1.0815e+01,\n","         -7.4584e-02, -1.2277e+00, -2.3661e+00, -2.5119e+00,  4.1312e+00,\n","          1.4996e+00,  2.9084e+00, -2.5738e+00, -3.8349e+00,  2.8053e+00,\n","          9.3845e-01, -9.1211e-01, -1.0226e+00,  1.5953e+00, -1.7848e+00,\n","          3.8446e-02, -1.2977e+00, -2.4100e+00,  7.8976e-01, -8.5374e-01,\n","         -3.1264e+00, -2.3347e+00, -1.4564e+00,  2.5844e+00,  2.5801e+00,\n","         -3.2930e+00,  5.8684e-01,  1.6340e+00,  2.0959e-01, -1.5673e+00],\n","        [-1.1814e+00, -1.0959e+00, -4.9976e-01, -1.7704e+00,  2.7822e+00,\n","         -9.2904e-01, -1.0549e-01,  6.8453e-01,  1.1772e+00,  1.1697e+00,\n","         -9.3866e-01,  7.3760e-01,  1.8358e+00, -6.9311e-01, -3.2136e+00,\n","         -3.1104e+00, -1.3603e+00,  4.1944e-01, -1.5601e-01,  7.3433e-02,\n","         -1.5362e+00, -2.1930e-01,  1.7531e+00, -3.0492e+00, -6.5199e-01,\n","          7.5533e-01, -9.4452e-02, -2.5510e+00,  7.6216e-01,  8.1524e-01,\n","          3.0164e-01,  8.8783e-01,  4.7817e+00,  2.2941e-01, -5.5406e-01,\n","         -1.9835e+00, -2.0626e+00, -2.7977e-01, -2.4636e-01,  5.8844e-01,\n","          2.8078e+00,  3.2522e+00, -2.2528e+00, -1.0403e+00,  1.1057e+00,\n","          1.1988e+01, -3.1219e-01, -2.5024e+00, -1.0090e+00, -1.7020e+00],\n","        [-9.6754e-01, -1.1245e+00,  1.5143e+00, -1.4573e+00, -1.2700e+00,\n","         -1.5404e+00, -2.4936e+00, -7.9739e-01, -1.3981e+00,  8.4012e+00,\n","          1.5966e-01, -4.2020e-01, -5.6825e-01, -1.5410e+00, -2.9270e+00,\n","         -1.5164e+00, -1.3506e+00,  4.0915e+00,  3.3507e+00,  6.2652e-01,\n","          3.5318e+00, -2.5035e-01, -1.8403e+00, -1.9586e+00,  3.3064e+00,\n","         -1.9161e-02, -6.2251e-01, -2.2631e+00,  5.1187e-01,  6.7504e-01,\n","         -2.3271e-01,  1.8425e+00,  1.0750e-01, -2.3108e+00, -2.6054e+00,\n","         -1.9643e+00, -1.1413e+00,  1.4483e+00, -2.3734e-01, -2.5165e+00,\n","          8.5550e-01,  7.8057e-01,  2.2941e+00, -8.5459e-01,  2.3768e+00,\n","         -8.1905e-01,  2.5303e+00, -7.0885e-01, -2.7671e-01,  1.1654e+00],\n","        [-2.3769e-02, -4.1478e+00,  2.6736e+00, -3.7862e+00, -2.8420e+00,\n","          1.0856e+00, -2.0468e+00, -9.5631e-02, -2.3490e+00, -4.8964e-01,\n","          1.9100e+00,  1.4381e+01, -2.4130e+00, -2.3637e+00, -2.2055e+00,\n","         -2.5194e+00,  4.0727e+00,  3.2312e-01, -3.9330e-01, -5.3375e-01,\n","          5.3140e-01,  1.8059e+00, -2.3483e+00, -4.1295e+00, -1.6604e-01,\n","          2.4750e+00, -9.2496e-01, -1.7126e+00, -1.2747e-01, -5.3398e-01,\n","          2.7254e+00, -8.1159e-01,  8.1838e-01, -1.8066e+00, -4.3245e+00,\n","          7.2764e-01, -8.8348e-01, -4.5409e+00,  5.3987e+00,  3.5817e+00,\n","         -9.2380e-01,  2.0442e+00,  1.2374e+00, -2.1346e+00,  9.4050e-03,\n","         -2.0798e+00, -1.3032e+00,  5.7884e+00,  1.7113e+00, -3.5228e-01],\n","        [ 2.8918e+00,  2.4823e+00,  3.0713e+00,  1.3290e+01, -2.7710e+00,\n","          1.1004e+00,  5.5385e-01, -2.7025e+00, -1.2479e+00, -2.0305e-01,\n","         -1.1274e+00, -1.4140e+00, -3.3614e+00, -1.8255e-01, -2.7789e+00,\n","         -1.6364e+00,  2.7980e+00, -2.6748e-01, -1.8481e+00,  2.1044e+00,\n","          1.0624e+00, -1.1712e+00, -1.2725e+00, -1.6022e+00,  3.4850e+00,\n","          1.2077e+00,  2.7989e+00, -3.2965e+00, -3.1263e+00,  5.4506e-01,\n","          5.6139e-01, -1.5699e+00, -1.1906e+00,  1.4991e+00, -1.8000e+00,\n","          1.5963e-01, -1.7805e+00, -1.4218e+00,  3.7251e+00,  7.0285e-01,\n","         -2.2849e+00, -2.9967e+00, -1.9988e+00,  5.4084e-01, -1.5485e+00,\n","         -4.3319e+00,  2.6299e+00,  4.6095e+00, -6.4043e-01, -1.3861e+00],\n","        [-1.8598e-01,  2.9595e+00,  1.3769e-02, -6.2448e-01, -1.7510e+00,\n","          1.2972e+00,  5.3070e-01, -1.1067e+00,  7.2710e-01, -1.9590e+00,\n","         -1.7896e+00, -1.1537e+00, -1.5696e+00,  5.4116e-02, -7.2793e-01,\n","          2.7194e+00, -6.9128e-01, -1.9926e+00, -2.3738e+00, -2.4041e+00,\n","          3.0838e-01, -6.4429e-01,  2.8273e-01, -5.2256e-01,  4.2788e-02,\n","         -3.1881e+00, -9.0888e-01, -4.0172e-01, -1.1878e+00,  1.0180e+00,\n","         -5.5036e-02,  1.4385e-01,  2.3588e-01,  1.9163e+00,  1.1767e+01,\n","         -2.2142e-01, -5.9228e-01,  1.9488e+00, -8.9595e-02, -1.8680e+00,\n","          1.0055e+00, -6.4943e-02, -2.5908e+00,  3.8004e+00, -1.1147e+00,\n","         -9.2298e-01,  1.0747e+00, -1.3555e+00, -6.3710e-01,  1.9724e+00],\n","        [ 2.2625e+00, -2.2032e+00,  2.9112e+00,  7.5675e-01, -2.2962e+00,\n","          1.7207e-01, -1.5329e+00, -1.5959e+00, -1.0489e+00, -5.6494e-01,\n","          6.1405e-01,  2.3096e-01, -2.5931e+00, -1.0375e+00, -4.3441e-01,\n","         -2.6374e+00,  9.5230e+00,  1.5260e+00, -1.4388e-01,  8.2199e-02,\n","          6.2599e-01, -1.6966e+00, -1.1660e+00, -1.3195e+00, -2.6594e-03,\n","          3.0994e+00,  2.3681e+00, -1.4430e-01, -1.6044e+00, -1.5489e+00,\n","          4.2119e+00, -7.3351e-01,  8.4431e-01,  9.4752e-01, -2.5148e+00,\n","          2.3513e+00, -1.6189e+00, -1.3594e+00,  2.1773e+00, -8.3865e-01,\n","         -1.1261e+00, -1.2968e+00, -1.3328e+00,  1.0023e-01,  6.6833e-01,\n","         -2.3405e+00,  1.6410e+00,  8.0736e-01,  4.2368e-01, -7.9920e-01],\n","        [ 8.0644e-01, -1.8457e+00,  4.4585e+00, -2.4421e+00, -6.1134e-01,\n","          1.0938e+00, -1.1950e+00, -1.0474e+00, -1.9702e+00,  9.3258e-03,\n","          2.7717e+00,  2.3553e+00,  2.5578e+00, -2.6479e+00,  8.7027e-01,\n","         -7.1545e-01, -8.0713e-01, -1.6157e+00, -1.3580e+00, -1.8965e+00,\n","         -1.0768e+00,  1.9015e+00,  6.5325e-01, -2.4005e+00, -9.9702e-01,\n","         -7.7901e-01,  6.0325e-01,  9.7157e+00, -4.1855e-01, -1.1742e+00,\n","         -9.8934e-01,  4.6814e-01, -4.0193e-03, -1.1452e+00, -1.7244e+00,\n","          1.7070e+00, -3.3845e-01, -1.0724e+00,  2.7373e+00, -8.3412e-01,\n","         -4.9349e-01,  5.5944e-01,  5.9988e-01,  1.9986e-01,  1.1574e-01,\n","         -1.4101e+00, -3.4634e-01, -1.1682e-01,  8.2208e-01, -1.7335e+00],\n","        [-1.0699e+00, -2.6319e+00,  1.6507e+00, -2.8075e+00, -7.5911e-01,\n","          2.5338e+00, -1.6501e+00,  7.8949e-01, -4.5899e-01,  7.4908e-01,\n","          5.5680e-01,  7.1984e-01,  1.2814e+00, -3.3848e+00, -1.5295e+00,\n","          5.3306e-01, -6.4555e-01, -6.7541e-01,  3.2040e-01, -3.7750e-01,\n","         -2.9848e+00,  2.3224e-01,  1.5550e-01, -1.8056e+00, -3.6114e-01,\n","         -1.6276e+00, -1.5101e+00,  1.1049e+01,  2.7816e+00, -4.9517e-01,\n","          9.2188e-02,  9.5033e-01,  4.9094e-01, -2.5461e+00, -8.1302e-01,\n","          6.3139e-01, -6.5827e-01,  7.7042e-01,  6.6237e-01, -2.2205e+00,\n","          2.2790e+00,  4.7124e+00, -6.6930e-01, -1.3489e+00,  7.7316e-01,\n","         -1.5823e+00,  4.6170e-02, -5.2500e-01,  1.1815e+00,  2.2386e+00],\n","        [ 4.3472e-01, -2.0281e+00,  1.5395e-01, -4.3683e-01, -5.5057e-03,\n","          1.3797e-01, -7.4774e-01, -8.6903e-01,  4.2115e-02,  2.7623e-01,\n","          2.0252e+00, -7.4812e-01,  1.0924e+01, -2.8592e+00,  1.4655e+00,\n","         -3.6024e-01, -1.1547e+00,  1.7301e+00, -2.7284e+00, -2.2836e+00,\n","          8.1389e-01,  1.1993e-01,  3.5338e+00, -2.1250e+00, -8.8006e-01,\n","          3.8212e-01, -5.0668e-01, -2.0641e+00,  3.5880e+00, -7.2028e-01,\n","          1.9073e-01, -1.5903e-01,  1.8162e+00, -2.4962e+00, -2.2459e+00,\n","          2.9828e+00,  1.7866e-01,  1.3277e-01, -5.2060e-01, -9.5216e-01,\n","          2.9484e+00,  8.4751e-01,  1.4874e+00,  2.8309e-01,  2.0688e+00,\n","         -2.1053e+00,  8.2047e-01, -2.9844e+00,  8.4965e-02, -1.8682e+00],\n","        [-2.1221e-01, -2.8694e+00, -6.1382e-01, -2.2318e+00, -1.7014e+00,\n","          9.1269e-01,  6.5379e-01, -3.0786e-01, -4.9334e-01, -1.2458e+00,\n","         -2.6855e-01, -2.0829e+00,  2.5805e+00,  8.0556e-01,  1.2755e+01,\n","          3.3420e-02, -1.9490e+00,  1.4726e-03, -6.2963e-01, -2.6769e+00,\n","          1.8913e+00,  1.8845e-01,  3.0176e+00,  5.5904e-01, -5.6197e-01,\n","          1.1818e+00,  1.1016e+00,  8.5033e-01, -1.0324e+00, -5.9666e-01,\n","         -1.4439e+00,  2.6216e-01,  1.9612e+00, -1.3810e+00, -2.1251e+00,\n","          2.7631e+00, -6.3797e-01, -1.0327e+00,  5.9303e-02, -3.0592e-02,\n","          5.7826e-01,  2.4835e-01, -1.8051e+00,  1.8994e+00,  1.3430e+00,\n","         -3.2473e+00, -1.8955e+00,  3.0992e-01, -6.7103e-01, -2.5787e-01],\n","        [-2.5843e+00,  5.6642e+00,  9.9736e-01,  8.8391e-01,  1.4029e+00,\n","         -1.8656e+00, -1.4262e+00, -9.9168e-01, -2.3351e+00,  4.8715e-01,\n","         -1.6585e-01, -1.5429e-01,  2.8617e-01,  3.6516e-01, -2.2877e+00,\n","          2.9024e-01, -2.3680e+00, -9.6960e-01,  8.8339e+00, -3.8194e-02,\n","         -4.8324e-01,  9.7049e-01, -2.0030e+00,  3.7598e-01,  3.6619e-02,\n","         -2.0678e+00, -2.2189e+00, -1.5772e+00,  2.4068e+00,  1.9559e+00,\n","          2.3548e-01,  2.8397e+00,  4.5870e-01, -3.2316e-01,  3.5796e+00,\n","         -2.7814e+00, -1.9626e+00,  3.5522e+00, -1.2369e+00, -1.6468e+00,\n","         -3.7577e-01,  2.0554e+00, -7.4951e-01, -1.5055e+00, -2.0382e+00,\n","         -1.1092e-01,  1.1577e+00, -2.3198e+00, -2.2656e+00, -4.2500e-01],\n","        [-2.3778e+00, -3.9007e-01, -4.0338e+00, -1.8193e+00,  5.9401e+00,\n","          1.8456e+00, -1.5060e+00, -3.1811e+00,  1.8955e+00, -1.2888e+00,\n","         -7.4423e-01,  1.3520e+00, -9.3323e-01,  3.2542e+00, -2.5547e+00,\n","          6.9131e+00, -1.7119e+00, -2.0790e+00, -3.6846e+00, -2.3122e+00,\n","          2.9760e+00, -7.0169e-01, -3.5981e+00,  5.4171e+00, -1.7434e+00,\n","         -2.6420e+00, -1.7486e+00, -4.3390e+00,  7.0546e-01,  1.1657e+01,\n","         -1.9388e+00,  2.6370e+00,  3.9375e+00, -1.7858e+00,  8.3725e-01,\n","         -1.8234e+00,  5.5421e+00,  1.5939e+00, -9.8928e-01, -2.3562e+00,\n","          2.7146e-01,  2.0948e+00, -1.6318e+00,  2.2031e+00,  2.0293e+00,\n","         -3.2235e+00, -2.0378e+00, -3.5546e+00, -3.4565e+00,  6.1302e+00],\n","        [ 3.1291e+00,  2.4315e+00, -7.0170e-01,  2.1652e-01,  4.4968e+00,\n","         -7.6295e-01, -1.5617e+00, -2.1973e+00,  5.1455e+00, -5.6059e-01,\n","          6.7714e-01, -2.7573e+00,  6.7288e-01, -1.4017e+00, -2.2413e+00,\n","         -1.2433e+00, -3.7133e-02, -3.7503e+00, -2.6101e+00, -2.2103e+00,\n","          1.0550e+00, -3.4208e-01, -1.9394e+00,  4.9775e+00, -4.5296e-01,\n","         -4.2983e+00, -1.8145e+00, -3.3528e+00, -2.7276e-02,  3.8063e-01,\n","          4.2790e-01,  1.1556e+00, -1.1800e+00, -1.6552e+00,  9.2327e-01,\n","         -2.9954e+00,  4.3156e+00,  1.1238e+01, -7.2312e-01, -2.6138e+00,\n","          2.6887e+00,  8.2010e-01,  7.5339e-01,  2.5283e+00, -8.0337e-02,\n","         -2.7524e+00,  8.9937e-02, -3.6513e+00,  7.8400e-01,  3.4799e+00],\n","        [ 2.4213e+00, -2.9501e+00,  2.1227e+00,  3.3394e+00, -1.5012e+00,\n","         -1.5857e+00,  3.7990e+00, -2.0470e+00, -1.4069e+00, -4.0412e+00,\n","         -1.3069e+00,  4.0209e-01, -1.5165e+00,  8.6234e-01, -1.4270e+00,\n","         -2.3254e+00,  2.2173e+00,  1.7733e+00, -3.0008e+00,  2.1096e+00,\n","          1.9577e+00, -1.2293e+00,  1.6353e+00,  9.2837e-01,  1.8033e+00,\n","          3.5101e+00, -1.1916e+00, -2.9608e+00, -1.5893e+00, -5.7555e-01,\n","         -1.9684e-01, -1.6331e+00, -4.9425e-01,  1.7682e+00, -1.7534e+00,\n","          2.3971e+00,  5.3149e-02, -2.4906e+00,  2.9445e+00,  9.5906e+00,\n","         -3.3743e+00, -1.1107e+00, -2.1433e+00,  7.7845e-01, -1.7710e+00,\n","         -2.0232e+00, -1.6141e+00,  1.5119e+00,  1.0618e+00, -1.7956e+00],\n","        [-9.7034e-01,  4.2437e+00, -2.1182e-01,  6.6475e-01, -9.6993e-01,\n","          5.9694e-02, -1.2279e+00, -1.2329e+00,  8.2188e-01,  1.1718e+00,\n","         -2.4742e+00,  1.4800e-01, -1.1723e+00,  1.2007e+00, -1.0458e+00,\n","         -7.9682e-02, -3.1161e-01, -7.5093e-01,  7.8846e+00,  2.3089e-01,\n","          5.0037e-01,  2.9037e+00, -1.7064e+00,  1.2432e+00,  4.7660e-01,\n","         -2.5671e+00, -3.9343e-01,  7.3799e-02, -1.0466e+00,  1.0353e+00,\n","         -7.8365e-02, -7.9757e-02,  1.3295e+00, -1.1552e-01,  1.5399e+00,\n","         -3.2341e+00,  3.9604e-02, -1.7295e-01,  8.0323e-01, -2.2426e+00,\n","          1.5241e+00,  5.6429e-01, -3.7407e-01, -1.7238e+00,  4.0437e-01,\n","         -4.7504e-01,  9.4831e-01, -1.7820e+00, -1.9202e+00,  5.9916e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([19, 45,  9, 11,  3, 34, 16, 27, 27, 12, 14, 18, 29, 37, 39, 18],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7381, 10.8480, -0.5683,  ..., -1.7240, -2.3134,  2.6533],\n","        [-0.0488,  4.9117, -0.3732,  ..., -0.7791, -0.7378,  3.3577],\n","        [ 5.9634, -3.5308,  1.5363,  ...,  6.1997,  1.1198, -1.5540],\n","        ...,\n","        [ 2.1119, -0.2021, -0.9457,  ..., -2.1141,  0.4944, -0.5954],\n","        [ 1.7531, 16.1527,  1.0193,  ..., -1.5968, -3.3845,  1.6464],\n","        [ 1.0560, -4.2430,  3.8840,  ..., -0.5393,  2.1816, -0.5520]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 392/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.4388, -0.6560,  1.6081,  ...,  3.6735, -1.3477, -1.5315],\n","        [-2.7169,  2.1318,  0.3997,  ..., -1.4992, -2.8424, -0.2088],\n","        [-0.8091, -1.2800,  2.3903,  ..., -2.5280,  4.5439, -2.3961],\n","        ...,\n","        [-3.3682, -2.2403,  0.4755,  ...,  1.1001, -1.9383,  5.0150],\n","        [ 2.0420, -1.6998,  2.1606,  ..., -0.2331,  1.5725,  0.5478],\n","        [-3.4420, -1.7361,  4.4817,  ..., -0.2475, -1.5916,  0.2868]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 6, 18, 10, 39, 22, 22, 40,  3,  9, 33, 19, 16, 23, 25, 17, 32, 48,  9,\n","        42, 13, 39, 47, 37, 27, 29, 13, 12, 25, 41,  9, 36, 21, 18,  2, 47, 41,\n","        32, 40, 33, 29, 10, 28, 22, 34, 28, 15,  9, 42, 40, 31, 39,  7, 42,  7,\n","        23,  3,  0,  1,  0, 15, 27, 43,  8, 36, 35, 16,  2, 18, 20, 22, 45, 30,\n","        12, 27, 12, 37, 24,  8, 34, 20, 13,  3, 13, 10, 19, 10, 30, 17, 41, 40,\n","        47, 46, 17, 20, 38, 17, 13, 34,  6, 12, 44, 47, 24, 30, 15, 37, 49, 36,\n","        44,  3, 46, 22,  8, 43, 27,  7, 23, 19, 34, 13, 31, 27, 30, 19,  1, 29,\n","         5, 11], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.8417, -1.2489, -1.3374,  ..., 16.5398, -0.3936, -2.5641],\n","        [-2.4391, -0.0223,  2.3228,  ..., -2.2553,  0.5125,  0.3000],\n","        [-1.2338, -1.3473, -1.3338,  ..., -1.7715, -1.3203, -0.7252],\n","        ...,\n","        [ 0.7382, -0.9406,  2.2147,  ...,  0.1602,  1.1822, -0.1778],\n","        [ 2.8514,  2.6602,  0.4177,  ..., -0.9928, -1.8162,  1.0148],\n","        [ 0.3453, -2.4283,  0.9740,  ...,  0.0489,  2.0835, -1.5224]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([47, 40, 45, 35, 22, 14, 37, 41, 12, 21, 46, 46, 19, 40, 47, 14, 26, 45,\n","        29, 16, 32, 17,  1, 32, 19, 14, 42, 45,  2, 33, 29, 22, 46, 49, 28,  1,\n","        26,  6, 27, 35,  8, 17,  0, 35, 25, 20,  0, 26, 10, 35,  4, 11, 19, 25,\n","        16, 15, 49, 30, 49, 31,  5, 30, 23, 38, 27,  5, 48,  9, 45, 47, 27, 18,\n","        15, 25, 28, 14, 15, 21, 11,  2, 31, 21, 43,  5, 36, 33,  2,  9, 38,  0,\n","        29, 33,  5, 26, 44, 30, 30,  4,  7, 49,  5,  8,  6,  2, 32, 49, 27,  1,\n","         7, 38, 33, 35, 29, 18, 33, 29, 11, 31, 34,  1, 40, 44,  0,  2,  7, 26,\n","        24, 10], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1177,  0.2438, -2.1724,  ...,  0.6398, -3.5154,  4.6405],\n","        [ 3.7974,  5.6620,  1.3141,  ...,  3.8244, -1.6539, -0.7350],\n","        [-1.3861,  0.5381, -1.7651,  ..., -0.2340, -1.4644,  3.1838],\n","        ...,\n","        [ 0.7908, -0.9649,  1.9729,  ...,  2.1463,  0.8461, -0.7979],\n","        [ 1.5840, -2.4121,  2.0448,  ...,  1.5457, -0.8594, -1.6839],\n","        [ 0.5693,  1.9266,  1.6124,  ...,  1.9230, -0.0761, -2.0973]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([15, 24, 15,  1, 43, 20, 18, 37, 28,  6, 48, 30,  4, 27, 39, 18, 11,  9,\n","        48,  6,  8, 41, 41, 17,  0, 46, 24, 38, 20, 20,  9,  3,  1, 44, 31, 31,\n","        10,  7, 12, 14, 38, 48, 17, 12, 29, 49, 43, 34, 36, 16, 25, 12, 46, 16,\n","        49,  2,  4, 11, 12,  8, 22,  4,  9, 24, 44, 21, 32, 23, 32, 19,  5, 24,\n","        28, 43, 16, 26, 48, 11, 10, 14, 40, 26, 16, 31, 25, 11,  4, 47, 21, 24,\n","        41, 23, 41, 16, 10, 37, 14, 42,  3, 30, 14, 13, 23, 37, 45, 48, 25,  1,\n","         0, 32, 28, 31, 36, 36, 45, 24, 16,  8, 28, 20, 35,  4,  4,  7, 36,  6,\n","        35,  3], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1760e+00, -1.6735e+00,  1.0839e+00, -1.0367e+00, -3.2615e-01,\n","         -3.5397e-01, -2.1564e+00,  3.7923e-01, -3.3327e+00,  1.1189e+01,\n","         -4.3455e-01,  1.3711e+00,  1.5986e+00, -2.8987e+00, -2.2348e+00,\n","         -1.4713e+00, -1.0605e+00,  6.3508e-02,  3.2431e+00,  2.9070e-01,\n","          1.4194e+00,  6.6352e-01,  3.5524e-01, -2.1909e+00,  3.8512e+00,\n","         -2.8530e-01, -1.4869e+00, -4.0339e-01,  1.9420e+00,  1.6920e+00,\n","         -1.7053e-01,  2.7857e+00,  2.3382e-01, -2.7003e+00, -1.8709e+00,\n","         -1.3980e+00, -2.0121e+00,  4.6673e-01,  1.5817e-01, -1.0942e+00,\n","         -1.3929e-01,  1.8758e+00, -1.8164e+00, -2.5448e+00,  7.1551e-01,\n","          1.4935e+00,  1.0305e+00,  7.1415e-01, -8.1977e-01,  2.3805e-01],\n","        [-2.4642e+00,  4.6868e+00, -1.4520e+00, -2.1962e+00,  3.0826e+00,\n","         -7.3670e-01, -1.6840e+00, -2.0686e+00,  1.9405e+00, -3.5044e-01,\n","         -2.3190e+00, -2.5333e+00,  2.3487e+00, -1.0670e+00,  3.4169e-01,\n","          2.9234e+00, -1.2471e+00, -4.3317e+00,  1.7056e+00, -2.1233e+00,\n","          6.9435e-01,  1.0466e+00, -2.3768e+00,  4.6989e+00, -1.4533e+00,\n","         -3.7706e+00, -2.2425e+00, -8.9575e-01,  9.5591e-01,  9.8237e-01,\n","         -4.5589e-01,  2.3305e+00, -5.9377e-01, -1.9804e+00,  4.3591e+00,\n","         -1.9187e+00,  2.1306e-01,  1.0903e+01, -1.5157e+00, -3.1195e+00,\n","          4.4736e+00,  2.7642e+00, -1.9987e+00,  9.1341e-01, -5.3526e-01,\n","         -2.5783e+00, -8.2245e-01, -3.2885e+00, -2.3492e+00,  3.5017e+00],\n","        [ 4.3505e-01, -2.1189e+00,  1.7491e+00, -3.1306e+00, -7.7892e-01,\n","          8.9489e-01,  4.1028e-01, -2.5206e+00, -6.6933e-01, -5.7649e-02,\n","         -2.3619e+00,  2.1649e-01,  1.0241e+00,  1.1487e+00,  1.0152e+00,\n","         -1.0935e+00, -9.4087e-01, -1.5338e+00,  1.3385e+00, -2.2173e+00,\n","          9.5094e+00,  1.0063e-01,  6.3809e-01,  1.6784e+00, -2.3394e-01,\n","          8.5579e-01, -3.0106e+00,  1.4120e+00, -1.3801e-01,  4.2142e-01,\n","         -2.2636e-01,  8.2760e-01,  1.5624e+00, -3.0775e+00, -1.6558e+00,\n","          1.6943e+00,  3.1332e+00, -3.2427e-01,  1.0240e+00, -2.0736e-01,\n","          6.6005e-02,  1.8415e+00, -3.3860e+00,  2.4353e+00, -7.0185e-01,\n","         -3.1463e+00, -2.9365e+00,  1.8649e-01, -4.9702e-01,  1.6122e+00],\n","        [-1.1174e-01, -1.2690e+00,  6.1818e-01, -1.5649e+00, -6.6666e-01,\n","         -2.1220e-01,  4.7957e-01, -1.5474e-01, -1.0358e+00, -5.6628e-01,\n","          5.7391e+00,  3.7008e-01,  1.4088e-01, -8.5574e-01, -1.5572e+00,\n","         -1.9991e+00, -7.3608e-01,  1.0329e+01, -1.0309e+00,  9.6027e-01,\n","         -7.3796e-01, -8.5958e-01,  3.2213e-01, -2.0942e+00, -6.2468e-01,\n","          1.0973e+00, -1.2496e+00,  8.7798e-02, -6.3979e-02, -5.5441e-01,\n","          2.1565e+00, -7.0909e-01,  1.1843e+00, -1.0296e+00, -1.8656e+00,\n","          5.5527e-02, -1.1259e+00, -2.6004e+00,  5.4035e-02,  4.0932e-01,\n","         -6.8507e-01, -1.5151e+00,  2.0208e+00,  4.6242e-01,  1.5966e+00,\n","         -2.0941e-01,  1.3710e+00, -4.0609e-01,  2.1732e+00, -2.3277e+00],\n","        [ 7.5323e-01, -3.0143e+00,  1.6454e-01, -4.0825e-01,  4.4830e-02,\n","         -5.1537e-01, -1.2486e-01,  3.6723e+00, -3.2734e+00, -2.2956e+00,\n","         -1.2266e+00,  5.0164e+00, -1.1021e+00, -3.0017e+00, -8.0078e-01,\n","         -7.0424e-01,  1.8902e+00,  1.2154e+00, -7.3726e-01, -6.9529e-01,\n","         -2.4538e+00,  1.8224e+00,  1.9462e+00, -4.2003e+00, -1.2769e-01,\n","          1.6945e+00,  4.6823e-01,  5.7621e-02, -9.5864e-01,  1.1616e+00,\n","         -3.7035e-01, -3.7592e-01,  3.1771e+00, -8.1508e-01, -1.2970e+00,\n","          1.5862e+00, -2.8940e+00, -3.2738e+00,  2.6358e+00,  9.8704e+00,\n","         -6.0569e-01, -2.4052e-01, -2.0723e+00, -1.8957e+00, -1.2341e+00,\n","          1.8755e+00, -4.7868e-01,  3.9720e-01,  1.7866e+00, -2.4659e+00],\n","        [-2.1859e+00, -1.6879e+00,  1.3734e+01, -3.4721e+00,  1.1463e+00,\n","          1.9292e+00, -1.2008e+00, -3.2702e+00, -1.7311e+00,  2.0828e+00,\n","          7.6852e-01,  4.9528e+00, -1.0392e+00, -2.4396e+00, -2.5354e+00,\n","         -2.4813e+00,  2.0029e+00, -1.9553e+00, -6.6381e-01,  1.1795e+00,\n","         -6.1907e-02,  4.2783e-01, -1.5798e+00, -2.5880e+00,  5.7963e-01,\n","          3.4682e+00,  1.3319e+00,  1.4577e+00, -1.8957e+00,  2.1437e+00,\n","          1.1035e+00,  4.3718e-01,  1.7716e+00,  5.1499e-01, -3.0727e+00,\n","         -9.8419e-01, -2.7005e+00, -1.9263e+00,  2.1242e+00, -1.5545e+00,\n","          1.7713e+00, -8.6141e-01, -3.2433e+00, -4.1690e-01,  1.2393e-01,\n","         -1.9943e+00,  7.8816e-02, -7.3538e-01, -6.5889e-01,  6.3677e-01],\n","        [-2.9916e-01,  1.5338e+00, -1.1149e+00,  6.1156e-01, -2.5920e+00,\n","         -1.4407e+00,  1.4192e+00, -4.7340e+00,  4.5174e+00, -3.1961e+00,\n","         -3.1964e+00, -2.2248e+00, -2.5394e+00,  1.2898e+01, -1.2597e+00,\n","          2.9987e+00, -7.1556e-02, -1.3064e+00, -2.3556e+00,  4.8872e+00,\n","          1.9962e+00, -9.4031e-01,  7.6211e-01,  3.8175e+00,  2.6766e+00,\n","          2.6001e-01, -1.9290e+00, -3.3668e+00, -2.3478e+00,  1.3607e+00,\n","         -1.1328e+00,  2.1474e+00,  2.3896e+00,  1.6267e+00,  2.0576e+00,\n","         -9.0756e-01, -7.5365e-01, -9.9524e-01,  7.1024e-01, -4.8505e-01,\n","         -1.6928e+00, -1.6351e+00, -4.1840e+00,  4.3735e+00,  1.3969e-01,\n","         -1.3167e+00, -3.0378e+00, -1.4399e+00, -2.9052e+00,  1.4098e+00],\n","        [ 4.6974e+00,  4.4616e+00,  6.8435e-01,  1.0868e+01, -1.2395e+00,\n","          4.0028e-02, -8.7546e-01, -3.9470e+00, -2.8422e-01, -1.5309e+00,\n","         -9.0748e-01, -3.5403e-01, -2.2801e+00, -2.7370e+00, -2.4900e+00,\n","         -1.3645e+00,  3.1763e+00, -3.1804e+00,  1.6931e-01,  5.7498e+00,\n","         -1.9872e+00, -2.0251e+00, -4.9185e-01, -4.8836e-01,  5.7129e+00,\n","         -1.3664e+00, -1.2481e-01, -1.9708e+00, -2.2832e+00, -1.6181e-01,\n","          5.3224e+00, -1.0346e+00, -9.2095e-01, -1.9752e+00,  6.0166e-01,\n","          4.6471e-01, -1.3484e+00,  1.1548e-01,  3.6038e+00, -1.2761e+00,\n","         -1.6652e+00, -2.6425e+00, -2.2921e+00, -6.0469e-01, -2.7550e+00,\n","         -2.6640e+00,  3.4910e+00,  3.8208e+00, -9.4886e-01, -4.5780e-01],\n","        [ 2.4817e-01, -2.3827e+00, -8.8537e-02, -1.4640e+00, -2.6103e+00,\n","         -2.6123e-01,  3.2267e+00, -1.4026e+00, -1.3204e+00, -6.4923e-02,\n","          4.8606e+00, -5.1794e-01, -9.2301e-01, -8.7377e-01, -1.8570e+00,\n","         -1.6314e+00, -2.6772e-01,  1.1835e+01, -5.5286e-01, -1.0294e+00,\n","          4.6059e-01, -8.3090e-01, -2.5295e-01, -1.9946e+00, -1.0452e+00,\n","          7.8550e-01, -5.0500e-01, -5.1815e-01, -8.1311e-01, -3.2946e-01,\n","          1.5583e+00, -2.0552e+00,  1.6179e+00,  1.7229e-01, -1.6905e+00,\n","          1.3995e+00,  6.0894e-01, -2.1071e+00,  3.0433e-02, -3.3643e-01,\n","         -8.8502e-01, -5.2874e-01,  1.4077e+00,  6.4641e-01,  2.7355e+00,\n","         -1.7340e+00,  1.3739e+00,  5.7915e-01,  2.4682e+00, -1.6456e+00],\n","        [-2.8734e-01, -8.6761e-01,  2.4462e+00,  2.0737e+00, -2.2858e+00,\n","          4.7272e+00,  2.5620e+00, -2.1403e+00, -9.1306e-01, -2.2074e+00,\n","         -2.0637e+00, -6.3795e-01, -1.9739e+00,  2.7405e-01, -6.8354e-02,\n","         -1.9195e+00,  2.5967e+00, -7.8262e-01, -8.3884e-02, -1.3986e-01,\n","         -7.2404e-01, -8.7863e-01, -1.2131e+00, -9.6949e-01,  6.7645e-01,\n","         -2.2819e-01,  1.3176e+01, -3.7990e-01, -3.2846e+00,  1.4616e+00,\n","          3.6887e-01, -8.8172e-01,  1.0283e-01,  5.7679e+00,  1.0840e+00,\n","          2.5919e+00, -3.5922e+00, -1.7798e+00,  7.3392e-01, -1.3231e+00,\n","         -1.1883e+00, -2.7818e+00, -3.5861e+00,  1.0842e+00,  1.1100e+00,\n","         -2.4298e+00, -8.6489e-01, -1.0793e+00, -4.8726e-01,  8.2040e-01],\n","        [ 2.4457e+00, -8.1974e-02,  3.0496e-01, -1.8993e+00,  1.7576e-02,\n","          1.3896e-01, -1.4830e+00, -1.0066e+00,  2.6226e+00, -1.1547e-01,\n","          2.0365e+00,  4.2018e-01,  1.7025e+00, -3.0933e+00, -1.6921e+00,\n","         -1.3386e+00,  4.5960e-01, -1.6347e+00, -2.4905e+00, -1.0066e+00,\n","         -1.3709e-01,  2.2117e-01, -2.6950e-01, -5.4486e-01, -1.1581e+00,\n","         -9.9155e-01, -4.7060e-01,  5.7323e-01,  2.0634e-01, -3.1695e-01,\n","         -8.9531e-02, -1.6387e+00, -1.1421e-01, -6.9809e-01, -1.2479e+00,\n","         -3.0584e-01,  1.2702e+00,  3.0708e+00,  5.9775e-01, -2.1256e+00,\n","          2.0884e+00,  2.9970e-01,  7.1955e+00,  3.7699e-01,  1.6981e+00,\n","         -1.3592e+00,  2.0378e+00, -6.9454e-01,  1.7370e+00, -7.8407e-02],\n","        [ 5.9674e+00, -1.3602e-04,  1.3917e+00,  1.2633e+01, -1.5722e+00,\n","         -3.7862e-01,  9.5168e-01, -3.2414e+00, -1.0878e+00, -1.1808e+00,\n","         -1.6167e+00, -1.4794e+00, -1.3771e+00, -1.2608e+00, -1.5943e+00,\n","         -1.3349e+00,  5.7068e+00, -1.7550e+00, -1.8773e+00,  3.8700e+00,\n","          2.9484e-01, -1.5710e+00, -4.8825e-01,  8.5133e-01,  2.8272e+00,\n","          1.1549e+00, -1.0620e-01, -2.5682e+00, -2.8782e+00, -1.1381e+00,\n","          4.9706e+00, -1.3409e+00, -2.0290e+00, -1.3536e-01, -1.6469e+00,\n","          1.1476e-01, -2.1077e+00,  1.6435e-01,  3.8593e+00,  2.7151e+00,\n","         -1.3001e+00, -1.9898e+00, -2.7038e+00,  2.3727e-02, -2.3329e+00,\n","         -3.2029e+00,  7.8403e-01,  1.9950e+00, -3.0262e-01, -1.9614e+00],\n","        [ 1.5005e+00,  1.2884e+00, -8.2478e-01, -1.7777e+00,  1.1741e+00,\n","          1.3677e+00,  2.4677e+00, -3.4620e+00,  3.4232e+00, -2.7293e+00,\n","         -2.3048e+00,  2.2890e+00, -3.5614e-01,  8.1311e-01, -1.0487e+00,\n","          3.6862e-01, -5.7447e-01, -2.7980e+00, -9.8716e-01, -1.3792e+00,\n","          4.1318e+00, -5.1523e-01, -2.7383e+00,  8.7001e-01,  8.2736e-02,\n","         -9.4326e-01, -3.2847e+00,  5.6907e-01, -2.9114e+00,  5.1298e-01,\n","         -8.6192e-01, -4.3372e-01, -3.5054e-01, -1.6562e+00,  1.0244e+00,\n","          1.2766e+00,  1.0191e+01, -1.8510e-01,  1.3221e+00, -5.0272e-01,\n","         -8.1946e-01,  7.9058e-01, -1.2391e+00,  2.8585e+00,  9.2681e-01,\n","         -3.2810e+00, -1.3343e+00,  1.2291e+00, -1.4936e+00,  2.0194e+00],\n","        [-1.4967e+00,  6.8257e-01, -4.8234e-01, -1.7678e+00, -3.1727e+00,\n","          6.4332e-01, -2.6361e-01,  1.2977e-01,  2.4831e-01, -1.3934e+00,\n","         -1.5366e+00,  1.8734e+00, -6.1166e-01, -4.1336e-01,  9.1199e+00,\n","          2.0763e+00, -4.9088e-02,  7.3786e-02,  1.4559e+00, -7.0646e-01,\n","         -7.6272e-01,  4.6249e-01,  3.6154e-02, -8.4271e-01, -2.9905e-01,\n","         -2.7745e-01, -3.8245e-01,  1.8217e+00, -1.5780e+00,  1.4372e+00,\n","         -1.0430e+00,  7.6649e-01,  3.2669e+00, -1.2195e+00, -2.9588e-01,\n","         -2.8849e-01, -3.5850e-02, -1.5250e+00,  8.7330e-01, -1.1390e+00,\n","          1.7295e+00, -2.1600e+00, -1.8311e+00,  1.4439e+00,  2.1688e+00,\n","         -1.9193e+00, -2.8897e-01,  2.0445e-01, -1.3839e+00,  1.7137e+00],\n","        [-3.2494e+00, -2.2677e+00, -2.2377e+00, -3.1387e+00,  2.3814e+00,\n","          1.0282e+00, -1.2095e+00,  9.9947e-01,  7.1167e-01,  1.8327e+00,\n","         -8.1626e-01,  6.2193e-01,  2.4272e+00, -7.6757e-01, -2.8556e+00,\n","         -8.6579e-01, -2.4656e+00, -1.2302e-01,  2.3540e+00, -8.8368e-01,\n","         -1.2890e+00, -9.9636e-01, -1.3259e+00, -8.2977e-01, -1.0657e+00,\n","         -2.6503e-01, -1.9005e+00,  1.6877e-01,  5.3306e+00,  3.5076e+00,\n","         -9.8627e-01,  3.2693e+00,  2.8863e+00, -1.4463e+00,  7.7255e-01,\n","         -1.5481e+00, -1.8823e+00,  1.0448e+00, -7.4176e-01, -1.2663e+00,\n","          3.0373e+00,  1.2024e+01, -2.9251e+00, -3.3563e+00, -3.1308e-01,\n","          4.9541e+00, -1.3212e+00, -3.8764e+00, -1.1923e+00,  8.8286e-01],\n","        [ 1.5112e+00, -7.3911e-01, -1.4518e+00, -1.7311e+00,  4.5908e-01,\n","         -8.1983e-01, -1.7892e+00,  6.5145e-02, -9.0212e-01, -2.5126e-01,\n","          1.8488e+00,  4.0028e-01,  1.4760e+00, -2.3020e+00, -8.6762e-01,\n","         -1.5232e+00, -8.9907e-01, -9.2094e-01,  1.1462e+00, -2.6935e+00,\n","          1.4758e+00,  2.9736e+00, -3.5291e-01, -1.4469e+00, -1.5038e+00,\n","         -2.0656e+00, -5.6866e-01,  9.4796e-01,  1.2807e+00,  5.2994e-01,\n","         -1.7094e+00, -7.1312e-01,  6.6640e-01, -1.4936e+00, -7.6471e-01,\n","         -3.2070e-01,  1.0927e+00,  1.4752e+00,  1.4411e+00, -1.1300e+00,\n","          9.9204e-01,  5.9138e-01,  9.5586e+00,  7.1390e-02,  5.0389e-01,\n","         -1.8926e+00,  1.9220e+00, -8.9832e-01,  1.2657e+00, -1.0475e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 9, 37, 20, 17, 39,  2, 13,  3, 17, 26, 42,  3, 36, 14, 41, 42],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7279, 10.8230, -0.5718,  ..., -1.7141, -2.3069,  2.6582],\n","        [-0.0559,  4.8892, -0.3742,  ..., -0.7689, -0.7343,  3.3519],\n","        [ 5.9495, -3.5244,  1.5493,  ...,  6.1936,  1.1081, -1.5440],\n","        ...,\n","        [ 2.1173, -0.2006, -0.9480,  ..., -2.1149,  0.4908, -0.5918],\n","        [ 1.7467, 16.1360,  1.0122,  ..., -1.5875, -3.3799,  1.6580],\n","        [ 1.0516, -4.2442,  3.8879,  ..., -0.5311,  2.1638, -0.5579]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 393/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.2110, -1.7693, -0.5864,  ..., -0.4730,  1.4093, -3.2835],\n","        [ 1.6307, -2.5027,  3.4462,  ...,  3.1069, -1.6125, -0.3129],\n","        [-0.2603,  2.1425, -1.2454,  ..., -2.6879, -0.7851,  3.8728],\n","        ...,\n","        [-0.6676, -3.3376, -1.2945,  ..., -0.6207,  1.0012, -2.9703],\n","        [-1.0801, -0.8893, -0.9754,  ..., -1.2118, -1.2233, -0.6514],\n","        [-2.5633, -2.3396,  1.6308,  ..., -0.1844, -2.7013, -1.4593]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([22, 35, 23, 37, 44, 47, 16,  4, 22, 22,  4, 26, 30, 28,  6, 44,  3,  3,\n","        38, 44, 17, 17, 28, 10, 11, 12, 22, 16, 20, 19, 36,  4, 31, 13, 24,  8,\n","        33, 25, 25, 13,  9,  0, 49, 32, 18, 30, 46, 13, 34, 42, 16, 27, 33,  2,\n","        14,  0, 11, 31,  5, 20, 44, 17, 47,  8,  5, 40, 20,  0, 38, 39,  4, 15,\n","        34,  2,  1, 11, 48, 20, 37, 34,  1, 12, 21,  7, 49, 40,  5, 29, 14, 17,\n","        23, 11, 40, 33, 33,  9, 43, 37, 37, 37, 13,  2, 11, 15,  4, 16,  0, 34,\n","        46, 37, 46, 35, 30, 35, 20, 40,  9,  9,  1, 34, 16, 27, 47, 10, 13, 32,\n","        45,  9], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-4.2306, -0.1500, -2.2037,  ..., -2.6137, -2.5632,  3.2381],\n","        [ 1.2186, -2.3076,  0.9414,  ...,  4.7646, -0.3243, -1.3054],\n","        [-1.7974,  0.1868,  1.8046,  ..., -1.8338, -0.0129, -0.2721],\n","        ...,\n","        [-2.1971,  0.4731,  0.5658,  ..., -3.5413, -2.4756,  0.9811],\n","        [ 0.8496, -1.6577,  2.5077,  ...,  0.7434,  1.1741, -0.6793],\n","        [-4.7795, -3.0790, -0.8964,  ...,  1.1909, -1.4940,  4.2807]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([41, 25, 40, 32, 49, 14,  0, 20, 43, 15, 46, 16, 24, 14, 29, 12, 31, 23,\n","         3,  6, 36, 27,  8, 38,  8, 22, 36, 11, 45, 23, 24, 24, 33, 45, 10,  1,\n","        35, 27, 12,  5, 19, 30,  7, 49, 33, 13, 24,  1, 26, 35, 15, 38, 22, 32,\n","        10, 32, 15, 47,  7, 48, 39, 43, 27,  0,  4, 25, 11, 27,  3, 31, 26, 15,\n","        35, 36,  5, 47, 37,  1, 14, 16, 25, 15, 16, 27, 15, 42, 17, 48, 40,  3,\n","        41, 29, 31,  3, 26,  9,  8, 19, 24, 48, 10, 35, 13, 30,  5, 36, 12,  1,\n","        42, 44, 41, 40, 18, 46,  2, 18, 22, 17, 20,  1, 47, 42,  7, 26, 10, 31,\n","        27, 29], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[14.1250,  1.0648,  2.6510,  ..., -1.4706,  6.2054, -1.1438],\n","        [-0.3384, -0.7517,  1.4402,  ..., -0.1148, -0.6481,  0.7626],\n","        [ 1.8703, -1.6792,  0.6305,  ...,  3.9449,  0.0705, -1.8166],\n","        ...,\n","        [-0.5106, -0.3325,  2.5124,  ..., -2.1776,  2.6561, -2.7744],\n","        [-1.6969,  3.7220, -0.1163,  ..., -0.8905, -2.9831,  1.4441],\n","        [ 0.3122, -0.0823,  0.2376,  ...,  3.6787, -0.5548, -2.1906]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 0, 14, 25, 49, 45, 46, 48, 31,  9, 21, 19, 30,  9, 30, 39, 26,  6, 16,\n","        41, 10, 45,  6, 28, 43,  2, 31, 26, 29, 20, 17, 48, 12, 38, 28,  7, 18,\n","        41, 13, 29,  3, 17, 12,  0, 42, 49, 43, 18, 49, 22, 10, 46, 36,  2, 32,\n","        35, 17, 36, 19, 41, 30, 47, 17, 24, 43, 25, 36, 19, 21, 45, 14, 38,  3,\n","        34, 30,  6, 39, 24, 27, 12, 45, 21, 37,  3,  4, 12, 20, 25, 23, 42,  9,\n","        29, 32, 47, 27,  8, 23, 41, 48, 28, 39, 41, 29,  6, 31, 29, 28, 33, 14,\n","        21,  2,  2, 32,  8,  7, 49, 28, 41, 28,  8, 26, 40,  4, 14, 42, 36, 10,\n","        18, 19], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-8.9909e-01, -1.1222e+00, -9.2845e-01, -9.3304e-01, -1.8466e-01,\n","         -2.2694e-02, -9.6862e-01,  8.0515e+00, -1.9520e+00, -3.8063e-01,\n","         -7.2140e-01,  1.4351e+00,  2.1426e+00, -1.2487e+00,  7.8148e-02,\n","          1.3670e-03, -1.5201e+00, -2.6646e-01, -7.1160e-01, -2.5002e+00,\n","         -4.3764e-01,  8.7523e-01,  1.3841e+00, -1.7132e+00, -2.1356e+00,\n","         -1.0770e+00, -1.7883e-01, -7.4939e-01,  3.3578e+00, -3.9409e-01,\n","         -1.7297e+00,  8.6038e-01,  3.1285e+00, -6.7490e-01,  1.2384e-01,\n","          8.5759e-01, -4.0547e-01, -6.0059e-01, -5.4734e-01,  2.0439e+00,\n","          1.9634e+00,  1.8673e+00,  7.7099e-02, -2.8921e-01, -8.2791e-01,\n","          1.2650e+00, -3.8044e-01, -1.0454e+00, -8.8860e-02,  5.6959e-02],\n","        [ 9.9266e-02, -2.1102e+00, -9.4857e-01,  1.4515e-01, -3.1649e+00,\n","          9.5262e+00,  8.6059e-01, -3.4368e+00,  2.1806e-01, -4.6182e-01,\n","          6.4658e-01,  2.0062e+00, -9.6786e-01,  9.8654e-01,  1.3460e+00,\n","          2.1471e+00, -4.4339e-01,  3.3291e-01,  2.0294e-02, -8.9972e-01,\n","          5.3197e-01, -1.1962e+00, -3.8564e+00, -1.7408e+00, -1.1766e+00,\n","         -2.2925e+00,  9.4737e-01,  4.0109e+00,  2.2547e-01,  1.0965e+00,\n","         -3.5155e-01,  2.6352e+00,  6.5641e-01, -1.6424e-01,  4.5708e-01,\n","         -3.5569e-01,  2.8435e+00,  1.8562e-01, -8.3057e-01, -3.1632e+00,\n","         -5.6568e-01,  1.5896e+00, -6.1310e-01,  1.6986e+00,  2.6863e+00,\n","         -2.7543e+00, -2.4037e+00, -5.7993e-01, -1.6473e+00, -1.4960e+00],\n","        [-2.5059e+00, -4.0671e+00,  1.1435e+01,  5.1128e-01,  1.1241e+00,\n","          2.5635e+00,  1.4993e-01, -4.9148e+00, -3.4201e+00, -6.4212e-01,\n","          1.6793e-01,  9.3596e-01,  1.3196e+00, -2.0200e+00, -1.7074e+00,\n","         -1.1390e+00, -6.2347e-01,  1.5275e+00, -3.1853e+00, -3.9960e-01,\n","          3.7364e+00, -1.0164e+00,  1.5960e+00, -2.2588e+00, -1.9009e+00,\n","          1.0741e+00,  1.8661e+00, -9.0221e-01, -2.0278e+00,  9.1378e-01,\n","         -8.8101e-01, -3.1405e-03,  8.9399e-01,  1.4677e+00, -1.3020e+00,\n","          3.9477e+00, -1.7386e+00, -2.1541e+00,  2.5862e+00,  7.0041e-01,\n","          7.8461e-02,  5.7527e-01, -3.7349e+00,  1.8316e+00,  1.2504e-01,\n","         -1.7523e+00, -2.8074e-01, -1.0237e+00,  1.7008e+00,  3.3240e-02],\n","        [-2.0593e+00,  3.5856e+00, -1.8920e+00, -1.0467e+00,  2.4024e+00,\n","         -2.8614e+00, -1.0485e+00, -3.3131e+00,  6.1293e+00, -2.8079e+00,\n","         -2.4379e+00, -2.5378e+00, -6.8157e-01,  5.9433e+00, -4.6131e-01,\n","          3.2244e+00, -1.2175e+00, -2.3659e+00,  8.1688e-01, -6.3338e-02,\n","          2.6439e+00,  5.9775e-01, -2.8015e-01,  1.2676e+01, -1.1713e+00,\n","         -2.5250e+00, -2.3914e+00, -3.2148e+00, -1.0815e+00,  2.1434e+00,\n","         -3.7629e-01,  1.9789e+00,  1.4098e+00, -1.1235e+00,  3.3521e+00,\n","         -2.9303e+00, -8.4078e-02,  4.8357e+00, -1.2009e+00, -3.0674e+00,\n","          1.5603e-01,  2.3424e-01, -2.5263e+00,  2.5656e+00, -1.4968e+00,\n","         -1.4664e+00, -2.6792e+00, -3.7456e+00, -2.5661e+00,  4.1266e+00],\n","        [ 5.7739e-01, -2.9057e+00,  4.7057e+00, -2.8168e+00, -1.7817e+00,\n","          1.4322e+00, -3.7634e-02, -1.5720e+00, -2.6943e+00, -1.4394e-01,\n","          1.3813e+00,  1.0552e+01,  1.7949e+00, -2.4629e+00,  4.2773e-01,\n","         -2.7922e+00,  1.2196e+00,  4.7009e-02, -3.9788e-01, -6.9949e-01,\n","          8.1166e-02,  2.4946e+00, -6.3705e-01, -3.5686e+00, -7.5316e-01,\n","          2.4349e+00, -6.0426e-01,  4.1673e+00, -1.7650e-01, -5.7380e-01,\n","          1.7965e+00, -2.5013e+00,  5.6622e-01, -1.1735e+00, -4.2739e+00,\n","         -1.2848e-01, -5.9074e-01, -2.8133e+00,  4.9037e+00,  9.0339e-01,\n","          2.2119e+00,  1.9006e-01, -5.6610e-01, -2.4938e-01, -1.1042e+00,\n","         -1.7206e+00, -3.0436e-01,  1.4316e+00, -3.1958e-01, -1.2680e+00],\n","        [ 7.7389e-01, -4.6570e-01,  1.2936e+00,  3.4369e+00, -1.1779e+00,\n","          1.5509e-01,  3.0004e+00, -3.5767e+00,  3.8330e-01, -5.0791e-01,\n","         -1.7016e+00, -6.7804e-01, -2.3389e+00,  1.5994e+00, -1.4333e+00,\n","         -2.9106e-01, -7.0067e-02,  9.7489e-01,  8.7192e-01,  1.0142e+01,\n","          4.5922e-02, -1.8049e+00, -1.1484e+00, -2.2929e+00,  3.5911e+00,\n","          2.9943e+00,  6.8131e-01, -8.9848e-01, -2.9159e+00,  2.7926e+00,\n","         -8.7010e-01,  2.5213e-01, -4.5328e-01, -2.5488e-01, -1.1780e+00,\n","         -7.7435e-01, -1.1931e+00, -1.0569e+00,  5.3372e-01,  1.5804e+00,\n","         -1.9334e+00, -2.1260e+00, -1.5842e+00,  3.4679e-01, -2.6820e-01,\n","         -1.5430e+00, -1.5271e+00,  1.8975e+00, -2.5490e-01, -2.5423e+00],\n","        [-1.8229e-01, -1.7934e+00, -3.7216e-01, -1.2920e+00, -3.5942e+00,\n","          2.5818e+00, -1.5492e+00, -1.7931e+00, -3.6487e-01,  1.9587e+00,\n","          3.4646e+00, -5.5906e-01, -2.3668e+00, -2.5496e+00,  1.1985e+00,\n","         -2.8057e+00, -1.5093e+00,  4.4821e+00, -9.4425e-01, -2.7750e+00,\n","          1.4592e+00, -2.1663e+00, -1.4491e+00, -6.6408e-01, -1.3277e+00,\n","         -7.6388e-01,  2.3720e+00, -9.8222e-02, -2.6072e+00,  2.6249e+00,\n","         -2.3104e+00, -1.8446e-01,  1.7744e+00,  3.5455e-01,  2.7000e-01,\n","         -1.5327e+00,  6.8244e-01, -9.7183e-01,  1.4138e+00, -1.8481e+00,\n","         -1.6656e+00,  8.7224e-01,  1.5013e+00,  2.4602e+00,  1.2479e+01,\n","         -2.3418e+00,  1.5031e-01, -3.9085e-01,  3.4140e+00,  1.1978e+00],\n","        [ 4.2552e+00, -1.8655e+00,  1.0069e+00,  1.1359e+00, -2.1532e+00,\n","          1.5066e+00, -2.0756e+00, -2.4509e+00,  2.8038e-01, -2.6218e+00,\n","         -1.7004e+00,  2.6957e+00, -2.6549e+00, -1.9410e+00, -1.0029e+00,\n","         -2.0835e+00,  1.2206e+01, -9.1384e-01, -3.0696e+00, -1.8716e+00,\n","          4.9465e-01, -2.3200e+00,  4.0326e-01, -6.1330e-01,  1.3326e+00,\n","          2.2921e+00,  2.6181e+00, -7.0017e-01, -2.9137e+00,  3.9931e-01,\n","          2.3747e+00, -2.2873e+00,  1.7113e+00,  3.2977e+00, -1.0309e+00,\n","          3.2066e+00, -8.9374e-01, -1.1857e+00,  2.5161e+00,  9.0891e-01,\n","         -6.4638e-01, -4.9585e-01, -2.2238e+00, -1.8287e-01,  7.0267e-01,\n","         -2.2954e+00, -7.4446e-01,  1.4643e-01,  1.7979e+00,  4.2066e-01],\n","        [ 1.2648e-01, -2.3192e+00,  2.7824e+00,  8.1822e-01, -2.2702e+00,\n","          9.0907e-03,  3.7715e-01, -2.8897e+00, -1.8566e+00, -1.7455e+00,\n","          9.8456e-01,  2.4604e+00,  1.0221e+00, -2.3239e+00, -2.2598e+00,\n","         -1.8256e+00,  1.2649e+00,  2.2447e+00, -2.8164e-01,  3.4492e+00,\n","          2.8134e-03, -2.0855e+00, -1.7237e+00, -3.3417e+00, -1.2125e+00,\n","          4.8511e-01, -9.5692e-01,  8.1874e-01,  1.9110e+00, -4.7574e-01,\n","          1.1712e+01, -2.2002e+00, -4.3866e-01, -1.3170e+00, -1.3726e+00,\n","          2.3352e+00, -6.7328e-01, -1.9491e+00,  1.9809e+00,  4.9434e-01,\n","         -2.1385e-01, -2.6854e-01, -8.9021e-01, -8.7432e-01, -1.3435e+00,\n","         -7.5508e-01,  4.4542e+00,  2.0456e-01,  7.2752e-01, -8.7423e-01],\n","        [-1.4249e+00,  2.9679e-01,  8.6403e-01, -1.5421e+00,  1.6695e+00,\n","         -1.5909e+00, -1.6073e+00, -1.2032e+00,  1.7659e-01,  3.2358e+00,\n","          8.6175e-02, -1.6207e+00,  6.3201e-01, -4.1402e-01, -8.7404e-01,\n","         -1.6066e+00, -1.2341e+00,  4.6674e-01,  8.8898e+00, -3.4879e-01,\n","          1.6396e+00,  1.8348e+00, -1.0387e+00, -3.4154e-01,  8.2193e-01,\n","         -5.8726e-01, -6.6334e-01, -2.5271e-01, -8.4490e-02, -1.1617e+00,\n","         -3.3080e-01,  9.4393e-01,  7.3085e-01, -2.0541e+00, -3.3934e-01,\n","         -1.3528e+00, -3.1048e-01,  7.5537e-01, -6.6683e-01, -1.3938e+00,\n","          7.5379e-01,  1.2706e+00,  1.4084e+00, -1.4910e+00,  3.0559e-01,\n","          2.8180e-01,  1.0472e+00, -1.1095e+00, -3.9180e-01, -2.7250e-01],\n","        [-6.9135e-01,  4.9187e-01, -1.1039e+00, -3.1414e-01,  1.8495e-01,\n","         -5.4530e-01, -1.3694e+00,  1.1038e+01, -1.2566e+00, -3.6716e-01,\n","         -1.5161e+00,  4.9358e-01,  1.7042e+00, -9.9582e-01,  9.2171e-02,\n","         -2.6152e-01, -8.2429e-01, -7.9427e-01,  9.1077e-02, -2.4924e+00,\n","         -1.1004e+00,  1.8372e+00,  3.0806e-01, -2.4447e+00, -1.9115e+00,\n","         -1.8048e+00,  9.7502e-01, -8.3838e-01,  3.3805e+00, -4.7516e-01,\n","         -2.3206e+00,  1.7034e-01,  2.5170e+00, -5.8113e-01, -3.8508e-01,\n","          6.7335e-01, -1.1321e+00,  2.0734e+00, -8.1112e-01,  5.6898e-01,\n","          2.0046e+00,  1.3652e+00,  1.0136e+00, -1.9131e-01, -1.1633e+00,\n","          1.6093e-01,  9.6657e-01, -1.5710e+00, -1.3397e-01,  3.3241e-01],\n","        [ 2.8248e+00,  1.0350e+01, -6.1328e-01,  2.5857e+00, -1.5113e-01,\n","         -6.9287e-01, -1.1621e+00, -1.8258e+00,  2.6198e+00, -9.4440e-01,\n","          3.2873e-01, -2.8106e+00, -1.2781e+00, -3.0469e-01, -1.5258e+00,\n","          9.3712e-02, -1.6374e+00, -6.0320e-01, -2.2806e+00, -4.2602e-01,\n","          6.1169e-01, -1.6511e+00, -6.9868e-01,  2.1118e+00,  1.1757e+00,\n","         -2.1972e+00, -1.5442e+00, -3.0829e+00, -1.7246e+00,  3.3736e-01,\n","         -1.5216e+00,  6.5285e-01, -1.1014e+00,  3.7043e-01,  2.7884e+00,\n","         -3.2394e+00,  1.9733e+00,  3.9400e+00,  2.8616e-01, -2.0689e+00,\n","          1.3520e+00, -1.2438e+00,  1.5855e+00,  2.9103e+00, -3.9748e-01,\n","         -1.8631e+00,  2.9434e+00, -8.2507e-01, -6.5110e-01,  6.3235e-01],\n","        [ 5.3839e+00,  9.6625e-01, -3.0435e-01,  4.8869e+00, -2.1043e+00,\n","         -2.4727e+00, -1.8011e+00, -5.0659e+00, -1.6170e+00, -2.0504e-01,\n","         -2.0044e+00, -2.5567e-01, -3.4124e+00, -8.5923e-01, -3.0762e+00,\n","         -2.8363e-01,  4.3802e+00, -2.8762e+00, -1.4811e+00,  3.2829e+00,\n","         -6.5298e-01, -2.8262e+00, -8.2029e-01, -5.6952e-01,  1.6224e+01,\n","          2.3827e+00, -1.8107e+00, -2.5442e+00, -3.5332e-01,  2.1137e+00,\n","          1.5202e+00,  4.2312e-01,  6.2548e-01, -6.1632e-01,  4.8697e-01,\n","          5.9638e-01, -6.9507e-01,  4.5680e-01,  4.2285e+00,  1.7277e+00,\n","         -3.3884e+00, -1.2633e+00, -4.8776e+00, -1.2592e+00, -2.7100e+00,\n","         -2.3331e+00,  1.0362e+00,  4.9824e+00, -1.0971e+00, -1.5492e-01],\n","        [ 2.4366e+00, -6.3469e-01,  5.9139e-01, -8.1689e-01, -2.0645e+00,\n","          4.7132e-01,  1.0483e+01, -3.0416e+00,  1.9620e+00, -3.8150e+00,\n","          4.9075e-01,  3.1923e-01, -1.9110e-01,  7.1530e-01,  4.3255e-01,\n","         -4.2870e-01, -8.5407e-01,  2.5875e+00, -2.7635e+00,  1.7547e+00,\n","          1.8501e+00, -2.4237e+00,  4.7569e-01, -8.1476e-02, -1.5646e+00,\n","          5.4525e-02, -9.3026e-01, -1.8970e+00, -1.5414e+00, -1.4972e+00,\n","          6.9991e-01, -1.9467e+00, -2.0206e+00,  1.2583e+00, -1.1900e+00,\n","          4.5503e+00,  9.4655e-01, -2.1186e+00,  8.6604e-01,  6.1064e-01,\n","         -1.4240e+00, -1.2994e+00, -2.9732e-01,  4.2060e+00,  8.9908e-01,\n","         -2.1103e+00, -2.2100e+00,  1.8802e+00, -2.1880e-01, -8.9980e-01],\n","        [-1.7584e+00, -4.2475e-01,  3.4188e+00, -1.6899e+00,  1.3736e+00,\n","         -2.0274e+00, -2.7933e+00, -2.5103e+00, -1.0029e+00,  7.4780e-01,\n","         -1.5782e-01,  7.4072e-01,  5.0047e-01, -1.6618e+00,  1.1691e+00,\n","          1.0595e+00, -2.9262e-01, -1.9576e+00,  3.6066e+00, -1.6818e+00,\n","         -1.7098e-01,  1.1176e+01, -9.9348e-02, -1.6745e+00, -1.5745e-01,\n","         -1.6184e+00, -3.0915e-01,  3.5741e+00, -9.4616e-01,  1.4008e+00,\n","         -1.8415e+00,  2.1104e+00,  1.2483e+00, -3.0620e+00, -9.6515e-01,\n","         -2.9335e+00, -2.1678e-02,  9.6189e-01,  2.5186e+00, -2.1694e+00,\n","          4.1703e-01,  2.4321e+00, -2.6017e-01, -1.5953e+00, -1.6924e+00,\n","         -1.9804e+00,  5.9488e-03, -9.1082e-01, -2.1071e+00,  3.0429e+00],\n","        [-3.0082e+00, -1.8190e+00,  6.2175e-01, -1.1774e+00,  1.9235e+00,\n","         -9.5345e-01, -3.1628e+00, -2.1826e+00, -1.4602e+00,  1.0835e+01,\n","          4.8670e-01, -2.0893e+00,  3.5206e+00, -2.0167e+00, -2.1014e+00,\n","         -2.5506e-01, -2.1777e+00, -4.6639e-01,  2.1755e+00, -1.4887e+00,\n","          9.5994e-01, -5.8119e-01,  1.6078e-01, -5.3199e-01,  2.6059e+00,\n","         -1.6523e+00, -2.1107e+00, -9.2593e-01,  1.2475e+00,  3.8510e+00,\n","         -1.0739e+00,  3.5110e+00,  2.5482e+00, -3.2308e+00, -1.2966e+00,\n","         -3.0825e+00, -1.1099e+00,  4.0001e+00, -9.5334e-01, -2.2662e+00,\n","          4.0527e+00,  4.1896e+00,  3.5770e-01, -2.3213e+00,  1.7430e+00,\n","          1.0982e+00, -6.6811e-02, -3.5486e+00, -5.4437e-01,  1.4316e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7,  5,  2, 23, 11, 19, 44, 16, 30, 18,  7,  1, 24,  6, 21,  9],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7163, 10.8009, -0.5795,  ..., -1.7106, -2.3052,  2.6577],\n","        [-0.0516,  4.8849, -0.3824,  ..., -0.7716, -0.7331,  3.3519],\n","        [ 5.9251, -3.5242,  1.5532,  ...,  6.1879,  1.1071, -1.5468],\n","        ...,\n","        [ 2.1145, -0.2057, -0.9512,  ..., -2.1110,  0.4927, -0.5932],\n","        [ 1.7413, 16.1123,  1.0056,  ..., -1.5879, -3.3809,  1.6667],\n","        [ 1.0563, -4.2472,  3.8786,  ..., -0.5298,  2.1737, -0.5527]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 394/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.3714,  3.2215,  0.1375,  ..., -1.7287, -3.5110, 16.5678],\n","        [-2.7313, -1.3754,  0.2042,  ...,  2.2825, -0.8714,  3.9992],\n","        [-0.5310, -1.2442,  1.9594,  ..., -0.5143,  2.3089, -0.6719],\n","        ...,\n","        [ 5.0245,  2.6806,  1.0580,  ...,  2.4489, -0.4784, -3.0210],\n","        [-4.0927, -2.2151, -1.2709,  ..., -4.0864, -2.8011, -1.4395],\n","        [-0.6073,  1.6467, -2.0692,  ..., -3.8541, -0.1957,  1.5250]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([49, 29, 20,  1, 38, 40, 49,  6,  5, 31, 13, 16, 13, 48, 27, 30,  2, 14,\n","         3,  9, 48,  7,  0, 17, 15, 30,  9, 35, 40, 47, 43, 46,  2, 25, 30, 36,\n","         8, 28, 41, 37, 17, 32,  7, 29, 43,  4, 35, 12, 29, 46, 29,  6, 31, 35,\n","         2, 46,  7, 27, 30, 30,  4,  6, 36, 34, 22, 47, 30,  1,  3, 43,  4, 45,\n","        40, 22,  3, 21, 11, 49, 27, 20,  0, 37, 17, 41, 24, 30, 22, 30, 21,  3,\n","        25,  2, 10, 25, 32, 15, 10, 14, 16,  0, 18,  8, 38, 28, 39,  5, 44, 27,\n","        32, 32, 33, 24,  0, 17, 45,  0,  9, 33, 27, 12, 17,  3, 49, 20, 16, 24,\n","        28,  8], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.5849, -1.0442,  0.2963,  ..., -0.8778,  0.8997, -0.3219],\n","        [ 1.5231,  0.6543, -0.7592,  ..., -0.9060,  3.0114, -1.6078],\n","        [-1.1579,  2.8033,  0.6870,  ..., -1.6507, -1.0166,  0.7657],\n","        ...,\n","        [ 0.6401, -1.6321,  1.6251,  ...,  0.7958,  1.2289, -0.9694],\n","        [-1.5242, -1.1153, -0.8407,  ..., -0.3135, -0.3103, -1.4804],\n","        [-0.4963, -1.3638,  0.2983,  ..., -0.4103,  3.3644, -1.8037]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([44, 42, 34, 21, 21, 36, 24, 44, 31, 22, 27, 12, 41, 23, 14,  9, 13, 47,\n","        11, 48,  4, 13, 24, 25, 19, 25, 34, 19, 25, 16, 28, 32,  4, 12,  5, 11,\n","        23, 28, 29,  5, 13, 14, 40, 29,  2, 23, 42, 44, 23,  0, 20,  2, 26, 14,\n","        37, 35, 18, 44, 37,  7, 46, 31, 28, 17, 13, 15, 41, 12, 15,  9,  6, 11,\n","        49,  4, 12, 45, 40, 47,  0, 29, 37, 31,  1, 41, 30, 11,  3, 38, 14, 13,\n","        36, 15, 10, 12,  8, 19,  1,  4, 42, 35, 33, 33, 33, 35, 40, 45, 29, 32,\n","        28, 24, 39, 20, 32, 34,  1, 11,  1, 28,  5, 42, 43, 37, 36, 16, 20, 27,\n","         7, 17], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 7.6430,  3.3983, -1.6361,  ...,  5.2863, -1.3502, -0.3651],\n","        [-3.4745, -0.7074,  0.4843,  ..., -2.1231, -1.7659, -2.8147],\n","        [-2.1923,  2.1070, -1.7112,  ..., -2.5868, -1.8969,  4.1347],\n","        ...,\n","        [-1.4111, -1.4783,  0.9017,  ..., -1.6465, -2.8572, -0.6176],\n","        [-0.6229,  2.8418, -1.1822,  ..., -1.4883, -1.9127,  5.7740],\n","        [ 1.5043,  2.0438,  0.0548,  ..., -0.7915, -0.5581,  1.2095]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([24, 18, 23, 20, 42, 31, 44,  1, 41, 33,  2,  3, 10,  1, 40, 27, 36, 33,\n","        37,  8,  9,  5, 42, 45, 27, 12, 20, 35, 26, 24, 46,  6,  8,  7, 13, 26,\n","        14, 16,  8, 10, 16, 19, 49, 38, 26, 39, 25, 17,  6, 31, 41, 32, 16,  9,\n","        16, 18,  7, 18, 29, 26, 14, 10, 48, 27, 37, 16, 11, 31, 36, 10, 10, 22,\n","         1, 21, 22, 38,  7,  5, 10, 41, 18, 38, 39, 11,  3, 48, 31, 17, 35, 45,\n","        34, 36, 42, 48,  8, 46, 47, 47, 19, 21, 26, 22, 41, 19, 49, 15, 40, 45,\n","        26, 46, 24, 47, 25,  9, 48, 18,  3, 39, 34, 43, 17,  2, 20, 47, 12,  9,\n","        23, 43], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.1929e+00, -8.5451e-01,  1.5734e+00,  6.8158e-01, -2.6963e+00,\n","         -1.6501e-03,  1.2072e+01, -1.1151e+00, -8.1857e-01, -2.4735e+00,\n","          2.3023e+00,  6.5127e-01, -2.1566e+00, -3.2329e-02, -1.6146e+00,\n","         -2.1331e+00,  2.5779e-01,  4.5528e+00, -2.1236e+00, -2.9299e-01,\n","          4.6289e-01, -1.8373e+00, -1.1184e+00, -2.3949e+00,  5.3146e-01,\n","          1.4515e-03,  1.3400e+00, -1.6164e+00, -2.0531e+00, -1.4999e+00,\n","          7.8112e-01, -2.9066e+00, -1.5260e+00,  5.3244e+00, -1.3324e+00,\n","          4.6759e+00,  2.1878e-01, -2.6188e+00, -1.9515e-01,  8.6059e-01,\n","         -2.9493e+00, -1.4051e+00,  3.6488e-01,  1.8403e+00,  9.1323e-02,\n","         -2.3085e+00, -4.0127e-01,  1.7327e+00,  1.5064e+00, -1.4691e+00],\n","        [-3.1111e+00,  2.7283e-02,  4.6639e-01, -7.4775e-01,  8.9784e-01,\n","         -1.4578e-01, -3.9828e+00, -2.1498e-01, -1.0485e+00,  1.0994e+01,\n","          9.8542e-01, -1.4797e+00,  1.2935e+00, -3.4614e+00, -2.7095e+00,\n","         -3.4799e+00, -1.9597e+00, -1.0471e-01,  3.0263e+00, -2.1717e+00,\n","          1.4527e+00,  7.0491e-01, -9.9132e-01, -1.0348e+00,  2.6153e+00,\n","         -1.6828e+00, -9.4063e-01, -2.4500e+00,  1.4403e+00,  2.8464e+00,\n","         -2.3307e+00,  3.5211e+00,  2.1948e+00, -3.0478e+00, -8.7672e-01,\n","         -3.8438e+00, -3.0373e+00,  4.1141e+00,  8.5649e-01, -1.9497e+00,\n","          4.3109e+00,  4.0992e+00,  1.0791e+00, -2.2480e+00,  3.5968e+00,\n","          1.3925e+00,  7.4890e-01, -2.0773e+00, -4.3066e-01,  7.5920e-01],\n","        [ 1.6362e+01, -7.6777e-01, -1.7090e+00,  1.9435e+00, -4.2159e+00,\n","          9.0777e-01, -9.4616e-01, -2.3112e+00, -1.7060e-01, -1.4309e+00,\n","         -1.1980e+00,  1.5118e+00, -7.3088e-01, -3.0143e+00, -1.4541e+00,\n","         -3.1627e+00,  5.6314e+00, -1.3754e+00, -1.9926e+00, -1.3501e+00,\n","          2.0904e+00, -1.8677e+00,  1.4844e+00, -2.9498e+00,  2.4724e+00,\n","          2.3395e+00,  4.1513e-01,  2.4629e+00, -2.0056e+00, -1.4569e+00,\n","          3.7720e-02, -3.5095e+00, -3.0149e-01, -1.5631e+00, -1.1640e+00,\n","          2.5289e+00, -5.1207e-01, -1.1346e+00,  4.3325e+00, -4.0371e-01,\n","         -1.4050e+00,  7.2377e-02, -8.7079e-02,  5.7682e-01, -1.2657e+00,\n","         -2.7938e+00,  5.7746e-01,  4.7417e+00,  1.8614e+00, -2.2132e+00],\n","        [ 3.3485e-02, -7.4308e-01,  1.0377e+01, -1.1512e+00, -1.4504e+00,\n","         -4.0593e-02, -7.6171e-01, -1.6341e+00, -1.9995e+00, -1.0278e+00,\n","          2.2973e+00,  4.7735e+00, -4.1385e-01, -2.5811e+00, -1.5937e+00,\n","         -2.5905e+00,  3.0412e+00, -6.9494e-01, -9.4147e-01, -1.6679e-01,\n","          1.4901e+00, -4.6346e-02, -1.2938e+00, -2.8714e+00,  2.4121e+00,\n","          3.6850e-01,  1.4364e-01,  1.6726e+00, -1.0493e+00, -1.0932e+00,\n","          1.2281e+00, -1.0861e+00, -9.4513e-01,  9.3948e-02, -1.1933e+00,\n","          1.2860e-02, -9.7695e-01, -2.0128e+00,  2.4220e+00,  1.1544e+00,\n","         -2.9785e-01, -4.7603e-01, -2.3180e-01,  1.0243e+00, -1.1634e+00,\n","         -2.6830e+00,  1.8214e+00, -1.6977e+00,  1.9735e+00, -1.0540e+00],\n","        [-1.5625e+00,  3.1500e+00, -7.8978e-01, -4.2261e-01, -1.2084e+00,\n","          2.2358e+00, -1.2073e+00, -1.2066e+00, -5.6875e-01, -1.5341e+00,\n","         -6.6617e-01, -9.9197e-01, -1.7135e+00,  2.1550e+00,  2.6230e-01,\n","          1.1110e+01,  9.5996e-02, -2.3464e+00,  1.1168e+00, -1.0384e+00,\n","          1.8507e-01,  2.0301e+00, -1.3481e+00,  2.3682e+00, -1.6564e+00,\n","         -2.3958e+00, -1.4342e+00, -8.0666e-01, -1.3317e+00,  5.6677e+00,\n","         -2.9795e+00,  2.6107e+00,  9.8352e-01, -4.2763e-03,  3.7269e+00,\n","         -2.6127e+00, -1.1544e+00,  1.6404e+00, -5.7859e-02, -3.4627e+00,\n","          9.7135e-03,  6.9440e-01, -3.2123e+00,  1.7067e+00,  1.7305e-01,\n","         -1.9976e+00, -1.0928e-01, -1.6380e+00, -3.9147e+00,  2.3161e+00],\n","        [-2.5497e+00, -1.3729e+00,  5.6045e-01, -1.2083e+00,  9.6182e+00,\n","         -1.0026e+00, -1.3559e+00,  7.2143e-02, -1.2617e+00,  1.5454e+00,\n","         -1.7365e-01,  1.5358e+00,  3.0348e+00, -8.9290e-01, -2.9103e+00,\n","         -8.7942e-01, -2.3137e+00, -1.7870e+00,  1.1972e+00,  1.3906e-01,\n","          7.1663e-01,  1.9239e+00,  4.0191e-02, -1.4449e+00, -1.0978e+00,\n","         -8.9718e-01, -2.0372e+00, -1.8836e-01,  3.6732e+00,  6.2777e-01,\n","         -5.7299e-01,  3.1022e+00,  2.5976e+00, -2.6779e+00, -1.3899e+00,\n","         -4.9920e-01, -4.2400e-01,  7.3485e-01, -8.4818e-01,  7.2959e-01,\n","          1.5120e+00,  5.6074e+00,  5.1507e-01, -2.2783e+00, -2.0252e+00,\n","          2.9215e+00, -1.0965e+00, -2.2388e+00, -2.0547e+00, -9.0830e-02],\n","        [-3.6314e-01, -8.0777e-01, -2.4514e-01, -1.8878e-01, -7.2223e-01,\n","         -1.3136e-01, -1.8362e+00, -3.3340e+00,  5.9382e+00, -2.0929e+00,\n","          1.5346e+00, -4.5821e+00, -1.6107e-01,  2.0491e+00,  2.8251e-01,\n","         -1.7882e+00,  5.3734e-01, -2.0516e+00, -9.3016e-01, -2.0684e+00,\n","          4.7796e+00,  8.3340e-02, -1.1869e+00,  1.1716e+01, -1.4839e+00,\n","         -3.0940e+00, -1.7471e+00, -1.2291e+00, -7.2985e-01, -1.4742e+00,\n","         -1.7299e+00,  5.1907e+00, -3.7472e-01,  3.5468e-01,  1.7971e+00,\n","         -1.3011e+00,  1.2979e+00,  5.8840e+00, -5.6777e-01, -1.5784e+00,\n","         -1.5927e+00,  1.3255e+00,  5.2620e-01,  4.0797e+00,  1.0507e+00,\n","         -4.8087e+00, -9.9409e-01, -4.3307e+00,  1.9265e+00,  1.3397e+00],\n","        [ 1.5246e+00, -1.0637e+00, -9.6097e-01, -6.7848e-02, -1.3276e+00,\n","         -1.9596e+00, -1.2441e+00, -4.8691e-01, -1.3450e+00, -2.9389e-01,\n","         -8.3779e-01, -1.4795e+00,  3.1435e+00, -4.0888e-01,  1.4078e+00,\n","         -2.4551e+00,  3.5459e-01,  1.2531e+00, -7.1393e-01, -1.5716e+00,\n","         -1.1373e-01,  1.1346e-01,  1.2547e+01, -1.3643e+00,  1.1577e+00,\n","          4.1496e+00, -2.3505e+00, -2.4487e+00,  3.8134e-01, -8.1298e-01,\n","         -3.6892e-01, -9.1229e-01,  6.2721e+00, -9.6164e-01, -1.8074e+00,\n","          1.1706e+00, -1.3029e+00, -1.0408e+00,  1.6566e+00,  1.5284e+00,\n","          5.4103e-01,  1.2080e-01, -1.6504e+00, -7.7069e-01, -4.3421e-01,\n","          2.5217e-01, -7.6679e-01, -4.2849e-01, -1.2094e+00, -3.3056e+00],\n","        [-1.3680e+00, -3.0524e+00, -3.6486e-01, -2.8154e+00, -2.0779e+00,\n","          6.3332e-01, -1.0267e-01,  3.7646e-01, -5.9707e-01, -1.2294e+00,\n","          4.6962e-02,  7.5491e-01,  2.8381e+00,  1.4504e+00,  1.3046e+01,\n","         -1.5401e+00, -2.3140e+00,  1.0646e-01,  5.4922e-01, -2.6337e+00,\n","          1.4432e+00,  9.3435e-01,  1.5698e+00, -6.5493e-01, -1.0855e+00,\n","          1.0410e+00,  3.2719e-01,  1.7333e+00,  5.2819e-02, -5.0102e-01,\n","         -1.5720e+00,  1.8696e+00,  3.6235e+00, -1.6459e+00, -2.5397e+00,\n","          1.1621e+00, -7.7763e-01, -3.5701e-01,  1.7185e-01, -1.4646e-01,\n","          2.8163e-01, -4.0858e-01, -1.3925e+00,  1.6709e+00,  2.6416e+00,\n","         -2.4261e+00, -2.4440e+00, -7.9857e-01, -1.1263e+00, -4.1237e-01],\n","        [ 3.2031e-01, -3.1324e+00,  3.2678e+00,  6.7593e-01, -2.5211e+00,\n","          5.7519e+00, -2.2263e+00, -1.7833e+00, -3.1349e+00,  1.4110e+00,\n","         -4.6850e-01, -4.8711e-01, -6.8897e-01, -1.3155e+00, -7.8668e-01,\n","         -1.8800e+00,  7.7607e-01, -1.6057e+00,  9.6710e-01, -2.4383e-02,\n","         -2.1419e-02,  4.5003e-01, -2.1945e+00, -1.8731e+00,  1.1244e+00,\n","         -3.1861e-01,  1.1680e+01,  4.6721e+00, -3.6840e+00,  1.4769e+00,\n","         -1.2908e+00,  1.0126e+00,  8.5549e-01,  2.6842e+00, -3.3567e+00,\n","          1.4460e+00, -3.5711e+00, -1.2763e+00,  3.3379e-01,  5.5235e-01,\n","          3.8204e-01, -2.8941e+00, -1.0927e+00, -1.5364e+00,  6.3291e-01,\n","         -1.1872e+00, -1.1558e+00,  1.1457e+00,  1.7314e+00, -8.0575e-01],\n","        [ 2.5617e+00,  2.5743e+00,  3.1703e-01, -1.5020e+00,  6.2990e-01,\n","          1.9748e-01, -7.2083e-01, -2.4457e+00,  1.4179e+00, -1.2222e+00,\n","          1.1978e+00,  4.1656e-01,  1.6183e+00, -1.9437e+00, -1.4019e+00,\n","         -2.2822e+00, -1.2325e+00, -1.2988e-01, -2.2087e+00, -2.9065e+00,\n","          2.2916e+00, -1.3096e+00, -1.0143e+00, -6.9715e-01,  1.2192e+00,\n","         -1.5516e+00, -3.5716e+00,  3.4345e-01,  7.7289e-01, -3.0041e-01,\n","          1.2211e+00,  1.3135e-01, -2.7676e-01, -3.3938e+00, -6.3332e-01,\n","         -5.1498e-01,  1.2970e+01,  1.0063e+00,  1.1825e+00, -1.1406e+00,\n","          2.1734e+00,  7.8193e-01,  3.2212e+00,  1.2605e+00,  2.0799e+00,\n","         -3.1957e+00,  8.5941e-02, -1.4848e+00, -6.9079e-01,  1.1166e+00],\n","        [-2.8055e-01, -6.8701e-01,  3.0172e+00,  4.0814e+00, -4.4981e-01,\n","         -1.7512e+00,  1.5091e+00, -2.9733e+00, -9.6865e-01,  4.4698e-01,\n","         -1.2316e+00,  1.8409e+00,  4.6724e-01, -1.2629e+00, -3.7219e+00,\n","         -3.0342e+00,  4.3430e-01,  2.2127e+00,  2.6917e+00,  1.0223e+01,\n","         -1.6917e+00,  5.9109e-01, -2.1008e+00, -2.4322e+00,  1.7184e+00,\n","          1.5043e+00, -8.9677e-01, -1.6923e+00, -3.3182e-01,  7.4061e-01,\n","          5.3018e+00, -2.3201e+00, -3.3747e-01, -1.3558e+00, -1.9200e+00,\n","          9.2303e-01, -3.5752e+00, -5.2994e-01,  3.5095e+00,  4.7974e-01,\n","         -1.0392e+00, -1.8120e+00, -1.4109e+00, -1.4532e+00, -4.3112e-01,\n","         -8.3783e-01,  3.2010e+00,  9.0068e-01, -1.2576e+00, -1.5085e+00],\n","        [-5.4210e-01, -7.1870e-01,  5.0161e-02,  2.9495e+00, -3.5073e+00,\n","         -6.9684e-01,  3.2057e+00, -2.7065e+00,  1.0633e+00, -3.2371e+00,\n","         -2.0084e+00,  2.1135e+00, -3.3819e+00,  2.6715e+00, -1.8006e+00,\n","         -1.7241e+00,  1.9473e+00,  3.4119e+00,  4.1699e-02,  1.1602e+01,\n","         -5.8306e-01, -8.7385e-01, -2.6732e+00, -3.1160e+00,  1.6296e+00,\n","          3.5480e+00, -2.4999e+00, -2.5616e+00, -6.4911e-01,  3.0135e-01,\n","          2.4048e+00, -1.8885e+00,  5.0513e-01, -1.6522e-01, -9.6354e-01,\n","          1.2894e-01, -1.3256e+00, -2.8054e+00,  2.5681e+00,  4.5559e+00,\n","         -2.6430e+00, -1.1644e+00, -1.5529e+00,  1.2279e+00, -6.0700e-01,\n","         -1.7582e+00, -2.2243e-02,  4.9296e+00,  3.1074e-01, -3.4242e+00],\n","        [-1.7055e+00, -3.2605e-01, -2.8144e+00, -2.8410e-01,  2.3164e-02,\n","          3.0619e+00, -2.0372e+00, -7.9389e-01,  1.5202e-01, -1.6089e+00,\n","         -1.6544e+00,  3.2281e-02, -8.4444e-01,  9.1805e-01,  4.0870e-01,\n","          1.2681e+01,  6.2616e-01, -1.6659e+00, -1.7539e+00, -2.8851e+00,\n","          4.2090e-02, -6.4241e-01, -2.7936e+00,  2.3641e+00, -1.9400e+00,\n","         -2.3412e+00, -2.6269e+00,  9.9460e-01, -1.5724e-01,  4.7177e+00,\n","         -2.0210e+00,  7.2593e-01,  2.2954e+00, -1.2453e+00,  2.7294e+00,\n","         -2.0264e+00,  3.3805e-02,  7.5067e-01, -3.7611e-01, -2.0071e+00,\n","          8.4391e-01,  1.6625e+00, -2.5502e+00,  2.8983e+00,  7.5422e-01,\n","         -1.1047e+00, -7.9855e-01, -1.0851e+00, -1.1207e+00,  3.2956e+00],\n","        [-1.8113e+00,  1.9859e+00, -2.0342e-01, -2.3066e+00,  3.7838e+00,\n","         -7.2779e-01, -1.9896e+00, -8.4115e-01,  4.0510e+00, -7.9021e-01,\n","         -1.7204e+00,  1.3865e+00, -1.8677e+00,  1.5570e+00, -2.4767e+00,\n","         -1.6991e+00, -1.4634e-01, -2.2187e+00, -1.3955e+00, -2.2058e+00,\n","          7.5213e-01, -5.8677e-01, -4.4164e+00,  1.2345e+00, -1.2695e+00,\n","         -3.1231e+00, -1.0064e+00, -1.1298e+00, -5.5198e-01,  3.3823e+00,\n","         -2.1484e+00,  9.0597e-01, -3.3572e-01, -3.2432e-01,  4.3733e+00,\n","         -1.9966e+00,  2.4568e+00,  2.8807e+00,  1.6191e+00, -2.2639e+00,\n","          1.0760e+00,  3.5438e+00, -1.7701e+00,  1.7727e+00,  1.5522e+00,\n","         -3.8603e-01,  3.7376e-01, -3.2686e+00, -1.8558e+00,  1.2547e+01],\n","        [-1.6654e+00, -1.8610e+00,  2.8305e+00,  9.1831e-01, -1.6046e+00,\n","          2.4428e-01, -1.8630e+00, -2.4033e+00, -3.3356e+00,  1.4158e+00,\n","          9.4615e-01,  2.6079e+00, -3.5661e-01, -2.6604e+00, -2.7304e+00,\n","         -3.1023e+00,  1.4150e+00,  3.5576e+00,  1.9484e+00,  4.2641e-01,\n","          1.3864e+00, -1.3459e-01, -2.3713e+00, -3.4641e+00,  1.8867e-01,\n","          1.2257e+00, -2.1310e-01, -6.2419e-01,  7.0217e-01,  1.0602e+00,\n","          1.1403e+01, -1.2993e+00, -3.0757e-01, -1.6568e+00, -1.6179e+00,\n","          3.7043e-01, -8.9905e-01, -1.4839e+00,  9.8918e-01, -3.0553e-01,\n","          7.5868e-01, -2.0062e+00,  8.2694e-01, -1.1213e+00,  1.0636e+00,\n","         -1.9056e+00,  4.5181e+00,  9.9464e-01,  6.0847e-01, -1.8672e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 6,  9,  0,  2, 15,  4, 23, 22, 14, 26, 36, 19, 19, 15, 49, 30],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7197, 10.8080, -0.5859,  ..., -1.7098, -2.3019,  2.6499],\n","        [-0.0477,  4.8808, -0.3866,  ..., -0.7686, -0.7256,  3.3427],\n","        [ 5.9016, -3.5272,  1.5638,  ...,  6.1813,  1.1113, -1.5513],\n","        ...,\n","        [ 2.1145, -0.2047, -0.9524,  ..., -2.1067,  0.4972, -0.5967],\n","        [ 1.7542, 16.1508,  1.0042,  ..., -1.5844, -3.3865,  1.6674],\n","        [ 1.0513, -4.2441,  3.8706,  ..., -0.5160,  2.1760, -0.5744]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 395/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.2181, -3.1258,  3.2350,  ...,  1.8004,  0.1916, -0.8856],\n","        [ 0.1632, -1.1612,  2.3041,  ...,  1.2767,  1.0991,  0.5524],\n","        [-2.7292, -1.8756,  2.6040,  ..., -1.0724,  0.6039, -1.5184],\n","        ...,\n","        [-1.1192, -0.2799, -0.1788,  ..., -0.8535, -0.3338, -0.1140],\n","        [-1.7988, -1.5582, -0.9981,  ..., -0.2399, -1.1517,  0.5617],\n","        [-1.1349,  4.8153, -0.6901,  ..., -2.1043, -1.9483,  2.2844]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([25, 26, 33, 40, 48, 13, 29, 44, 17,  0, 11, 16,  2,  9, 31,  9, 20, 16,\n","        20, 13, 18, 12, 13, 45,  9,  6, 44, 28,  6, 41,  8, 46,  5, 13, 36,  0,\n","        10,  5, 42, 23, 21, 40, 41,  4, 10,  2, 23,  9, 29, 35,  5, 27, 48,  4,\n","        26,  9, 36, 10, 32, 24, 32, 13,  7, 28, 48, 30, 25, 39, 28, 32, 20, 27,\n","        17, 49, 32, 41,  0, 40, 38, 31, 30, 19,  3, 48, 28, 31, 22, 31, 35, 49,\n","        22, 19, 36, 30, 30, 26, 37, 32,  0, 18, 14, 29, 11,  2, 27, 45, 42,  3,\n","        43, 30,  7,  8,  8,  2, 46, 16, 45, 33, 33, 39, 17,  7,  3, 39, 44,  7,\n","        41, 37], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0631,  2.3529, -0.0417,  ..., -1.5706, -1.7381,  0.4083],\n","        [ 0.3981,  0.2624, -0.2635,  ..., -1.5794,  1.4264, -0.8593],\n","        [ 0.4895,  2.5844, -1.9971,  ..., -2.9222,  0.0712,  1.6548],\n","        ...,\n","        [ 0.7224, -3.8306,  4.6063,  ...,  0.7141,  1.0081, -1.7002],\n","        [ 4.1950,  0.3332,  1.1766,  ...,  2.3095, -0.5397, -1.1941],\n","        [ 2.0597, -4.1113,  2.2856,  ...,  1.2616, -0.9708, -0.8306]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 42,  8, 29,  0, 26, 45, 41, 12, 33, 40, 17,  3, 42,  1,  7, 28, 36,\n","        37, 23, 14,  5,  4, 21, 46, 38, 30, 48, 38, 14,  3,  3,  6, 36, 15,  2,\n","        39, 26, 43,  6,  1, 10, 11, 47, 15,  1, 24,  8, 10, 15, 42, 47, 35, 39,\n","        45, 46, 13, 18, 43, 27, 41, 40, 17,  6, 20, 41,  9, 31, 25, 12,  9, 40,\n","        31, 21, 19, 44, 33, 15, 47, 37, 22,  3, 32,  5, 26, 16, 41,  8, 30, 25,\n","        12, 29, 30, 36,  4, 27, 29, 13, 16, 10,  1, 14, 20, 17,  4, 14, 47, 49,\n","         4, 19, 24,  8, 27, 25, 31, 14, 24, 34, 12, 36, 49, 16, 49, 28, 46, 35,\n","        24, 35], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.2309, -0.2105,  0.6856,  ..., -1.6924, -0.0663,  0.8841],\n","        [-1.0870, -0.8024,  1.7669,  ...,  0.4296, -0.4092, -0.8227],\n","        [-1.1779, -2.3475,  1.5057,  ..., -2.4408,  1.1040, -1.6160],\n","        ...,\n","        [ 3.1321, -1.2478,  1.8334,  ...,  3.4472,  0.4935, -0.8715],\n","        [-3.2158, -1.2919,  3.1307,  ..., -3.2296, -2.1670, -2.2524],\n","        [ 2.7846, -3.0461,  0.2528,  ..., 17.0954,  1.6554, -1.8137]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([18, 26, 44,  7, 22, 32, 34, 45, 18, 24, 35, 15, 47, 26,  1,  7, 25, 20,\n","        19,  1, 16, 28, 17, 16, 17, 17, 21, 10, 27,  5, 21, 24,  2, 34,  1,  5,\n","        34, 27, 18, 11,  9, 27, 15,  0, 31, 13, 18, 46, 15, 27, 42, 36, 37, 25,\n","        12, 22, 42, 29, 17, 12, 31, 48, 29, 20, 28, 14, 16, 10,  9, 49, 22, 20,\n","        19, 22, 22, 43,  6, 33, 10, 43, 16, 40, 41, 29, 43, 19, 35, 12,  2, 49,\n","        23, 25, 44, 14, 32, 38, 38, 14, 37, 11, 24,  1, 23, 20,  8,  2,  1, 21,\n","        35, 12, 11, 37, 34, 47, 15, 40, 23, 23,  0, 45,  0, 24, 38, 19,  2,  6,\n","         9, 47], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.9350e+00, -2.0680e+00,  9.9710e-02,  1.5961e-01, -4.1026e+00,\n","         -3.1002e-01,  4.9155e+00, -3.0423e+00, -2.2600e+00, -4.0484e+00,\n","         -2.5944e+00,  8.5465e-01, -3.9531e+00,  1.0156e+00, -3.7641e-01,\n","          1.4361e-02,  2.3519e+00,  1.3849e+00,  1.0869e+00,  1.3521e+00,\n","          3.7161e+00, -8.9259e-01,  2.8992e-01, -7.3180e-01,  1.2107e+00,\n","          5.4520e+00, -1.0673e+00, -1.3794e+00, -2.1022e+00, -1.0510e+00,\n","          2.3396e+00, -1.6527e+00,  1.5078e+00, -1.1273e+00, -1.5726e+00,\n","          6.6871e+00, -1.3917e+00, -3.5191e+00,  2.2858e+00,  9.0470e-01,\n","         -3.3617e+00, -9.7488e-01, -2.0146e+00,  5.5610e-01, -5.3508e-01,\n","         -3.9950e+00, -2.3961e+00,  1.3513e+01, -1.3896e-01, -1.2781e+00],\n","        [ 2.0102e+00, -2.0626e+00,  4.8791e+00, -7.6428e-01, -5.3453e+00,\n","          1.1497e+00, -3.9213e-01, -3.4064e+00, -1.6118e+00,  1.1401e+00,\n","         -2.0902e+00,  7.2919e-01,  1.7006e+00, -1.7072e+00, -2.6862e+00,\n","         -2.0127e+00,  3.8357e+00,  2.5990e+00,  1.5711e+00,  2.8168e+00,\n","          2.1844e-01, -7.0711e-01,  2.3620e-01, -3.0795e+00,  2.7535e+00,\n","          1.2622e+00,  3.9428e-01,  2.1070e+00,  1.9964e+00,  2.6293e-01,\n","          1.2186e+01, -3.6944e-01, -1.8539e+00, -3.4666e+00, -2.5495e+00,\n","         -1.0541e+00, -2.7375e+00, -1.9019e+00,  1.9751e+00, -1.9711e+00,\n","          2.6173e+00,  3.1042e-01, -1.8146e+00, -1.4317e+00,  7.3193e-02,\n","         -1.2894e+00,  1.4167e+00, -2.0220e+00, -4.4082e-01, -2.5369e+00],\n","        [-3.2076e+00,  1.1830e-02,  2.5503e-01, -7.9643e-01,  1.0203e+01,\n","         -1.8405e+00, -2.2518e+00, -2.1784e+00,  1.3940e+00,  2.3747e+00,\n","         -6.6361e-02, -2.4081e+00,  2.1782e+00,  3.9877e-01, -1.3349e+00,\n","          1.5071e+00, -1.7575e+00, -2.2351e+00,  1.2781e+00, -2.8269e-01,\n","          2.8736e+00,  9.8139e-01, -6.6002e-02,  2.7945e+00, -1.0505e+00,\n","         -1.3742e+00, -2.1237e+00, -1.7545e+00, -3.0889e-01,  1.5721e-01,\n","         -2.6828e+00,  5.3583e+00,  2.7388e+00, -1.9244e+00,  6.1563e-01,\n","         -1.1479e+00, -1.6511e-01,  1.4183e+00, -1.4890e+00, -2.6790e-01,\n","          8.1599e-01,  1.9732e+00,  3.5433e-01,  6.6486e-01, -5.0901e-01,\n","          7.3786e-02, -7.6897e-01, -4.3240e+00, -1.8640e+00,  1.4425e+00],\n","        [-7.4676e-01, -1.5057e+00,  3.1039e+00, -4.5858e-01, -2.2800e+00,\n","         -5.8487e-01,  8.2857e-01, -1.9292e+00, -8.4569e-01, -8.6367e-01,\n","          1.1022e+00,  2.8859e+00,  3.9423e-01, -1.2441e+00, -2.1053e+00,\n","         -2.0843e+00,  9.8575e-01,  2.8398e+00, -7.7705e-02,  3.3560e+00,\n","          8.1582e-03, -8.1167e-01, -1.1386e+00, -2.6751e+00, -4.2457e-01,\n","          2.2218e+00, -1.1788e+00,  2.4596e-01,  6.4642e-02, -6.9420e-02,\n","          9.2891e+00, -1.3384e+00, -5.2987e-02, -8.7593e-01, -1.8983e+00,\n","          1.3925e+00, -1.0912e+00, -2.5584e+00,  1.3963e+00,  5.5404e-01,\n","         -7.6817e-01, -4.0254e-01, -8.9581e-01, -4.5604e-01,  1.2972e-01,\n","         -9.1348e-01,  2.3472e+00,  8.1872e-01,  3.3771e-01, -1.4940e+00],\n","        [ 1.7174e+00,  1.0315e+00,  4.1481e-01, -1.7818e+00,  1.0607e+00,\n","          1.6026e-01,  6.9466e-01, -1.5988e+00,  4.9389e-01, -1.8981e+00,\n","         -6.3602e-01, -5.0290e-01,  2.9175e-01,  1.3275e+00, -4.5077e-01,\n","         -1.3193e-01, -1.4163e+00, -7.3536e-01, -2.0989e+00, -2.1731e+00,\n","          3.0665e+00, -2.2898e+00, -1.6798e+00,  8.2767e-01,  5.2094e-01,\n","         -1.1724e+00, -2.4858e+00, -8.6228e-02, -2.6299e-01,  4.1767e-01,\n","         -1.2574e+00,  1.5691e+00,  8.9488e-01, -1.0508e+00, -1.1298e-01,\n","          9.3068e-01,  1.2126e+01,  5.4717e-01,  3.0236e-01, -8.7149e-01,\n","         -9.2540e-01,  1.0656e+00,  5.6441e-01,  1.4853e+00,  2.6448e+00,\n","         -2.4939e+00, -1.4897e+00, -4.0122e-01, -1.0695e+00,  8.6417e-01],\n","        [ 3.1951e+00,  6.2996e+00,  1.0819e+00,  1.3887e+01, -1.9343e+00,\n","          3.2892e-02, -5.3659e-01, -3.8812e+00, -6.7326e-01,  4.0292e-01,\n","         -2.0024e+00, -4.1383e+00, -1.6270e+00, -2.0324e+00, -2.0867e+00,\n","         -1.0512e+00,  2.2759e-01, -1.9684e+00, -9.7266e-02,  5.5436e+00,\n","         -1.4816e+00, -1.7041e+00, -3.1391e-01,  3.0905e-02,  7.0374e+00,\n","         -1.4091e+00,  1.2713e+00, -3.1242e+00, -1.8537e+00,  1.0308e+00,\n","          1.5172e+00,  6.6603e-01, -5.1946e-01, -2.2723e+00,  1.0367e+00,\n","         -7.4531e-01, -2.1742e+00,  5.1229e-01,  1.7898e+00,  3.5996e-01,\n","         -5.1041e-01, -2.3267e+00, -2.8025e+00, -1.6663e-01, -1.9630e+00,\n","         -1.9604e+00,  1.4781e+00,  2.0819e+00, -9.1259e-01, -1.6903e+00],\n","        [-1.5985e+00,  6.2730e-02, -1.7908e+00, -6.6760e-01, -2.1690e+00,\n","         -1.3433e+00, -6.9924e-01,  1.1434e+01, -8.2806e-01,  3.9457e-01,\n","         -1.1061e+00,  4.6854e-01,  4.9025e-01, -6.2226e-01,  6.0556e-01,\n","         -8.7084e-01, -4.8432e-01,  9.1720e-01,  2.3979e+00, -6.2255e-01,\n","         -1.3671e+00,  1.6962e+00, -5.2681e-01, -2.3638e+00, -2.1209e+00,\n","         -1.2063e+00,  1.0358e+00, -4.7937e-01,  3.1239e+00, -3.6592e-01,\n","         -2.1312e+00,  9.3480e-01,  2.4072e+00, -1.1043e+00, -8.1385e-01,\n","          2.5349e-01, -9.5716e-01, -2.9484e-01, -9.4394e-01,  8.9611e-01,\n","          1.0134e+00,  1.8779e+00,  9.2304e-01, -1.0288e+00, -8.0628e-02,\n","          1.2292e+00,  1.3720e-01, -7.1436e-01, -5.9179e-01, -7.4077e-01],\n","        [-8.6139e-01, -2.8488e+00,  1.3727e+00, -1.7039e+00, -1.1818e+00,\n","          1.7054e+00, -1.4395e-01, -2.3704e+00, -1.5258e+00, -3.6727e-01,\n","          1.7637e+00,  1.0645e+01,  7.6308e-01, -7.8890e-01,  8.2845e-01,\n","         -7.5946e-01,  3.0654e-01, -5.8350e-01, -1.5409e+00, -9.9022e-01,\n","          8.9485e-01,  4.7014e-01, -2.0584e+00, -2.1606e+00, -3.6540e-01,\n","          3.0615e-01, -1.4211e+00, -3.3585e-01,  2.2361e-01,  4.1475e+00,\n","         -1.7576e+00, -4.8968e-01,  1.8201e+00, -5.6416e-01, -1.5076e+00,\n","          2.5375e+00, -8.5337e-01, -3.1277e+00,  2.9484e+00,  1.5277e+00,\n","         -1.8759e+00, -1.4760e-01, -1.2656e+00,  1.2782e+00,  2.1383e+00,\n","         -1.2742e+00, -9.8475e-01,  7.4704e-01, -1.2630e+00,  1.4392e+00],\n","        [ 2.0458e+00,  1.3216e+00,  7.1374e-01,  8.3254e-01, -2.4173e+00,\n","         -1.4492e+00, -3.3308e+00, -1.1934e+00, -1.3314e+00,  2.5553e+00,\n","          5.0302e+00, -1.5971e+00, -1.6213e+00, -1.9185e+00, -2.4755e+00,\n","         -1.6924e+00,  1.8228e+00,  3.2552e+00,  1.5107e+00,  7.4126e-01,\n","         -3.0892e-01, -1.2971e+00, -1.6140e+00, -2.7347e+00, -3.5084e-01,\n","         -1.2784e+00, -1.6470e+00, -1.0446e+00,  1.9023e+00,  2.2513e-01,\n","         -3.9567e-01,  1.5853e-01, -9.8756e-02, -6.5303e-01,  8.1426e-01,\n","         -1.7542e+00, -1.1378e+00,  1.9909e+00,  9.6806e-01, -3.5054e+00,\n","          3.8143e-01, -5.4874e-01,  2.7270e+00,  5.6911e-02,  2.1614e+00,\n","         -3.0861e+00,  1.2750e+01, -2.9027e+00,  2.4085e-01, -8.2036e-01],\n","        [-2.2619e+00,  9.7886e-01, -6.2284e-01, -5.9399e-01,  1.0944e+01,\n","         -1.5257e+00, -8.4479e-01, -8.5725e-01,  1.0756e+00,  2.9170e-01,\n","         -5.7094e-01, -4.2579e-01,  1.6377e+00,  1.0504e+00, -1.9299e+00,\n","          8.7923e-01, -1.8689e+00, -2.7449e+00, -4.4139e-01, -4.9294e-01,\n","          8.3613e-01,  2.0719e-01,  2.8096e-01, -2.4231e-01, -1.2882e+00,\n","         -1.4044e+00, -2.2525e+00, -2.4708e+00,  2.8417e-01,  3.6824e+00,\n","         -2.5713e+00,  1.5508e+00,  2.8451e+00, -1.4260e+00,  1.3591e+00,\n","         -1.3480e+00,  1.3454e-01,  2.1583e+00, -1.6272e+00,  1.3606e-01,\n","          1.8097e+00,  2.7848e+00, -8.9232e-01,  6.3670e-01, -1.4435e+00,\n","          2.7648e+00, -7.8189e-01, -3.4780e+00, -2.7670e+00,  2.4193e+00],\n","        [-6.3803e-01, -4.1566e-01, -1.4505e+00, -2.8039e+00,  5.8346e-01,\n","          6.3859e-01, -1.7123e-01, -3.1573e+00,  3.2690e+00, -1.1665e+00,\n","         -2.9324e+00, -8.6440e-01,  6.1330e-01,  2.7069e+00,  1.6161e+00,\n","          4.0378e+00, -8.2012e-01, -1.9855e+00, -1.5479e+00, -2.0797e+00,\n","          3.5550e+00,  1.0346e-01, -2.1213e+00,  5.5735e+00, -1.4005e+00,\n","         -1.9548e+00, -9.2989e-01, -1.8298e-01, -2.0481e+00,  3.8962e+00,\n","         -2.2144e+00,  1.1322e-01,  5.4250e-01, -2.2282e+00,  7.0026e-01,\n","          8.1505e-02,  1.7706e+00,  1.2026e+00,  8.6329e-01, -1.6746e+00,\n","          5.8397e-01,  2.4118e+00, -3.0131e+00,  2.3779e+00,  3.3234e-01,\n","         -2.1146e+00, -2.5141e+00, -2.0509e+00, -2.8145e+00,  1.0484e+01],\n","        [ 1.3729e+00, -3.9315e+00,  5.7906e+00, -3.6688e+00, -3.3264e+00,\n","          2.0972e+00, -1.5623e+00, -1.6899e+00, -1.6675e+00,  1.4697e+00,\n","          1.3771e+00,  1.0382e+01,  1.2752e+00, -2.7219e+00,  1.6755e+00,\n","         -3.4975e+00,  2.4237e+00,  1.1000e-01, -2.5558e-02, -1.2001e+00,\n","          1.0085e+00,  2.3367e+00,  1.0604e+00, -3.9473e+00,  8.0592e-04,\n","          2.6269e+00, -8.5871e-02,  5.2453e+00, -1.5474e+00, -2.5574e-01,\n","         -1.0168e+00, -1.7091e+00,  1.0931e+00, -1.9189e+00, -4.3531e+00,\n","         -6.2379e-01, -2.2333e+00, -3.8326e+00,  5.1115e+00, -2.3802e-01,\n","          2.0760e+00,  1.8938e-01, -6.2882e-02, -1.0134e-01,  4.9556e-01,\n","         -2.3959e+00, -1.0111e+00,  1.0858e-01, -6.6480e-02, -1.1704e+00],\n","        [ 3.6336e+00,  7.2656e-01,  2.1532e+00,  7.8572e+00, -2.7199e+00,\n","          1.1720e+00,  2.3130e-01, -2.9488e+00, -1.7737e+00,  7.2383e-01,\n","         -2.1780e+00, -1.2146e+00, -2.1900e+00, -1.3596e+00, -1.5558e+00,\n","         -9.4181e-01,  2.9371e+00, -1.4945e+00, -6.1442e-02,  1.5306e+00,\n","          1.0122e-01, -4.0311e-01,  6.4833e-01, -8.3084e-01,  4.9082e+00,\n","          1.3490e+00,  2.3017e+00, -3.8152e-01, -3.3339e+00, -2.9215e-01,\n","         -6.8535e-01,  9.0997e-01, -4.3871e-01, -9.5054e-01,  9.4400e-01,\n","          3.4006e-01, -1.8194e+00, -9.1611e-01,  2.0773e+00,  1.5238e+00,\n","         -1.8681e+00, -8.6396e-01, -3.1249e+00, -8.8666e-01, -2.0535e+00,\n","         -2.8065e+00, -3.8032e-01,  4.7262e+00, -8.9768e-01, -1.5990e+00],\n","        [ 1.4898e+00,  2.3741e+00, -1.6196e+00, -3.8844e-01,  2.4430e+00,\n","         -2.6611e-01, -1.7165e+00, -2.1315e+00,  2.8986e+00, -5.9739e-02,\n","         -2.7319e-01, -3.3428e+00,  1.6845e+00, -1.2037e+00, -3.5002e-01,\n","         -9.6161e-01,  5.1064e-01, -3.4115e+00, -6.0945e-01, -2.4928e+00,\n","          1.3708e-01,  1.3982e+00, -8.4537e-01,  3.0092e+00, -8.0890e-03,\n","         -3.4087e+00, -8.6939e-01, -2.2285e+00,  5.0861e-02,  6.3371e-01,\n","         -6.1327e-01,  2.4689e+00,  3.8997e-02, -1.6795e+00,  2.0816e+00,\n","         -2.3789e+00,  1.9789e+00,  1.1103e+01, -6.0284e-01, -1.2317e+00,\n","          2.8739e+00,  1.4301e+00,  2.5992e-01,  1.0532e+00,  8.3321e-02,\n","         -1.6281e+00, -1.4317e+00, -3.1776e+00,  1.6711e-01,  1.1647e+00],\n","        [-1.4971e+00,  9.3827e-01,  1.0149e+00, -1.3706e+00, -3.8692e+00,\n","          4.1696e+00,  4.6875e+00, -1.8959e+00, -3.6723e-02, -1.8842e+00,\n","         -8.5694e-01, -1.3155e+00, -2.2358e+00,  1.9356e+00, -7.0630e-01,\n","         -1.0963e-01,  8.4315e-01,  1.6338e+00, -1.1927e+00,  8.0852e-01,\n","         -1.7973e+00, -1.1550e+00, -8.1196e-01, -1.0635e+00,  3.7364e-01,\n","         -1.1298e+00,  4.0763e+00, -8.0338e-01, -2.7625e+00,  2.1743e+00,\n","         -7.7971e-01, -2.4729e+00,  1.9604e+00,  1.4713e+01,  2.5736e+00,\n","         -5.0509e-01, -2.7621e+00, -8.4939e-01, -7.4119e-01, -1.2123e+00,\n","         -2.1171e+00, -2.5536e+00, -1.6165e+00,  4.2963e+00,  3.6199e+00,\n","         -1.5246e+00,  3.4222e-01, -2.5952e+00, -2.2708e-01, -2.8018e+00],\n","        [ 1.1277e+00, -3.3935e+00, -3.1392e-01, -2.8203e+00, -4.0112e+00,\n","          8.3656e-01, -1.3712e+00, -1.9314e+00,  6.5434e-01,  1.1386e+00,\n","          4.9501e+00, -1.7474e+00, -3.4075e-02, -3.7745e+00, -3.8925e-02,\n","         -1.8654e+00, -1.0607e+00,  5.9507e+00, -2.3519e+00, -1.8117e+00,\n","          6.2013e-01,  1.8978e-02,  8.0070e-01, -1.1281e+00, -1.2205e+00,\n","         -1.1669e-01,  1.0213e-04,  3.1997e-01, -3.3551e-01, -1.0862e-01,\n","         -1.7559e+00, -6.4797e-01,  2.3616e-01, -2.9124e+00, -1.6463e+00,\n","         -8.9939e-01,  2.4712e-02, -1.4281e-01,  2.4115e+00,  2.7777e+00,\n","          1.1545e+00,  3.2102e+00,  2.7157e+00, -2.2945e-01,  2.3483e+00,\n","         -1.6296e+00, -1.2821e+00, -1.6528e+00,  1.2126e+01, -6.4267e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([47, 30,  4, 30, 36,  3,  7, 11, 46,  4, 49, 11,  3, 37, 33, 48],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7136, 10.7797, -0.5924,  ..., -1.7113, -2.3002,  2.6551],\n","        [-0.0555,  4.8718, -0.3850,  ..., -0.7733, -0.7267,  3.3489],\n","        [ 5.8994, -3.5286,  1.5646,  ...,  6.1677,  1.1125, -1.5570],\n","        ...,\n","        [ 2.1159, -0.2018, -0.9521,  ..., -2.1055,  0.4980, -0.5945],\n","        [ 1.7406, 16.1070,  0.9982,  ..., -1.5787, -3.3767,  1.6570],\n","        [ 1.0429, -4.2438,  3.8608,  ..., -0.5220,  2.1720, -0.5784]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 396/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.4704, -0.7422,  2.0500,  ...,  1.1318,  0.3784, -1.5608],\n","        [ 5.5042, -2.9640,  4.2770,  ..., -0.8270, -0.0226,  0.3241],\n","        [-0.8844, -1.4520,  1.9357,  ..., -2.5409,  3.9665, -1.7025],\n","        ...,\n","        [-3.0289,  1.8283,  1.0846,  ..., -2.9529, -0.8099,  1.1969],\n","        [ 2.6421,  1.4132,  0.8619,  ...,  2.9487,  0.3223, -1.6263],\n","        [-1.1407, -0.4592,  1.4935,  ..., -1.2578,  0.1805, -0.7523]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([19, 16, 10, 28, 49, 26,  5, 46, 17, 16, 35,  4,  3, 38, 48, 25, 14, 12,\n","        16, 14, 29, 43, 21, 36, 47, 15, 27, 47,  4, 12, 14, 40,  9, 27, 30, 25,\n","        17, 29, 45, 17, 16, 43, 11, 25, 24, 29, 29, 21, 16, 31, 44,  0, 13, 10,\n","        19, 41, 31, 31, 41, 27,  3, 24, 35,  3, 38, 11, 20,  5,  0,  2,  1, 10,\n","        21, 16, 30,  6,  2, 24, 11, 30, 17, 40,  3, 14, 38,  9, 46,  1, 32, 23,\n","         1, 10, 36, 36,  7, 45, 32,  4, 13, 49, 42, 27, 27, 44, 14, 32, 19, 46,\n","        42,  4,  3, 19, 47, 40, 34, 10, 46, 44, 20, 34, 24, 28, 31, 45, 25, 40,\n","         3, 33], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.0128, -1.3968, -0.6322,  ..., -0.2238,  2.2480, -1.7716],\n","        [ 1.2895, -3.2390,  1.8752,  ...,  4.1396, -0.8874,  0.7858],\n","        [ 3.4117, -1.6880,  3.6229,  ...,  0.4775, -2.3885, -0.6047],\n","        ...,\n","        [ 3.6560, -3.2737,  1.1688,  ...,  1.9309, -1.6393, -0.8477],\n","        [ 0.8972,  1.4143, -2.3684,  ..., -3.1890, -0.9267,  0.6644],\n","        [ 2.1402, -3.3788,  2.0829,  ...,  1.1329,  1.9326, -1.0315]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([17, 11, 16, 14, 11, 36, 25,  2, 22, 37,  2,  1,  2,  2,  9, 24,  7,  9,\n","        25, 26, 29, 15, 25, 17, 19, 11, 12, 39, 38, 18, 13, 18,  2, 20, 40, 29,\n","        13, 28,  2, 35, 22,  6,  9, 31, 30,  6, 33,  5, 44, 48, 13,  8, 43, 20,\n","        18, 23, 39, 25, 14, 49,  9, 23,  8,  7, 33, 44,  8,  4, 12, 32, 37, 14,\n","        23, 49, 13,  1,  5, 39, 18, 49, 41, 49,  5, 15, 37,  4,  3, 17, 34, 12,\n","         1, 27, 13, 42,  1, 35, 34,  8, 12,  8, 41, 31, 28, 30, 16, 47, 24, 32,\n","        26, 10, 15, 41, 35, 30, 10,  6, 37, 12, 37,  3, 39, 48, 46, 27, 39, 35,\n","         8, 11], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1084, -3.4628, -2.2473,  ..., -5.2588, -2.1205, -1.3801],\n","        [-1.4344, -2.3903,  0.9688,  ..., -1.3840,  1.7130, -2.0634],\n","        [ 1.8209, -0.4184,  2.1805,  ...,  0.2994,  2.2601,  3.4001],\n","        ...,\n","        [ 1.8724,  2.8099,  0.5748,  ..., -0.5645, -1.4775,  1.1252],\n","        [ 0.5273,  0.3014,  0.6689,  ...,  2.6196, -0.2855, -1.8405],\n","        [-1.9071,  0.5048, -1.8118,  ..., -0.4884, -1.1797,  3.2350]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([28, 17, 20, 23, 32, 20, 15, 26,  0, 33,  8, 41, 37,  9,  2, 36,  1,  8,\n","        47, 36, 47, 10, 32, 42, 24, 15, 44, 41, 33, 30,  0, 45, 14,  4, 30, 22,\n","         3,  6, 31, 11,  4, 17, 12,  7,  5, 21, 35, 42, 22,  9,  7, 13, 26, 29,\n","        47, 20,  0, 47,  9,  7, 33, 29, 48, 22, 26, 42, 22, 34, 40,  5, 23, 17,\n","        23,  0,  6, 27, 27, 45,  6, 27, 28, 31, 24, 26,  1, 28, 46, 30, 49, 37,\n","        21, 18, 33, 48, 31, 37,  0, 43, 38, 20, 28, 22, 21,  0, 20, 29, 49, 42,\n","        18, 40, 41, 19, 15, 43, 45,  7, 22, 36, 43, 30, 16, 10,  7, 35,  9, 36,\n","        19, 15], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.5899e+00, -6.3172e-01,  6.1952e-01, -1.6949e+00,  2.7813e-01,\n","         -9.7472e-01,  3.6084e-02, -1.2745e+00,  1.1197e+00,  2.9294e+00,\n","         -1.4313e+00, -4.7444e-01, -5.5771e-01,  2.0220e+00, -3.7049e-01,\n","         -1.7042e+00, -9.5831e-01,  1.6177e+00,  9.4718e+00,  1.1728e+00,\n","          2.8408e+00,  1.7659e+00, -1.0737e+00,  3.5155e-01,  1.7337e+00,\n","          5.0183e-01, -1.5463e+00, -1.4587e-01,  2.7771e-04, -7.3394e-01,\n","          4.2083e-01,  6.8153e-01,  1.3340e+00, -2.4614e+00, -1.5022e+00,\n","         -1.3698e+00, -1.7534e+00, -1.1395e+00,  2.6934e-01, -9.9615e-01,\n","         -5.3222e-02, -1.1777e-01,  2.7417e-01, -1.5617e+00,  1.0431e-01,\n","         -7.7243e-01, -3.4909e-01, -1.1072e-01, -1.1309e+00,  4.1874e-01],\n","        [ 2.9724e-02,  3.2719e-01,  7.2097e-01, -9.2709e-01, -4.7397e-01,\n","          9.9776e-01, -1.9589e+00, -1.0911e-01, -4.8684e-01, -1.6640e-01,\n","         -5.8845e-01,  2.4910e+00,  3.0418e+00, -8.6305e-01,  1.4511e+00,\n","          5.5388e-03, -4.8670e-01, -1.7046e+00, -1.0564e+00, -1.6953e+00,\n","         -1.5472e-01,  1.0570e+00,  3.7477e-01, -2.0436e+00, -9.1132e-01,\n","         -5.7757e-01, -7.2506e-01,  1.5439e+00,  5.0899e-01,  2.4711e-02,\n","          3.5222e+00,  3.0338e-01,  1.4441e-01, -2.8349e+00, -1.4112e+00,\n","         -2.0641e+00, -5.7142e-01,  2.9608e+00, -3.0001e-01, -2.4819e+00,\n","          1.0532e+01, -8.3612e-01,  9.6972e-01,  3.7951e-01, -5.2764e-01,\n","         -2.1713e+00,  5.5069e-01, -6.6460e-01, -1.2235e+00, -4.7140e-02],\n","        [ 5.0386e+00, -3.4548e+00,  3.3168e+00,  2.5285e+00, -3.5769e+00,\n","          1.3760e+00, -1.8195e+00, -2.2562e+00, -1.3791e+00, -2.4488e+00,\n","         -2.7594e+00,  2.4939e+00, -2.9295e+00, -1.0183e+00, -3.8309e-01,\n","         -7.4195e-01,  1.5445e+01, -1.0133e+00, -1.8559e+00,  1.3180e-01,\n","         -1.0982e+00, -2.4699e+00, -2.0664e+00, -1.7115e-01,  2.6405e+00,\n","          3.4691e+00,  2.4963e+00,  7.1650e-01, -3.1109e+00, -3.4013e-01,\n","          2.1842e+00, -2.0561e+00,  4.9032e-01,  3.5499e+00, -1.9750e+00,\n","          1.8208e+00, -3.2338e+00, -1.5324e+00,  3.4428e+00,  1.3360e+00,\n","         -1.6185e+00, -1.8209e+00, -2.9849e+00,  2.9174e-01, -1.5442e-01,\n","         -3.5344e+00,  2.3179e-01,  2.0631e+00, -2.9056e-01,  6.4080e-01],\n","        [ 1.3897e+00,  5.2634e-01,  1.7717e+00,  1.2431e+00, -1.2372e+00,\n","         -1.2471e+00, -1.7495e+00, -1.3278e+00, -1.2256e+00,  3.3313e-01,\n","          1.4018e+00,  1.4049e+00, -9.3547e-01, -1.2526e+00, -1.5733e+00,\n","         -9.2389e-02,  1.2636e+00,  1.0018e+00,  7.9906e-01,  1.5449e+00,\n","         -8.5942e-01, -1.1410e+00, -1.5418e+00, -2.2782e+00, -7.1931e-01,\n","          4.8964e-01, -1.1150e+00,  6.2672e-01,  1.6263e+00,  7.7864e-01,\n","          3.8040e+00, -1.5283e+00, -3.3126e-01, -1.2182e+00, -9.7824e-01,\n","         -4.5544e-01, -9.2629e-01,  6.0525e-01,  1.5351e-01, -2.6775e+00,\n","          1.5600e-01, -4.9385e-01, -5.9104e-01, -3.6192e-02, -2.9606e-01,\n","         -2.9936e+00,  9.7758e+00, -8.0619e-01, -1.6873e+00, -9.2227e-02],\n","        [ 1.3982e+00, -2.8307e+00,  7.2414e-01, -1.6066e+00, -3.0507e+00,\n","          1.9103e+00, -5.6938e-01, -1.4868e+00, -3.1345e-01, -4.0170e-01,\n","          5.2675e+00,  1.6385e+00, -6.7105e-01, -1.6469e+00, -2.3196e-01,\n","         -1.9284e+00, -7.2873e-01,  3.7467e+00, -3.3450e+00, -9.8597e-01,\n","          1.6413e+00,  8.0840e-02, -1.1604e+00, -1.6112e+00, -1.7591e+00,\n","         -6.4496e-02,  1.9173e-01,  2.2759e-01,  8.2411e-02, -1.8948e-01,\n","         -6.8148e-01, -1.3352e+00, -9.5103e-01, -5.4100e-01, -2.2416e+00,\n","          8.0893e-01, -5.0745e-01, -7.7063e-01,  8.4093e-01,  1.5927e+00,\n","         -5.3923e-01,  1.1763e+00,  3.7761e+00,  2.0437e+00,  6.7802e-01,\n","         -2.3233e+00, -2.3019e-01, -3.0324e-02,  8.1303e+00, -3.9469e-01],\n","        [ 1.6507e+00, -2.3477e+00,  6.8691e-01, -1.5792e+00, -1.1125e+00,\n","          1.8632e+00, -9.3003e-01, -1.6673e+00,  1.1848e+00, -1.1945e+00,\n","          6.9629e+00,  1.0862e-01, -1.7115e+00, -3.3536e+00, -1.6197e+00,\n","         -1.6665e+00, -1.2113e+00,  1.4986e+00, -3.4435e+00, -2.3032e+00,\n","          1.6022e+00, -6.1397e-01, -5.7727e-01, -1.2435e-01, -2.1718e+00,\n","         -7.3798e-01, -5.8669e-01,  1.7143e+00, -1.3473e+00,  1.2149e-01,\n","         -6.5962e-01, -5.3366e-01, -4.9586e-01, -1.3091e+00, -1.1554e+00,\n","         -1.6922e-01, -6.6769e-01,  2.8721e-01,  7.7529e-01,  2.3011e+00,\n","         -3.7387e-01,  2.0732e+00,  2.6892e+00,  1.3130e+00,  9.4206e-01,\n","         -2.6752e+00,  8.1088e-02, -9.2810e-01,  1.1496e+01, -1.2188e+00],\n","        [-2.8147e+00, -2.3150e+00,  1.8646e-01, -2.3769e+00,  3.7390e+00,\n","          3.2907e-01, -1.3607e+00, -6.6371e-01,  1.1367e+00,  4.8975e+00,\n","          6.0593e-01,  7.1786e-01,  1.5010e+00, -1.6475e+00, -1.2528e+00,\n","         -1.2463e+00, -1.7553e+00, -6.5440e-01,  2.1061e+00, -1.3469e+00,\n","          9.6679e-01,  1.8641e+00, -1.6954e+00, -1.8200e+00, -1.7926e+00,\n","         -6.5466e-01, -2.9393e+00,  7.5233e-01,  1.1230e+00,  1.9457e+00,\n","         -1.2776e+00,  3.2888e+00,  1.1679e+00, -3.0727e+00,  2.1894e-01,\n","         -8.4567e-01,  1.9096e-01,  2.3752e+00,  1.0241e-01, -2.5103e+00,\n","         -1.0752e-02,  1.1750e+01, -9.8457e-01, -8.3958e-01,  1.9961e+00,\n","          6.1403e-01, -1.2760e+00, -6.7994e-01, -1.9362e+00,  1.1990e+00],\n","        [-3.9231e-01,  1.1509e+00,  3.4153e+00,  4.5833e+00, -2.2745e+00,\n","         -1.1123e+00,  4.4664e+00, -4.7117e+00,  5.9808e-01, -1.7918e-01,\n","         -3.7825e+00, -7.3230e-01, -2.3808e+00,  3.4575e+00, -2.4356e+00,\n","         -4.8712e-01, -1.1260e+00, -2.3459e-01,  1.2432e+00,  1.1429e+01,\n","          1.3679e+00,  7.1110e-01, -8.8385e-01,  1.2877e+00,  3.4747e+00,\n","         -4.4294e-01, -1.6610e+00, -1.9176e+00, -2.0135e+00,  7.4445e-01,\n","          1.5246e+00,  1.1641e+00, -2.5091e-01,  6.2434e-01, -5.7459e-01,\n","          1.2197e-01, -4.6085e-01, -2.8424e+00,  3.2644e+00,  1.2787e+00,\n","         -4.4834e+00, -2.9038e-01, -4.1841e+00,  1.0254e+00, -1.0422e+00,\n","         -1.7634e+00, -2.1200e+00,  1.5009e+00, -3.2608e+00, -3.6163e-01],\n","        [-1.7323e+00, -1.2167e+00, -1.2661e+00, -1.0022e+00,  1.9075e+00,\n","         -6.7002e-01, -3.9523e-01,  1.5210e+00,  3.3712e-01,  1.6862e+00,\n","         -1.5671e+00,  5.8085e-01,  1.6102e-01, -4.7789e-01, -2.0837e+00,\n","          2.4288e-01, -8.7628e-01,  2.0021e-01,  1.8006e+00, -4.9112e-01,\n","         -3.8663e-01, -1.5578e-01, -2.7919e-01, -2.0280e+00, -9.9121e-01,\n","         -1.1173e+00, -6.8465e-01, -1.4073e+00,  9.8297e-01,  2.0535e+00,\n","         -9.5006e-01,  1.9334e+00,  2.0621e+00, -1.2912e+00,  2.7799e-01,\n","         -2.2382e+00, -1.9620e+00,  5.3229e-01, -2.2563e+00,  9.4132e-01,\n","          3.0383e+00,  2.0566e+00, -1.4205e+00, -1.2989e+00, -4.1721e-01,\n","          1.1622e+01,  1.9987e-01, -1.9538e+00, -1.6921e+00,  4.0126e-01],\n","        [ 2.1638e-01,  7.8938e+00, -6.8813e-01, -2.5232e-01, -1.1004e-01,\n","          2.1963e+00, -2.3519e-01, -7.7162e-01,  1.8104e+00, -1.6783e+00,\n","         -2.4670e+00, -1.9986e+00, -2.0906e+00,  4.5406e-01, -8.4537e-01,\n","          2.8357e+00, -1.9768e-01, -3.8267e+00, -1.2753e+00, -2.5270e+00,\n","          5.4120e-01, -6.2666e-01, -2.2928e+00,  1.8818e+00, -7.0498e-01,\n","         -4.1441e+00, -1.0791e-02, -1.0546e+00, -1.1536e+00,  2.7829e+00,\n","         -1.8452e+00,  6.3877e-01, -1.3796e-01,  8.7245e-01,  1.2407e+01,\n","         -1.4771e+00,  3.8926e-01,  3.9828e+00, -8.0691e-01, -3.0189e+00,\n","          2.3912e-01, -2.6951e-01, -2.4589e+00,  3.3331e+00, -4.7671e-01,\n","         -2.3257e+00,  1.2338e+00, -9.3925e-01, -2.5089e+00,  4.1316e+00],\n","        [ 1.0731e+00, -2.1569e+00,  1.1737e+00, -1.3669e+00, -2.1189e-01,\n","         -8.6874e-01, -4.7739e-03, -1.1753e-01, -8.5136e-01,  6.6936e-01,\n","         -6.2001e-01, -1.7849e-01,  1.2953e+01, -3.5497e+00,  4.5119e-01,\n","         -2.4876e+00, -3.4298e+00, -5.9367e-01, -1.2768e+00, -1.0387e+00,\n","         -1.0945e+00,  1.3333e+00,  2.8509e+00, -2.6462e+00, -1.1585e+00,\n","         -2.8937e-01, -1.3085e+00,  3.9014e+00,  3.6039e+00, -1.5316e-01,\n","         -1.2318e-01, -2.8221e-01,  7.7800e-01, -2.6807e+00, -1.7796e+00,\n","          3.6402e+00, -1.5564e+00,  1.7141e+00,  1.2860e+00,  1.2161e+00,\n","          1.1623e+00,  1.4392e+00,  1.6379e+00, -2.3338e-01, -4.6634e-03,\n","          4.0856e-01, -8.6175e-01, -1.7194e+00, -4.7453e-01, -2.8778e+00],\n","        [ 5.7574e-01, -9.3328e-01,  2.3953e+00,  4.2504e-01, -2.2963e+00,\n","         -6.5383e-01,  1.1641e+00, -7.3392e-01, -1.3123e+00, -1.2267e+00,\n","         -2.6348e-01,  4.6401e+00,  2.6957e-01, -2.1818e+00, -3.1386e-01,\n","         -1.5877e+00, -1.2856e-01,  2.7018e-01, -1.7923e+00,  8.5345e-01,\n","         -4.9430e-01,  1.8230e+00,  2.1353e+00, -2.2380e+00,  9.6957e-01,\n","         -1.1040e+00, -9.0916e-01, -1.5324e+00, -1.5963e+00, -1.1400e+00,\n","         -3.6254e-01, -1.0451e+00,  5.4321e-01, -2.2525e+00, -2.3954e+00,\n","          1.0185e+00, -2.5482e-01, -3.1187e+00,  1.1677e+01,  3.6178e+00,\n","         -1.3833e+00, -6.9966e-01, -3.0521e-02,  1.7695e-01,  9.8208e-01,\n","         -2.5070e+00, -1.0818e+00,  2.9276e+00, -6.6944e-02, -1.1288e+00],\n","        [ 2.0351e+00,  2.3041e+00, -4.1462e-01, -1.8956e-01,  1.6222e+00,\n","         -3.9161e-01, -6.8155e-01, -2.5849e+00,  1.4815e+00, -2.0857e+00,\n","         -6.5048e-03,  1.8302e-01, -6.8393e-01,  1.9053e-01, -8.3687e-01,\n","          1.0055e+00, -5.1884e-01, -1.6803e+00, -2.0378e+00, -3.0510e+00,\n","          3.3344e+00, -1.5475e+00, -1.2525e+00,  2.6449e+00,  2.0543e-01,\n","         -1.7349e+00, -3.6478e+00, -1.3055e+00, -8.1940e-01,  9.1758e-01,\n","          6.0764e-01,  7.5119e-01,  1.0667e+00, -2.6442e+00, -3.8723e-01,\n","         -4.9797e-01,  1.3320e+01,  1.3849e+00, -4.8760e-01, -1.3574e+00,\n","          1.2097e-01,  1.0032e+00,  1.0729e+00,  1.9473e+00,  5.1341e-02,\n","         -3.2193e+00, -4.3562e-01, -1.3477e+00, -1.4674e+00,  3.4901e+00],\n","        [-2.0733e+00, -2.4753e+00, -1.1891e+00, -2.8584e-01,  3.0833e+00,\n","          1.2787e+00, -1.6140e+00, -2.0033e+00,  4.9099e-01, -1.5096e-01,\n","          1.0256e-01, -6.7952e-01,  8.9427e-01,  4.0564e+00,  1.5108e+00,\n","          2.0913e+00, -6.8818e-01, -7.4505e-01, -1.1474e+00, -1.2564e+00,\n","          2.0282e+00, -7.6759e-01,  3.6904e+00,  2.7779e+00, -8.3438e-01,\n","          8.1279e-01, -1.3082e+00, -4.5434e+00,  3.0126e-01,  2.1640e+00,\n","         -2.0572e+00,  3.6520e+00,  1.0900e+01, -6.6752e-02, -1.6841e+00,\n","          3.2897e-01, -1.2505e+00, -1.3880e+00, -1.0786e+00, -4.1346e-01,\n","         -9.5383e-01, -7.3535e-01, -2.7807e+00,  1.0701e+00,  2.1250e+00,\n","         -4.9808e-01, -2.1909e+00, -3.7470e+00, -3.8119e+00, -4.4907e-01],\n","        [ 3.2061e+00,  5.1162e+00,  1.4211e+00,  6.1273e+00, -2.0255e+00,\n","         -2.1762e+00, -2.1033e+00, -3.7597e+00, -2.3413e+00,  1.8011e+00,\n","         -2.2187e+00, -3.9117e-01, -2.4805e+00, -7.5925e-01, -2.3293e+00,\n","         -1.1504e+00, -3.7050e-01, -6.7114e-01,  6.4202e-01,  3.1177e+00,\n","          5.3546e-01, -1.0227e+00, -2.5030e-01, -3.7571e-01,  1.3556e+01,\n","          2.1201e+00,  5.6214e-01, -3.9555e+00, -9.3711e-01,  2.3278e+00,\n","          2.8711e+00,  2.1475e-01, -7.8968e-01, -2.2034e+00, -6.5292e-01,\n","         -9.8096e-01,  2.8202e-01, -7.3451e-03,  4.9382e-01, -9.4040e-01,\n","          1.6722e-01, -2.9632e+00, -2.6670e+00, -1.6169e+00, -1.2826e+00,\n","         -2.5631e+00,  9.2684e-01,  3.4533e+00, -2.2517e+00, -1.6322e-01],\n","        [ 4.3590e-02, -8.8342e-01,  2.8257e+00,  5.6874e-01, -2.0893e+00,\n","          2.6436e+00,  4.8540e+00, -6.8976e-01, -9.4870e-01, -1.5923e+00,\n","         -3.3920e-01, -4.1561e-01, -2.5911e+00, -5.1917e-01, -1.3697e+00,\n","         -1.3256e+00,  9.9912e-01,  1.0602e+00,  3.3379e-01, -1.2799e+00,\n","         -1.6402e-01, -5.2318e-01, -2.6510e+00, -1.8900e+00, -1.8242e+00,\n","         -1.0578e+00,  1.0443e+01,  2.9064e-01, -2.5760e+00,  6.3340e-01,\n","         -5.0659e-01, -1.3572e+00, -1.4847e+00,  7.3731e+00, -3.0425e-01,\n","          2.9253e+00, -2.1132e+00, -1.1730e+00, -1.5551e-01, -1.2661e+00,\n","         -2.7169e+00, -2.5324e+00, -2.9978e-01,  2.2259e+00,  1.8033e+00,\n","         -2.3284e+00,  4.2268e-01,  1.8793e-01,  3.5335e-01, -2.5784e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([18, 40, 16, 46, 48, 48, 41, 19, 45, 34, 12, 38, 36, 32, 24, 26],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7090, 10.7953, -0.5956,  ..., -1.7241, -2.3104,  2.6685],\n","        [-0.0609,  4.8986, -0.3860,  ..., -0.7820, -0.7387,  3.3652],\n","        [ 5.8881, -3.5241,  1.5787,  ...,  6.1596,  1.0942, -1.5506],\n","        ...,\n","        [ 2.1171, -0.2013, -0.9516,  ..., -2.1077,  0.4965, -0.5957],\n","        [ 1.7353, 16.0853,  0.9936,  ..., -1.5814, -3.3756,  1.6498],\n","        [ 1.0403, -4.2477,  3.8793,  ..., -0.5226,  2.1559, -0.5767]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 35.1\n","Epoch 397/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.1017,  0.6615,  0.0833,  ..., 13.7495,  0.2155, -2.2422],\n","        [ 6.1281,  0.6259, -0.0419,  ...,  2.9143, -0.9677, -1.6300],\n","        [-1.2923, -2.8399, 16.8261,  ..., -2.4833, -1.1061, -0.9091],\n","        ...,\n","        [ 0.6769, -2.4575,  2.4635,  ...,  2.5242, -1.9729, -0.0186],\n","        [ 2.5231,  1.3373,  0.0878,  ..., -0.1957, -0.3141, -3.1280],\n","        [-2.5710, -0.1084,  0.4393,  ..., -3.8288, -1.8517,  0.1679]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([47, 24,  2, 11, 20, 24, 48, 15, 23, 20, 10, 25, 13,  2, 16,  7, 35, 32,\n","        10, 34, 12,  6, 28, 25, 14, 43,  3, 16, 37, 46, 44, 14, 27, 30,  5, 23,\n","        18, 25, 13, 17, 13,  1, 41, 31, 27, 10, 10,  9,  2,  8, 25, 25, 34, 13,\n","        15, 42, 37, 19, 20,  8,  7,  1, 11, 19, 49, 36, 22, 36, 12, 18, 39, 35,\n","        27, 41,  9, 23, 37, 11,  4,  3, 28,  0, 18, 26, 12, 37, 26,  9, 39, 10,\n","        38, 47, 34, 41, 44,  0, 15, 43,  4, 14, 42, 15, 13, 41,  9, 16, 22, 27,\n","        21,  2, 19, 38, 14, 29, 29, 11, 16, 16,  5, 40, 12, 46, 30, 32, 40, 35,\n","        19, 31], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.8991, -0.0095, -0.5959,  ..., -1.7057,  2.4153, -0.6160],\n","        [ 4.2335, -1.0633,  2.4830,  ...,  4.0253, -0.8428, -1.6740],\n","        [-1.7302, -0.6342,  0.6356,  ..., -1.1801,  0.0279,  0.6444],\n","        ...,\n","        [-1.7695, -1.7457, -1.0153,  ..., -1.7248, -1.4051, -1.1466],\n","        [-0.3814, -1.3233, -0.3512,  ..., -0.5373, -0.5997, -0.2055],\n","        [ 1.7298, -1.4432,  1.0445,  ...,  1.0169, -0.4016, -1.7986]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([42,  3,  4, 35,  8, 47,  1, 30, 44,  2,  9, 47,  9, 28, 16, 27, 38, 29,\n","         2, 29, 34,  0,  1,  4,  8, 39, 24, 44, 28, 30,  8, 36, 23, 16, 26, 46,\n","        44, 30,  3,  1, 41, 33, 16,  6, 18, 48, 17, 20,  1, 24,  3, 36, 40, 49,\n","        48, 36, 48, 20, 32,  0, 35, 27, 36, 48,  5, 15, 26,  9, 32, 49,  5,  5,\n","        15, 31,  6,  2, 29, 44, 40, 20, 17,  4, 21, 10, 14,  8, 33, 40,  7, 14,\n","        17, 45,  5, 43,  1, 21, 16,  3, 32, 40, 32, 27, 48,  5, 24, 28, 38,  0,\n","        46,  9, 22, 22, 31, 24, 31, 47, 10, 22,  4, 36, 49, 49, 49, 20, 47, 45,\n","        14, 30], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.6200, -2.7573, -1.5434,  ...,  0.3942, -2.5825, -2.1766],\n","        [-1.5173, -0.9678, -0.5874,  ..., -2.6104, -1.0947, -1.2745],\n","        [-2.1782, -2.4303,  0.5051,  ..., -3.4451, -1.7053, -0.3013],\n","        ...,\n","        [ 1.1306, -1.5403,  0.8766,  ...,  2.1918,  0.8832, -2.1439],\n","        [ 5.8918,  6.2405,  1.1130,  ...,  3.6550, -1.7470, -0.8318],\n","        [ 0.0874, -1.8237,  3.5376,  ...,  0.3055,  0.1476, -0.3240]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([32, 45, 28, 17, 12,  8, 37, 29, 23, 19,  6,  0, 45, 11,  0,  7, 36,  3,\n","        43, 13,  2, 49, 15, 33, 21, 31, 39, 34, 17,  9, 21, 41,  7,  7, 30, 37,\n","        29, 37, 46, 29, 41, 23, 12, 49, 30, 18, 34, 11, 24, 42, 13, 18,  4, 14,\n","        32, 40, 19, 21, 48, 37, 26, 26, 40,  1,  8, 45, 43, 11, 38, 14, 28,  7,\n","        23, 12, 45, 35, 17, 41,  6, 30, 27, 46,  2, 13,  3, 12, 33, 10, 45,  9,\n","        42, 31, 38, 16, 24, 20, 15,  0, 17, 29, 25, 35, 22, 19,  3, 18,  4, 33,\n","        35, 47, 36,  7, 43, 39, 28, 46, 17, 42, 17, 30, 10, 33, 11, 25, 19, 27,\n","        24,  6], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.7013e+00, -2.8526e+00, -2.1268e+00, -3.1288e+00,  4.0279e+00,\n","          8.3064e-02, -1.2750e+00,  1.5157e+00, -1.1397e+00,  3.5695e+00,\n","          4.2949e-01,  1.5984e+00,  5.3481e-01, -2.0660e+00, -1.7363e+00,\n","          9.9229e-01, -1.1008e+00, -1.1876e+00,  2.3692e+00, -1.1589e+00,\n","         -1.2986e+00,  3.0194e+00, -2.3587e+00, -1.9664e+00, -3.7992e-01,\n","         -1.2179e+00, -2.0294e+00, -6.1507e-01,  5.2454e+00,  2.6144e+00,\n","         -2.1167e+00,  1.7070e+00,  1.0006e+00, -1.8293e+00, -1.3275e+00,\n","         -6.6657e-01,  1.2002e-01,  9.6999e-01,  6.7034e-01, -1.4762e+00,\n","          2.3088e+00,  1.4084e+01, -1.4917e+00, -2.7522e+00,  2.6477e-01,\n","          2.3594e+00, -9.8328e-01, -1.7980e+00, -1.4713e+00,  2.3466e+00],\n","        [-3.2709e-01, -3.3769e-01, -1.3191e-01,  8.2820e-01,  9.3066e-01,\n","          1.8913e+00, -2.1023e+00, -2.3473e+00,  3.2092e+00,  1.7305e+00,\n","          1.2882e+00,  2.4825e-01, -5.5572e-01,  3.1075e+00,  4.5483e-01,\n","          4.1810e-01,  2.2648e-01, -2.7806e+00, -8.4328e-01, -3.5253e-01,\n","          3.0702e+00,  8.5661e-01, -3.5186e+00,  3.0430e+00, -3.0732e-01,\n","         -3.4030e+00, -2.1618e+00, -1.4525e+00, -3.0915e-01,  4.0396e-01,\n","         -1.8453e+00,  8.8365e+00,  5.3804e-01, -2.0887e+00,  3.0189e+00,\n","         -3.2360e+00, -2.8988e-01,  3.2950e+00,  3.1262e-02, -2.1923e+00,\n","         -5.8326e-02,  1.5554e+00, -2.6766e+00,  1.4458e+00, -3.2939e-01,\n","         -1.1646e+00,  4.6959e-02, -2.1906e+00, -2.2629e+00,  1.6742e+00],\n","        [ 7.8088e-01, -2.2819e+00,  5.2635e-01, -1.0079e+00,  8.4025e-01,\n","         -1.9503e+00, -4.9155e-01, -6.7580e-01, -5.6635e-01,  2.0454e+00,\n","         -1.0122e+00,  3.4729e-01,  1.2448e+01, -3.4797e+00, -1.1821e+00,\n","         -1.9120e+00, -2.5371e+00, -9.9776e-01, -1.3046e+00,  3.1990e-01,\n","         -1.5624e+00,  6.2875e-01,  1.1644e+00, -2.2288e+00, -2.9078e-01,\n","         -9.5104e-01, -2.7658e+00,  2.2621e+00,  4.1563e+00,  8.2567e-01,\n","          1.1797e+00, -1.5430e+00, -2.0769e-01, -3.3128e+00, -1.3587e+00,\n","          1.6805e+00, -1.0525e+00,  8.8138e-01,  2.3379e+00,  1.7019e+00,\n","          1.9734e+00,  1.9476e+00, -2.3065e-01, -8.1849e-01,  4.6513e-01,\n","          2.1185e+00,  7.1930e-01, -1.7616e+00, -2.6435e-01, -1.5375e+00],\n","        [ 2.9784e+00,  1.5595e+01, -5.6262e-01,  2.7900e+00,  2.0832e+00,\n","         -6.0953e-02, -1.7983e+00, -1.4786e+00,  1.9544e+00, -1.1411e+00,\n","         -2.0939e+00, -2.0585e+00, -1.1081e+00, -1.9244e+00, -1.6151e+00,\n","          5.2818e-02, -7.5733e-01, -4.4629e+00,  2.8696e-01, -2.2354e+00,\n","          1.9727e-01, -1.5278e+00, -2.7212e+00,  2.9065e+00,  2.4094e+00,\n","         -4.6340e+00, -2.0350e+00, -2.5106e+00, -8.1060e-01,  1.2984e+00,\n","         -1.3961e-01, -1.4877e+00, -9.7698e-01, -1.6711e+00,  7.3921e+00,\n","         -3.1595e+00,  2.0203e+00,  7.1773e+00,  3.0456e-02, -3.7379e+00,\n","          1.9137e+00, -1.0315e+00, -1.5182e+00,  6.2123e-01, -9.4805e-01,\n","         -1.8290e+00,  3.0252e+00, -2.9458e+00, -2.5011e+00,  3.6232e+00],\n","        [ 1.8650e+00, -2.3424e-01,  5.5477e-01,  3.8460e+00, -2.9361e+00,\n","         -5.3880e-01,  7.9373e-01, -2.8317e+00, -9.5111e-01, -3.9676e-01,\n","         -1.4316e+00,  2.4958e+00, -4.2133e+00,  7.1659e-01, -8.9836e-01,\n","         -7.0117e-03,  9.8280e-01,  9.5864e-01,  1.3435e-01,  3.3751e+00,\n","          1.6067e+00, -9.2057e-01, -2.4272e+00, -1.9862e+00,  3.7998e+00,\n","          3.3361e+00, -2.3699e+00, -1.0934e+00, -2.3033e+00, -3.3500e-01,\n","          2.0947e+00, -2.4874e+00, -4.9304e-01, -2.2008e+00, -1.3563e+00,\n","          2.1287e+00, -4.0884e-01, -2.1238e+00,  2.7038e+00,  1.3073e+00,\n","         -9.9673e-01, -2.0313e+00, -1.2452e+00,  5.9142e-01, -1.0400e+00,\n","         -2.6368e+00, -1.9073e-01,  1.2196e+01, -7.2757e-03, -6.2518e-01],\n","        [ 2.3096e+00,  2.1150e-01, -1.4826e-01,  6.6791e-01,  1.9311e-01,\n","         -2.2040e+00, -2.8490e+00, -2.0783e+00,  1.1802e+00,  3.3543e-01,\n","         -1.0780e+00, -4.0970e+00,  1.9642e+00, -9.1003e-01, -2.3331e+00,\n","         -1.0212e+00,  1.5751e+00,  4.4887e-01, -7.2018e-01,  1.0011e+00,\n","         -1.1887e-01, -1.7561e+00,  9.2457e+00,  2.2070e+00,  1.7285e+00,\n","          1.1231e+00, -2.6726e+00, -2.2426e+00,  5.2880e-01,  9.8403e-02,\n","         -5.0714e-01,  1.2330e-01,  2.7929e+00, -2.5278e+00, -5.6687e-01,\n","         -7.4412e-01, -5.7148e-01,  1.3467e+00,  1.9042e+00,  6.0850e-01,\n","          2.5416e+00,  5.1435e-01, -5.5587e-01,  2.2490e-02,  1.5232e-01,\n","         -4.8672e-01,  5.3446e-01, -2.5571e+00,  5.0191e-01, -1.9157e+00],\n","        [ 9.5054e-01, -1.4928e+00,  3.7144e+00,  3.3649e+00, -2.6945e+00,\n","          3.9049e+00, -1.1652e+00, -2.7224e+00, -2.3313e+00,  6.3386e-01,\n","          2.5995e-01, -5.8048e-01, -1.7752e+00, -2.2540e+00, -1.3908e+00,\n","         -2.2686e+00,  2.7155e+00,  1.4109e+00,  2.3809e-01,  2.0859e-01,\n","         -1.5591e+00, -3.7720e-02, -3.1734e+00, -3.4108e+00,  1.3854e+00,\n","         -1.9363e+00,  1.2074e+01, -7.9125e-01, -3.5347e+00,  2.2330e+00,\n","          4.0751e+00, -1.7101e+00,  3.5883e-01,  2.8342e+00, -4.7546e-01,\n","         -4.6225e-02, -3.6629e+00, -1.2555e+00,  1.8050e+00, -9.4016e-01,\n","          6.1098e-01, -2.8120e+00, -2.5462e+00,  1.9151e-01,  1.9059e+00,\n","         -2.7783e+00,  2.1980e+00, -1.2449e+00,  1.3152e+00,  5.5095e-01],\n","        [-1.5967e+00,  3.4372e-02,  2.9543e+00, -8.0134e-01, -1.6491e+00,\n","          3.3604e+00,  3.6212e+00, -1.4583e+00, -9.9031e-01, -1.2080e+00,\n","          1.3083e+00,  2.5090e-01, -2.0810e+00,  8.4545e-01, -1.7738e+00,\n","          5.9050e-01,  1.2229e+00,  6.0917e-01, -8.8116e-01,  1.7727e+00,\n","         -1.9360e+00, -1.3179e+00, -3.5314e+00, -1.3781e+00, -4.7692e-01,\n","         -1.4872e+00,  1.8024e+00, -1.6729e+00, -8.2561e-01,  1.0152e+00,\n","          1.6606e+00, -2.0061e+00,  8.3870e-01,  1.2536e+01,  1.2049e+00,\n","          3.8651e-01, -2.0753e+00,  1.3265e-01, -1.4274e+00, -1.0142e+00,\n","         -1.5450e+00, -2.9039e+00, -1.4923e+00,  2.5407e+00,  1.3402e+00,\n","         -1.5099e+00,  3.1461e+00, -2.2158e+00, -4.1089e-01, -1.2690e+00],\n","        [ 2.0528e+00, -1.6001e+00, -5.6134e-01,  8.3895e-01, -1.1792e+00,\n","         -1.3594e+00, -1.6376e+00, -1.7815e+00, -2.1403e+00,  9.1107e-02,\n","         -1.1247e+00, -1.5949e-01,  8.8377e-01,  7.0791e-01,  1.0355e+00,\n","         -4.2264e-01,  1.5104e+00,  1.1848e+00, -1.0915e+00,  3.2645e-01,\n","          2.4585e-01,  2.6453e-02,  9.8364e+00, -8.3699e-01,  2.4595e+00,\n","          3.0316e+00, -2.4615e+00, -3.3278e+00, -8.6937e-01,  9.6959e-01,\n","          6.6723e-01, -1.2310e+00,  5.3980e+00, -2.2624e+00, -2.9702e+00,\n","         -2.7271e-02, -1.2161e+00, -1.8611e+00,  2.5840e+00,  2.7274e+00,\n","          1.1691e+00, -5.1258e-01, -2.6771e+00, -1.1679e+00, -5.0721e-01,\n","         -2.2655e-03, -1.0780e+00, -2.3097e-01, -8.3316e-01, -2.6325e+00],\n","        [-1.9692e-01, -3.0403e+00,  8.8018e-01, -6.9620e-01, -6.5616e-01,\n","         -8.9257e-01, -3.2707e-01, -9.5336e-01, -1.9575e+00,  7.9913e-01,\n","         -1.5650e+00,  1.5937e+00, -1.2429e+00, -1.8229e+00,  9.2598e-02,\n","         -2.0728e-01,  6.8011e-01,  2.6162e+00, -3.9399e-01,  8.6197e-01,\n","          3.9260e-02, -9.7786e-01,  1.1811e+00, -2.1843e+00,  1.3119e+00,\n","          1.2421e+01, -2.9176e+00, -6.6323e-01, -1.4346e+00,  2.2208e+00,\n","          1.2279e-01, -1.5360e+00,  2.8759e+00, -1.9486e+00, -2.7416e+00,\n","          1.1731e+00, -4.7174e-01, -3.2264e+00,  1.5322e+00,  1.4889e+00,\n","         -1.5816e+00, -1.0487e+00, -2.2351e+00,  1.2947e-01,  2.0066e+00,\n","         -9.8673e-01, -1.6403e+00,  3.2333e+00, -1.4426e-01, -1.1850e+00],\n","        [ 2.0285e+00, -1.3015e+00,  2.6529e+00,  1.4378e+00, -1.2951e+00,\n","          5.3858e-02,  1.1501e+01, -1.8045e+00, -2.4531e-02, -3.3451e+00,\n","          4.6665e-01,  4.4419e-01, -2.0572e+00, -6.7919e-01, -1.1508e+00,\n","         -1.6398e+00,  2.1171e-01,  2.7542e+00, -2.0913e+00,  1.8437e+00,\n","          1.4099e+00, -1.9141e+00, -1.6357e+00, -8.5447e-01,  1.3711e+00,\n","         -2.7227e-01,  5.4412e-01, -1.3900e+00, -2.3620e+00, -1.2136e+00,\n","          2.1769e+00, -2.9278e+00, -1.9504e+00,  1.6546e+00, -1.6413e+00,\n","          5.0247e+00,  1.0147e+00, -2.5638e+00,  5.1436e-01,  1.7539e+00,\n","         -2.1280e+00, -1.2779e+00, -1.0260e+00,  1.6036e+00, -3.0551e-01,\n","         -2.6532e+00, -9.4477e-01,  1.7245e+00,  1.1753e+00, -4.5824e-02],\n","        [ 1.8743e-01, -2.7231e+00,  1.9335e+00, -2.3847e+00, -1.1043e+00,\n","          9.6566e-01,  7.9005e-01, -2.9965e+00, -3.2009e-01, -2.2702e-01,\n","         -1.6987e+00,  1.2464e+00, -9.8452e-01,  2.8500e+00, -2.7677e-01,\n","         -1.2367e+00, -6.6718e-01,  5.0651e-01,  3.7025e+00, -3.9784e-01,\n","          1.1268e+01, -2.3206e-02, -1.7026e+00,  1.4601e+00, -3.4555e-02,\n","          7.7533e-01, -3.4812e+00,  7.9825e-01, -4.7524e-01, -2.2101e-01,\n","          2.5296e+00, -2.8102e-01,  4.5458e-01, -2.9425e+00, -2.3286e+00,\n","         -3.5597e-01,  4.0002e+00, -9.5402e-01,  6.9433e-01, -9.2493e-02,\n","         -4.6549e-01,  1.2353e+00, -1.0045e+00,  1.7585e+00, -6.9240e-01,\n","         -2.0800e+00, -3.0842e+00,  2.2769e-01, -9.5072e-01,  1.4465e+00],\n","        [-6.2279e-01, -3.0769e+00,  3.2028e+00, -1.8995e+00, -1.3432e+00,\n","          2.4326e+00, -2.5814e+00, -9.9007e-01, -2.3878e+00,  2.1437e+00,\n","         -8.4895e-01,  2.5451e+00,  1.1529e+00, -4.3374e+00,  6.0313e-01,\n","          5.7919e-01,  8.0712e-01, -6.0771e-01,  1.7283e+00,  4.0453e-01,\n","         -1.9340e+00,  1.5865e+00, -9.6166e-01, -2.0334e+00, -7.0156e-01,\n","          1.0159e-01, -1.2261e+00,  1.3216e+01, -1.2698e+00,  1.1256e+00,\n","         -1.2194e+00,  3.7694e-01,  1.5962e+00, -2.8421e+00, -1.3615e+00,\n","          1.1956e+00, -1.2482e+00, -1.4288e+00,  3.7712e-01, -3.4742e-01,\n","          9.6711e-01,  1.6351e+00, -1.7827e+00, -7.9761e-01,  7.1172e-01,\n","         -2.5368e+00, -1.0644e+00, -4.6841e-01,  1.1270e+00,  6.3047e-01],\n","        [ 2.3169e+00, -2.7317e+00,  3.0243e+00, -1.2593e+00, -2.8912e+00,\n","          3.6334e+00,  1.5168e+00, -1.9537e-01, -2.5047e-01, -3.0910e+00,\n","         -2.2280e-01,  3.1229e+00, -1.0518e+00, -2.0689e+00,  1.6488e+00,\n","         -1.8049e+00,  2.1000e+00,  9.5329e-01, -2.5551e-01, -1.2620e+00,\n","         -8.1797e-01,  2.0628e+00, -4.3204e+00, -3.9421e+00, -1.2131e+00,\n","         -2.0578e+00,  1.1432e+01,  2.1363e-01, -3.4129e+00,  1.6632e+00,\n","          3.1885e-01, -2.0668e+00,  4.3814e-01,  1.9733e+00, -2.0491e+00,\n","          2.0089e+00, -1.3273e+00, -1.5617e+00,  2.7360e+00, -6.7974e-01,\n","         -8.9788e-01, -1.1165e+00, -8.1327e-01,  2.2712e+00,  3.1149e+00,\n","         -2.5201e+00, -7.5295e-01,  2.7304e-01,  2.4819e+00,  1.3873e+00],\n","        [ 8.0469e-01,  1.4554e-01, -1.4036e+00, -6.8477e-01, -5.1366e-01,\n","         -1.3438e+00, -1.9948e+00,  1.0261e-01,  2.3021e+00, -6.3851e-02,\n","          4.4305e+00, -6.2661e-01,  4.5876e-01, -9.0688e-01, -6.5098e-01,\n","         -1.2152e+00, -1.3594e+00,  1.9032e+00, -1.6294e+00, -1.1391e+00,\n","         -4.7038e-01,  1.5419e+00,  4.3402e-01, -1.3017e+00, -1.4966e+00,\n","         -2.1260e+00, -7.9762e-01, -1.1907e+00, -1.7365e-01, -4.1559e-01,\n","         -1.7215e+00, -1.9875e+00, -4.8661e-01, -1.2439e+00, -6.4170e-01,\n","         -2.0835e+00, -4.7897e-01,  2.9056e+00,  1.3735e-01,  2.0684e-01,\n","          9.4315e-01, -1.5759e+00,  1.2353e+01,  2.1205e+00,  1.2430e+00,\n","         -2.0167e+00,  2.1873e+00, -1.0671e+00,  3.7946e+00, -7.1435e-01],\n","        [-1.9029e+00,  3.6912e-01,  5.7510e-01,  1.3990e+00,  7.0238e-01,\n","          3.3002e-01, -3.0978e+00, -2.9480e+00,  2.5294e+00,  1.2056e+00,\n","          7.5286e-01,  3.9699e-01, -9.2755e-01,  3.6144e+00, -5.1049e-01,\n","         -3.4628e-01, -9.0708e-02, -3.2267e+00,  1.1806e+00,  8.0716e-02,\n","          3.2813e+00,  4.6533e-01, -3.0874e+00,  3.9681e+00,  4.6109e-01,\n","         -4.2155e+00, -1.7172e+00, -2.3101e+00, -1.2362e+00,  2.6608e-01,\n","         -2.2447e+00,  1.1738e+01,  1.2282e+00, -2.4350e+00,  2.4921e+00,\n","         -3.9308e+00,  1.4196e+00,  2.6411e+00,  8.1319e-01, -1.2190e+00,\n","          4.2837e-01,  7.1029e-01, -1.5704e+00,  1.1592e+00, -4.4240e-01,\n","         -1.2539e+00,  2.5488e-01, -2.3591e+00, -2.8898e+00,  8.5633e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([41, 31, 12,  1, 47, 22, 26, 33, 22, 25,  6, 20, 27, 26, 42, 31],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.6997, 10.7605, -0.6052,  ..., -1.7332, -2.3109,  2.7045],\n","        [-0.0688,  4.8728, -0.3881,  ..., -0.7859, -0.7360,  3.3824],\n","        [ 5.8726, -3.5194,  1.5893,  ...,  6.1444,  1.0926, -1.5423],\n","        ...,\n","        [ 2.1092, -0.2078, -0.9507,  ..., -2.1086,  0.4907, -0.5919],\n","        [ 1.7410, 16.1044,  0.9972,  ..., -1.5981, -3.3837,  1.6881],\n","        [ 1.0311, -4.2459,  3.8836,  ..., -0.5241,  2.1478, -0.5644]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 398/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.9848, -1.4572,  4.2523,  ..., -1.5189,  0.8094, -1.2050],\n","        [ 2.2877, 14.8009,  0.1160,  ..., -1.3855, -2.7491,  0.6664],\n","        [-2.4690, -0.0590,  2.6056,  ..., -1.4165, -0.4382,  0.5453],\n","        ...,\n","        [ 1.2788, -1.2061,  1.3065,  ...,  1.9436,  1.8372, -0.5307],\n","        [-0.6921, -1.1411,  0.9418,  ..., -0.7405,  0.6036, -1.8108],\n","        [ 2.1498, -3.4038, -1.0094,  ...,  1.0015,  2.0970, -2.6515]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([33,  1, 40, 36, 35, 24, 38, 16, 22, 29,  3, 35, 24, 14, 22, 12, 28, 42,\n","         5, 32, 10,  8, 38, 20,  3, 22, 28, 19, 45, 18, 44, 14, 31,  3,  5, 43,\n","        37, 15, 27, 11, 18, 38, 20, 14, 49, 18,  4, 30,  0, 49, 37, 30, 36, 37,\n","         9,  9, 30, 20,  6, 12,  9, 47,  8, 32, 24, 30, 47,  1, 48, 25, 17, 22,\n","        24, 19, 21, 31, 19, 43, 42,  8, 12, 26,  8, 33, 37, 23, 11, 19, 43, 45,\n","        20, 22, 39, 21,  7,  0, 38, 36, 16, 14, 28, 19, 17, 11,  8, 43,  0,  6,\n","         3, 49, 12, 10, 43, 17, 24, 31,  1,  5,  7, 27, 11, 33, 46, 32, 19,  6,\n","        17, 39], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.6002, -2.1957, -0.8138,  ..., -0.4379, -0.3495, -0.4124],\n","        [-1.8664,  0.2729, -0.8509,  ...,  0.7387, -3.7687,  1.9794],\n","        [ 1.8696, -2.9828,  2.8817,  ...,  2.6181, -1.0465, -1.6540],\n","        ...,\n","        [ 6.4911,  2.0479,  1.2447,  ...,  4.9190, -0.5680, -0.7431],\n","        [-0.0263, -3.6233,  4.1586,  ...,  5.0318, -1.3652, -0.1440],\n","        [ 0.7925, -1.3516,  2.1741,  ...,  1.5199,  0.3710, -0.7795]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([32, 15, 35, 26, 28,  9,  8, 29, 12,  2, 37,  3, 28, 31, 23, 29, 29, 30,\n","        36, 34, 16, 35, 15, 46, 21, 44,  4, 40, 45,  0, 27, 36, 31, 13, 22, 35,\n","        13, 11, 16, 18,  5, 41, 48,  1,  2,  9,  7, 29, 10, 16, 36, 40, 10, 16,\n","        41, 27, 21, 32, 11, 23,  7, 38, 11, 14, 20,  3, 27,  9,  5, 30, 25, 46,\n","        34,  1, 31, 39, 25, 30, 27, 15, 15,  0, 49, 17, 40, 28, 28,  0,  4, 44,\n","        10, 26, 48, 33, 21, 47,  2,  0, 25, 34,  2,  1, 29, 22, 31, 45, 41, 46,\n","         6, 17, 40,  2,  0, 37, 49, 34,  7,  8, 32,  8, 42, 27, 25,  2, 15, 24,\n","        11,  6], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.6074, -3.0088,  4.5239,  ...,  2.2836, -1.1218,  0.2495],\n","        [ 0.2863, -1.6991,  0.1038,  ..., -0.2858,  1.1138, -1.8564],\n","        [ 5.7564,  3.1690,  0.9236,  ...,  2.2501, -1.9616, -2.4399],\n","        ...,\n","        [-2.2166, -4.3655,  0.3219,  ..., -2.8450,  3.9682,  3.0981],\n","        [-3.2973,  0.9389, -1.0592,  ..., -2.4143, -2.9868,  1.1594],\n","        [ 1.2604, -0.6070,  1.5203,  ...,  1.9100,  1.3075, -0.6920]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([35, 17, 24, 15, 30, 41, 12, 19, 28, 48,  1, 32, 48, 16, 33,  4, 10, 41,\n","        44,  6, 33, 25,  2, 36, 38, 22, 31, 23, 30, 14, 40, 18, 10, 36, 45, 44,\n","         5, 23, 29, 48, 13, 49, 27, 16, 26,  3,  9, 47, 49, 41,  2, 42, 47, 17,\n","         7, 47, 24, 42, 32, 46, 43, 27, 31, 17, 45, 34, 13,  5, 14, 23, 26, 23,\n","        45, 46, 36, 14, 19, 30, 14,  4, 47, 13, 41,  1, 35, 47,  4, 37,  7, 46,\n","        40,  7, 41, 20, 39, 20,  3, 34,  4, 16, 12, 29,  1, 25, 48, 27, 29, 26,\n","        42,  2, 18, 10, 13, 25, 26, 41, 40,  3, 26, 16, 15, 33, 20,  4, 24, 44,\n","        13,  6], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0410e-02, -8.3120e-01,  4.3939e-01, -1.1251e+00,  1.8173e+00,\n","         -2.9832e+00, -1.4875e+00, -7.0278e-01,  7.8767e-01,  2.3941e-01,\n","         -1.4607e+00, -5.6922e-01,  1.0125e+01, -1.6131e+00,  3.1969e-01,\n","         -1.6170e+00, -2.2590e+00, -1.7570e+00, -7.7394e-01, -1.5705e+00,\n","         -1.0708e+00,  6.0227e-01,  6.0441e+00, -9.2673e-01, -1.5750e+00,\n","         -9.0476e-01, -2.7134e+00, -2.8947e-01,  2.6487e+00, -7.3755e-01,\n","         -9.1360e-01, -2.2412e-01,  2.9336e+00, -2.6165e+00, -1.1922e+00,\n","          4.5800e-01,  3.2066e-01,  4.9065e-01,  2.0428e+00,  9.4790e-01,\n","          2.8932e+00,  2.0047e+00, -4.3023e-01,  1.7087e-01, -1.4750e+00,\n","          1.3000e+00, -5.5479e-01, -1.3717e+00, -1.7278e-01, -1.2464e+00],\n","        [ 3.2551e+00,  1.9950e+00, -9.7128e-01, -5.6136e-01, -2.5041e+00,\n","          1.1896e+00,  3.2569e-02, -8.1774e-01,  3.2937e+00, -2.5172e+00,\n","          6.6833e+00, -2.5287e-01, -6.1580e-01, -1.6898e+00, -1.5326e+00,\n","         -1.9712e+00, -2.0664e+00,  2.0870e+00, -3.6487e+00, -2.2716e+00,\n","          7.6875e-01, -1.1491e+00, -9.1290e-04, -1.4376e+00, -2.1376e+00,\n","         -1.9049e+00,  5.6174e-01, -8.7614e-01, -1.4677e+00, -4.0362e-02,\n","         -9.6867e-01, -3.0350e+00, -1.6948e-01,  1.8833e+00, -3.2231e-01,\n","         -3.1536e+00,  1.3315e+00, -5.0025e-02,  4.3522e-01, -1.3317e+00,\n","          1.8009e-01, -2.1219e+00,  1.0490e+01,  6.4976e+00,  2.6824e+00,\n","         -1.8574e+00,  2.1954e+00, -1.8842e+00,  5.2526e+00, -1.7553e+00],\n","        [ 2.1884e+00,  4.6588e-01,  4.4290e-01,  8.2601e-01, -2.2176e+00,\n","         -1.6240e+00,  1.7925e+00, -1.2734e+00, -1.1232e+00, -1.0820e+00,\n","          4.7909e+00, -6.2948e-01, -2.4905e+00, -1.2321e+00, -2.2561e+00,\n","         -2.2140e+00,  1.7077e-01,  1.2906e+01, -1.2406e+00,  2.4695e+00,\n","         -9.7844e-01, -2.4401e+00, -4.8169e-01, -2.3936e+00,  7.3377e-01,\n","          2.0233e+00, -6.2171e-01, -1.7565e+00, -9.2417e-01,  4.1780e-01,\n","          1.5175e+00, -2.2781e+00, -5.0536e-01,  4.5016e-01, -2.3127e+00,\n","         -5.2209e-01,  1.8238e-01, -2.1195e+00,  7.7571e-01,  9.5359e-01,\n","         -9.4358e-01, -1.9481e+00,  1.9829e+00,  4.2995e-01,  1.5880e+00,\n","         -1.2956e+00,  3.3115e+00, -7.7277e-01,  1.9179e+00, -2.0779e+00],\n","        [-1.5529e+00, -3.4930e-01,  7.6243e-01,  2.0286e-01,  5.5444e-01,\n","         -3.8488e-01, -1.3571e+00, -1.0143e+00, -1.3993e+00,  7.3073e+00,\n","         -2.6420e-01,  1.7586e+00, -6.3568e-01, -2.4707e+00, -2.8642e+00,\n","         -1.5583e+00,  6.0076e-01,  2.0124e+00, -2.5831e-01,  1.7863e+00,\n","         -8.5422e-01, -1.6751e+00, -5.0305e-01, -1.6708e+00,  1.5623e+00,\n","          2.1862e+00, -1.3938e+00, -5.7858e-01,  7.6188e-01,  2.2283e+00,\n","          1.1960e+00,  1.8289e+00,  1.1959e+00, -5.7591e-01, -1.1987e+00,\n","         -1.4770e+00, -1.2638e+00, -2.1035e+00,  9.7605e-01, -1.3018e+00,\n","         -2.4373e-01,  2.2414e+00, -1.9866e+00, -1.4118e+00,  1.7697e+00,\n","          9.2708e-01,  9.9650e-01, -4.0182e-01, -2.9484e-01, -6.9706e-01],\n","        [-1.1910e+00,  9.5395e-01, -8.1782e-01, -9.6915e-01, -1.7197e+00,\n","          2.9370e-01,  3.3411e+00, -4.5324e+00,  3.0456e+00, -3.2502e+00,\n","         -2.0966e+00,  1.4735e+00, -4.1901e+00,  1.4496e+01, -1.5334e+00,\n","          2.7866e+00,  1.2820e-01, -1.5351e+00,  1.1137e+00,  2.2517e+00,\n","          4.6451e+00, -6.5392e-01, -1.9218e+00,  3.7911e+00,  1.4616e+00,\n","         -6.6718e-01, -2.7127e+00, -4.1081e+00, -1.6855e+00,  2.8237e+00,\n","         -1.3945e+00,  3.4492e+00,  2.1691e+00,  1.4354e+00,  6.2551e-01,\n","         -3.1881e-01,  2.6485e+00, -1.9127e+00, -4.9058e-01, -1.0265e+00,\n","         -3.0292e+00, -1.0495e+00, -3.6140e+00,  3.3634e+00, -1.1538e+00,\n","         -2.2200e+00, -2.6334e+00,  6.0228e-02, -4.5070e+00, -1.4650e-01],\n","        [ 1.1088e+00,  1.0092e+00,  1.4650e+00,  1.1248e+00, -3.0044e-01,\n","         -1.4912e+00,  8.3592e-01, -1.5611e+00, -7.8786e-01, -7.0490e-01,\n","         -2.2496e+00,  1.4443e+00, -1.2523e+00, -9.0523e-01, -1.0139e+00,\n","         -5.5176e-01,  2.1660e-01, -2.0877e+00,  3.7674e+00, -4.3809e-01,\n","          1.3337e+00,  9.3303e+00, -3.9815e-01,  4.3928e-01,  2.1515e+00,\n","          6.3679e-01,  2.8027e-01,  1.7009e+00, -3.3933e+00,  2.4175e+00,\n","         -1.2919e+00, -2.0471e+00,  1.2740e+00, -1.7709e+00, -7.7180e-01,\n","         -8.2649e-01, -1.1499e+00, -3.2640e-01,  2.3377e+00,  2.0646e-01,\n","         -1.4959e+00, -9.0569e-02, -1.0385e+00, -2.9433e-01, -1.8571e+00,\n","         -1.3546e+00, -1.7140e+00,  1.0550e+00, -8.8379e-01,  9.9675e-01],\n","        [-7.1757e-01, -1.9931e+00,  1.5269e+00, -2.2113e+00, -1.2410e+00,\n","          1.5489e-01, -2.4723e-01,  1.3971e+00, -1.3917e+00, -8.6073e-01,\n","          4.4454e-02,  1.8432e+00,  9.1815e+00, -2.1825e+00,  3.6490e+00,\n","         -1.1474e+00, -1.9107e+00,  2.2706e+00, -1.3375e+00, -1.8419e+00,\n","         -9.1146e-01,  2.2212e-01,  2.4798e-01, -3.0933e+00, -2.0181e+00,\n","         -2.5704e-01, -4.2988e-02,  1.0417e+00,  3.1497e+00, -3.3348e-01,\n","         -5.6828e-01, -6.5996e-01,  1.7644e+00, -1.6879e+00, -2.6045e+00,\n","          1.2197e+00, -5.8788e-01, -7.0346e-01,  6.4622e-01, -8.3213e-01,\n","          2.3299e+00,  8.2658e-01,  4.3851e-01, -6.7670e-02,  3.6421e+00,\n","         -1.2186e+00,  4.1141e-01, -1.6105e+00, -8.8898e-01, -8.5529e-01],\n","        [-8.5442e-01,  2.9981e+00, -1.9134e+00, -1.0460e+00,  1.8534e+00,\n","          2.1866e+00, -1.2186e+00, -1.8015e-01,  3.9415e+00, -1.9230e+00,\n","         -6.1817e-01, -3.4847e+00, -1.0162e+00, -1.9338e-01, -7.5839e-01,\n","          1.6644e-01,  3.6117e-01, -2.5934e+00, -5.0357e-01, -2.0384e+00,\n","         -1.1465e+00, -6.5151e-01, -1.8400e+00,  2.5926e+00, -2.2662e+00,\n","         -2.9797e+00, -4.8758e-01, -2.2255e-01,  2.5230e-01, -4.0827e-01,\n","          3.1402e-02,  3.1097e+00,  1.3631e+00,  7.1367e-01,  6.2974e+00,\n","         -2.9756e+00, -1.6435e+00,  1.2715e+01, -2.9025e+00, -3.9260e+00,\n","          5.1767e+00,  2.3483e+00, -1.7799e+00,  1.2108e+00,  6.6693e-02,\n","         -7.4817e-01,  5.8355e-01, -3.4046e+00, -1.2363e+00,  4.5679e-01],\n","        [-1.4613e+00,  1.4746e+00,  1.2767e+00, -7.6317e-01,  1.0777e+00,\n","         -1.2458e+00, -9.2926e-01, -1.3440e+00,  1.3629e+00,  1.2253e+00,\n","         -1.0106e+00, -1.6597e+00, -8.2559e-01, -2.9318e-01, -4.1060e-01,\n","         -2.3583e+00, -6.5987e-01, -7.0880e-01,  1.0440e+01,  2.1928e+00,\n","         -3.4852e-01,  2.3671e+00, -1.5071e+00,  8.7503e-01,  2.3026e+00,\n","         -9.6047e-01,  7.1253e-01,  3.3713e-02, -8.7135e-01, -1.4687e+00,\n","          5.0631e-01,  1.7747e-01,  4.9749e-01, -1.4978e+00, -3.4706e-01,\n","         -1.8153e+00, -5.9016e-01,  4.4216e-01,  2.7621e-01, -1.6457e+00,\n","          3.4946e-01,  1.7902e-02, -4.8041e-02, -1.4058e+00,  1.0361e+00,\n","          1.1382e-01, -4.6132e-02, -1.3102e+00, -4.4131e-01, -3.5623e-01],\n","        [-2.6839e-01, -3.8137e+00,  2.1832e+00, -1.0613e+00, -2.6540e+00,\n","          6.1303e-01,  3.0349e+00, -1.9507e+00, -2.9821e+00, -3.6382e+00,\n","         -1.2856e+00,  3.2092e+00, -2.3422e+00, -1.5243e+00,  3.1457e+00,\n","         -2.0375e+00,  3.6887e+00,  1.3151e+00, -9.1021e-01, -1.0699e+00,\n","          1.6874e+00, -9.5642e-01,  1.0932e-01, -3.0554e+00, -5.6766e-01,\n","          2.4353e+00,  6.7744e-01,  1.5630e-01, -1.1735e+00, -2.1937e+00,\n","          4.7371e+00, -1.7156e+00,  2.3492e+00,  3.0135e+00, -1.9439e+00,\n","          1.1260e+01, -4.1236e-01, -2.8165e+00,  2.6054e+00,  5.9418e-01,\n","         -2.3836e+00, -8.1624e-01, -2.8788e+00,  5.1593e-01,  1.3983e+00,\n","         -4.1377e+00,  1.8254e-01,  4.7483e+00, -1.4180e-01, -8.9923e-01],\n","        [ 1.3945e+00, -4.4392e-01, -2.5732e-01,  1.0154e+00, -3.5924e-01,\n","          2.7636e+00, -1.1323e+00, -4.3959e+00,  9.1349e-01, -1.3648e+00,\n","         -1.7782e+00, -2.6398e+00, -6.9815e-01,  2.2902e+00,  8.5575e-01,\n","         -5.4420e-01, -2.2907e+00, -2.6970e+00,  4.4155e-01, -2.5878e+00,\n","          1.2321e+01, -1.4843e+00, -2.0198e+00,  5.5948e+00, -7.1574e-01,\n","         -1.9957e+00,  8.8219e-01, -1.9439e+00, -2.4172e+00,  3.2906e+00,\n","         -7.3845e-01,  4.3399e+00, -7.0836e-01, -2.1453e+00,  2.5118e-01,\n","         -1.9908e-01,  1.7893e+00,  2.3535e+00, -7.9524e-03, -1.4183e+00,\n","          4.0691e-01, -7.3165e-01, -7.0007e-02,  2.9485e+00, -3.0819e-01,\n","         -3.2230e+00, -1.7542e+00, -1.8637e+00,  9.2232e-01,  1.7779e+00],\n","        [ 1.3724e+00, -3.4498e+00,  3.5413e+00, -1.9489e+00, -2.9478e+00,\n","          3.9254e+00, -1.0487e-02, -7.2277e-01, -2.1486e+00, -5.3449e-01,\n","          9.0967e+00,  4.8044e+00, -1.6547e-01, -2.0497e+00,  1.2890e+00,\n","          1.0043e+00,  8.4042e-01,  3.9190e-02, -2.9555e+00, -1.5092e+00,\n","         -5.3253e-01,  3.0874e-01, -3.0123e+00, -2.9807e+00, -5.8244e-01,\n","         -7.7555e-02,  1.0695e+00,  3.2996e+00,  4.3358e-01, -1.2176e-01,\n","          1.0438e-01,  2.0216e+00, -1.2254e-01, -1.5906e+00, -1.9432e+00,\n","          8.0209e-01, -7.5608e-01, -1.2366e+00,  1.0629e+00, -1.1724e+00,\n","         -1.8126e+00,  1.5261e+00, -1.1107e+00,  1.0065e+00,  1.1945e+00,\n","         -2.3881e+00, -9.4250e-01,  2.0598e+00,  3.3776e-01, -3.9721e-01],\n","        [ 2.8004e+00, -3.2943e+00,  3.7296e+00,  5.2355e+00, -1.6961e+00,\n","         -2.2024e+00,  2.4380e+00, -3.2087e+00, -2.1017e+00, -3.3215e+00,\n","         -2.8637e+00,  2.7397e+00, -3.1505e+00, -1.0548e+00, -1.3223e+00,\n","         -2.1291e+00,  4.9344e+00, -3.3420e-01, -2.0192e+00,  4.9447e+00,\n","          1.1115e+00, -4.9471e-01, -1.1633e-01, -1.1383e+00,  4.3597e+00,\n","          3.8114e+00, -3.6925e-01, -1.6687e+00, -2.7197e+00, -1.2670e+00,\n","          2.2009e+00, -2.5603e+00, -7.2585e-01,  1.0672e+00, -2.1043e+00,\n","          2.6948e+00, -1.5332e+00, -3.9200e+00,  5.3871e+00,  1.1362e+01,\n","         -3.4331e+00, -1.1560e+00, -3.6613e+00, -1.0613e+00, -2.6680e+00,\n","         -2.1581e+00, -1.9575e+00,  3.6033e+00,  6.6892e-01, -1.9768e+00],\n","        [ 8.8881e-01, -1.6816e+00,  2.5643e+00, -3.8503e-01, -4.4629e-01,\n","          1.9337e+00, -2.1528e+00, -2.9442e+00, -2.5260e+00,  9.3631e+00,\n","         -2.0034e-01,  3.2733e-01, -1.3451e+00, -5.0994e+00, -2.6781e+00,\n","         -1.3652e+00,  6.8375e-01, -1.9707e+00,  1.0966e+00, -7.3177e-01,\n","          3.6996e-01, -1.4025e-01,  1.7783e+00, -1.6637e+00,  4.4403e+00,\n","          6.9416e-01,  1.2396e-01,  2.8735e+00, -1.7697e+00,  1.2807e+00,\n","          1.6410e-01,  1.3291e+00,  5.7517e-01, -2.3544e+00, -1.8253e+00,\n","         -1.2372e+00, -5.8660e-01, -2.0089e-01,  1.0042e+00, -1.1405e+00,\n","          3.9159e+00,  3.1019e+00, -1.6342e+00, -2.5954e+00,  5.4044e-01,\n","         -1.9139e+00,  5.8165e-01,  7.1853e-01,  7.8220e-01, -1.8951e+00],\n","        [ 1.1709e-01, -3.7855e-01,  1.0661e+00,  1.2269e+00, -1.0871e+00,\n","          2.6988e+00, -3.1025e+00, -2.3555e+00, -2.7495e+00,  7.7742e+00,\n","         -3.9562e-01,  6.9880e-01,  6.2112e-01, -3.5179e+00, -8.9887e-01,\n","         -1.1267e+00, -6.8721e-02, -2.2740e+00,  9.6735e-01, -7.3203e-01,\n","         -1.3225e+00, -2.5169e+00, -3.1805e-01, -1.9414e+00,  4.5194e+00,\n","         -1.1344e+00,  6.8786e-01, -1.2978e-01,  1.2087e+00,  3.3359e+00,\n","          1.9613e+00,  3.1305e+00,  2.0227e+00, -2.2331e+00,  7.2377e-01,\n","         -1.2819e+00, -3.7156e-01,  1.0261e+00,  1.9240e-01, -3.2022e+00,\n","          1.6644e+00,  2.3357e+00, -2.8181e+00, -2.0852e+00,  2.6718e+00,\n","          7.0869e-02,  1.1129e+00, -8.2237e-01, -2.0732e+00,  8.1619e-01],\n","        [-1.1416e+00,  2.8940e+00,  8.0852e-01,  3.4065e-01,  3.3130e+00,\n","          1.1339e+00, -1.4857e+00,  7.2083e-01,  1.0797e+00, -3.6207e+00,\n","         -3.2728e+00,  3.1016e-01, -1.6826e+00, -9.6610e-01, -1.5278e+00,\n","          5.5935e+00,  7.7442e-01, -3.4077e+00, -2.5696e+00, -5.8725e-01,\n","         -2.9914e-01, -3.0105e-01, -2.9182e+00,  6.5795e-01, -1.0591e+00,\n","         -2.8777e+00, -1.1327e+00, -8.7047e-01, -5.0215e-01,  4.4348e+00,\n","         -2.1252e+00, -1.7977e-01,  7.7968e-01, -1.7567e+00,  3.2778e+00,\n","         -1.1842e+00,  1.4164e+00,  1.7021e+00,  1.5855e+00, -1.7251e+00,\n","          1.6082e+00,  1.1534e+00, -3.5371e+00,  2.1580e+00, -1.2874e+00,\n","          2.8171e-01, -3.0965e-01, -2.1174e+00, -2.6869e+00,  1.3343e+01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([12, 42, 17,  9, 13, 21, 12, 37, 18, 35, 20, 10, 39,  9,  9, 49],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7111, 10.7585, -0.6044,  ..., -1.7314, -2.3060,  2.6919],\n","        [-0.0624,  4.8695, -0.3923,  ..., -0.7841, -0.7309,  3.3695],\n","        [ 5.8856, -3.5145,  1.5984,  ...,  6.1352,  1.0922, -1.5442],\n","        ...,\n","        [ 2.1119, -0.2048, -0.9484,  ..., -2.1124,  0.4885, -0.5929],\n","        [ 1.7585, 16.1177,  0.9979,  ..., -1.5962, -3.3818,  1.6829],\n","        [ 1.0585, -4.2478,  3.8885,  ..., -0.5264,  2.1617, -0.5534]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Epoch 399/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.7080,  2.9036,  2.1208,  ...,  4.6754, -0.5803, -1.9668],\n","        [-4.3226, -1.3999,  1.0452,  ..., -3.3694, -2.6988, -0.7722],\n","        [-3.5805, -0.3295, -2.1925,  ..., -2.4222, -2.3185,  6.6445],\n","        ...,\n","        [ 0.2142, -1.1569,  2.4661,  ..., -0.6241,  2.7211,  0.5260],\n","        [-2.3419, -2.3000, -0.1788,  ..., -0.9976, -0.4784,  0.7759],\n","        [-1.5550, -2.0785, -0.6770,  ..., -1.3945, -0.5086,  0.9730]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 3, 31, 29,  0,  5, 44, 24, 22, 10, 33,  1,  3, 38, 16,  8, 31,  2, 31,\n","         8,  1, 41, 27, 43, 11, 39, 10, 37, 26, 11, 22, 12, 30,  2, 27, 19,  3,\n","         0, 13, 25, 10, 36, 24, 36, 20,  9, 45,  6, 28, 43, 49,  0, 45, 35,  7,\n","        17, 31,  0, 43, 41, 12, 47, 36, 24,  4,  1, 35, 28,  9, 32, 24, 25, 29,\n","        20, 45, 46, 47, 42, 22, 13, 48, 27,  1, 32, 29, 10, 10,  8, 16,  0, 39,\n","        10, 48, 49, 38,  4,  5, 11, 17, 23, 25, 30, 40, 19, 25, 35, 46,  4,  4,\n","         3,  3, 32, 26, 14, 18, 12, 27,  8, 20, 36, 49, 17, 18, 29, 18, 44, 20,\n","        41, 14], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.9430, -0.2265, -1.1725,  ...,  1.3300, -0.5951,  3.0039],\n","        [-0.7189,  1.5719,  2.0463,  ..., -0.2935, -1.3635,  0.9675],\n","        [-2.5278, -5.5170,  0.3406,  ...,  0.9154, -1.3127, -1.0955],\n","        ...,\n","        [ 2.3482, -2.4173,  2.7521,  ...,  2.2252, -0.9517, -2.1344],\n","        [ 4.5403, -0.7600, -0.5201,  ..., -0.8293, 14.4755,  0.5455],\n","        [-0.5870,  0.6587, -0.3935,  ..., -0.2594, -3.3954,  3.5097]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([36, 21,  9, 32, 45, 16, 29, 16, 37, 33, 12, 38, 35, 24,  7, 25, 18,  2,\n","        45, 40, 14, 10, 48, 16, 15,  2, 19, 19, 21, 15, 17, 40, 36, 26, 34, 17,\n","        15, 26, 20,  7, 31, 39,  9, 22, 45, 13,  9,  5, 15, 28,  5,  4, 29, 37,\n","         7, 15, 33, 19, 47, 25, 34, 13, 41,  1, 16, 44, 27, 46,  8, 12, 46, 37,\n","        32, 44, 30, 33, 48, 14, 19, 23, 21, 44, 43, 37, 47,  2,  5, 25, 10, 28,\n","        18, 14, 46, 49,  2, 32, 16,  2, 38, 23, 49, 28,  9, 15,  8, 29, 31, 21,\n","        36, 30, 22, 12, 24, 17, 46, 34, 20, 40,  7, 21,  9, 19, 47, 21, 37, 35,\n","        48, 29], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.3465e-01, -1.4558e+00,  6.0761e-01,  ..., -1.3481e+00,\n","          2.2689e+00, -1.7874e+00],\n","        [-2.8182e+00,  8.4355e-02, -3.9547e-01,  ..., -2.0555e+00,\n","         -1.4099e+00,  1.4331e+01],\n","        [-1.7327e-02, -1.3141e+00,  1.0982e+00,  ...,  3.0772e-01,\n","          7.8246e-01, -1.6890e+00],\n","        ...,\n","        [-2.6735e-01, -3.7359e+00,  3.4674e+00,  ...,  4.4903e+00,\n","         -3.1461e-01, -1.1336e+00],\n","        [-7.4638e-01,  1.8559e+00,  4.9861e-03,  ..., -1.0769e+00,\n","         -6.4382e-01,  1.0025e-01],\n","        [-1.9000e-01, -3.2054e+00,  5.1889e+00,  ...,  4.0392e-01,\n","         -1.2225e+00, -1.8671e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([10, 49, 17, 36, 30,  6,  3, 18, 39, 22, 42, 25, 35, 12, 40, 13, 22,  1,\n","        20,  6, 30, 48, 30, 48, 49, 47, 40, 42, 47,  5,  1,  6, 26, 16,  3,  9,\n","        27, 31,  3, 13, 43,  2, 38, 11, 27, 42,  8,  4, 28, 40, 12, 17, 14, 26,\n","        11, 26, 15, 14, 49, 22,  4,  1, 23, 41,  6, 35, 40, 37, 15, 12, 30, 13,\n","        39, 19, 20, 37, 34, 44,  9, 23,  7,  1, 13,  7, 36, 38, 33, 11, 31, 14,\n","        17,  6, 32, 34,  7, 41, 41,  0,  8, 20, 41, 16, 42, 16, 32, 46, 28, 18,\n","        47, 14,  5, 27, 31,  0, 17,  9,  3, 26,  0, 24, 45, 30, 43,  6, 42, 11,\n","        34, 11], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.3700e+00, -2.5818e+00, -9.5724e-01, -1.4846e+00, -4.1795e+00,\n","          3.9856e+00, -1.4723e+00, -1.4368e+00, -7.1382e-01,  2.3523e+00,\n","          9.6951e-01, -2.1175e-01,  2.2844e+00, -3.3881e+00,  6.8745e-02,\n","         -1.5848e+00, -1.2758e+00,  8.4850e-01,  1.7301e-01,  1.7480e-01,\n","          1.5392e+00, -3.3715e-01, -3.8242e-01, -2.1997e+00, -1.2022e+00,\n","         -1.7585e-01, -2.1336e+00,  8.3003e+00,  2.1632e-01, -2.0891e-01,\n","          2.8417e+00,  1.3950e+00, -1.1212e+00, -4.1520e+00, -1.5736e+00,\n","         -2.1300e-01, -9.8170e-04,  1.4551e-01,  1.6038e+00, -7.9247e-01,\n","          2.1700e+00,  3.8725e+00,  3.9972e-01, -6.8550e-01,  1.0564e+00,\n","         -1.6631e+00, -1.6112e+00,  4.1275e-01,  5.2455e+00, -2.3193e+00],\n","        [ 6.4922e-01,  2.4249e+00, -1.3273e+00, -2.2012e-01,  1.3333e+00,\n","         -8.7186e-01,  2.4306e-01, -2.9924e+00,  6.8642e+00, -2.2048e+00,\n","         -1.8866e+00, -2.9408e+00, -2.5936e-01,  2.7835e+00,  1.3539e+00,\n","         -9.9346e-01,  1.6703e-01, -2.2987e+00, -6.9649e-01, -2.5263e+00,\n","          3.1268e+00, -1.2988e+00,  3.2856e-01,  1.1513e+01, -1.7301e+00,\n","         -1.7967e+00, -1.3085e+00, -2.7688e+00, -2.6583e+00, -1.2118e-01,\n","         -1.9421e+00,  9.6620e-01, -1.1008e-01, -1.3142e+00,  2.4358e+00,\n","         -1.3730e+00,  2.5218e+00,  4.2547e+00,  4.5182e-01, -2.0104e+00,\n","          1.1513e-01,  2.5443e-01, -1.0321e+00,  3.6588e+00,  1.4236e+00,\n","         -3.0023e+00, -2.8586e+00, -1.5951e+00, -9.1383e-01,  3.1460e+00],\n","        [-2.2180e+00, -2.1330e+00, -5.4917e-01, -1.9850e+00, -5.4698e-01,\n","          7.9444e-01, -8.5448e-01,  1.6875e+00, -2.5547e+00, -6.3135e-01,\n","         -9.7107e-01,  6.9766e-01,  5.5565e+00, -1.0404e+00,  1.5588e-01,\n","          9.9521e-02, -3.6368e-01,  4.8311e-01,  2.1818e+00, -7.9097e-01,\n","         -1.2756e+00,  1.1714e+00,  4.0075e-01, -3.2584e+00, -1.5078e+00,\n","         -3.0847e-01, -1.1975e+00,  1.1672e-02,  1.3258e+01,  9.9708e-01,\n","         -2.6497e-01,  7.2699e-01,  2.3039e+00, -2.1253e+00, -1.8480e+00,\n","          1.2793e-01, -7.7307e-01,  1.4590e+00,  3.0032e-01, -1.2103e+00,\n","          3.0676e+00,  3.7367e+00, -9.1550e-01, -2.5450e+00,  1.8920e-01,\n","          3.0439e-01, -2.3369e-01, -2.9108e+00, -2.0415e+00, -5.0120e-01],\n","        [ 1.1846e+00, -2.0099e+00,  1.9005e+00, -2.4522e+00, -2.3071e+00,\n","          1.5575e+00,  1.6471e+00, -1.4814e+00, -1.6822e+00, -4.6022e-01,\n","         -1.0325e-01,  1.0676e+00,  2.1337e+00, -1.5132e+00,  4.0607e+00,\n","         -1.0529e+00,  1.3653e+00, -7.6401e-01, -9.6752e-01, -4.5754e-01,\n","          2.0917e+00, -3.6926e-01,  8.4247e-01, -1.3343e+00,  5.5980e-01,\n","         -4.2135e-01,  5.7558e-01,  8.6737e-01, -2.1339e+00, -3.9074e+00,\n","          5.8722e-01, -1.6054e+00,  1.5274e+00,  1.4703e-01, -1.8864e+00,\n","          1.0692e+01, -7.5591e-01, -1.9283e+00,  4.1467e-01, -1.1225e+00,\n","          4.2640e-01, -6.8247e-01, -1.5065e+00,  1.1489e+00,  4.1899e-01,\n","         -2.1317e+00, -5.3317e-01,  2.3149e+00, -1.9001e+00, -3.4937e-01],\n","        [ 9.1201e-01, -2.6401e+00,  1.2228e+00, -2.2220e+00, -1.6634e+00,\n","          2.0571e+00, -9.4125e-01, -3.2173e-01, -1.2355e+00,  1.1484e+00,\n","         -7.0542e-01,  1.5026e+00,  1.6971e+00, -4.1973e+00, -8.5009e-02,\n","         -6.6413e-01,  1.1438e+00, -4.2595e-01, -7.9811e-01, -1.8742e+00,\n","         -8.5680e-01,  1.6404e+00, -1.0543e+00, -2.4879e+00, -1.4216e+00,\n","          1.2410e-01,  3.3405e-01,  1.4477e+01, -1.8946e+00, -1.6982e+00,\n","         -2.3993e+00, -3.1931e-01,  1.9692e-01, -2.3598e+00, -7.8970e-01,\n","          3.3526e+00,  6.5656e-01, -9.6045e-01,  2.0179e+00,  8.4174e-01,\n","         -1.0564e+00,  3.8697e+00, -1.1243e+00, -5.4079e-01,  5.2901e-01,\n","         -3.1356e+00, -1.3765e+00,  1.6546e+00,  2.5723e+00,  1.1345e-01],\n","        [ 1.2488e+00, -1.5929e+00,  2.6430e+00,  4.5550e-01, -3.4056e+00,\n","         -1.6515e+00, -1.1796e+00, -3.3206e+00, -2.5192e+00, -2.0288e-01,\n","         -1.4576e+00,  2.8144e+00,  4.3480e-01, -1.7984e+00, -2.9155e+00,\n","         -2.4800e+00,  4.5055e+00,  3.5302e+00,  5.2266e-01,  5.6245e+00,\n","         -1.1312e+00, -1.1992e+00, -1.1619e+00, -4.0887e+00,  2.0416e+00,\n","          2.0657e+00,  2.0898e-01, -2.6860e-01, -2.0704e-02, -1.4999e-01,\n","          1.6305e+01, -2.1251e+00, -1.4543e+00, -3.0803e+00, -2.8370e+00,\n","         -1.4140e-01, -3.0812e+00, -2.0090e+00,  2.7466e+00, -5.5149e-01,\n","          1.0380e+00, -2.1899e+00, -8.1145e-01, -2.6277e+00, -2.5477e-01,\n","         -1.2292e+00,  6.4828e+00, -2.9710e-01,  1.9335e-01, -1.6528e+00],\n","        [-9.8924e-01,  1.0308e+00,  1.2316e-01, -9.1174e-02,  1.1333e+01,\n","         -1.8935e+00, -4.9466e-01, -1.6019e+00,  4.6758e-01, -3.4583e-02,\n","         -6.4322e-01,  1.4878e+00,  1.3081e+00, -1.3542e-01, -1.9661e+00,\n","          5.8946e-01, -2.1601e+00, -2.6740e+00, -1.1033e+00, -2.7658e-01,\n","          1.7617e+00, -5.3118e-02,  7.8381e-01, -1.9498e+00, -1.3612e+00,\n","         -9.4824e-01, -3.0640e+00, -3.4173e+00, -2.4494e-01,  2.9960e+00,\n","         -1.2755e+00,  1.3283e+00,  3.1086e+00, -2.4411e+00,  1.3596e+00,\n","          6.3440e-03,  9.4008e-01,  1.8800e+00, -4.1218e-01,  1.6702e-01,\n","          1.0581e+00,  1.8519e+00, -5.2574e-01,  5.8142e-01, -1.5977e+00,\n","          2.0014e+00,  1.2068e-01, -2.1443e+00, -2.4935e+00,  1.7499e+00],\n","        [-7.1581e-01, -1.0016e-01,  2.0369e+00, -3.8500e-01, -2.3608e+00,\n","          1.9730e+00,  4.6789e+00, -3.5419e-01,  4.9618e-01, -1.4087e+00,\n","          2.3985e+00,  6.3530e-01, -1.5542e+00,  3.9064e-01, -1.8432e+00,\n","         -1.5949e+00,  4.9619e-01,  2.5929e+00, -2.2591e+00, -1.3290e+00,\n","         -1.9183e-01, -1.1326e+00, -2.4087e+00, -1.5813e+00, -1.2012e+00,\n","         -1.5838e+00,  3.2607e+00, -2.3226e+00, -1.7018e+00, -1.1892e-01,\n","         -7.8366e-01, -2.1153e+00, -8.5825e-02,  1.3043e+01,  5.6210e-01,\n","          1.5159e+00, -9.9451e-01, -1.1038e+00, -7.6161e-01, -1.1736e+00,\n","         -2.1410e+00, -2.1189e+00,  2.9367e-01,  3.1736e+00,  2.8185e+00,\n","         -1.9970e+00,  2.1964e+00, -9.3155e-01,  3.5791e-01, -1.1370e+00],\n","        [-2.1957e+00,  1.0508e+00, -1.4820e+00, -6.8738e-01,  2.8394e+00,\n","         -2.3129e+00,  2.1294e-01, -4.6496e+00,  4.0272e+00, -2.8804e+00,\n","         -3.5100e+00, -3.0287e+00, -1.4408e+00,  7.7345e+00, -5.8247e-01,\n","          4.6948e+00, -8.9795e-01, -1.8349e+00,  8.2809e-01,  6.7115e-01,\n","          6.7384e+00,  7.9363e-01,  1.5098e-01,  1.3715e+01, -1.0925e+00,\n","         -1.5802e+00, -3.3005e+00, -4.5748e+00, -2.8708e+00,  2.6286e+00,\n","         -2.6933e+00,  5.7027e+00, -6.1884e-01, -2.8604e+00,  2.3251e+00,\n","         -3.1427e+00,  1.9552e+00,  4.0625e+00, -3.2595e-01, -1.7121e+00,\n","         -1.8399e+00, -5.6948e-01, -4.9302e-01,  4.2646e+00, -8.3426e-01,\n","         -3.8274e+00, -3.5642e+00, -3.3167e+00, -2.1999e+00,  5.1830e+00],\n","        [-3.3989e-01,  1.0813e+00, -1.4820e+00,  2.2471e-01, -1.5631e+00,\n","          1.7067e+00,  2.7428e-01, -3.2520e+00, -7.9046e-01,  1.1267e+00,\n","         -2.1510e+00,  9.6062e-01, -2.0243e+00,  6.0487e-01, -1.5855e+00,\n","          3.9076e+00,  4.5554e-01, -1.4591e-01, -3.1724e-01, -4.8376e-01,\n","          4.7247e-01,  1.0110e+00, -3.1320e-01,  7.8159e-01,  5.1099e-01,\n","          4.3813e+00, -1.9448e-01, -3.8813e+00, -2.2351e+00,  1.4609e+01,\n","         -2.0798e+00, -3.7076e-01,  3.1248e+00, -1.7530e+00,  2.6793e-01,\n","         -1.4975e+00, -4.1709e-02, -1.6083e+00,  6.8126e-01, -1.5537e+00,\n","         -5.6471e-01, -1.3103e-02, -4.8949e+00, -8.6598e-01,  9.1373e-01,\n","         -7.2938e-01, -2.6602e-01, -1.7512e-01, -3.2915e+00,  3.9836e+00],\n","        [ 6.4386e+00,  1.9756e+00,  1.0925e+00,  5.6657e+00, -2.4046e+00,\n","         -2.3122e+00, -4.8562e-01, -2.3021e+00,  5.9254e-01, -1.0330e+00,\n","          6.9486e-01, -7.5849e-01, -1.4287e+00, -2.1023e+00, -2.2515e+00,\n","         -3.0915e+00,  2.9257e+00,  3.9152e-01, -3.1223e+00,  2.8196e+00,\n","         -1.6525e+00, -1.4050e+00,  6.2191e-01, -1.1919e+00,  9.8386e+00,\n","          1.2688e-01, -1.9501e+00, -3.2408e+00, -1.5581e+00, -1.7060e+00,\n","          2.6176e+00, -1.4689e+00, -1.9461e-01, -1.1418e+00, -1.2653e+00,\n","          6.2225e-01,  1.4211e+00, -1.3901e+00,  5.0704e+00,  3.4873e+00,\n","         -2.5629e+00, -1.3084e+00, -1.4885e+00, -2.8765e-01, -2.4956e-01,\n","         -1.9855e+00,  2.4843e-01,  3.3272e+00, -4.7799e-01, -1.8478e+00],\n","        [-2.3689e+00, -2.2872e+00, -1.2701e+00, -3.0361e+00,  1.4436e+00,\n","         -6.0394e-01, -2.3389e+00,  1.7046e+00,  6.9835e-01,  1.2869e+00,\n","         -2.1117e+00,  1.5847e+00,  5.9724e-01, -1.1429e+00, -1.7581e+00,\n","         -1.8080e+00,  1.1756e+00,  2.8624e-01,  1.5216e+00, -1.1160e+00,\n","         -3.9530e-02,  1.4194e+00, -7.4166e-01, -3.7143e+00, -9.8083e-01,\n","         -2.5787e-01, -1.8775e+00, -2.4239e+00,  3.4676e+00,  2.0529e-01,\n","         -6.5082e-01,  1.3366e+00,  2.7145e+00, -2.8484e+00,  1.2773e+00,\n","         -9.4670e-01, -1.0389e+00,  1.2347e+00,  1.2532e+00,  4.3056e-01,\n","          3.6589e+00,  1.1036e+01, -2.8110e+00, -2.0382e+00,  3.6970e-01,\n","          2.8965e+00,  7.2941e-02, -2.6841e+00, -1.2169e+00,  1.1491e+00],\n","        [ 2.1285e-01,  3.4083e-01, -7.3330e-01, -4.2469e-01,  3.5297e-01,\n","         -8.5351e-01, -1.6745e+00,  1.9757e-01,  8.3486e-02,  1.5512e+00,\n","          4.0329e+00, -4.7059e-02,  7.2105e-01, -1.7704e+00, -1.0557e+00,\n","         -1.9444e+00, -2.0294e+00,  2.6285e+00,  4.9114e-01, -1.0666e+00,\n","          5.6619e-01,  6.5217e-01, -1.1361e-01, -1.8382e+00, -1.5447e+00,\n","         -1.6403e+00, -1.0839e+00, -8.4848e-01,  7.6367e-01, -3.2978e-01,\n","         -1.8269e+00, -8.5576e-01,  4.0267e-01, -1.8913e+00, -1.1360e+00,\n","         -2.7926e+00,  6.9845e-01,  2.3178e+00,  5.1195e-02, -1.1886e+00,\n","          7.7471e-01, -9.3507e-01,  1.1883e+01,  6.6865e-01,  2.3951e+00,\n","         -8.7002e-01,  1.0787e+00, -1.1080e+00,  2.0027e+00, -8.6480e-01],\n","        [-6.0504e-01, -5.1368e-01,  1.5353e+00,  2.0526e+00, -3.8467e+00,\n","          1.6993e+00,  2.4492e+00, -1.1164e+00,  6.6043e-02, -9.7359e-01,\n","          3.3758e+00, -1.4412e-01, -3.2988e+00,  2.8116e+00, -1.3987e+00,\n","         -1.8203e+00,  5.0675e-01,  3.0604e+00, -3.7671e-01,  5.9929e-01,\n","         -2.6046e-02, -4.1251e-01, -1.8263e+00, -1.7591e+00, -2.6771e+00,\n","         -8.3103e-01,  4.5000e+00, -5.6818e-01, -2.7108e+00, -4.4747e-01,\n","         -9.1499e-01, -1.8321e+00,  6.4570e-01,  9.4106e+00, -7.1212e-02,\n","          5.2007e-01, -2.3039e+00, -8.3874e-01, -1.0604e+00, -5.2817e-01,\n","         -1.5128e+00, -2.2991e+00, -5.2183e-02,  2.9262e+00,  1.8322e+00,\n","         -1.3321e+00,  2.4248e+00, -1.3878e+00,  1.2189e+00, -2.5885e+00],\n","        [-4.6724e-03,  1.4072e+00,  1.2096e+01,  2.6953e-01,  7.7530e-01,\n","          2.2394e+00,  4.7743e-01, -9.0323e-01, -3.4739e+00,  3.1447e-01,\n","         -9.6543e-01,  4.1435e+00, -1.1870e+00, -3.0309e+00, -1.3984e+00,\n","         -1.6401e+00,  1.6010e+00, -1.1056e+00, -7.1340e-01, -1.5563e+00,\n","          1.7590e+00,  5.0612e-01, -2.8025e+00, -2.0249e+00, -8.1784e-01,\n","         -1.6394e+00,  2.9628e+00, -2.1664e+00, -2.4140e+00,  2.0789e+00,\n","         -2.1280e+00,  9.8570e-01,  2.1477e+00,  9.8141e-01, -6.3066e-01,\n","         -1.2293e+00, -5.6063e-01, -1.2532e+00,  3.7064e+00,  4.7238e-02,\n","         -9.0172e-01, -3.4119e+00, -2.2671e+00,  8.8830e-01,  1.0830e+00,\n","         -3.5494e+00,  4.7396e-01, -7.8215e-01, -2.0393e-01,  2.9219e+00],\n","        [ 3.3208e+00,  1.2490e+00,  1.5240e-01,  6.7271e+00, -3.6512e+00,\n","         -1.0518e+00, -1.7101e+00, -3.7046e+00, -3.0845e+00,  3.5444e+00,\n","         -1.4293e+00, -1.5743e+00, -3.1709e+00, -6.1791e-01,  2.4802e-01,\n","         -9.4991e-01,  3.8259e-01, -1.3271e+00,  3.1827e+00,  6.1001e+00,\n","         -9.5637e-01, -1.4991e+00,  7.8285e-01, -2.3752e+00,  1.4655e+01,\n","          3.0037e+00,  2.4067e+00, -2.8082e+00, -3.7502e+00,  7.8195e-01,\n","          2.0216e+00,  2.1881e+00,  9.7904e-01, -3.6889e+00, -1.3439e+00,\n","         -2.8570e+00, -2.8719e+00,  1.1606e-01,  1.5423e+00,  1.6329e+00,\n","          1.2410e+00, -2.5878e+00, -5.0798e+00, -1.7419e+00, -1.7267e+00,\n","         -2.9721e+00, -4.6078e-01,  3.0488e+00,  5.5858e-01, -1.9914e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([27, 23, 28, 35, 27, 30,  4, 33, 23, 29, 24, 41, 42, 33,  2, 24],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","train Loss: 0.00 Acc: 33.3\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.7277, 10.7851, -0.6070,  ..., -1.7314, -2.3049,  2.6848],\n","        [-0.0517,  4.8833, -0.3945,  ..., -0.7812, -0.7260,  3.3551],\n","        [ 5.8974, -3.5146,  1.5902,  ...,  6.1494,  1.1054, -1.5445],\n","        ...,\n","        [ 2.1182, -0.2003, -0.9482,  ..., -2.1143,  0.4906, -0.5915],\n","        [ 1.7647, 16.1070,  0.9955,  ..., -1.5879, -3.3737,  1.6619],\n","        [ 1.0675, -4.2459,  3.8718,  ..., -0.5223,  2.1779, -0.5604]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 34, 11, 15, 44, 35, 28, 22, 49, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22, 17, 14, 46, 45, 28, 23, 46, 35, 48,\n","        20, 18, 40, 23,  6, 18, 43, 39, 38, 24, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","valid Loss: 0.29 Acc: 33.8\n","Training complete in 26m 58s\n","Best valid Acc: 12 - 40.0\n","model saved\n"]}],"source":["model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=400) \n","#torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/image_model_210110.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sr3Mx2Wvvz30"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNIpPJXrw-2b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95ODQ0VQw-44"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kA8fc3mEw-8Y"},"outputs":[],"source":["def test_and_visualize_model(model, phase = 'test', num_images=4):\n","    # phase = 'train', 'valid', 'test'\n","    \n","    was_training = model.training\n","    model.eval()\n","    fig = plt.figure()\n","    \n","    running_loss, running_corrects, num_cnt, running_corrects_topK, num_cnt_topK, running_corrects_topK_forMAP = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            false_list, preds_list = torch.sort(outputs,  descending=True)  #/** additional part **/#\n","\n","            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n","\n","            running_loss    += loss.item() * inputs.size(0)\n","            running_corrects+= torch.sum(preds == labels.data)\n","\n","            #dcg 적용: 아래 #----------------------------------------------------------------------------\n","            topKval = 5 #test로 top3로\n","            for iii in range(topKval):\n","              indices = torch.tensor([ iii ], device=\"cuda:0\")\n","              predTopK = torch.index_select(preds_list, 1, indices)\n","              predTopK = torch.reshape( predTopK, (-1, ) )\n","\n","              #print(\"iii is %d      divison by zero???  : \"%(iii), math.log(2, iii+2 ) )\n","              print( \"iii is %d     다음 값은 사실 1을 넘으면 안 됨 :: %2f\"%(iii, ( (predTopK == labels.data) / math.log(2, iii+2 )     ) )  )\n","              running_corrects_topK += torch.sum(   (predTopK == labels.data) / math.log(2, iii+2 )   )\n","              running_corrects_topK_forMAP += torch.sum(   (predTopK == labels.data) / ( iii+1 )   )\n","\n","              #print(\" running_corrects_topK : \", running_corrects_topK, \" num_cnt_topK :\", num_cnt_topK)\n","              \n","              num_cnt_topK += len(labels)\n","            #dcg 적용: 위 #----------------------------------------------------------------------------\n","\n","            num_cnt += inputs.size(0)  # batch size\n","\n","    #         if i == 2: break\n","\n","        test_loss = running_loss / num_cnt\n","        test_acc  = running_corrects.double() / num_cnt       \n","        dcg_mean = running_corrects_topK / num_cnt #/ ** additional part ** /#\n","        mapK = running_corrects_topK_forMAP / num_cnt\n","        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n","        print(' dcg_mean : %.2f' %(dcg_mean) )\n","        print(' MAP@K    : %.2f' %(mapK))\n","\n","    # 예시 그림 plot\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)        \n","\n","            # 예시 그림 plot\n","            for j in range(1, num_images+1):\n","                ax = plt.subplot(num_images//2, 2, j)\n","                ax.axis('off')\n","                ax.set_title('%s : %s -> %s'%(\n","                    'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n","                    class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n","                imshow(inputs.cpu().data[j])          \n","            if i == 0 : break\n","\n","\n","    # model.train(mode=was_training);  # 다시 train모드로\n","    \n","    "]},{"cell_type":"code","source":["## TEST!\n","test_and_visualize_model(model, phase = 'test') #test done : loss/acc : 2.17 / 46.0"],"metadata":{"id":"L5qa2Q2y0mSw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DA7Eid0P1bO-"},"outputs":[],"source":["datasets['real_test'] = tests_dataset\n","\n","dataloaders['real_test'] = torch.utils.data.DataLoader(datasets['real_test'],\n","                                              batch_size=batch_size, shuffle=True,\n","                                              num_workers=4)\n","\n","batch_num['real_test'] = len(dataloaders['real_test'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":245712,"status":"ok","timestamp":1642156959638,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"dGwDEd44ZHjM","outputId":"e9a01fa9-bd12-4e45-c8ac-93bf8fa7c9eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","test done : loss/acc : 3.92 / 2.4\n"," dcg_mean : 0.19\n"," MAP@K    : 0.05\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["## TEST!\n","test_and_visualize_model(model, phase = 'real_test')  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wh_VqaCTnE06"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xrSL_2pnE3v"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"elapsed":4415,"status":"error","timestamp":1642160077502,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"UdwH0RE6IIMu","outputId":"caead4f4-924d-48e3-c2d1-8094e6721ee6"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-12f27eb6c2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m\"/content/drive/MyDrive/model/image_class/complete/image_model_210113_1.pt\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_and_visualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'real_test'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m##image_model_220110_2.pt (from 210110)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-45eb56b58bae>\u001b[0m in \u001b[0;36mtest_and_visualize_model\u001b[0;34m(model, phase, num_images)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0;31m#print(\"iii is %d      divison by zero???  : \"%(iii), math.log(2, iii+2 ) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"iii is %d     다음 값은 사실 1을 넘으면 안 됨 :: %2f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredTopK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m               \u001b[0mrunning_corrects_topK\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mpredTopK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m   \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m               \u001b[0mrunning_corrects_topK_forMAP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0mpredTopK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0miii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m   \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}],"source":["## TEST!\n","\n","model.load_state_dict(torch.load(  \"/content/drive/MyDrive/model/image_class/complete/image_model_210113_1.pt\" ))\n","\n","test_and_visualize_model(model, phase = 'real_test')  ##image_model_220110_2.pt (from 210110)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HaYajAoIIP5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":19180,"status":"ok","timestamp":1642159594467,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"YFhdyzWdnE6W","outputId":"5d06d599-533d-453d-886f-f639923ba9fe"},"outputs":[{"output_type":"stream","name":"stdout","text":[" running_corrects_topK :  tensor(67., device='cuda:0')  num_cnt_topK : 0.0\n"," running_corrects_topK :  tensor(103.4541, device='cuda:0')  num_cnt_topK : 128.0\n"," running_corrects_topK :  tensor(119.4541, device='cuda:0')  num_cnt_topK : 256.0\n"," running_corrects_topK :  tensor(131.0638, device='cuda:0')  num_cnt_topK : 384.0\n"," running_corrects_topK :  tensor(143.9886, device='cuda:0')  num_cnt_topK : 512.0\n"," running_corrects_topK :  tensor(225.9886, device='cuda:0')  num_cnt_topK : 640.0\n"," running_corrects_topK :  tensor(249.7630, device='cuda:0')  num_cnt_topK : 768.0\n"," running_corrects_topK :  tensor(265.7630, device='cuda:0')  num_cnt_topK : 896.0\n"," running_corrects_topK :  tensor(277.3727, device='cuda:0')  num_cnt_topK : 1024.0\n"," running_corrects_topK :  tensor(285.1276, device='cuda:0')  num_cnt_topK : 1152.0\n"," running_corrects_topK :  tensor(369.1276, device='cuda:0')  num_cnt_topK : 1280.0\n"," running_corrects_topK :  tensor(392.9020, device='cuda:0')  num_cnt_topK : 1408.0\n"," running_corrects_topK :  tensor(418.9020, device='cuda:0')  num_cnt_topK : 1536.0\n"," running_corrects_topK :  tensor(423.5459, device='cuda:0')  num_cnt_topK : 1664.0\n"," running_corrects_topK :  tensor(423.5459, device='cuda:0')  num_cnt_topK : 1792.0\n"," running_corrects_topK :  tensor(503.5459, device='cuda:0')  num_cnt_topK : 1920.0\n"," running_corrects_topK :  tensor(524.1504, device='cuda:0')  num_cnt_topK : 2048.0\n"," running_corrects_topK :  tensor(552.1504, device='cuda:0')  num_cnt_topK : 2176.0\n"," running_corrects_topK :  tensor(556.7943, device='cuda:0')  num_cnt_topK : 2304.0\n"," running_corrects_topK :  tensor(574.8890, device='cuda:0')  num_cnt_topK : 2432.0\n"," running_corrects_topK :  tensor(650.8890, device='cuda:0')  num_cnt_topK : 2560.0\n"," running_corrects_topK :  tensor(682.5883, device='cuda:0')  num_cnt_topK : 2688.0\n"," running_corrects_topK :  tensor(698.5883, device='cuda:0')  num_cnt_topK : 2816.0\n"," running_corrects_topK :  tensor(728.7733, device='cuda:0')  num_cnt_topK : 2944.0\n"," running_corrects_topK :  tensor(733.9432, device='cuda:0')  num_cnt_topK : 3072.0\n"," running_corrects_topK :  tensor(818.9432, device='cuda:0')  num_cnt_topK : 3200.0\n"," running_corrects_topK :  tensor(839.5477, device='cuda:0')  num_cnt_topK : 3328.0\n"," running_corrects_topK :  tensor(855.5477, device='cuda:0')  num_cnt_topK : 3456.0\n"," running_corrects_topK :  tensor(864.8354, device='cuda:0')  num_cnt_topK : 3584.0\n"," running_corrects_topK :  tensor(872.5903, device='cuda:0')  num_cnt_topK : 3712.0\n"," running_corrects_topK :  tensor(948.5903, device='cuda:0')  num_cnt_topK : 3840.0\n"," running_corrects_topK :  tensor(977.1196, device='cuda:0')  num_cnt_topK : 3968.0\n"," running_corrects_topK :  tensor(1001.1196, device='cuda:0')  num_cnt_topK : 4096.0\n"," running_corrects_topK :  tensor(1015.0512, device='cuda:0')  num_cnt_topK : 4224.0\n"," running_corrects_topK :  tensor(1027.9761, device='cuda:0')  num_cnt_topK : 4352.0\n"," running_corrects_topK :  tensor(1105.9761, device='cuda:0')  num_cnt_topK : 4480.0\n"," running_corrects_topK :  tensor(1131.3354, device='cuda:0')  num_cnt_topK : 4608.0\n"," running_corrects_topK :  tensor(1147.3354, device='cuda:0')  num_cnt_topK : 4736.0\n"," running_corrects_topK :  tensor(1158.9451, device='cuda:0')  num_cnt_topK : 4864.0\n"," running_corrects_topK :  tensor(1169.2849, device='cuda:0')  num_cnt_topK : 4992.0\n"," running_corrects_topK :  tensor(1251.2849, device='cuda:0')  num_cnt_topK : 5120.0\n"," running_corrects_topK :  tensor(1281.3992, device='cuda:0')  num_cnt_topK : 5248.0\n"," running_corrects_topK :  tensor(1297.3992, device='cuda:0')  num_cnt_topK : 5376.0\n"," running_corrects_topK :  tensor(1306.6869, device='cuda:0')  num_cnt_topK : 5504.0\n"," running_corrects_topK :  tensor(1311.8568, device='cuda:0')  num_cnt_topK : 5632.0\n"," running_corrects_topK :  tensor(1386.8568, device='cuda:0')  num_cnt_topK : 5760.0\n"," running_corrects_topK :  tensor(1413.8011, device='cuda:0')  num_cnt_topK : 5888.0\n"," running_corrects_topK :  tensor(1437.8011, device='cuda:0')  num_cnt_topK : 6016.0\n"," running_corrects_topK :  tensor(1447.0889, device='cuda:0')  num_cnt_topK : 6144.0\n"," running_corrects_topK :  tensor(1449.6738, device='cuda:0')  num_cnt_topK : 6272.0\n"," running_corrects_topK :  tensor(1523.6738, device='cuda:0')  num_cnt_topK : 6400.0\n"," running_corrects_topK :  tensor(1563.2979, device='cuda:0')  num_cnt_topK : 6528.0\n"," running_corrects_topK :  tensor(1579.2979, device='cuda:0')  num_cnt_topK : 6656.0\n"," running_corrects_topK :  tensor(1593.2294, device='cuda:0')  num_cnt_topK : 6784.0\n"," running_corrects_topK :  tensor(1595.8143, device='cuda:0')  num_cnt_topK : 6912.0\n"," running_corrects_topK :  tensor(1660.8143, device='cuda:0')  num_cnt_topK : 7040.0\n"," running_corrects_topK :  tensor(1698.8534, device='cuda:0')  num_cnt_topK : 7168.0\n"," running_corrects_topK :  tensor(1718.8534, device='cuda:0')  num_cnt_topK : 7296.0\n"," running_corrects_topK :  tensor(1739.7507, device='cuda:0')  num_cnt_topK : 7424.0\n"," running_corrects_topK :  tensor(1752.6755, device='cuda:0')  num_cnt_topK : 7552.0\n"," running_corrects_topK :  tensor(1827.6755, device='cuda:0')  num_cnt_topK : 7680.0\n"," running_corrects_topK :  tensor(1857.7898, device='cuda:0')  num_cnt_topK : 7808.0\n"," running_corrects_topK :  tensor(1883.7898, device='cuda:0')  num_cnt_topK : 7936.0\n"," running_corrects_topK :  tensor(1890.7556, device='cuda:0')  num_cnt_topK : 8064.0\n"," running_corrects_topK :  tensor(1898.5105, device='cuda:0')  num_cnt_topK : 8192.0\n"," running_corrects_topK :  tensor(1973.5105, device='cuda:0')  num_cnt_topK : 8320.0\n"," running_corrects_topK :  tensor(2000.4548, device='cuda:0')  num_cnt_topK : 8448.0\n"," running_corrects_topK :  tensor(2020.4548, device='cuda:0')  num_cnt_topK : 8576.0\n"," running_corrects_topK :  tensor(2029.7426, device='cuda:0')  num_cnt_topK : 8704.0\n"," running_corrects_topK :  tensor(2037.4974, device='cuda:0')  num_cnt_topK : 8832.0\n"," running_corrects_topK :  tensor(2110.4976, device='cuda:0')  num_cnt_topK : 8960.0\n"," running_corrects_topK :  tensor(2145.3667, device='cuda:0')  num_cnt_topK : 9088.0\n"," running_corrects_topK :  tensor(2159.3667, device='cuda:0')  num_cnt_topK : 9216.0\n"," running_corrects_topK :  tensor(2170.9763, device='cuda:0')  num_cnt_topK : 9344.0\n"," running_corrects_topK :  tensor(2178.7312, device='cuda:0')  num_cnt_topK : 9472.0\n"," running_corrects_topK :  tensor(2240.7312, device='cuda:0')  num_cnt_topK : 9600.0\n"," running_corrects_topK :  tensor(2277.1853, device='cuda:0')  num_cnt_topK : 9728.0\n"," running_corrects_topK :  tensor(2305.1853, device='cuda:0')  num_cnt_topK : 9856.0\n"," running_corrects_topK :  tensor(2316.7949, device='cuda:0')  num_cnt_topK : 9984.0\n"," running_corrects_topK :  tensor(2332.3047, device='cuda:0')  num_cnt_topK : 10112.0\n"," running_corrects_topK :  tensor(2422.3047, device='cuda:0')  num_cnt_topK : 10240.0\n"," running_corrects_topK :  tensor(2442.9092, device='cuda:0')  num_cnt_topK : 10368.0\n"," running_corrects_topK :  tensor(2456.9092, device='cuda:0')  num_cnt_topK : 10496.0\n"," running_corrects_topK :  tensor(2466.1968, device='cuda:0')  num_cnt_topK : 10624.0\n"," running_corrects_topK :  tensor(2476.5366, device='cuda:0')  num_cnt_topK : 10752.0\n"," running_corrects_topK :  tensor(2547.5366, device='cuda:0')  num_cnt_topK : 10880.0\n"," running_corrects_topK :  tensor(2579.2358, device='cuda:0')  num_cnt_topK : 11008.0\n"," running_corrects_topK :  tensor(2603.2358, device='cuda:0')  num_cnt_topK : 11136.0\n"," running_corrects_topK :  tensor(2617.1675, device='cuda:0')  num_cnt_topK : 11264.0\n"," running_corrects_topK :  tensor(2630.0923, device='cuda:0')  num_cnt_topK : 11392.0\n"," running_corrects_topK :  tensor(2712.0923, device='cuda:0')  num_cnt_topK : 11520.0\n"," running_corrects_topK :  tensor(2737.4517, device='cuda:0')  num_cnt_topK : 11648.0\n"," running_corrects_topK :  tensor(2757.4517, device='cuda:0')  num_cnt_topK : 11776.0\n"," running_corrects_topK :  tensor(2766.7393, device='cuda:0')  num_cnt_topK : 11904.0\n"," running_corrects_topK :  tensor(2777.0791, device='cuda:0')  num_cnt_topK : 12032.0\n"," running_corrects_topK :  tensor(2850.0791, device='cuda:0')  num_cnt_topK : 12160.0\n"," running_corrects_topK :  tensor(2880.1934, device='cuda:0')  num_cnt_topK : 12288.0\n"," running_corrects_topK :  tensor(2908.1934, device='cuda:0')  num_cnt_topK : 12416.0\n"," running_corrects_topK :  tensor(2917.4810, device='cuda:0')  num_cnt_topK : 12544.0\n"," running_corrects_topK :  tensor(2922.6509, device='cuda:0')  num_cnt_topK : 12672.0\n"," running_corrects_topK :  tensor(3004.6509, device='cuda:0')  num_cnt_topK : 12800.0\n"," running_corrects_topK :  tensor(3028.4253, device='cuda:0')  num_cnt_topK : 12928.0\n"," running_corrects_topK :  tensor(3044.4253, device='cuda:0')  num_cnt_topK : 13056.0\n"," running_corrects_topK :  tensor(3060.6787, device='cuda:0')  num_cnt_topK : 13184.0\n"," running_corrects_topK :  tensor(3063.2637, device='cuda:0')  num_cnt_topK : 13312.0\n"," running_corrects_topK :  tensor(3146.2637, device='cuda:0')  num_cnt_topK : 13440.0\n"," running_corrects_topK :  tensor(3181.1328, device='cuda:0')  num_cnt_topK : 13568.0\n"," running_corrects_topK :  tensor(3193.1328, device='cuda:0')  num_cnt_topK : 13696.0\n"," running_corrects_topK :  tensor(3197.7766, device='cuda:0')  num_cnt_topK : 13824.0\n"," running_corrects_topK :  tensor(3208.1165, device='cuda:0')  num_cnt_topK : 13952.0\n"," running_corrects_topK :  tensor(3283.1165, device='cuda:0')  num_cnt_topK : 14080.0\n"," running_corrects_topK :  tensor(3311.6458, device='cuda:0')  num_cnt_topK : 14208.0\n"," running_corrects_topK :  tensor(3321.6458, device='cuda:0')  num_cnt_topK : 14336.0\n"," running_corrects_topK :  tensor(3337.8992, device='cuda:0')  num_cnt_topK : 14464.0\n"," running_corrects_topK :  tensor(3350.8240, device='cuda:0')  num_cnt_topK : 14592.0\n"," running_corrects_topK :  tensor(3425.8240, device='cuda:0')  num_cnt_topK : 14720.0\n"," running_corrects_topK :  tensor(3459.1082, device='cuda:0')  num_cnt_topK : 14848.0\n"," running_corrects_topK :  tensor(3479.1082, device='cuda:0')  num_cnt_topK : 14976.0\n"," running_corrects_topK :  tensor(3486.0740, device='cuda:0')  num_cnt_topK : 15104.0\n"," running_corrects_topK :  tensor(3498.9988, device='cuda:0')  num_cnt_topK : 15232.0\n"," running_corrects_topK :  tensor(3581.9988, device='cuda:0')  num_cnt_topK : 15360.0\n"," running_corrects_topK :  tensor(3612.1130, device='cuda:0')  num_cnt_topK : 15488.0\n"," running_corrects_topK :  tensor(3634.1130, device='cuda:0')  num_cnt_topK : 15616.0\n"," running_corrects_topK :  tensor(3641.0789, device='cuda:0')  num_cnt_topK : 15744.0\n"," running_corrects_topK :  tensor(3648.8337, device='cuda:0')  num_cnt_topK : 15872.0\n"," running_corrects_topK :  tensor(3734.8337, device='cuda:0')  num_cnt_topK : 16000.0\n"," running_corrects_topK :  tensor(3766.5330, device='cuda:0')  num_cnt_topK : 16128.0\n"," running_corrects_topK :  tensor(3768.5330, device='cuda:0')  num_cnt_topK : 16256.0\n"," running_corrects_topK :  tensor(3777.8206, device='cuda:0')  num_cnt_topK : 16384.0\n"," running_corrects_topK :  tensor(3785.5754, device='cuda:0')  num_cnt_topK : 16512.0\n"," running_corrects_topK :  tensor(3863.5754, device='cuda:0')  num_cnt_topK : 16640.0\n"," running_corrects_topK :  tensor(3900.0295, device='cuda:0')  num_cnt_topK : 16768.0\n"," running_corrects_topK :  tensor(3914.0295, device='cuda:0')  num_cnt_topK : 16896.0\n"," running_corrects_topK :  tensor(3923.3171, device='cuda:0')  num_cnt_topK : 17024.0\n"," running_corrects_topK :  tensor(3928.4871, device='cuda:0')  num_cnt_topK : 17152.0\n"," running_corrects_topK :  tensor(4004.4871, device='cuda:0')  num_cnt_topK : 17280.0\n"," running_corrects_topK :  tensor(4037.7712, device='cuda:0')  num_cnt_topK : 17408.0\n"," running_corrects_topK :  tensor(4055.7712, device='cuda:0')  num_cnt_topK : 17536.0\n"," running_corrects_topK :  tensor(4069.7029, device='cuda:0')  num_cnt_topK : 17664.0\n"," running_corrects_topK :  tensor(4077.4578, device='cuda:0')  num_cnt_topK : 17792.0\n"," running_corrects_topK :  tensor(4156.4580, device='cuda:0')  num_cnt_topK : 17920.0\n"," running_corrects_topK :  tensor(4183.4023, device='cuda:0')  num_cnt_topK : 18048.0\n"," running_corrects_topK :  tensor(4199.4023, device='cuda:0')  num_cnt_topK : 18176.0\n"," running_corrects_topK :  tensor(4211.0122, device='cuda:0')  num_cnt_topK : 18304.0\n"," running_corrects_topK :  tensor(4221.3521, device='cuda:0')  num_cnt_topK : 18432.0\n"," running_corrects_topK :  tensor(4250.3521, device='cuda:0')  num_cnt_topK : 18560.0\n"," running_corrects_topK :  tensor(4251.9370, device='cuda:0')  num_cnt_topK : 18606.0\n"," running_corrects_topK :  tensor(4259.9370, device='cuda:0')  num_cnt_topK : 18652.0\n"," running_corrects_topK :  tensor(4266.9028, device='cuda:0')  num_cnt_topK : 18698.0\n"," running_corrects_topK :  tensor(4272.0728, device='cuda:0')  num_cnt_topK : 18744.0\n","test done : loss/acc : 1.46 / 60.4\n"," dcg_mean : 1.14\n"," MAP@K    : 0.72\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["## TEST!\n","\n","model.load_state_dict(torch.load(  \"/content/drive/MyDrive/model/image_class/complete/president_model.pt\" ))\n","\n","test_and_visualize_model(model, phase = 'real_test')  ##image_model_220110_2.pt (from 210110)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWeK4rUvKy8H"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1795207,"status":"ok","timestamp":1642158777496,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"Bi6wZoCVO8O1","outputId":"cd12843e-d428-43c5-e413-6fe33524b9d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","         7, 42, 38, 26, 33,  6, 30, 27,  5, 28, 33, 43, 35, 27, 45, 11, 49, 27,\n","        27,  4], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.7633e+00, -1.2239e+00, -1.4043e+00, -2.5252e+00,  5.8487e-01,\n","         -7.0474e-01, -2.0754e-01,  2.0460e+00, -2.2712e+00,  4.2152e-01,\n","         -2.3991e+00,  2.6536e+00, -1.0612e+00, -9.9492e-01,  1.8812e+00,\n","          1.7958e-01, -3.8193e-01,  2.6647e-01, -7.5460e-02, -9.4643e-01,\n","         -1.9278e+00,  7.9365e-01,  1.6279e+00, -4.1953e+00,  4.8729e-01,\n","          1.7374e-01,  5.2647e-01,  7.5811e-02, -3.0781e-01,  3.6146e+00,\n","         -9.2465e-01, -7.0978e-01,  9.5879e+00,  1.4795e-01, -8.5318e-01,\n","          1.4447e+00, -1.8244e+00, -1.6192e+00,  1.4374e+00,  7.4846e-01,\n","          2.3264e-01,  1.6437e+00, -3.6036e-01, -1.5854e+00,  2.6489e+00,\n","          7.8261e-01, -1.0803e+00,  4.4508e-01, -1.7685e+00,  3.1741e-01],\n","        [-1.1122e-01, -4.9286e-01,  1.6750e+00, -1.8413e+00,  3.6200e-01,\n","          1.6782e+00,  2.3459e-01, -9.8672e-01, -7.1737e-01, -3.7334e-01,\n","          1.2331e+01,  5.3055e-01, -2.8066e-01, -2.5299e+00, -1.7884e+00,\n","         -2.1749e+00, -1.6189e+00,  6.3327e+00, -1.5447e+00, -1.6489e+00,\n","         -1.3266e+00, -5.2262e-01, -1.1349e+00, -1.7623e+00, -1.0568e+00,\n","         -1.7656e+00,  1.1572e+00, -6.2469e-01, -4.8645e-01, -1.2079e+00,\n","          4.5349e-01, -1.2914e+00,  7.9948e-02,  3.1588e-01, -1.0343e+00,\n","         -8.5101e-01, -1.1060e+00, -6.4046e-01, -1.0478e+00, -1.7188e+00,\n","         -1.0985e+00, -6.3759e-01,  3.8398e+00,  1.1082e+00,  2.9275e+00,\n","         -5.0780e-01,  6.8738e-01, -1.2297e+00,  3.9881e+00, -2.7584e+00],\n","        [-2.4520e+00, -3.2586e+00, -2.2297e-01, -1.3142e+00,  2.6530e+00,\n","         -1.5340e+00, -1.0894e+00,  5.3464e-01, -1.0382e+00,  2.3044e+00,\n","         -7.6877e-02,  8.1707e-01,  1.3077e+01, -3.9663e+00, -1.4846e+00,\n","         -1.3332e+00, -2.9202e+00, -7.7639e-01,  3.9002e+00, -6.9741e-01,\n","         -2.2791e+00,  1.3196e+00,  2.4839e+00, -3.6134e+00, -7.9014e-01,\n","         -9.6545e-01, -5.2870e-01,  2.9659e+00,  6.3138e+00, -1.1687e+00,\n","         -7.6774e-01,  9.5988e-01,  7.6047e-01, -2.7489e+00, -9.2417e-01,\n","         -1.3705e-01, -1.7425e+00,  2.7619e+00,  2.4513e+00, -7.4120e-01,\n","          2.3337e+00,  4.1229e+00,  4.5863e-01, -2.4704e+00, -1.5527e+00,\n","          2.8882e+00, -1.1729e+00, -2.4470e+00, -6.7525e-01, -3.5304e+00],\n","        [-5.0177e-01, -7.9651e-01,  2.7335e+00, -1.3949e+00, -8.8515e-01,\n","          1.2436e+00,  5.9032e-01, -1.6314e+00, -2.8926e+00,  1.5147e+00,\n","         -1.1578e+00,  3.4877e+00,  7.1904e-01, -3.5232e+00, -7.2164e-01,\n","         -1.6102e+00,  1.2838e+00, -7.3208e-01,  3.0385e-01, -6.2407e-01,\n","         -2.7003e+00,  1.4264e+00, -1.3823e-01, -2.8103e+00,  1.3326e-02,\n","          2.7406e-01,  1.4780e+00,  1.3287e+01, -2.3405e-01, -1.8203e-01,\n","         -4.3402e-01, -9.2562e-01, -1.1978e+00, -1.4228e+00,  5.9042e-01,\n","          2.3200e+00, -1.6542e+00,  4.6128e-02,  8.6919e-01, -1.3974e+00,\n","         -1.0384e+00,  2.9129e+00, -7.5949e-01, -1.2780e+00, -3.4231e-01,\n","         -1.8992e+00, -2.4009e-01, -3.7536e-01,  5.6311e-01, -9.1261e-01],\n","        [ 2.6738e+00,  1.2726e+00, -1.4779e-01, -1.6108e+00,  6.0631e-01,\n","         -4.8419e-01, -7.3532e-01, -1.9335e+00,  1.7681e+00, -1.1953e-01,\n","         -1.9265e+00, -4.1884e-02, -1.6387e+00,  3.6681e-01, -1.6279e+00,\n","         -1.3074e+00, -1.7889e-01, -8.9888e-01, -1.6240e+00, -1.1285e+00,\n","          2.8385e+00, -1.4641e+00, -2.1892e+00, -9.8177e-01,  1.7338e+00,\n","         -9.2633e-01, -1.6561e+00, -1.5197e+00, -2.1619e+00,  1.1684e+00,\n","          2.2268e+00, -1.5981e-01,  2.6299e-01, -3.6798e+00,  1.5075e+00,\n","         -6.9929e-01,  1.1986e+01, -8.9968e-01,  1.0459e+00, -1.3923e+00,\n","          4.3259e-01, -3.7166e-01,  1.6727e+00,  1.6640e+00,  1.0807e+00,\n","         -2.1578e+00, -3.8857e-01,  2.1658e-01, -4.3342e-01,  3.5473e+00],\n","        [ 2.3738e+00,  2.7665e+00,  8.7820e-01, -5.4899e-01, -6.3454e-02,\n","          6.3302e-01,  2.8835e-01, -1.1478e+00,  1.4060e-01, -9.5250e-01,\n","         -1.5596e+00, -2.8791e-01, -5.7942e-01, -1.7101e+00, -1.8452e+00,\n","         -2.4626e+00, -1.7734e-01, -1.1805e+00, -1.0570e+00, -1.4058e+00,\n","          2.0212e+00, -1.0038e+00, -1.3440e+00, -8.7616e-01,  1.5172e+00,\n","         -1.6610e+00, -1.7874e+00, -1.4888e-01, -1.2005e+00, -6.2347e-01,\n","          1.7770e+00, -4.7250e-01, -6.8693e-01, -2.6740e+00,  2.4450e+00,\n","          4.5089e-01,  1.0364e+01, -5.4220e-01,  2.0397e+00, -1.1588e+00,\n","         -1.2116e+00,  5.4969e-02,  1.3535e+00,  2.3334e+00,  8.5314e-01,\n","         -2.0430e+00,  4.0863e-01, -1.0261e-01,  8.1315e-01,  1.2883e+00],\n","        [ 1.8136e+00,  2.5344e+00,  1.1465e+00,  2.9171e+00, -2.3925e+00,\n","          1.4107e+00, -7.1021e-01, -1.7097e+00, -1.5578e+00,  7.1819e-01,\n","          1.7414e+00,  1.5067e+00, -1.9277e+00, -1.9860e+00, -7.5325e-01,\n","         -9.8912e-01,  2.8285e+00,  6.5656e-01, -1.7360e-01,  2.7329e+00,\n","         -3.3702e+00, -3.8335e-01, -3.9641e+00, -6.9646e+00,  1.2924e+00,\n","         -1.8035e+00,  2.4944e+00, -1.5178e+00,  9.8645e-01,  2.3057e+00,\n","          4.1852e+00, -1.1092e+00, -6.9030e-01,  4.6996e-01,  2.4757e+00,\n","         -2.2340e+00, -3.3973e+00,  1.6264e+00,  4.7744e-01, -3.0626e+00,\n","         -6.1803e-01,  1.6457e+00,  1.3846e+00, -8.5348e-01, -3.5125e-02,\n","         -3.2616e+00,  1.2174e+01, -1.4054e+00, -4.9360e-01,  5.1618e-01],\n","        [ 2.5392e+00,  1.2705e+00,  1.4772e+00,  3.2461e+00, -3.1340e+00,\n","          1.5953e-01, -7.9040e-01, -1.9434e+00, -1.5700e+00,  1.6395e-01,\n","          1.4494e+00,  2.1549e+00, -2.1777e+00, -1.1613e+00, -1.6525e+00,\n","         -1.0937e+00,  1.4092e+00,  2.7476e+00, -1.6121e+00, -3.0888e-01,\n","          4.8422e-02,  4.4816e-02, -2.7139e+00, -3.7750e+00, -3.9374e+00,\n","         -7.0207e-01,  3.0586e+00, -3.9063e-01, -1.8902e+00, -1.0484e+00,\n","          5.4026e+00, -1.9793e+00, -1.5429e-01,  1.0406e+00, -6.0741e-01,\n","         -5.6773e-01, -3.0315e+00, -1.7873e+00,  2.1065e+00, -1.9054e+00,\n","          4.2569e-01, -2.7073e+00,  2.0984e-01,  2.4769e+00,  5.0981e-01,\n","         -3.1718e+00,  1.1894e+01, -7.9617e-01,  2.0169e+00,  2.3706e-01],\n","        [ 2.9721e+00, -3.2723e+00, -2.5423e-01,  7.7341e-02, -2.4982e+00,\n","          1.2305e+00,  3.7454e+00, -2.7625e+00, -2.4657e+00,  3.3640e-01,\n","         -3.8291e+00,  3.8233e+00, -3.7496e+00,  3.0780e-01, -1.8700e+00,\n","         -1.9663e+00,  5.3871e+00,  4.3737e-01, -2.5514e-01,  4.3188e+00,\n","         -2.5965e+00, -1.2458e+00, -1.8986e+00, -1.9648e+00,  2.5594e+00,\n","          6.8819e+00,  1.4490e+00, -3.9852e-01, -1.7549e+00,  1.4084e+00,\n","          2.6210e+00, -1.9944e+00,  6.1959e-01,  4.6212e-01, -1.0970e+00,\n","          4.6082e+00, -3.2500e+00, -4.0549e+00,  3.1812e+00,  3.6718e+00,\n","         -4.4785e+00,  9.7488e-01, -2.8552e+00, -1.8639e+00,  1.7566e+00,\n","         -2.4000e+00, -4.3359e+00,  1.2236e+01, -1.7965e+00, -1.2289e+00],\n","        [ 3.6482e+00, -6.9599e-01,  2.2966e+00,  1.1729e+01, -2.1993e+00,\n","         -1.8285e-01,  3.0080e+00, -2.2110e+00, -1.2980e-01, -1.8813e+00,\n","         -3.2941e+00, -8.7311e-01, -2.6541e+00, -2.3797e-02, -9.4840e-01,\n","         -3.2085e+00,  3.7866e+00, -8.0543e-01,  1.7575e-01,  5.4240e+00,\n","         -4.2511e-01, -1.1573e+00, -1.7595e+00, -8.5315e-01,  6.4879e-01,\n","          1.9242e+00,  2.5604e+00, -2.1712e+00, -2.3348e+00, -4.6095e-01,\n","          1.4781e+00, -1.0283e+00, -1.7964e+00,  1.8923e+00, -1.3936e+00,\n","         -1.9989e-01, -2.2626e+00, -1.9539e+00,  1.8500e+00,  5.3290e+00,\n","         -1.9944e+00, -2.0005e+00, -1.9188e+00,  1.4368e+00, -2.0277e+00,\n","         -2.1931e+00, -1.1546e+00,  2.2487e-01,  1.3255e+00, -2.6270e+00],\n","        [-1.3613e+00,  2.0908e+00,  3.8076e-01,  9.0761e-01,  3.2363e+00,\n","         -1.2447e+00, -2.4099e+00, -4.8760e+00,  1.0207e+00,  5.1730e-01,\n","         -2.7602e+00, -1.7888e+00, -1.5226e+00,  4.3483e+00,  3.6110e-01,\n","          3.6396e+00, -5.9502e-02, -2.5072e+00, -9.2053e-01, -5.9572e-01,\n","          1.0475e+00,  8.4860e-01, -1.5278e+00,  9.8440e+00,  1.3068e+00,\n","         -1.0305e+00, -2.2909e+00, -2.8902e+00, -1.6536e+00,  4.9463e+00,\n","          7.2787e-01,  2.4001e+00, -1.8719e+00, -2.0271e+00,  1.6666e+00,\n","         -2.5004e+00,  1.2174e+00,  3.7542e+00,  1.0408e+00, -1.2985e+00,\n","         -1.0279e+00, -1.9964e+00, -8.7505e-01,  2.2230e+00, -1.3706e+00,\n","         -2.5101e+00, -2.1372e+00, -1.9064e+00, -1.5271e+00,  4.9726e+00],\n","        [-1.8486e+00,  4.6418e-01, -6.4355e-01, -9.8713e-01,  1.6561e+00,\n","         -1.2607e+00,  8.2600e-01, -2.5781e+00,  5.0337e+00, -8.9641e-01,\n","         -2.8949e+00, -1.4393e+00, -1.3963e+00,  4.6277e+00, -8.5810e-02,\n","          2.2312e+00, -8.2095e-01, -2.5885e+00,  1.8088e+00,  3.3167e-01,\n","          1.5734e+00,  9.3850e-01, -1.7345e+00,  1.1636e+01, -2.7608e-02,\n","         -3.0815e-01, -1.9337e+00, -2.3746e+00, -1.2704e-01,  1.0556e+00,\n","         -8.7143e-01,  1.0296e-01,  3.8097e-01, -1.4353e+00,  2.7309e+00,\n","         -2.9142e+00,  1.5252e-01,  4.6447e+00,  2.7654e-01, -3.1290e+00,\n","         -1.4598e+00, -2.2323e-01, -2.7851e-01,  2.3984e+00, -1.3712e+00,\n","         -1.3510e+00, -3.2265e+00, -2.3557e+00, -2.1971e+00,  2.9880e+00],\n","        [-7.4937e-01, -1.9945e+00,  1.5614e+00, -1.3098e+00,  1.3584e+00,\n","          2.3925e+00,  8.5338e-02, -2.8463e+00, -1.3254e+00,  2.9942e+00,\n","         -6.9911e-01, -6.2759e-01, -7.0603e-01,  4.7910e-01, -1.1592e+00,\n","         -3.4590e-01, -2.9832e+00, -5.7758e-01,  5.6892e-01, -1.9620e+00,\n","          1.2339e+01,  1.0790e+00, -2.6936e+00,  1.8182e+00,  1.0421e+00,\n","          3.7441e-01,  2.0151e-01, -1.1718e+00, -2.7963e+00,  1.2095e+00,\n","          4.6847e-01,  3.1857e+00, -9.2222e-01, -2.4902e+00, -1.1528e+00,\n","         -5.2911e-01, -9.6406e-01,  5.0769e-01, -5.8560e-01, -9.6895e-01,\n","          8.1561e-01,  3.6426e-01,  4.0226e-01,  1.7752e+00, -1.5876e-01,\n","         -1.1833e+00, -1.3574e+00, -1.0200e+00,  8.0204e-01,  1.1933e+00],\n","        [ 1.3901e+00, -1.4508e+00,  8.9037e-01,  2.6978e-01, -1.6415e+00,\n","         -2.2799e+00, -9.8323e-01, -1.3799e-01, -1.5632e+00, -1.0569e-01,\n","         -2.8283e+00, -1.2391e+00,  1.8198e+00, -2.3906e+00,  1.7411e+00,\n","         -2.8750e+00, -6.8360e-01,  5.6582e-01, -5.5867e-01,  8.7417e-01,\n","          1.0631e+00,  5.3641e-02,  1.3721e+01, -9.1541e-01,  4.2886e+00,\n","          3.3007e+00, -4.8387e-01, -2.7296e+00,  1.5798e-01, -2.7736e+00,\n","          5.3385e-01, -1.5696e+00,  3.7642e+00, -2.8464e+00, -2.9902e+00,\n","          9.4476e-02, -1.4616e+00, -2.1663e+00,  2.7913e+00,  1.9781e+00,\n","          3.0176e+00, -1.2145e+00, -8.8788e-01,  1.5723e+00, -5.7230e-01,\n","         -9.1037e-01, -1.4988e+00,  1.9980e-01,  1.1505e+00, -2.8784e+00],\n","        [-3.0722e+00, -1.3479e+00,  1.2709e+00, -1.2927e+00,  4.4589e+00,\n","          1.3398e+00,  1.5744e-01, -3.2509e-01, -5.8074e-01,  9.8153e-01,\n","         -4.6792e-01, -1.1314e+00, -7.0115e-01,  2.1507e+00, -3.7095e-01,\n","          1.3321e+00, -3.4023e+00,  1.9083e-01,  2.6919e+00,  3.0280e-01,\n","          2.0202e+00,  4.6820e-02, -3.0003e+00,  1.6885e+00,  1.0617e+00,\n","         -4.6604e-01,  1.0859e+00, -1.8411e+00,  2.4831e+00,  2.9619e+00,\n","         -1.3590e+00,  1.2811e+01,  1.6111e+00, -1.4167e+00, -1.3439e+00,\n","          5.2004e-01, -2.4059e+00,  1.1645e+00, -2.7584e+00,  4.2256e-01,\n","         -9.4905e-01,  4.6742e-01, -2.6402e+00, -1.9243e+00, -8.4655e-01,\n","          4.4443e-01, -3.8291e+00, -3.2575e+00, -1.3682e+00,  6.6420e-02],\n","        [-1.7524e+00,  4.1318e-01,  1.4043e-01, -2.1095e+00,  7.0833e-01,\n","          8.4525e-01, -1.8494e+00, -1.2766e+00,  9.0512e-01,  2.1310e+00,\n","          2.1545e-01,  1.3994e+00,  9.8220e-01, -1.4645e+00, -1.5355e+00,\n","          1.8223e+00,  4.2665e-01, -1.6957e+00,  1.3024e+00, -2.0236e+00,\n","         -1.1687e+00,  1.8260e+00,  4.2932e-01, -3.3030e+00,  1.0565e+00,\n","         -7.7604e-01, -4.9416e-01, -3.2972e-01,  4.9508e-01,  6.0757e-01,\n","          2.8674e+00,  1.1696e+00, -3.2233e-01, -3.1598e+00,  1.4499e-01,\n","         -3.3271e+00, -1.1154e+00,  2.6622e+00,  5.6102e-01, -3.0866e+00,\n","          1.2217e+01, -3.4882e-01,  7.0137e-01, -1.8765e+00, -6.2220e-01,\n","         -1.6128e-01,  1.2787e+00, -1.2350e+00, -1.5223e-01,  7.3949e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([32, 10, 12, 27, 36, 36, 46, 46, 47,  3, 23, 23, 20, 22, 31, 40],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8935,  8.2393, -0.8865,  ..., -1.7499, -2.1974,  2.5462],\n","        [-0.3488,  4.6880,  0.0954,  ..., -0.5641, -0.7844,  3.8269],\n","        [ 8.3500, -3.2023,  1.6135,  ...,  7.4609, -1.3092, -1.9905],\n","        ...,\n","        [ 2.0107,  0.4076, -0.7366,  ..., -2.1519,  1.6127, -0.4241],\n","        [-0.3564, 11.0555,  0.8881,  ..., -1.3197, -2.0624,  1.6957],\n","        [ 1.0463, -3.0052,  4.9726,  ..., -1.8529,  1.7251, -0.0902]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 381/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.2887, -3.7839,  0.9426,  ...,  0.2089, -0.2158, -1.0173],\n","        [-2.4544, -2.6407, -0.3507,  ..., -1.4226,  3.4467, -0.2831],\n","        [-0.5521,  3.8990,  2.2171,  ..., -0.8428,  1.7937,  1.0420],\n","        ...,\n","        [-3.4349, -2.7654, -2.9805,  ..., -1.9078, -1.7572, -0.9306],\n","        [ 0.0506, -1.7068,  2.2949,  ...,  5.3265, -1.9071, -0.9467],\n","        [ 5.6630,  0.4888,  0.9387,  ...,  2.2002, -0.4217, -0.6133]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([27, 44, 43, 28,  5, 48,  9,  3, 32,  1,  6,  3, 30,  7,  1, 16, 26, 11,\n","         3, 13, 20, 10, 42, 37, 46,  8, 14, 27, 43, 27, 23,  8,  3, 46, 30, 46,\n","        16, 13, 40, 23, 35, 42, 22, 21, 31, 22, 46, 49, 33, 36,  5, 16,  8, 16,\n","        17, 49,  4, 24, 44, 35, 43, 29,  4, 20, 15, 31,  2,  2, 14, 26, 34, 44,\n","        19, 46, 13,  0, 25,  9, 16,  7, 29, 28, 11, 14, 21,  9, 27, 19, 33, 45,\n","        18,  6,  3,  9, 34, 10,  5,  5, 27, 36, 13, 27, 41, 10, 25, 41, 21,  3,\n","         1,  8, 39, 34, 21, 26, 13, 30, 11, 37, 28, 32, 21, 30, 10, 17,  5, 28,\n","        25, 24], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.5874, -0.4274,  1.3960,  ..., -2.2515, -0.7836, -1.6622],\n","        [ 0.6383, -3.7849, -0.7022,  ..., -0.9919,  0.9927, -2.4583],\n","        [-1.1523, -1.7572, -0.0580,  ..., -2.1775, -1.1035, -1.8219],\n","        ...,\n","        [ 0.8849,  1.3829,  1.7573,  ..., -0.4565,  2.6737, -0.6375],\n","        [-1.1373, -0.7231,  1.7675,  ...,  0.6773, -0.4650, -2.4077],\n","        [-1.7662, -1.7390, -2.3233,  ..., -0.8660, -1.9639,  0.2128]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([33, 39, 12, 20, 29,  9, 44,  1, 36,  2, 18, 49,  9,  4, 10, 10, 48, 12,\n","        25, 27, 41, 42,  2,  9, 17, 26,  6, 17, 11, 29, 24, 26, 30, 46,  9, 49,\n","        28, 36, 37, 11, 40, 31, 29, 25, 28, 38,  0, 41, 15, 34, 12, 44, 37, 38,\n","        12, 23, 42, 47,  3,  6, 20, 31, 15, 38, 17, 41, 16, 22,  8, 19, 25,  0,\n","        39, 31,  7, 19, 22,  0, 12, 40, 45, 43, 32, 40, 32, 20, 20, 35,  1, 18,\n","         7,  6,  1, 47, 32,  6, 40, 30,  2, 41, 48,  0, 49,  0,  7, 29, 22, 23,\n","        24, 39,  2, 23,  3, 48, 24, 24, 30,  5, 17, 15, 47, 12, 29, 49, 48, 26,\n","        22, 45], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.3922, -3.2548,  5.0729,  ...,  0.8474, -0.4167, -3.0098],\n","        [-3.0839, -0.6355,  0.7024,  ..., -2.5628, -2.3587,  2.7419],\n","        [-1.0164,  0.4772, -0.6280,  ...,  0.9517, -0.3280, -2.1821],\n","        ...,\n","        [-0.9376, -4.2875,  1.1027,  ...,  0.3190,  0.0380,  0.0280],\n","        [-0.1889, 17.3602, -0.2395,  ...,  0.0571, -1.2674,  1.2583],\n","        [-2.2235, -3.2111, 15.7805,  ..., -1.0160,  0.3276, -0.1017]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([11,  4, 18, 26, 20,  7, 45, 10, 14, 38, 18, 44, 47, 42, 36, 37, 33, 18,\n","        31, 25, 13,  0, 15, 35,  8, 33,  7,  4, 14, 16, 12, 19, 34, 28, 38,  7,\n","        36, 17, 14,  8, 33, 16,  2, 47, 42, 17, 34, 42, 37, 32,  4, 35, 19,  4,\n","        49, 28, 11, 22, 26, 14, 30, 30, 13,  9, 20, 16, 35, 12, 10, 19, 24, 31,\n","        33, 46,  5, 43, 14, 14, 39, 24, 29,  3, 48, 37, 13, 17, 12, 27, 16, 23,\n","         1,  4, 47, 36, 32, 43, 23, 47, 47, 27,  0, 21, 37, 36, 32, 40, 20, 10,\n","        22, 31, 18, 29, 15, 41, 30, 40, 35, 41, 19,  8, 25, 48, 24, 45, 15, 27,\n","         1,  2], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.9164e+00, -2.0529e+00,  1.3329e+00, -2.0389e+00, -1.7865e+00,\n","          9.9664e-01,  2.6009e+00, -9.9533e-01, -1.3417e+00, -7.7009e-01,\n","         -2.3908e-01,  2.7455e+00,  2.4688e+00, -1.5539e+00,  1.6500e+00,\n","         -1.5008e+00,  2.1540e+00,  1.5999e-01, -1.8401e+00,  1.1710e+00,\n","          2.1827e-01, -8.0409e-01, -8.0950e-01, -7.9951e-01,  4.2384e-01,\n","          1.1512e+00,  3.2829e-01,  3.3454e+00, -2.1702e+00, -3.6057e+00,\n","          2.2785e-01, -1.2721e+00,  7.8989e-01,  3.0543e-01, -2.5356e-01,\n","          1.2188e+01, -1.1101e+00, -2.3441e+00,  1.4179e-01, -7.4009e-01,\n","         -2.0197e+00, -1.3416e+00, -1.6339e+00,  1.0990e+00,  2.7483e-01,\n","         -2.4488e+00, -7.8022e-01,  9.9486e-01, -1.5699e+00, -8.4013e-01],\n","        [ 1.1941e+00, -1.5057e+00, -6.0011e-01,  2.3644e+00, -3.9025e+00,\n","         -1.1832e+00,  4.7051e-01, -2.9940e+00,  5.6803e-01, -1.3216e+00,\n","         -3.1663e-01, -2.4814e+00, -1.6492e+00,  2.5312e+00, -1.2416e-01,\n","         -9.7640e-01,  9.8421e-02,  1.1895e+01, -8.0728e-01,  4.8937e+00,\n","          2.0817e+00, -8.7443e-01, -1.4992e-01, -9.0047e-01,  1.9336e+00,\n","          3.4686e+00, -3.3846e-01, -2.7543e+00, -1.3647e+00,  1.7716e+00,\n","          2.0526e+00, -3.4145e+00,  9.8005e-01, -2.8118e-01, -2.8113e+00,\n","         -2.8703e+00, -1.6276e+00, -1.8128e+00, -1.0317e-01,  2.3548e+00,\n","         -1.3310e+00, -3.1210e+00,  2.2666e+00,  2.5645e+00,  3.3082e-01,\n","         -3.3902e+00,  3.8393e-01,  5.2937e-01,  4.4574e+00, -3.2375e+00],\n","        [-1.9096e+00, -1.5445e+00, -1.0800e+00, -3.1694e-01,  3.6427e+00,\n","         -2.0479e+00, -6.3706e-01,  2.8791e-01,  6.6586e-01,  7.9002e-01,\n","         -3.6753e-01, -1.3131e-01,  1.0725e+00, -1.0191e+00, -2.4450e+00,\n","         -2.8505e+00, -1.8957e+00,  1.8116e-01,  2.2964e+00,  9.4791e-01,\n","         -1.6691e+00,  1.2988e+00,  1.8574e+00, -1.9100e+00,  1.6734e+00,\n","         -1.1300e+00, -6.4274e-01, -4.4380e-01,  2.3783e-01, -4.3438e-01,\n","          2.3961e+00,  8.5552e-01,  4.0848e+00, -1.9497e+00, -6.2824e-01,\n","         -2.8227e+00, -9.9458e-01,  4.9064e-01, -5.5028e-02,  1.0935e+00,\n","          2.7056e+00,  2.6375e+00, -5.1363e-01, -1.6093e+00,  1.1033e-01,\n","          8.8963e+00,  3.3145e-01, -2.0117e+00, -7.5173e-01, -1.6158e+00],\n","        [-1.9080e+00, -1.2844e+00,  9.8754e-01, -1.2282e+00,  3.2651e+00,\n","          3.4976e-01, -2.1369e+00,  8.4855e-01,  2.2704e+00,  1.8132e+00,\n","          6.0653e-01, -3.0270e+00, -1.3429e-01, -3.7021e-01, -2.6919e-01,\n","         -4.6512e-01, -7.7141e-01, -1.7486e+00,  1.5630e+00, -1.8213e+00,\n","          2.7937e+00,  1.0521e+00, -5.8241e-01,  3.6227e-02, -1.2709e-01,\n","         -1.5426e+00,  6.0433e-01, -3.8281e-01,  3.0472e+00,  1.8592e-01,\n","         -6.0747e-01,  1.1136e+01,  1.8458e+00, -2.0971e+00,  4.3321e-01,\n","         -1.1245e+00, -1.7170e+00,  1.4768e+00, -1.5510e+00, -9.6565e-01,\n","         -8.7194e-01,  2.1291e+00, -1.0580e+00, -2.0852e+00, -1.5934e+00,\n","         -9.6427e-01,  2.0136e-01, -2.9852e+00,  6.7549e-02, -1.0728e-01],\n","        [ 2.8612e+00, -1.7237e+00,  1.3563e+00,  1.0828e+00, -1.0253e+00,\n","          7.0888e-01,  1.3011e+01, -2.0631e+00,  1.1698e+00, -1.7400e+00,\n","         -1.5550e+00, -4.1286e-01, -1.7743e+00,  2.8502e-02, -1.3194e+00,\n","         -3.0832e+00, -7.3840e-01,  1.4711e+00, -1.4950e+00,  1.5384e+00,\n","          1.2840e+00, -1.9417e+00, -2.7761e+00, -3.3880e-01,  2.3163e-01,\n","          2.8331e+00,  3.9601e+00, -4.0678e-01, -1.6343e+00, -5.8915e-01,\n","          8.8373e-01, -1.1608e+00, -1.6266e+00,  4.9549e+00, -2.7118e+00,\n","          3.2359e+00, -7.9356e-01, -3.3168e+00, -1.7626e+00,  1.3386e+00,\n","         -2.6885e+00,  6.8481e-01, -1.3954e+00,  1.4177e+00, -1.2870e+00,\n","         -2.1702e+00, -2.4589e+00,  1.8762e+00,  1.8671e+00, -1.0608e+00],\n","        [-4.0853e-01, -1.8742e+00, -1.7642e+00, -1.4748e+00, -9.4728e-01,\n","         -6.3924e-01, -2.8534e+00,  4.6046e-01,  1.2543e-02,  2.2765e+00,\n","          2.1478e+00,  2.1060e-01,  3.0984e+00, -2.6230e+00, -3.2713e+00,\n","         -3.0148e+00,  3.5872e-01,  1.2791e+00,  1.6779e-01, -2.4390e-01,\n","         -4.7696e-01,  2.9343e-01,  8.8754e-01, -2.1172e+00,  1.1236e+00,\n","         -9.2927e-01, -2.0973e+00,  2.0156e+00,  2.6957e+00, -2.5703e-01,\n","          2.3160e+00,  4.9253e-02,  1.8376e+00, -2.4729e+00, -6.0732e-01,\n","         -1.5576e+00, -6.6214e-01,  1.2109e+00,  2.7057e-01, -2.1237e-02,\n","          9.6641e-02,  7.9586e+00,  2.2246e+00, -1.5155e+00,  2.2798e-01,\n","         -2.5621e+00,  1.0144e+00, -1.7015e+00,  3.5239e+00, -9.6389e-01],\n","        [ 2.6447e+00, -4.0847e-01,  2.3883e+00, -3.5894e+00, -2.4076e+00,\n","          3.4125e+00,  5.2112e-01, -5.4429e-01, -2.6671e+00, -2.1593e+00,\n","          3.5575e-01,  1.1319e+01, -6.1057e-01, -3.3690e+00, -2.7895e+00,\n","         -1.5792e+00,  2.4249e+00,  6.0792e-01, -1.5737e+00, -3.4970e+00,\n","          7.3529e-03, -4.1081e-02, -1.3313e+00, -4.7621e+00, -1.0139e+00,\n","          2.3565e-01,  1.8777e+00,  5.9108e-01,  2.6007e-01,  7.3186e-01,\n","          1.6166e+00, -2.3871e+00,  2.9886e+00,  1.6704e+00,  1.1217e+00,\n","          1.4468e+00, -4.4068e-01, -1.7461e+00,  9.6568e-01, -1.1377e+00,\n","          6.2739e-01,  4.5304e-01,  2.0654e-01,  2.3086e+00,  1.9263e+00,\n","         -3.1849e+00,  7.2444e-01, -2.1270e+00,  2.4322e+00,  3.7371e-01],\n","        [ 3.4654e+00,  1.4555e+01, -1.2093e+00,  4.7626e+00, -2.5188e+00,\n","         -2.6621e-01, -2.1719e-01, -2.8731e+00,  2.6892e+00,  2.4106e-01,\n","         -1.4641e+00, -2.1115e+00, -1.9583e+00,  9.3962e-01, -2.1652e+00,\n","         -1.3119e+00, -2.1696e+00, -3.5318e+00,  2.1996e+00,  1.1475e+00,\n","         -1.0852e+00,  5.9349e-01, -2.4932e+00,  7.9358e-01,  1.1945e+00,\n","         -2.5540e+00,  2.2658e+00, -2.0163e+00, -3.5942e+00,  8.4978e-01,\n","          4.1319e-01, -1.6581e-01, -2.8642e+00, -3.6334e+00,  4.8795e+00,\n","         -1.8861e+00,  9.7521e-01,  4.5606e+00, -1.4391e-01, -4.6906e+00,\n","         -1.8721e+00, -3.5808e+00,  1.7566e+00,  2.3632e+00,  1.2817e-01,\n","         -4.3455e+00,  6.4124e+00, -6.5693e-01, -1.1076e+00,  1.6364e-01],\n","        [-1.9293e+00, -2.3557e+00,  4.3577e-01,  1.0237e+00,  1.0236e+00,\n","         -5.5518e-01, -2.1738e+00, -1.4424e+00, -3.7686e+00,  1.0187e+01,\n","         -1.7196e+00, -3.2318e-01,  1.0686e+00, -2.1730e+00, -5.7705e-01,\n","         -7.1998e-01,  1.1904e-01, -2.2365e+00,  3.9633e+00,  3.9520e-01,\n","          3.2094e-01,  1.4937e+00,  2.0611e+00, -2.5673e+00,  2.5887e+00,\n","          8.3585e-01,  1.6765e+00,  4.5044e-02,  4.0593e-01,  1.3168e+00,\n","          2.2980e-01,  1.1290e+00,  1.0910e-01, -3.0277e+00, -2.3745e+00,\n","         -1.0671e-01, -2.0337e+00,  9.7620e-02,  2.2076e+00, -1.1667e+00,\n","          7.7193e-01,  1.8196e+00, -3.9832e-01, -2.7480e+00,  1.4591e+00,\n","         -1.9493e+00, -4.6209e-01,  2.0419e+00, -1.6446e+00, -7.1200e-01],\n","        [-4.5956e-02,  1.2030e-01,  9.9080e+00,  3.0754e+00, -3.6036e-01,\n","          4.4014e-01,  1.0028e+00, -2.4093e+00, -8.2970e-01,  4.1797e-01,\n","         -1.0779e+00, -3.2997e-01, -2.1205e+00, -2.5122e+00,  4.2356e-01,\n","         -2.4612e+00,  2.8636e+00, -4.6284e-01,  5.9214e-01,  1.1908e+00,\n","         -1.2298e+00, -6.1738e-02,  9.8791e-01, -1.7836e+00,  2.5146e+00,\n","          1.3213e+00,  3.0906e+00,  1.7935e-01, -3.5590e+00, -1.0472e+00,\n","          2.0466e+00, -6.8635e-01, -2.6388e-01,  1.3258e+00, -1.4631e+00,\n","         -5.3304e-01, -2.2357e+00, -5.6857e-01,  9.3024e-01, -7.8816e-01,\n","          4.2090e-01, -2.9161e+00, -1.4276e+00,  1.5040e+00, -6.1692e-01,\n","         -3.1156e+00,  2.5473e+00,  3.8885e-01, -6.1037e-01, -2.2169e+00],\n","        [ 5.3048e+00, -9.7754e-01,  2.8269e+00,  2.5219e+00, -1.0974e+00,\n","         -5.4338e-01, -1.9488e+00, -2.5661e+00, -2.7342e+00,  1.3567e+00,\n","         -1.4851e+00,  3.4387e+00,  6.4184e-01, -3.4656e+00, -1.4431e+00,\n","         -4.8544e+00,  1.1637e+00,  1.1134e-01,  1.2625e+00,  2.1427e+00,\n","         -1.4683e+00,  1.1323e-01,  1.6606e+00,  8.0205e-01,  1.1963e+00,\n","          1.8224e+00, -3.2381e-01, -1.3564e-01,  2.0735e-01, -2.8134e-01,\n","          2.7349e+00, -5.7839e-01, -1.5521e+00, -3.9491e+00, -2.2991e+00,\n","         -3.1838e+00, -4.7091e-01, -4.8990e-01,  1.2333e+01,  3.3600e+00,\n","          1.7026e-01, -2.1569e+00,  4.1046e-01, -8.3270e-01,  6.9592e-01,\n","         -3.1090e+00, -6.2953e-01,  1.4166e+00,  3.3279e-01, -4.1427e+00],\n","        [-1.7463e+00, -2.2058e+00, -1.8640e+00,  1.6953e-02,  2.1976e+00,\n","         -4.3673e-01, -1.2214e+00,  9.6672e-01, -9.0929e-01,  9.5070e-01,\n","          6.4196e-01, -1.0167e+00, -3.7686e-01, -1.5218e-01, -1.2100e+00,\n","         -1.5562e+00, -1.3529e+00,  3.4267e-01,  2.3416e+00, -2.2930e-01,\n","         -5.0719e-01,  6.3018e-01, -2.0533e-01, -2.0273e+00,  1.0686e+00,\n","         -1.4980e+00,  5.4806e-01, -1.4039e+00,  8.6482e-01,  2.6639e+00,\n","         -4.1719e-01,  1.9376e+00,  2.5837e+00, -6.1766e-01,  5.8316e-01,\n","         -2.0833e+00, -1.8720e+00,  4.1448e-01, -1.2427e+00,  8.4208e-01,\n","          1.6557e+00,  1.8535e+00, -5.9786e-02, -1.8287e+00,  1.1149e+00,\n","          9.2120e+00, -6.0518e-01, -3.9898e-01, -1.2145e+00, -4.4194e-01],\n","        [-2.6339e+00,  3.0865e-01, -1.3310e+00, -7.2804e-01,  2.1000e+00,\n","          2.5245e+00, -2.7040e+00, -2.7981e+00, -7.1508e-01, -3.4437e-01,\n","         -1.8415e+00, -9.2678e-01, -2.1855e+00,  6.3920e+00,  6.2059e-01,\n","          1.6660e+01,  6.3941e-01, -2.4548e+00, -1.2898e+00, -4.8986e-02,\n","         -1.1553e-01,  7.3120e-01, -3.7361e+00,  4.5812e+00, -1.1162e+00,\n","         -1.8199e+00, -1.9837e-01, -1.2017e+00, -1.1275e+00,  5.6639e+00,\n","         -3.1242e+00,  3.6969e+00,  7.1911e-01,  1.0917e+00,  1.3897e+00,\n","         -2.6823e+00, -2.2577e+00,  2.9649e+00, -1.9593e+00, -2.3668e+00,\n","         -2.5350e-01, -1.0423e+00, -2.6456e+00, -3.8340e-01, -1.2491e+00,\n","         -3.5283e+00, -2.4704e-01, -1.2299e+00, -3.4952e+00,  3.2286e+00],\n","        [-1.9757e+00,  2.1167e+00, -7.9274e-02, -6.3116e-01,  3.0679e+00,\n","          1.2724e+00, -1.5549e+00, -8.2921e-01,  3.1186e-01, -1.6134e+00,\n","         -1.3003e+00, -7.7378e-01, -3.4614e+00,  2.0742e+00, -2.8735e+00,\n","          3.0805e+00,  9.6556e-01, -1.7479e+00, -2.0780e+00, -2.1611e+00,\n","          1.9485e+00, -2.2223e+00, -3.0528e+00,  1.9470e+00, -1.2990e+00,\n","         -3.1608e+00, -1.6600e-01, -9.3361e-01, -9.7171e-01,  4.2218e+00,\n","          1.1802e+00,  4.4183e-01, -8.7999e-01, -1.8565e+00,  3.6805e+00,\n","         -2.2454e+00,  2.5104e+00,  1.6022e+00, -1.3305e+00, -3.1627e+00,\n","         -6.6202e-01,  7.8280e-01, -3.8232e-01,  2.9774e+00,  1.7098e+00,\n","         -1.4981e+00,  8.2057e-01, -1.6239e+00, -1.0271e+00,  1.3224e+01],\n","        [-2.1673e+00,  3.6513e-01,  1.4318e+00,  4.1497e-01, -6.0185e-01,\n","          7.1398e-02, -1.3180e+00, -7.8836e-02, -1.1282e+00, -9.2248e-02,\n","         -4.1673e-01,  2.5522e+00,  2.4603e+00, -1.7625e+00,  1.5039e+00,\n","         -1.1558e+00, -2.0760e+00, -4.2428e-01,  5.8899e-01,  6.3850e-01,\n","          1.1472e-01,  7.5697e-01,  1.4300e+00, -2.7307e+00, -5.9144e-01,\n","          9.2229e-01, -4.9907e-01,  3.1411e+00,  1.4304e-01,  4.3843e-01,\n","          3.2527e+00, -5.0122e-01, -6.1767e-01, -2.7174e+00, -7.1275e-01,\n","         -1.5660e+00, -1.6873e+00, -3.1172e-01,  6.3953e-01, -1.7681e+00,\n","          8.3907e+00, -5.6645e-01,  1.6235e-01, -1.0778e+00, -1.7002e+00,\n","         -1.7067e+00,  1.5033e+00,  4.8017e-01,  3.9590e-01, -1.2587e+00],\n","        [ 2.6026e+00, -5.3321e-02, -8.2490e-01, -4.9531e-01, -2.1974e-01,\n","          4.3282e-01,  7.1286e-01, -2.4601e+00,  3.0165e+00, -3.0076e+00,\n","         -5.5993e-01, -1.6447e+00, -7.9434e-01,  1.1816e+00,  2.9758e-01,\n","         -2.8863e+00, -1.9300e+00, -9.9758e-01, -1.4819e+00, -1.4063e+00,\n","          4.7581e+00, -8.4020e-01, -1.9048e+00,  3.2002e+00,  7.6207e-01,\n","         -4.8799e-01, -2.8052e+00, -1.1155e+00, -1.8250e+00, -1.4944e+00,\n","          1.1342e+00, -1.4947e+00, -7.1322e-01, -3.7108e+00,  6.1724e-01,\n","         -1.1615e-01,  1.1792e+01,  5.7777e-01,  1.7960e+00,  3.0359e-01,\n","         -6.3025e-01,  3.9295e-01,  2.9428e+00,  4.1737e+00,  1.0627e+00,\n","         -4.2388e+00, -7.6022e-01,  1.1491e+00,  1.7569e-01,  5.8826e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([35, 17, 45, 31,  6, 41, 11,  1,  9,  2, 38, 45, 15, 49, 40, 36],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8769,  8.2568, -0.8908,  ..., -1.7492, -2.1955,  2.5267],\n","        [-0.3318,  4.7086,  0.0920,  ..., -0.5578, -0.7828,  3.8084],\n","        [ 8.3699, -3.2061,  1.6101,  ...,  7.4448, -1.3028, -1.9867],\n","        ...,\n","        [ 2.0093,  0.4002, -0.7372,  ..., -2.1502,  1.6171, -0.4271],\n","        [-0.3523, 11.0764,  0.8829,  ..., -1.3187, -2.0627,  1.6877],\n","        [ 1.0538, -3.0120,  4.9535,  ..., -1.8556,  1.7311, -0.1041]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 382/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.8136, -1.1443,  2.1527,  ..., -0.1784,  0.4319,  0.8800],\n","        [-2.1480,  0.4995,  0.6385,  ..., -1.1443, -0.3158,  0.0268],\n","        [ 2.0081, -4.0181,  4.2725,  ...,  0.5379, -1.0472, -2.4920],\n","        ...,\n","        [-4.0720, -0.5553, -0.5844,  ..., -2.3235, -1.9059,  1.5801],\n","        [ 2.8395, -0.3416,  0.2115,  ..., -0.7692,  4.6694, -1.2206],\n","        [ 0.2543, -1.4001, -3.1272,  ..., -0.5270, -1.3235, -2.3414]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 5, 33, 11,  4, 42, 43,  9,  3, 31, 38, 17, 38, 42,  9,  3, 27, 16, 20,\n","        22, 34,  6, 20, 28,  6,  6, 23, 17,  1,  2, 27, 26, 31,  9,  9, 10,  6,\n","        15, 39, 17, 47, 15, 12, 33, 43, 34, 37, 47, 43, 44, 26, 15, 10, 34, 45,\n","        44, 38, 27,  5,  5, 36, 14,  8, 30, 17,  2,  9,  5, 22, 26,  4, 19, 36,\n","         0, 37, 16, 24, 44, 10, 22,  1, 13,  0, 41, 31, 26, 23, 33, 47, 13, 16,\n","        12, 43,  0,  2, 45, 22, 31, 34, 29,  9, 13, 17, 42, 17, 38, 48, 27, 39,\n","        23, 45, 36, 27, 20, 25, 18,  6, 12, 35,  1, 32, 37,  4, 48, 14, 21, 41,\n","        17, 32], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.4100, -0.4344, -1.2477,  ..., -2.1220, -1.0562,  0.0269],\n","        [ 2.0535, -3.8351,  2.2347,  ...,  0.4138, -0.9754, -2.1984],\n","        [ 0.8025,  0.0311,  0.4573,  ..., -0.6014,  1.7979, -0.2923],\n","        ...,\n","        [-1.9932, -1.0780, -2.3056,  ..., -0.5494,  0.0103, -1.1573],\n","        [-0.6533, -1.9667,  0.2511,  ..., -2.1259, -0.2401, -2.0291],\n","        [-1.2528, -0.0829,  0.8555,  ..., -1.3146, -0.1004, -0.9631]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([40, 35, 26, 11, 44,  4, 18, 16, 30, 23, 35, 11, 48, 24,  6, 37, 14, 21,\n","        35,  0, 46, 29, 42, 27, 27, 24, 28, 47,  1,  2, 27, 40, 40,  8, 36,  5,\n","        30,  1, 20, 22, 28, 36, 19, 28, 29, 18, 35,  2, 25, 29, 35, 47, 29, 21,\n","        19,  3, 33, 45,  3, 27,  2, 41, 40, 23, 14,  7, 12, 42, 12,  9, 41, 48,\n","        13, 29, 20, 27, 30, 35,  4,  8, 13, 24, 36, 40, 14, 14,  8, 18, 46, 39,\n","        18, 30, 41, 38, 31, 31, 48, 46, 15, 17, 16, 46,  9,  8, 45,  0, 12, 44,\n","        13, 45, 15, 21, 45, 26, 40, 29,  2, 49, 18, 47, 10, 23, 31,  9, 41, 32,\n","        12, 33], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.6674,  0.2943,  4.1205,  ..., -1.1954,  1.4019, -1.4395],\n","        [ 3.9901, -3.5769,  2.2014,  ...,  3.3924,  1.8682, -2.3861],\n","        [ 6.8179,  2.5194,  3.4610,  ..., -1.3421,  1.9264, -2.6066],\n","        ...,\n","        [-2.2591, -1.5969, -0.5419,  ..., -2.2800, -2.6262,  2.3214],\n","        [ 4.3141,  2.0306,  1.5334,  ...,  3.5225, -0.1901, -1.8578],\n","        [-0.7205, -1.4463,  1.5629,  ..., -1.2697,  0.1062, -0.4567]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([26, 25,  3, 11,  4, 26, 49, 10, 34,  7,  1, 29,  1,  0, 30,  0, 15,  8,\n","        46, 41, 38, 22,  5, 19,  7, 19, 49, 11, 46, 14, 47, 32, 48, 16, 30, 23,\n","        20, 20, 19,  7,  8, 24, 24,  1, 12, 31, 48, 32, 33, 10,  2, 35, 13, 29,\n","         3, 28, 16, 25, 37, 21, 30,  0, 43, 30, 20, 22, 47,  3, 46,  7, 49, 31,\n","        17, 28,  3, 41, 11, 37,  6, 34,  8, 22, 15, 24, 41, 39, 16, 43, 12, 16,\n","        32, 37, 42, 16, 28, 32, 40, 25, 49, 13, 32,  5, 15, 39, 49, 11, 25, 10,\n","         9,  2, 28, 25, 49, 25, 40, 14,  4, 20,  3,  7, 19, 33, 36, 42, 18,  4,\n","        24, 14], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1049e+00,  6.2430e-01, -1.0660e+00, -1.4732e+00, -5.6156e-02,\n","         -6.1106e-01, -4.8455e-02,  9.8758e+00, -8.4292e-01,  3.3461e-01,\n","         -1.5971e+00, -5.1095e-01,  4.6179e-01, -7.1064e-01, -4.7752e-01,\n","          7.6860e-03, -3.7460e-01,  1.4125e-01,  5.9003e-01, -1.3240e+00,\n","         -6.5442e-01, -3.3316e-01,  4.2205e-01, -1.9176e+00, -1.5683e+00,\n","         -9.9516e-01,  9.3372e-01,  2.3871e-01,  2.4142e+00, -1.0282e+00,\n","         -9.2418e-01,  9.0001e-01,  2.5544e+00,  7.1550e-01,  5.8835e-01,\n","          7.1779e-01, -1.7670e+00,  1.3369e+00, -1.6560e+00,  1.1998e+00,\n","          7.4811e-01,  1.6853e+00, -9.0364e-01, -1.1765e+00, -1.9264e-01,\n","          1.0180e+00,  2.9810e-01, -1.2323e+00, -1.2343e+00, -1.4877e-01],\n","        [-2.0065e+00, -1.8625e+00, -1.9578e-01, -2.2008e+00, -1.8688e-01,\n","          7.7545e-01, -5.8933e-01, -1.0842e+00,  3.6060e-01,  9.8896e-01,\n","         -1.8697e+00,  1.1757e+00,  1.9929e+00, -1.7054e-01,  2.0007e+00,\n","          9.3131e-01, -8.8638e-01,  1.8438e+00, -1.2661e+00, -2.5983e-01,\n","         -1.8159e+00,  3.8989e-01, -4.3681e-01, -1.8577e+00, -2.6779e-01,\n","          3.8454e-01,  2.7993e-01,  8.6800e-01,  4.7509e-01,  9.1575e-01,\n","         -2.2181e+00, -2.4129e-01,  2.9642e+00, -1.1684e+00, -8.2972e-01,\n","          2.2678e+00,  2.2524e-01, -5.1651e-01,  1.4564e+00, -9.7333e-01,\n","          6.0450e-01, -1.3954e+00, -1.4507e+00, -8.7704e-01,  1.1436e+01,\n","          5.0567e-02, -3.3916e-01, -2.3813e+00, -3.6172e-01,  5.3653e-02],\n","        [-7.1398e-01,  1.2313e+01,  1.4654e-01,  1.5790e+00, -1.6234e+00,\n","          2.1939e+00,  1.1413e+00, -9.9762e-01,  1.3979e+00,  1.3888e+00,\n","         -3.3052e+00,  1.6671e-01, -2.0869e+00, -7.4888e-01, -2.1115e+00,\n","          1.2901e+00, -5.6515e-01, -1.8899e+00,  2.4633e+00, -1.2391e+00,\n","         -8.4681e-01, -1.0407e+00,  5.0657e-01, -8.3030e-01,  1.2214e+00,\n","         -1.5080e+00,  1.2925e+00,  1.3835e+00, -2.0197e+00,  1.4995e+00,\n","         -1.0102e+00,  1.9699e+00, -6.3567e-01,  4.0159e-01,  4.2445e+00,\n","          1.7421e-01, -1.2250e+00,  3.6532e-01, -5.0411e-01, -3.1810e+00,\n","         -4.9183e-01, -3.1829e+00, -1.1166e+00,  5.5559e-01, -2.1411e+00,\n","         -2.0807e+00,  1.5334e+00,  7.2377e-01, -2.2453e+00, -4.4777e-01],\n","        [ 2.3060e-01, -3.0963e+00,  3.8439e+00,  1.2307e+00,  1.2931e+00,\n","          1.6311e+00,  4.7732e-01, -2.9701e+00, -2.4231e+00,  4.1849e+00,\n","         -2.4952e+00, -6.7645e-01, -6.2031e-01, -6.1069e-01, -1.2351e+00,\n","          8.8135e-01,  1.1357e+00, -2.8900e+00,  3.0372e+00, -2.6135e+00,\n","          3.5345e+00,  1.2200e+01, -1.1703e+00,  7.8491e-01,  1.0070e-01,\n","          8.1890e-01,  1.0298e+00,  2.9087e+00, -2.0988e+00,  4.1673e-01,\n","         -1.4239e+00,  1.0423e+00, -2.0113e+00, -3.0777e+00, -1.3168e+00,\n","          3.9056e-01, -2.1085e+00,  1.3617e+00,  1.9640e+00, -9.9833e-01,\n","         -6.3832e-01, -1.0256e+00,  3.4558e-01, -4.2457e-01, -2.1571e+00,\n","         -3.3925e+00,  5.5586e-01, -7.0281e-01, -2.0418e+00, -5.6865e-01],\n","        [-7.9067e-01, -2.1905e+00,  1.9762e+00, -1.0942e+00,  3.7633e-01,\n","          2.2247e+00, -3.6900e-01, -2.6028e+00, -3.5150e-01,  1.1082e+00,\n","          1.0429e+01, -4.7807e-01,  2.5907e+00, -3.6513e+00, -1.3212e+00,\n","         -3.2107e+00, -2.7733e+00,  3.7334e+00, -3.6578e-01, -2.9758e+00,\n","          2.7224e-01, -1.3783e+00, -9.0252e-01, -1.2412e+00, -2.0049e+00,\n","         -1.6780e+00,  1.3131e+00,  1.8511e+00, -1.9586e-02, -9.3790e-01,\n","          1.8095e+00,  1.0725e+00,  2.8202e-01, -2.3444e+00, -2.2132e+00,\n","         -1.0124e+00, -2.1099e-01, -3.1904e-01, -3.7451e-01, -2.7386e+00,\n","          1.0925e+00,  1.5979e+00,  3.7457e+00,  1.3484e+00,  2.2076e+00,\n","         -1.6690e+00,  7.7684e-01, -2.2481e+00,  6.4919e+00, -3.0234e+00],\n","        [ 8.8921e-01, -4.0470e+00,  3.8509e+00, -2.9467e+00,  6.6440e-01,\n","         -5.7383e-01,  3.7163e-02, -1.0347e+00, -3.2704e+00, -2.3806e-01,\n","         -1.7985e+00,  1.4661e+01, -6.6623e-01, -3.7573e+00, -2.2628e+00,\n","         -4.5292e+00,  1.4316e+00, -1.4522e+00,  7.0810e-01,  1.8950e+00,\n","         -3.0745e+00,  5.4792e-01,  1.0498e+00, -3.5458e+00,  7.9994e-01,\n","          3.7811e+00,  9.2669e-01,  4.5163e+00, -2.4665e-01,  1.4489e+00,\n","          2.3241e+00, -1.2635e+00,  1.2590e+00, -2.0566e+00, -2.6091e+00,\n","         -1.7263e+00, -2.4944e+00, -3.2787e+00,  7.1169e+00,  2.3529e+00,\n","          4.0654e-01,  1.3479e+00, -1.2009e+00, -2.3657e+00, -1.7801e+00,\n","          5.1699e-01, -1.6939e+00,  3.2405e+00, -1.5902e+00, -2.2416e+00],\n","        [ 1.0127e+00, -8.6159e-01,  1.8043e+00,  5.5942e+00, -8.6922e-01,\n","         -5.1083e-01, -2.0447e-01, -4.0344e+00, -2.0195e+00,  2.7060e-01,\n","         -2.1610e+00,  1.2839e+00, -1.0209e+00, -1.5107e+00, -1.1347e+00,\n","         -3.9323e+00,  1.9611e+00, -1.7134e+00,  9.3522e-01,  2.5902e+00,\n","         -4.4806e-01, -9.7172e-01, -1.1744e+00, -2.1788e+00, -5.1410e-01,\n","          1.6032e+00,  4.9191e-01, -7.5317e-01, -1.2012e+00,  9.7260e-02,\n","          1.3248e+01, -7.6255e-01, -5.5568e-01, -2.2190e+00, -6.2977e-01,\n","         -6.0094e-01, -9.9123e-01, -1.2996e-01,  1.8160e+00,  8.0653e-02,\n","          3.6850e+00,  9.3975e-01, -2.0164e+00, -6.3066e-01, -2.7413e+00,\n","         -8.3612e-01,  2.8691e-01,  2.6016e+00, -2.1330e-01, -9.2876e-02],\n","        [-1.8498e+00,  1.3345e-01,  4.2636e-01, -1.5901e+00,  3.5949e+00,\n","          2.8254e-01, -2.9657e+00, -3.7968e+00,  1.4302e+00, -2.1381e+00,\n","         -1.8954e+00, -1.0810e+00, -3.4596e+00,  4.0378e+00, -1.5454e+00,\n","          5.3996e+00,  1.0025e+00, -2.8005e+00, -1.9322e+00, -2.2238e+00,\n","          1.1241e+00,  6.0709e-02, -2.0378e+00,  3.1122e+00, -1.7718e+00,\n","         -2.3330e+00,  3.0568e-03, -7.0887e-01, -1.9194e+00,  5.6419e+00,\n","          4.8915e-01,  1.5922e+00,  1.6341e+00, -1.9033e+00,  2.7199e+00,\n","         -2.2932e+00,  1.3696e-01,  1.2216e+00,  1.8703e-01, -2.4679e+00,\n","          1.3383e+00, -1.0003e+00, -1.2005e+00,  2.6294e+00,  4.4730e-01,\n","         -6.3291e-01,  9.1356e-01, -2.0809e+00, -1.2374e+00,  1.2862e+01],\n","        [ 5.0470e+00, -2.4252e-01,  2.3914e-01,  1.7051e+00, -6.7682e-01,\n","         -1.3627e+00,  3.4559e+00, -4.9175e+00,  1.0173e-01, -1.1293e-01,\n","         -4.4097e+00, -1.4933e+00, -1.4326e+00,  1.5360e+00,  2.2331e+00,\n","         -5.7133e-01,  2.0233e+00, -2.7115e+00,  2.2631e-01,  3.8667e+00,\n","          4.2068e-01, -9.0040e-01,  2.0055e-01, -3.9582e-01,  1.3260e+01,\n","          3.0473e+00,  1.1821e+00, -2.6434e+00, -2.6707e+00,  1.4977e-01,\n","         -2.1276e-01,  1.4325e+00,  9.7323e-02, -1.6035e+00, -1.3981e+00,\n","          2.0976e+00, -2.0293e+00, -2.4923e+00, -9.3414e-01,  5.0342e-01,\n","         -1.1859e+00,  8.9266e-01, -2.1173e+00,  8.8172e-01, -4.2587e-02,\n","         -1.9010e+00, -1.8932e+00,  1.9448e+00, -2.3255e+00, -5.0059e-01],\n","        [ 7.2627e-01, -2.6294e+00,  8.0976e-01,  6.0120e+00, -2.7638e+00,\n","         -9.1561e-01,  3.3240e+00, -4.2470e+00,  1.2099e-01,  7.4214e-01,\n","         -5.0959e+00, -2.3385e-01, -3.0499e+00,  1.8569e+00, -1.1232e+00,\n","         -1.8591e+00,  3.2351e+00, -9.9843e-01,  3.3619e+00,  1.4916e+01,\n","         -1.8529e+00, -3.1477e+00,  2.5037e-02, -1.4116e+00,  4.7385e+00,\n","          2.8371e+00,  4.1182e-01, -1.9855e+00, -1.8367e+00,  1.4547e+00,\n","          2.9316e+00, -1.7442e+00, -1.7365e-01,  1.9302e+00, -6.3256e-01,\n","          1.1411e-01, -5.1867e+00, -2.5993e+00,  2.0773e+00,  2.3120e+00,\n","         -2.5650e+00, -9.4665e-01, -3.6447e+00, -1.9672e-01, -2.3924e+00,\n","         -1.2590e+00,  4.4895e-01,  4.2294e+00, -8.6691e-01, -3.4269e+00],\n","        [-8.6528e-01,  3.7566e+00, -1.1626e+00, -1.2102e-01, -1.7613e+00,\n","          1.0316e+00, -1.4285e-01,  1.1601e+01, -1.9808e+00,  1.7816e+00,\n","         -2.1169e+00, -1.4981e-01, -1.5617e-01, -2.1379e+00, -1.9422e+00,\n","         -8.0000e-02, -1.1646e+00, -1.2658e+00,  8.9983e-01, -2.3275e+00,\n","         -6.7394e-02,  1.1010e+00, -9.2840e-02, -1.3177e+00, -1.7716e+00,\n","         -1.7805e+00,  2.5424e+00, -8.3272e-01,  3.4414e+00, -1.5520e+00,\n","         -2.7202e+00,  1.0374e+00,  8.3740e-01, -5.6353e-01,  6.7465e-01,\n","         -6.9608e-01, -2.3561e+00,  3.0339e+00, -9.3222e-01, -2.6066e-01,\n","          1.3010e+00,  1.4071e+00, -1.4298e-01, -3.3997e-01, -8.1424e-01,\n","         -1.4800e-01,  2.6999e+00, -2.1179e+00, -4.9183e-01, -4.2510e-01],\n","        [-2.2893e+00,  3.7324e-01, -1.6820e+00, -5.4225e-01,  3.7923e+00,\n","          6.3396e-01, -2.2347e+00, -3.1358e+00,  2.3987e+00, -6.6298e-01,\n","         -1.1050e+00, -2.4850e+00,  8.7532e-01, -2.1100e-02, -7.5285e-01,\n","          2.4867e+00, -1.8979e+00, -4.4720e+00,  3.1252e+00, -3.3178e+00,\n","          5.3854e-01,  2.1519e+00, -2.6334e+00,  4.4458e+00, -2.3166e+00,\n","         -3.3018e+00, -8.5546e-01,  2.4560e-01,  6.0235e-01,  4.9093e+00,\n","         -2.2634e+00,  4.5982e+00, -7.2078e-01, -2.1184e+00,  5.0032e+00,\n","         -3.0997e+00,  4.7873e-01,  1.2036e+01, -1.4534e-01, -3.4355e+00,\n","          2.7385e+00,  3.0127e+00,  3.0792e-01, -1.3184e+00, -9.2996e-01,\n","         -1.2892e+00, -2.3014e-01, -4.3404e+00, -2.5818e+00,  9.3924e-01],\n","        [ 1.5609e+00, -2.0587e+00,  1.7818e-01, -9.0673e-01, -1.2862e+00,\n","          1.2768e-01, -6.7331e-01, -8.7759e-01, -1.3508e-02, -9.5221e-01,\n","          2.2667e+00, -1.5173e-02,  5.5885e-01, -1.4033e+00,  1.2575e+00,\n","         -1.2851e+00,  7.5541e-02,  1.1760e+01, -1.4989e+00,  1.2788e+00,\n","         -5.0124e-01, -5.3384e-01,  1.1167e+00, -2.2007e+00, -8.3427e-01,\n","          1.7713e+00,  7.6832e-01, -6.9721e-01, -6.7433e-01, -3.6567e-01,\n","          1.2934e+00, -1.4152e+00,  1.1434e+00, -2.7097e-01, -3.4491e+00,\n","         -4.5101e-02, -1.8178e+00, -2.4943e+00,  5.7081e-01,  6.5687e-01,\n","         -9.4715e-01, -2.2233e+00,  1.7594e+00,  1.2078e+00,  7.9969e-01,\n","         -1.7327e+00,  4.6362e-01, -1.5360e+00,  1.9903e+00, -1.9305e+00],\n","        [ 3.7375e+00,  1.1169e+00,  1.4965e+00, -6.9465e-01,  7.9780e-02,\n","          1.2914e+00,  1.4922e+00, -4.8525e+00,  3.2997e+00, -2.2885e+00,\n","         -1.3242e+00, -7.2543e-01,  9.3884e-01, -1.6000e+00,  1.1780e+00,\n","         -2.9568e+00, -8.8440e-01, -1.5949e+00, -2.1611e+00, -2.4867e+00,\n","          3.8340e+00, -1.3061e+00, -1.4470e+00,  1.4279e+00, -2.4982e-01,\n","         -1.1290e+00, -2.1373e+00, -1.3084e+00, -1.7246e+00, -1.3110e+00,\n","          1.0692e-01, -1.0043e+00, -5.9095e-01, -3.2562e+00,  2.1507e+00,\n","          1.3558e+00,  9.5389e+00, -3.1153e-01,  2.2062e+00, -2.4927e+00,\n","         -5.1749e-01, -1.9423e+00,  2.7676e+00,  7.1244e+00,  1.1859e+00,\n","         -4.0587e+00,  1.0571e+00, -6.2250e-01,  4.2359e-01,  6.8916e-01],\n","        [-3.1431e-02, -1.0146e+00,  1.6286e+00, -8.2115e-01,  2.1651e-01,\n","         -9.4806e-01, -1.8882e+00, -2.0535e+00,  7.0965e-01,  3.4051e-01,\n","          1.1853e+01, -4.8818e-01,  6.2275e-01, -1.5136e+00, -7.7074e-01,\n","         -2.1523e+00, -1.0000e+00,  4.7479e+00, -1.0857e+00, -2.6261e+00,\n","         -1.2020e-01, -7.5144e-01,  3.0467e-01, -9.1054e-01, -7.4509e-01,\n","         -2.1656e+00, -9.1992e-02, -1.3820e+00, -5.1488e-01, -2.4862e+00,\n","          1.9189e-01, -6.7302e-01,  1.6445e+00,  3.7999e-01, -6.2775e-01,\n","         -1.6355e+00, -1.7409e+00, -1.1837e+00, -1.6091e+00, -1.2100e+00,\n","         -5.0953e-01,  1.9745e-01,  4.9727e+00,  7.9615e-01,  2.6672e+00,\n","         -4.8555e-01,  2.6876e+00, -2.2024e+00,  5.4895e+00, -2.1254e+00],\n","        [ 2.1876e+00, -4.6885e-01, -2.4603e-02, -5.2968e-01,  9.7157e-02,\n","          1.0155e+00,  5.2258e-01, -3.1335e+00, -3.0767e-01, -4.2788e-01,\n","         -2.4174e+00, -1.3958e+00, -2.1249e+00,  1.4821e+00, -2.8572e+00,\n","         -2.0269e+00,  2.2616e-01, -9.0426e-01, -1.2418e+00, -1.2478e+00,\n","          7.1472e+00, -1.4513e+00, -2.2611e+00,  1.1588e+00,  1.2512e+00,\n","          6.9889e-01, -2.4084e+00, -6.6275e-01, -2.6341e+00,  1.6518e+00,\n","          2.2182e+00,  2.1072e+00,  7.5804e-01, -2.6040e+00,  5.5980e-01,\n","         -7.1056e-01,  1.1012e+01, -1.1393e+00, -1.3961e-01, -2.5755e-01,\n","         -4.9520e-01,  5.0615e-01, -2.0727e-01,  1.8955e+00,  1.2697e-01,\n","         -2.1867e+00, -3.8767e-01,  1.0242e+00,  4.3859e-01,  1.3783e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7, 44,  1, 21, 10, 11, 30, 49, 24, 19,  7, 37, 17, 36, 10, 36],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8717,  8.2434, -0.8844,  ..., -1.7518, -2.1980,  2.5436],\n","        [-0.3231,  4.7001,  0.0991,  ..., -0.5489, -0.7870,  3.8097],\n","        [ 8.4187, -3.2094,  1.5968,  ...,  7.4497, -1.2999, -1.9845],\n","        ...,\n","        [ 2.0139,  0.3938, -0.7352,  ..., -2.1496,  1.6203, -0.4234],\n","        [-0.3461, 11.0410,  0.8890,  ..., -1.3170, -2.0606,  1.6904],\n","        [ 1.0533, -3.0214,  4.9581,  ..., -1.8523,  1.7292, -0.0996]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 383/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.3580, -2.9453,  2.2202,  ..., -0.0054, -0.1184, -1.3968],\n","        [-3.6085, -2.3654, -0.2497,  ...,  0.6909, -2.0599, -0.5748],\n","        [ 2.0655,  1.2256,  1.7277,  ..., -1.8440,  3.9943, -2.0770],\n","        ...,\n","        [-1.0809, -2.0536,  2.2131,  ..., -0.3727,  0.7514,  0.1347],\n","        [-3.2808, -3.7234,  2.5740,  ..., -1.0622, -1.1372, -0.0759],\n","        [ 2.5289, -0.8577,  0.0156,  ..., -0.9087,  2.9492, -1.2801]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([30,  9, 26, 33,  2, 17, 31, 27, 35, 16, 10, 25, 28, 35, 37, 15, 20, 48,\n","        32, 42, 42, 26, 38, 47,  6, 33, 38,  0, 28, 32, 16, 30,  3, 31, 24,  9,\n","        23, 14, 21, 23, 37, 18, 42, 49,  8,  4, 45, 26, 49, 23, 29, 13, 11, 41,\n","        37, 48, 12,  1,  8, 40,  7, 20, 10, 47, 27, 46,  0, 36, 29, 40, 15,  7,\n","        22, 32, 15, 14,  8, 34, 38, 19,  2, 38, 46, 36, 33, 45, 10,  3, 27, 20,\n","        48, 35, 35, 47, 48, 22, 36, 18, 43, 23, 21,  8, 47, 17,  0, 12,  8, 32,\n","        26, 20, 33, 14, 32, 37,  0, 42, 45,  9, 25, 16, 22,  6, 45, 36, 16,  5,\n","        27, 17], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 6.0076, -0.5651,  1.5906,  ...,  2.4663,  2.4786,  0.6143],\n","        [ 3.7947,  1.8843, -0.0854,  ...,  1.7646, -1.3321, -1.5737],\n","        [-0.8687,  0.1671,  1.6993,  ..., -1.2428, -2.1319, 17.4273],\n","        ...,\n","        [ 0.2361, -0.5970,  2.3776,  ...,  0.3013, -0.4746, -1.4049],\n","        [-0.9882,  1.1151, -0.1358,  ..., -1.0267, -0.1305,  1.4480],\n","        [ 4.4961,  3.8791,  0.8011,  ...,  1.8001, -1.5623,  0.3590]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 6, 19, 49, 13, 25, 30,  7, 12, 36,  1, 38,  9, 22, 17, 46, 18, 30, 18,\n","        48, 39, 41, 32, 13,  4, 13, 23, 29, 41, 40,  9, 35, 14, 27, 10, 24, 23,\n","        26,  4, 28, 17, 33, 16, 15, 26, 41, 21,  0, 24, 17, 37, 20, 35, 36, 39,\n","        13, 20, 49,  6,  3, 36, 29, 20, 13, 48,  7, 46, 44, 36, 11, 18, 37, 16,\n","        40, 40,  2, 24,  8, 12, 25,  7, 25,  7, 11, 41, 37, 38, 20, 35,  9,  3,\n","        31,  2, 28, 34, 16, 14, 19, 49, 27, 15,  7, 10, 10, 49, 44,  8, 34, 43,\n","        12,  9, 31,  3, 47,  1, 45, 11, 18, 31, 33, 28, 14, 30,  2, 47, 17, 19,\n","        34, 24], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1176, -2.3022, -1.5995,  ..., -1.3238, -1.4276, -0.1737],\n","        [-1.8364, -1.3041, -0.8577,  ...,  0.2829,  2.2067, -0.3798],\n","        [-2.1159, -0.0976, -0.9007,  ..., -0.9480, -2.7880,  1.6805],\n","        ...,\n","        [ 4.5859,  0.7028,  0.5349,  ...,  3.1105, -1.3735, -2.7977],\n","        [-1.3104, -1.0217, -1.3658,  ..., -0.2209, -2.1413, -1.4420],\n","        [-2.3106, -0.4500,  1.9801,  ...,  1.1555, -1.4680, -1.3799]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([21, 44, 13, 30, 25, 32, 33, 22,  1, 45, 28, 30, 10,  3, 16, 46,  5, 29,\n","         3,  2, 15, 28, 44,  3,  1, 36, 19, 21, 12,  1,  5,  4, 11, 31, 42, 17,\n","        46,  2, 30,  6,  3, 12,  4, 27, 28, 41, 40,  9, 48, 16,  1,  8, 40, 44,\n","        44, 15, 35, 30, 29,  9, 16, 26,  0,  6, 25, 49,  2, 12, 26,  4, 24, 20,\n","        10, 17,  4, 14, 14, 22, 29, 46, 41, 10, 19, 41,  1, 24, 27, 31,  9, 11,\n","        41, 23,  5, 14, 13, 42, 11, 31, 47, 19, 12, 34, 49, 29, 27,  6,  1,  4,\n","         0, 45, 15, 11, 43, 43, 39, 43, 31, 39, 29, 47, 34, 24, 43, 37, 25, 24,\n","        18, 21], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.7371e+00,  3.6340e+00, -2.0199e+00,  1.5371e-01,  1.4996e-01,\n","         -1.7574e+00,  2.8692e-01,  1.3550e+01, -7.6571e-01,  1.1218e+00,\n","         -1.7629e+00, -1.4446e-01,  5.2520e-01, -2.1128e-01, -7.7206e-01,\n","         -3.2512e-01, -1.7491e+00, -1.1498e+00,  2.4698e+00, -1.6412e+00,\n","         -7.8339e-01,  1.1920e+00,  1.6926e-02, -4.4639e-01, -1.1828e+00,\n","         -1.6196e+00,  5.0770e-01, -1.3573e+00,  3.2963e+00, -2.8242e+00,\n","         -2.7778e+00,  3.5815e-02, -4.4395e-01, -5.6404e-01,  1.1828e+00,\n","         -1.7074e-01, -2.1354e+00,  4.0897e+00, -1.7377e+00, -2.4088e-01,\n","          3.2906e-01,  9.7576e-01,  1.9720e-01, -8.9052e-01, -1.1059e+00,\n","          5.9603e-01,  1.2087e+00, -1.2171e+00, -1.0398e+00, -1.3226e-01],\n","        [-1.6719e+00,  5.2998e-01,  1.0946e+01,  1.6502e+00,  7.0669e-02,\n","         -7.4654e-01,  2.2568e+00, -2.9051e+00, -1.1842e-01, -1.6879e-01,\n","         -2.2835e+00,  1.5277e+00, -1.0652e+00, -2.6677e+00, -1.6167e+00,\n","         -2.0548e+00,  8.8843e-01, -2.1612e+00, -2.1588e+00,  4.8069e-02,\n","          2.0568e+00, -1.7045e-01, -9.0222e-01,  3.6997e-01,  7.3959e-01,\n","          1.5058e+00,  1.3220e+00,  4.0571e-01, -1.5160e+00, -3.8317e-01,\n","         -6.1307e-02,  1.6362e-01, -2.6122e+00,  1.2300e-02,  7.1215e-01,\n","          1.8147e+00, -2.0832e+00, -6.0950e-01,  2.8771e+00, -1.7425e+00,\n","         -6.2378e-01,  2.2731e+00, -3.4814e+00,  2.2423e+00, -1.5770e+00,\n","         -3.3028e+00,  1.0364e+00,  4.3293e-01,  1.3663e+00,  2.4399e+00],\n","        [ 4.9070e-01,  1.8417e+00, -2.2909e+00, -3.1835e-01, -1.5969e+00,\n","          8.8020e+00,  2.5939e+00, -5.7844e+00,  2.4892e+00,  2.6126e-01,\n","         -5.2352e-01,  2.3561e-01, -1.6884e+00,  3.0183e+00,  1.7045e+00,\n","          1.1664e+00,  4.6736e-01, -1.5728e+00,  1.0910e+00,  5.5597e-01,\n","         -6.3896e-02, -9.7410e-01, -5.6588e+00, -2.0299e+00,  3.9066e-01,\n","         -2.5317e+00,  2.2008e+00,  1.3909e-01, -1.2099e+00,  3.1298e+00,\n","         -4.5306e-01,  5.5216e+00, -9.3446e-02,  1.0357e-01,  3.3739e+00,\n","         -1.0145e+00, -5.7820e-01,  3.8643e+00, -3.8639e-01, -4.0073e+00,\n","          1.4670e+00,  9.7845e-01, -8.4988e-01,  1.1064e+00,  2.0855e+00,\n","         -2.6833e+00, -8.7382e-01, -2.5925e+00, -3.3134e+00, -2.5198e+00],\n","        [ 3.9595e+00,  1.1775e+00, -6.6609e-01, -6.9415e-01,  6.9595e-01,\n","         -2.5438e+00, -8.8348e-01, -1.5104e+00,  1.9070e+00,  7.8586e-01,\n","          3.2049e+00,  5.7451e-01,  4.5428e-04, -2.6326e+00, -2.6389e+00,\n","         -3.8680e+00, -1.4443e+00,  2.5138e+00,  9.7345e-01, -6.1857e-01,\n","          9.7027e-01,  9.0592e-02, -1.6484e+00, -1.4765e+00, -5.1409e-01,\n","         -1.2966e+00, -1.4017e+00, -1.4539e+00, -4.5601e-01, -1.6732e+00,\n","          3.2433e-01, -2.3924e+00, -1.0112e+00, -3.7806e+00, -2.1448e-01,\n","         -1.4315e+00,  1.4244e+00,  2.4547e+00,  1.0677e+00, -1.9601e+00,\n","          6.1757e-01, -9.8763e-01,  1.3006e+01, -2.8149e-01,  1.2417e+00,\n","         -1.6616e+00,  3.9474e+00, -1.4428e-03,  2.0425e+00, -1.0535e+00],\n","        [-1.1273e+00,  7.4828e-01,  8.1443e-01, -1.9275e+00,  4.2701e-01,\n","          1.0308e+01, -6.5417e-01, -1.4618e+00, -1.2344e+00,  1.8499e+00,\n","          1.0294e+00, -1.0730e+00, -2.6924e+00, -2.3655e+00, -3.0395e+00,\n","          3.4990e+00,  5.5800e-01, -1.2237e+00, -1.0585e+00, -3.1820e+00,\n","          6.5142e-01, -4.4052e-02, -4.9485e+00,  1.0658e-01, -6.8881e-01,\n","         -3.3497e+00,  2.1065e+00,  3.7568e-01, -9.7413e-01,  5.0388e+00,\n","         -2.4268e+00,  3.8971e+00,  6.2758e-02, -4.8530e-01,  3.8673e+00,\n","         -2.3484e+00,  6.4699e-02,  2.6449e+00,  2.4712e-01, -3.8275e+00,\n","         -5.4527e-01,  5.1939e-01, -1.9216e+00,  2.0977e+00,  1.5393e+00,\n","         -2.2053e+00,  2.4597e+00, -1.0485e+00,  9.6975e-01,  2.7211e+00],\n","        [ 1.1640e+00, -8.4531e-01,  9.5369e-01, -2.5201e+00, -7.9624e-01,\n","          8.5683e+00,  1.8269e+00, -1.9957e+00,  1.1298e-02, -8.3019e-01,\n","          9.7625e-01,  1.4002e+00, -3.7445e+00,  1.7824e+00, -3.6160e+00,\n","          2.2201e+00, -5.1386e-01, -1.3783e+00,  4.8646e-01, -3.1858e+00,\n","          5.2541e+00,  1.1186e+00, -5.2098e+00, -1.4488e+00, -1.8670e+00,\n","         -2.3215e+00,  3.4351e+00, -1.0286e+00, -2.2667e+00,  3.1640e+00,\n","         -5.1837e-01,  1.5583e+00,  1.0380e+00,  1.6775e+00,  3.6556e-01,\n","         -2.3122e+00,  3.3852e+00, -2.3162e+00, -1.5672e+00, -2.1499e+00,\n","         -1.6815e+00, -7.0894e-01,  8.4157e-01,  2.8967e+00,  1.4426e+00,\n","         -2.2126e+00,  1.3570e-01, -2.1203e-01,  6.3867e-01,  1.2462e+00],\n","        [-2.5719e+00, -1.8100e+00,  6.3741e-01, -1.4182e+00,  1.1698e+00,\n","         -4.3741e-01, -1.0629e+00, -3.0021e+00,  1.2290e+00,  1.3774e+00,\n","          2.8467e-01,  5.2683e-01,  2.6260e+00, -1.3989e+00,  9.6681e-01,\n","          4.1678e-01, -9.8099e-01, -1.7026e+00, -2.7621e-01, -1.7203e+00,\n","          3.9692e-02,  2.4969e+00,  4.3717e-01, -5.0723e-01,  6.9116e-02,\n","          8.9419e-01, -1.5800e+00,  5.6118e-01,  4.0589e-01,  2.0886e+00,\n","          3.0109e+00,  7.8261e-01, -1.5670e+00, -2.4912e+00, -8.2089e-01,\n","         -3.0616e+00, -4.7695e-01,  3.2848e+00, -1.3921e-01, -3.0924e+00,\n","          1.1894e+01,  3.4575e-01,  2.0730e-01, -8.1207e-01, -1.3955e+00,\n","         -6.6457e-01,  8.0020e-01, -2.0262e+00, -5.8537e-01,  8.0442e-01],\n","        [-1.3982e+00, -3.4123e+00,  2.1177e-01, -1.7901e+00,  7.6095e-01,\n","         -2.6272e-01, -3.0171e-01, -1.2797e+00, -1.5107e+00,  1.4296e+00,\n","         -1.4430e+00,  2.0685e+00,  6.8443e-01, -1.9408e+00,  4.2460e-03,\n","          4.9992e-01,  1.9281e+00, -9.3271e-02,  5.7660e-01, -1.0794e+00,\n","         -1.2598e+00,  1.6616e+00, -7.4122e-01, -6.6398e-01, -8.5738e-01,\n","          1.2479e+00,  1.1519e-02,  1.2131e+01,  1.0997e+00,  1.0239e+00,\n","         -5.4281e-01,  1.0990e-01,  4.5898e-01, -1.4196e+00, -6.8294e-01,\n","          2.3361e+00, -4.6166e-01, -4.4207e-01,  6.2477e-01, -7.4155e-01,\n","         -1.1480e+00,  2.1020e+00, -1.0971e+00, -1.1896e+00, -8.4729e-02,\n","         -1.8023e+00, -2.1903e+00,  5.9706e-01, -3.0437e-01,  1.8197e-01],\n","        [-2.5049e+00, -1.3048e+00, -3.0546e+00, -6.3102e-01,  2.4127e+00,\n","         -2.0687e+00, -2.3810e+00,  4.4414e-01, -1.1263e+00,  9.8569e-01,\n","         -1.3801e+00,  1.2444e+00,  3.0464e-01, -5.3166e-01,  9.3296e-01,\n","          1.1346e+00, -1.0052e+00,  2.5926e-01,  2.6317e+00, -2.0236e+00,\n","         -9.3356e-01,  1.6511e+00,  1.2892e-01, -2.0117e+00,  6.1861e-01,\n","         -2.5748e+00,  6.6571e-01, -4.3933e-01, -6.3416e-01,  2.3798e+00,\n","          8.2257e-01,  2.0354e+00,  1.0642e+01, -2.9050e+00, -2.0046e-01,\n","         -1.6863e+00, -3.6006e-01,  1.1061e+00,  1.7664e+00,  4.0805e-01,\n","          1.5635e+00,  1.0152e+00, -7.5414e-01, -1.9013e+00,  1.8421e+00,\n","          3.3746e+00, -7.0575e-01, -1.4851e+00, -2.0265e+00,  3.5520e-01],\n","        [ 5.9991e-01, -1.3199e-01,  1.0822e+00,  5.1917e+00, -5.2230e-01,\n","         -2.2056e+00,  3.5502e+00, -3.8782e+00,  9.4579e-01,  1.8223e+00,\n","         -4.5982e+00,  3.3690e-01, -1.1454e+00,  7.2774e-01, -2.4949e+00,\n","         -3.0959e+00,  4.1865e-03, -8.7989e-01,  5.0173e+00,  1.0441e+01,\n","         -9.5716e-01, -9.3932e-01, -1.9931e+00,  1.4141e+00,  4.5994e+00,\n","         -6.8422e-02,  1.3285e-01, -1.4601e+00, -1.4791e+00, -7.4110e-01,\n","          1.9804e+00,  6.8188e-01, -2.1547e+00, -3.9018e-01, -1.7519e+00,\n","         -9.8546e-01, -3.1700e+00, -2.3595e+00,  4.1788e+00,  8.4329e-01,\n","         -2.2219e+00,  1.5464e+00, -3.1433e+00, -5.1136e-01, -1.7272e+00,\n","          3.0242e-01, -1.8351e+00,  3.2424e+00, -1.6642e+00, -1.0600e+00],\n","        [-1.3714e+00, -2.2488e+00, -9.8785e-01, -1.4434e-01,  1.5183e+00,\n","         -3.8456e+00, -1.2596e+00, -1.4835e+00, -1.0753e+00,  3.6793e-01,\n","         -1.1717e+00, -1.4756e+00,  3.9610e+00, -8.5311e-01,  2.0232e+00,\n","         -6.4569e-01, -8.3284e-01,  2.8493e-01, -1.3782e+00,  1.0526e-01,\n","          3.9131e-01, -6.7122e-02,  9.9834e+00,  1.6582e+00,  8.0916e-01,\n","          3.1869e+00, -2.8235e+00, -1.1457e+00,  1.5133e+00, -1.4480e+00,\n","         -3.3283e-01, -1.0796e+00,  3.4238e+00, -2.0659e+00, -2.2835e+00,\n","          2.4279e+00,  7.8813e-01, -9.9998e-01,  1.3870e+00,  2.2827e+00,\n","          9.1720e-01,  6.5166e-01, -5.3239e-01,  4.1038e-01, -5.1288e-01,\n","         -9.6334e-01, -2.3358e+00,  5.7406e-01, -8.2587e-01, -1.6919e+00],\n","        [ 1.3150e+01,  7.3709e-01,  3.3151e+00,  3.9910e+00, -2.2244e+00,\n","         -8.5851e-01, -2.3078e+00, -5.2471e+00, -1.4103e+00,  4.7162e-01,\n","         -2.5864e+00,  8.7391e-01, -2.4533e+00, -6.6978e-01,  3.2316e-01,\n","         -3.7588e+00,  3.7336e+00, -1.0495e+00, -2.2187e+00,  6.5564e-01,\n","          4.4695e-01, -1.8994e+00, -2.3614e+00, -8.5277e-02,  3.7104e+00,\n","          8.1609e-01,  2.6787e+00,  5.6877e-01, -3.4224e+00, -1.5467e+00,\n","          2.5289e+00,  3.0554e-01, -2.0497e+00, -4.6250e+00, -2.1511e+00,\n","          1.4902e+00,  9.9793e-01, -4.0299e-01,  5.0065e+00,  7.2143e-01,\n","         -1.9197e+00, -3.0605e+00, -1.0693e+00,  1.5612e+00, -2.3643e+00,\n","         -2.8741e+00,  1.4394e+00, -2.7583e-01,  3.3847e+00, -2.8803e-01],\n","        [ 1.6146e-01, -2.2855e+00,  2.1516e-01,  2.0012e+00,  1.4591e+00,\n","         -1.5590e+00,  1.1060e-01,  1.9984e+00, -2.5636e+00, -1.6319e+00,\n","         -7.5123e-01,  3.1233e+00, -2.3201e+00, -9.8435e-02, -2.2793e+00,\n","         -2.4858e+00,  2.9638e+00, -1.3468e+00, -1.0024e+00, -2.7762e-01,\n","         -1.2325e+00,  7.6192e-01,  2.3115e-01, -1.2867e+00,  1.9380e+00,\n","          1.0310e+00,  1.1617e+00, -1.4793e+00,  8.1231e-02,  4.6732e-01,\n","          7.0406e-01,  1.1742e+00, -9.0827e-02,  8.3679e-01, -1.2881e+00,\n","          3.1640e-02, -1.2951e+00, -1.6778e+00,  8.0918e-01,  1.2130e+01,\n","         -9.3363e-01,  7.2764e-01, -5.0145e-01, -9.4638e-01, -9.5292e-01,\n","          1.3066e+00, -1.7858e+00,  9.0979e-03,  5.1164e-01, -4.2501e-01],\n","        [-7.7781e-01, -6.5447e-01, -3.1440e-01, -1.6107e+00, -1.2088e+00,\n","          8.4504e-03, -2.4201e-01, -1.6781e+00,  3.0688e-02,  1.2341e+00,\n","          4.5887e+00, -6.5874e-01, -6.0716e-01, -1.4108e+00, -1.5235e+00,\n","         -7.7495e-01, -2.3550e+00,  1.3301e+01, -1.1760e+00, -9.7892e-01,\n","          3.8090e-01, -1.2059e+00, -2.4383e+00, -1.0816e+00, -3.7081e-01,\n","         -5.9446e-01,  4.3357e-01, -1.5870e+00, -7.1355e-01, -2.9288e-01,\n","          1.0631e+00, -1.1662e+00,  7.3047e-01, -3.3352e-02, -2.4337e+00,\n","         -1.7962e-01, -3.3400e-01, -1.9179e+00, -1.0474e+00, -1.9122e+00,\n","         -6.2753e-01, -1.5853e-01,  2.6435e+00,  9.4315e-01,  2.9823e+00,\n","         -1.1946e+00,  7.8740e-01, -8.5181e-01,  4.1454e+00,  3.6977e-01],\n","        [-1.3598e-01, -2.3868e+00, -4.9443e-01, -7.6957e-01, -9.7076e-01,\n","         -2.3323e+00, -9.4085e-01, -1.4368e+00, -3.1281e+00,  2.5965e-01,\n","         -2.4279e+00, -1.0190e+00,  1.9304e+00, -1.1242e+00,  1.2328e+00,\n","         -1.3715e+00,  5.6042e-01, -1.0091e+00, -4.2190e-01, -2.3826e-01,\n","          3.1871e+00,  7.1940e-01,  1.0533e+01,  3.8880e-01,  3.6588e+00,\n","          5.1929e+00, -2.3090e+00, -2.1941e+00,  1.2535e+00, -3.2377e-01,\n","          8.1762e-01, -7.3477e-01,  3.0325e+00, -1.1207e+00, -2.5980e+00,\n","          1.4213e+00, -1.1749e+00, -1.4116e+00,  4.7718e-01,  1.3185e+00,\n","          1.9078e-01, -4.4896e-01, -2.7153e+00,  1.4494e+00,  1.1974e+00,\n","         -1.1018e+00, -2.4987e+00,  4.4950e-01,  8.2760e-01, -1.3456e+00],\n","        [ 1.9765e+00,  1.0933e+00,  2.1532e+00,  3.5018e+00, -9.5061e-01,\n","         -2.0902e+00,  9.0278e-01, -4.1576e+00,  6.3179e-01, -1.0828e+00,\n","         -7.9537e-01,  1.8625e+00, -2.5141e+00, -1.0010e-01, -2.6663e+00,\n","         -1.8752e+00,  5.1238e+00,  1.7390e-01,  1.6122e-01,  3.1188e+00,\n","         -9.8775e-01, -1.2189e+00, -2.9859e+00, -2.2422e+00,  1.1915e-01,\n","          2.6590e+00,  1.7777e+00, -2.0036e+00, -3.0997e+00,  9.0467e-01,\n","          1.2409e+01, -3.3735e+00, -1.4364e+00,  9.8839e-01,  5.0211e-02,\n","         -7.3367e-01,  7.0518e-01, -2.8107e+00,  8.1573e-01, -1.4865e+00,\n","         -1.9807e+00, -1.7394e+00, -1.2735e+00,  1.0374e+00, -4.7769e-01,\n","         -2.8890e+00,  3.7641e+00,  1.0069e+00,  5.9060e-01,  2.2561e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7,  2,  5, 42,  5,  5, 40, 27, 32, 19, 22,  0, 39, 17, 22, 30],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8778,  8.2566, -0.8904,  ..., -1.7589, -2.2047,  2.5560],\n","        [-0.3235,  4.7176,  0.0884,  ..., -0.5528, -0.7914,  3.8038],\n","        [ 8.4119, -3.2074,  1.5899,  ...,  7.4603, -1.3056, -1.9785],\n","        ...,\n","        [ 2.0076,  0.3939, -0.7363,  ..., -2.1476,  1.6174, -0.4209],\n","        [-0.3460, 11.0124,  0.8805,  ..., -1.3166, -2.0599,  1.6904],\n","        [ 1.0622, -3.0183,  4.9473,  ..., -1.8446,  1.7289, -0.0885]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 384/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.5809, -3.0448,  1.7439,  ..., -0.1145, -1.5061, -1.1206],\n","        [-3.6348, -1.4644, -0.3291,  ...,  0.3922, -0.5241, -0.3959],\n","        [-2.5669, -2.5487, -2.7861,  ..., -3.8948, -1.1413, -1.2034],\n","        ...,\n","        [-4.2964, -3.0199, -1.9318,  ..., -3.8366, -1.7972,  0.4785],\n","        [-0.7982, -1.8959,  0.6022,  ..., -0.7521,  0.8225,  0.8486],\n","        [-2.4686, -0.0534,  0.4589,  ..., -2.7231, -3.1380,  2.5163]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 9,  9, 28, 48, 41,  0, 37, 28, 41,  0, 15, 18,  5, 38, 14, 32,  7, 11,\n","        13, 48, 15, 43, 28,  3, 49,  8, 16, 17, 14, 18, 16, 19,  7, 41, 15, 38,\n","         4, 40, 17,  3, 31, 41,  9, 47, 34, 36, 12, 24, 39, 32, 44,  6, 12, 38,\n","        11, 45,  8,  7, 12, 19, 23, 47, 30, 39, 35, 16, 35, 33, 43, 33,  8, 36,\n","        35,  9, 26,  4,  6, 15, 13, 31, 15, 25, 47,  6, 49,  4,  1,  3, 15, 35,\n","        34,  4,  5,  8, 19,  2, 18, 26, 24, 21, 40,  6, 22, 10, 48, 16, 20,  0,\n","        42, 13,  3, 29, 49, 30,  5, 46,  6, 33, 41, 22, 46, 30, 21, 14, 45, 28,\n","        20,  4], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.5901, -0.3511, -0.9032,  ..., -1.2540, -0.7333, -1.1313],\n","        [-2.2747, -1.9360, -1.1795,  ..., -1.2991, -1.5829, -0.0577],\n","        [-3.3266, -0.6434,  2.5878,  ...,  1.8529, -0.0839, -0.5340],\n","        ...,\n","        [-1.9889, -1.6409, -0.5012,  ...,  0.5432,  1.7326,  0.2671],\n","        [-3.0262, -1.3489, -2.0899,  ..., -1.0644, -0.7526,  3.5731],\n","        [ 0.1840, -2.1336, -0.1119,  ...,  4.2588, -0.8203, -1.7034]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7, 45, 11, 27,  4, 47,  1, 36, 20, 29, 26, 41,  3, 42, 28,  7, 24, 45,\n","        17, 25, 24, 20, 26, 10,  1, 20, 10, 49,  7, 23, 31, 32, 46, 31,  0, 17,\n","        42, 14, 21, 38, 40, 22, 25, 17, 13, 11,  4, 27,  8, 17, 10, 16,  2, 16,\n","         1, 20, 36, 25,  3,  6, 27, 30,  9, 11, 34, 46, 30, 44, 20, 30, 18,  8,\n","         3, 37, 37, 41,  6, 24, 43,  9, 10, 19, 12,  5,  3,  8, 13, 25, 29, 29,\n","        49, 37, 27, 21,  8, 21, 24, 14, 35, 38, 18, 26, 43, 30, 14, 19, 24, 46,\n","        30, 42, 16, 48, 27, 33, 23, 32, 27, 15, 48, 10, 18,  2, 34, 36, 32, 44,\n","        29, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.4905,  0.3629, -2.0603,  ..., -1.5032, -1.8504, -0.1961],\n","        [-2.2040,  0.7749,  0.5533,  ...,  0.5236, -1.0678, -2.2868],\n","        [-2.4850, -2.4881, 15.8811,  ..., -1.0794, -0.5532, -1.3938],\n","        ...,\n","        [-2.0182, -0.5767,  0.3052,  ...,  0.2141, -0.9618, -1.0386],\n","        [-1.0022,  0.8162, -2.2472,  ..., -1.9302, -3.0661,  1.9521],\n","        [ 1.4872,  2.2793,  2.3800,  ..., -2.3373,  2.7745,  0.6768]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([31, 27,  2, 18, 25,  0, 10, 26, 20, 28,  2, 22,  1, 12,  3, 49, 16, 39,\n","        27,  2, 44,  1, 34, 41, 13, 37,  4, 46, 45, 35,  2, 28, 36, 11, 16, 33,\n","        44,  2,  5, 26, 25, 49, 23, 35, 22, 48, 31, 38, 17, 29, 40, 12, 37,  1,\n","        34, 19,  7, 37, 39, 41, 14, 33,  0, 12, 40, 27, 47, 32, 30, 29, 26, 36,\n","         0, 44, 39, 24, 42, 17, 32, 11, 48, 49, 46, 19, 16, 31, 40, 21, 30, 23,\n","        15, 13, 17,  2, 11, 27, 45,  5, 31, 12, 22, 23, 20, 47, 36, 14, 29, 29,\n","        40, 24, 40, 12, 22, 28, 31, 43, 33, 22, 42, 42, 32, 37,  9, 36, 35,  9,\n","        13, 43], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.0825e+00, -2.2029e+00,  8.7845e-01, -1.1766e+00,  1.4189e+00,\n","          9.6734e-02, -2.3588e+00, -1.0111e+00, -3.8104e+00,  1.0793e+01,\n","         -2.1976e+00,  3.4100e-02,  1.3344e+00, -2.8479e+00, -1.5853e+00,\n","          8.9710e-01,  1.0640e-01, -2.1870e+00,  2.7789e+00, -1.7728e+00,\n","          1.1040e-01,  1.5113e+00,  9.2052e-01, -2.6884e+00,  8.9561e-01,\n","         -1.1543e+00,  1.6882e+00,  9.0257e-01,  1.2482e+00,  2.7318e+00,\n","         -9.5323e-01,  3.0347e+00,  2.0722e+00, -3.0068e+00, -2.3560e+00,\n","         -6.1203e-02, -2.6559e-01,  3.8901e-01,  1.7696e+00, -1.5766e+00,\n","          2.0832e+00,  3.3634e+00, -3.3201e-01, -3.7184e+00,  1.8704e+00,\n","         -2.3244e+00,  1.1663e+00, -2.3299e-01, -1.5097e+00,  3.5100e-01],\n","        [-4.1657e-01,  1.1254e+01,  6.8064e-01,  3.2001e+00, -6.0531e-02,\n","          7.4129e-01, -8.4233e-02,  5.4867e-01,  8.2133e-02, -1.6914e+00,\n","         -2.7036e+00, -1.0922e+00, -1.7916e+00, -5.5138e-02, -2.5521e+00,\n","          7.7339e-01, -2.9952e+00, -1.9340e+00,  4.8458e-01, -1.7190e+00,\n","          1.4168e+00, -2.5967e-01, -6.9528e-01, -1.2268e+00, -1.2855e+00,\n","         -2.7914e+00, -3.5345e-01, -9.0232e-01, -1.9198e+00,  9.8654e-02,\n","          7.5989e-02,  1.1495e+00, -7.2003e-01, -2.5366e-01,  5.9600e+00,\n","         -1.2322e+00,  5.4033e-01,  2.7756e+00, -1.4830e+00, -1.8913e+00,\n","          1.6600e+00, -1.1079e+00, -2.2510e-01,  3.1012e+00, -2.3306e+00,\n","         -1.4607e+00,  3.5536e+00, -1.4531e+00, -9.9354e-01,  2.0704e+00],\n","        [-3.0842e-01,  8.5170e-02,  2.2900e+00, -1.8714e+00,  1.1090e+00,\n","          3.3699e-01, -2.3294e+00, -2.2261e+00, -1.3694e+00, -4.3187e-01,\n","          1.2706e+01,  3.7184e-01,  2.8830e-01, -2.5184e+00, -1.5393e+00,\n","         -1.6241e+00, -2.5178e+00,  5.3302e+00, -1.2262e+00, -3.4775e+00,\n","         -2.8809e-01, -5.8439e-02, -1.0941e+00, -1.8541e+00, -1.8442e+00,\n","         -3.0066e+00,  7.5460e-01, -6.2940e-01, -6.0871e-01, -1.3780e+00,\n","          1.7025e+00, -5.9397e-01,  9.5354e-01, -6.8486e-01, -2.3986e-01,\n","         -1.3146e+00,  4.7689e-01,  6.4114e-01,  1.2525e-02, -3.2166e+00,\n","          6.4346e-01, -9.8593e-01,  5.6868e+00,  8.3914e-01,  2.0078e+00,\n","         -1.7024e+00,  4.7332e+00, -2.3637e+00,  3.4828e+00, -1.5196e+00],\n","        [-1.4414e+00,  9.9193e+00,  4.0807e-04,  1.7359e+00, -1.0126e+00,\n","          9.8522e-01,  2.4747e-02,  1.5861e+00,  1.9310e-01, -3.4314e-01,\n","         -2.4609e+00, -3.9800e-02, -1.2132e+00, -8.6095e-01, -2.5166e+00,\n","          8.1300e-01, -1.6488e+00, -1.6504e+00,  1.3764e+00, -1.7068e+00,\n","         -1.6813e-01, -3.5774e-01,  2.4575e-01, -5.8354e-01, -1.2015e-01,\n","         -2.0709e+00, -7.3026e-01,  1.3647e+00,  7.6642e-02,  3.1700e-01,\n","          1.0545e-01,  2.0372e+00, -8.1409e-02, -2.0589e-01,  5.4018e+00,\n","          3.8421e-01,  7.2290e-01,  1.7145e+00, -9.0287e-01, -2.3397e+00,\n","         -1.5581e-01, -2.3043e+00, -6.2806e-01,  1.0857e+00, -1.0567e+00,\n","         -1.9665e+00,  2.0524e+00, -1.6438e+00, -1.0656e+00,  2.6217e-01],\n","        [-1.4110e+00, -1.2685e+00,  3.0196e+00, -1.3411e+00,  1.9031e+00,\n","          1.2152e+00, -4.3110e-01, -1.9063e+00, -7.8412e-01, -1.0944e+00,\n","          1.2236e+01,  5.6972e-01,  2.7464e-01, -2.9697e+00, -2.6298e+00,\n","         -2.6137e+00, -1.3629e+00,  4.6778e+00, -1.5814e+00, -2.8675e+00,\n","         -7.1474e-01, -9.7880e-01, -3.6145e-01, -1.2879e+00, -1.1633e+00,\n","         -1.8158e+00,  4.4719e-02,  4.0995e-01, -1.5256e-01, -1.1532e+00,\n","          2.5890e+00, -1.3063e+00, -6.6290e-02, -3.0103e-01, -1.7602e+00,\n","         -9.9588e-01,  1.3265e-01, -7.2836e-01, -5.9151e-01, -1.8520e+00,\n","         -3.7122e-02,  8.3178e-02,  3.9037e+00,  1.5776e+00,  1.7708e+00,\n","         -9.3867e-01,  1.4692e+00, -2.0931e+00,  5.6154e+00, -1.7310e+00],\n","        [ 6.2236e-01, -9.1908e-01,  1.6293e+00,  3.5886e+00, -1.5188e+00,\n","         -1.5492e+00,  2.7745e+00, -2.9815e+00, -7.1732e-01, -6.3013e-01,\n","         -2.5459e+00,  3.7509e+00, -2.3254e+00,  5.1664e-02, -9.2411e-01,\n","         -2.4665e+00,  1.7323e+00, -1.5185e+00,  5.2873e-01,  2.4005e+00,\n","         -1.9242e-01, -6.2444e-01, -1.1201e+00, -1.6250e+00,  1.6859e+00,\n","          3.0082e+00,  5.5333e-01,  4.5970e-01, -1.8598e+00,  1.9224e+00,\n","          2.1727e+00, -1.5349e+00, -5.7533e-01, -2.0591e+00, -9.7528e-01,\n","          2.1832e+00,  2.9566e-01, -2.1691e+00,  3.7057e+00,  5.5600e-01,\n","         -1.4457e+00, -1.2320e+00, -1.0031e+00, -6.2611e-01, -2.0141e-01,\n","         -3.3958e+00, -2.2266e+00,  1.1405e+01, -6.5642e-01, -5.2510e-01],\n","        [ 1.4632e-02, -2.0660e+00, -8.5117e-01, -3.9745e-01, -3.6327e+00,\n","         -5.0598e-01,  6.6266e-02, -2.0617e+00,  9.6896e-01, -1.1262e+00,\n","         -7.7310e-01,  3.4295e-01, -5.0730e-01,  1.4126e+00, -4.6383e-02,\n","         -3.5020e-01, -2.6951e-01,  9.7639e+00, -6.9822e-01,  1.8800e+00,\n","          2.2181e+00,  3.7389e-01, -1.1845e+00, -2.6544e+00,  1.1114e+00,\n","          2.2652e+00,  6.2998e-01, -6.5273e-01,  7.6368e-01,  1.0723e+00,\n","          2.3784e+00, -2.2280e+00,  1.7069e+00,  9.1434e-02, -1.3348e+00,\n","         -2.5008e+00, -2.6796e+00, -1.2479e+00,  2.6130e-01,  9.8629e-01,\n","          2.4121e-01, -1.4236e+00,  2.0361e+00,  1.9303e+00,  6.5638e-02,\n","         -2.8641e+00,  1.0079e+00, -1.9828e+00,  4.1188e+00, -2.2088e+00],\n","        [ 2.5092e-01, -2.9652e+00,  2.6155e+00, -3.3336e+00, -2.0716e-01,\n","          1.3539e+01,  9.2343e-01, -1.8553e+00,  1.4882e-01, -2.1163e+00,\n","          1.1831e+00,  1.8586e+00, -2.8932e+00, -1.0373e+00, -2.7985e+00,\n","          1.7155e+00, -4.4978e-01, -3.7273e-01, -8.2537e-01, -2.4452e+00,\n","          2.3045e+00, -5.2814e-02, -4.3589e+00, -2.7796e+00, -2.1424e+00,\n","         -1.7117e+00,  3.6848e+00,  3.2613e+00, -1.7543e+00,  3.8195e+00,\n","          8.5596e-02,  2.0901e+00, -8.1358e-01,  8.5152e-01,  1.4269e+00,\n","         -2.2428e+00,  1.6747e+00, -1.1143e+00, -1.1006e+00, -2.4618e+00,\n","          4.6021e-02,  1.5291e+00,  5.3721e-01,  2.7381e+00,  7.3268e-01,\n","         -2.0940e+00, -1.4674e+00, -1.4813e+00,  1.2688e+00,  1.1678e+00],\n","        [-9.6177e-01, -1.9650e+00,  1.1599e+00, -2.1941e+00,  1.3674e+00,\n","         -1.0359e+00, -6.3530e-01, -1.5514e+00, -4.1233e-01, -1.8676e+00,\n","          3.5242e-01, -1.0398e+00,  3.6678e+00, -5.3526e-01,  1.3126e+01,\n","         -5.7540e-01, -2.1542e+00, -8.8890e-01, -1.8600e+00, -1.5649e+00,\n","         -6.7662e-01,  1.7704e+00,  3.3881e+00,  7.4320e-01, -1.7324e-01,\n","          8.3101e-01, -1.1315e-01,  1.2106e-01, -1.0815e-01, -6.4268e-01,\n","         -1.1982e+00,  6.1526e-01,  1.8810e+00, -3.3907e+00, -2.1791e+00,\n","          1.5861e-01,  7.4962e-02,  1.5000e+00,  1.6708e+00, -1.4267e+00,\n","          3.2338e+00, -3.1487e+00, -2.5057e-01,  7.4920e-01,  2.9431e+00,\n","         -2.0917e+00,  5.2930e-01, -2.0541e+00, -8.4429e-01, -1.5818e-01],\n","        [-2.0050e+00, -1.3070e+00, -8.1655e-01, -1.7573e+00, -1.7607e+00,\n","          7.9386e-02, -1.4335e+00,  1.0327e+01, -1.6612e+00,  1.8624e-01,\n","         -1.3608e+00,  2.1543e+00,  2.6560e+00, -1.8601e+00, -8.2353e-01,\n","          1.8514e+00, -3.0041e-01,  1.3768e+00,  8.9832e-01, -1.9180e+00,\n","         -2.1673e+00,  1.5642e+00,  2.8295e+00, -2.3011e+00, -1.3715e+00,\n","          5.8358e-01,  1.0339e+00,  1.6344e-01,  8.6897e-01, -3.7413e-01,\n","         -1.4327e+00, -1.3332e+00,  2.8731e+00,  1.0574e+00, -1.8724e+00,\n","          2.5933e-01, -1.5023e+00, -3.2360e-01, -3.8615e-02,  3.3742e+00,\n","          4.4303e-01, -6.0769e-01, -7.6118e-01, -1.3066e+00,  1.2572e+00,\n","          9.5001e-01, -8.0801e-01, -2.0191e+00, -7.2548e-01, -1.0402e+00],\n","        [ 1.6446e+01, -2.1232e+00,  1.3460e+00,  4.1910e+00, -3.1361e+00,\n","         -1.4465e+00,  5.0905e+00, -6.4884e+00,  2.4725e+00, -3.3267e+00,\n","         -6.0125e+00,  7.0423e-01, -2.9913e+00, -3.4585e-01, -9.5592e-01,\n","         -4.0991e+00,  6.0915e+00, -2.0245e+00, -1.4028e+00,  3.6792e+00,\n","         -1.6473e+00, -1.6447e+00,  5.7229e-01,  7.2761e-02,  7.0134e+00,\n","          4.8241e+00,  6.8156e-01, -4.0987e-01, -4.4451e+00, -2.4924e+00,\n","          2.2591e+00, -2.0357e+00, -6.3550e-01, -2.7676e+00, -2.5577e+00,\n","          1.6182e+00, -9.8121e-01, -4.4629e+00,  4.0566e+00,  1.6778e+00,\n","         -1.8202e+00,  1.1794e+00, -2.6757e+00,  3.1386e+00, -3.8070e+00,\n","         -4.4141e+00, -6.5992e-01,  3.5177e+00,  6.7043e-01, -6.8821e-01],\n","        [-2.4391e+00, -2.7742e+00,  3.9232e-01, -1.4853e+00,  1.0699e+00,\n","          8.3572e-01,  1.8898e+00, -2.2144e+00, -2.7022e+00,  1.2071e+01,\n","         -2.2793e+00, -8.5254e-01,  1.8341e+00, -2.6404e+00, -2.3905e+00,\n","         -5.5637e-01, -9.9575e-01,  3.1247e-01,  2.4506e+00, -5.2450e-01,\n","          2.9961e+00,  7.2680e-01, -1.2196e+00, -7.5146e-01,  2.2036e+00,\n","          1.1597e+00,  1.1500e+00,  1.9938e+00,  1.4708e-01,  2.2383e+00,\n","         -1.6782e-01,  1.5981e+00, -4.2719e-01, -2.4241e+00, -2.7780e+00,\n","          7.4251e-01, -5.7600e-01, -3.1238e-01,  9.6829e-01, -2.1754e+00,\n","          4.9522e-01,  3.0376e+00, -1.2887e+00, -2.0281e+00,  2.7761e+00,\n","         -1.2330e+00, -1.8134e+00, -3.8547e-01, -7.6164e-01, -9.0462e-02],\n","        [ 3.1139e-02, -1.6463e+00,  1.9338e+00,  4.7892e+00, -1.4878e+00,\n","         -6.4032e-01,  1.8221e+00, -3.6500e+00,  1.5266e+00, -4.0656e-01,\n","         -2.2482e+00,  3.0852e-02, -3.7787e+00,  2.7063e+00, -1.0496e+00,\n","         -1.3208e+00,  3.4812e+00, -1.0407e+00,  5.2627e-02,  1.1980e+01,\n","         -2.2801e+00, -1.3256e+00, -2.0917e+00, -1.4920e+00,  2.2826e+00,\n","          1.6219e+00,  2.1086e+00, -4.6146e-01, -2.8697e+00,  2.9229e+00,\n","          3.4502e+00, -2.6209e-01, -1.4110e+00,  1.0481e+00, -7.9265e-01,\n","         -1.1578e+00, -2.5382e+00, -1.1815e+00,  4.2519e-01, -1.1478e-01,\n","         -1.2147e+00, -2.4628e+00, -1.6621e+00,  5.6784e-01,  4.4147e-02,\n","         -2.5980e+00,  1.0630e+00, -9.1180e-02, -1.5312e-01, -9.5712e-01],\n","        [-1.9576e+00,  5.5575e-01, -3.7399e-01, -8.0936e-01,  3.6529e+00,\n","         -2.2438e+00, -3.3593e-02, -3.8789e+00,  6.1016e+00, -2.6211e+00,\n","         -3.5550e+00, -2.2975e+00, -1.2577e+00,  4.9903e+00, -1.4665e+00,\n","          2.0780e+00, -9.3557e-02, -3.7231e+00,  1.2502e+00, -5.1428e-01,\n","          3.4225e+00,  1.1948e+00, -2.4869e+00,  1.2460e+01, -7.2272e-01,\n","         -2.0042e+00, -3.7260e+00, -2.4050e+00, -3.4710e-02,  5.0989e-01,\n","          8.5222e-01,  1.7791e+00, -9.4806e-01, -2.2984e+00,  3.5134e+00,\n","         -3.4151e+00,  2.5485e+00,  6.0440e+00,  4.2146e-01, -2.1160e+00,\n","         -7.4482e-01,  1.3703e-01, -1.5129e-01,  1.6493e+00, -2.1278e+00,\n","         -2.1611e+00, -1.5560e+00, -3.7697e+00, -2.4757e+00,  4.9720e+00],\n","        [ 3.0871e+00, -2.1002e+00, -3.0621e-01,  1.1626e-01, -1.6268e+00,\n","         -9.9123e-01,  5.9374e-01, -9.2949e-01, -2.1060e+00, -7.9411e-01,\n","         -2.1807e+00,  3.9665e+00, -1.3173e+00, -3.5222e-01, -1.0459e+00,\n","         -1.7438e+00,  4.0052e+00, -1.7471e+00, -1.3548e+00,  1.6831e+00,\n","         -1.1837e+00, -5.0808e-01,  1.2756e+00, -1.0120e+00,  2.8469e+00,\n","          1.2660e+00, -1.3604e+00,  2.0950e-01, -1.1462e+00, -1.9604e+00,\n","          1.2416e+00, -5.1618e-01,  1.6744e+00, -3.4668e-02, -1.7521e-02,\n","          4.0229e+00, -1.0819e+00, -3.1570e+00,  4.2442e+00,  3.5991e+00,\n","         -2.8504e+00,  1.2972e-01, -9.8080e-01, -9.1894e-01, -5.5096e-01,\n","         -2.3381e+00, -1.6530e+00,  7.3658e+00, -1.6446e+00, -1.5833e-01],\n","        [-3.2465e+00, -2.3552e+00, -2.5810e+00, -1.3434e+00,  3.7854e+00,\n","         -2.4155e+00, -4.0578e-01,  2.2191e+00, -1.3641e+00,  1.8206e+00,\n","         -1.6254e+00,  1.0899e+00,  5.7443e-01, -4.3421e-01, -3.0166e+00,\n","         -2.9349e+00, -2.3374e+00, -5.9780e-01,  3.7922e+00,  1.3780e-01,\n","          1.1310e-01,  1.0771e+00,  3.0114e-01, -2.2090e+00,  1.6913e+00,\n","         -6.9106e-01, -2.7177e-01, -2.4998e+00,  1.7959e+00,  3.3965e+00,\n","         -8.1931e-01,  3.8246e+00,  3.9889e+00, -2.4474e+00, -5.1898e-01,\n","         -1.9921e+00, -2.0524e+00,  1.6457e+00, -9.4022e-01,  1.4039e+00,\n","          3.6008e+00,  4.5299e+00, -3.3876e-01, -3.2038e+00, -2.2496e-01,\n","          1.3282e+01, -1.6594e+00, -2.1658e+00, -2.5085e+00,  1.4489e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 9,  1, 10,  1, 10, 47, 17,  5, 14,  7,  0,  9, 19, 23, 47, 45],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8787,  8.2254, -0.8863,  ..., -1.7638, -2.1993,  2.5671],\n","        [-0.3260,  4.6941,  0.0873,  ..., -0.5605, -0.7919,  3.8288],\n","        [ 8.3716, -3.2114,  1.6130,  ...,  7.4259, -1.3068, -1.9779],\n","        ...,\n","        [ 2.0079,  0.3881, -0.7400,  ..., -2.1543,  1.6201, -0.4183],\n","        [-0.3460, 10.9919,  0.8849,  ..., -1.3253, -2.0545,  1.6939],\n","        [ 1.0673, -3.0315,  4.9538,  ..., -1.8525,  1.7309, -0.0845]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 385/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.5629,  4.2137, -1.9061,  ..., -3.0046, -1.0832,  0.2515],\n","        [-5.3790, -1.4631,  1.8918,  ..., -0.2221,  0.8557,  1.9212],\n","        [ 0.6578,  0.0961,  2.0835,  ..., -2.6890,  4.0210, -2.7303],\n","        ...,\n","        [ 0.5368, 13.3697, -0.6878,  ..., -1.1375, -1.9005,  1.5277],\n","        [ 0.2572,  0.4304, -1.3046,  ..., -0.3087, -1.2622, -1.8187],\n","        [ 1.5806, -1.4922,  0.7017,  ...,  0.4777, -0.4019, -2.3002]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([37, 29, 10, 26, 49, 27, 34,  1, 36, 27, 24, 21, 20, 47,  5, 15, 42, 41,\n","        17,  8, 30, 40, 28, 38, 29, 14, 18, 15, 18, 42, 20,  7, 37, 20, 26, 30,\n","        14, 14, 37,  3,  5, 25, 10, 28, 14, 19, 29, 47, 14, 13, 27, 29, 49, 47,\n","         6,  3, 12, 46, 20, 45, 34, 44, 32, 45,  9, 49,  2, 36, 18,  7, 42, 30,\n","        18, 48, 49,  2,  1, 19, 42,  2, 32, 29, 47, 33, 36, 31, 22,  7, 28, 30,\n","        35, 39, 16, 13, 30, 27, 46, 16, 41,  0, 42, 30,  7, 32, 22, 16, 27, 25,\n","        24, 37, 31, 36, 28, 17, 23, 33,  3,  6, 17, 28, 47, 40, 19, 22, 27,  1,\n","        21, 22], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.3130, -2.6228,  0.8421,  ...,  0.3854,  1.9634, -0.0319],\n","        [-1.7134, -0.9841,  1.0449,  ..., -0.6318,  0.7088,  0.5731],\n","        [-5.1575, -4.5806, -1.9598,  ..., -3.2470, -2.4391,  0.6456],\n","        ...,\n","        [ 0.5247,  2.1254,  1.8879,  ..., -3.7228,  0.4626, -0.8605],\n","        [-2.5743,  0.5502,  3.1466,  ..., -4.6647, -2.7392,  0.6692],\n","        [-4.4845, -0.5335,  0.8580,  ..., -1.6771, -1.5951,  3.9495]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20,  5, 41, 16, 35, 48, 26, 21, 48, 12, 45, 35, 39,  2, 19, 22, 41, 30,\n","        11, 22, 29, 15, 34, 40, 36, 23, 31, 20,  6, 10,  4, 17, 48, 18, 47, 15,\n","        24, 28, 13, 25, 16, 27, 19, 40, 29, 44,  4, 17, 24, 23, 12, 25,  4, 43,\n","        10, 27, 26, 14,  3, 11, 18,  7, 46, 41,  6, 16, 38, 20, 19, 32, 42, 16,\n","        25,  0,  0, 13,  4,  8, 33, 35, 28, 11, 35, 43, 49, 20, 36, 37, 13, 38,\n","        22,  3, 10, 43, 13, 40, 38, 24, 39, 32, 16, 14, 31, 43, 19, 32,  9, 26,\n","         1, 12, 14, 11, 17, 24, 12, 49,  1, 37, 23,  8, 28,  6, 15,  5, 34, 46,\n","        31, 29], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.7371, 13.8763,  0.4664,  ..., -0.2898, -1.0107, -0.1497],\n","        [ 0.6071, -0.7845, -1.5928,  ..., -0.3229, -0.4200,  2.9952],\n","        [-2.1470,  2.5129, -0.1280,  ..., -4.0195, -2.3252,  1.1043],\n","        ...,\n","        [-1.9857, -0.1193, -2.5022,  ..., -1.3409, -2.5796, -1.8120],\n","        [-0.2629, -1.8695,  0.6249,  ...,  1.3067, -1.9847, -0.9631],\n","        [ 0.7699,  0.3325, 15.2242,  ..., -2.1189,  0.7937,  2.2674]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 1, 36, 37,  2, 45, 30,  9, 13, 12, 40, 26, 12, 41,  8, 49, 23, 31,  9,\n","        30,  1, 40, 29, 38,  9, 33, 21, 48,  0, 47, 25, 21, 24, 44,  5, 25, 32,\n","        36, 46,  9, 35, 27, 22,  4, 41, 15, 11, 16, 10,  5, 45, 34, 42, 10, 17,\n","        36,  1, 31, 11, 32, 45,  2, 23,  9, 33,  0,  8, 33,  3, 39,  2, 48, 31,\n","         0,  9,  9,  3, 43, 11, 44, 26, 10,  6,  7, 10, 17, 47, 20,  7, 24, 48,\n","        31, 37, 19, 49, 17, 25,  3, 46,  1, 26, 15, 15,  0,  5,  0, 43, 38,  4,\n","         2, 16, 40, 13, 44, 24,  3, 12, 39, 46, 34, 30, 35,  9,  4,  6, 17, 18,\n","        21,  2], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-7.5849e-01, -2.0027e-01,  9.4026e-01,  1.4512e+00, -2.1163e+00,\n","          6.2924e-01,  3.9501e+00, -1.5904e+00, -8.2782e-01, -1.5796e+00,\n","         -1.1923e+00, -4.0114e-01, -2.2115e+00,  1.8251e+00, -1.1785e+00,\n","         -1.7541e-02,  4.4684e-01,  3.1991e-01, -2.8012e-02,  9.3423e-01,\n","         -1.1908e+00,  6.4397e-01, -2.4013e+00, -1.2880e+00, -1.9384e+00,\n","          9.8515e-01,  6.0103e+00, -6.6974e-01, -1.3753e+00,  2.7259e-01,\n","         -3.9981e-01, -9.7780e-01,  1.1128e+00,  1.1282e+01, -2.6977e-01,\n","          2.0129e+00, -1.6661e+00, -1.1160e+00, -1.9748e+00,  8.9354e-01,\n","         -2.0971e+00, -1.2236e+00, -1.4509e+00,  1.0210e+00, -1.2686e+00,\n","         -1.0774e+00,  6.1642e-01,  9.1734e-02,  1.6455e-01, -1.1819e+00],\n","        [-2.6682e+00, -2.3960e+00, -9.4001e-01, -5.2379e-01,  1.7630e+00,\n","         -1.5419e-01, -9.1616e-01,  2.8034e+00, -2.0866e+00,  1.8356e+00,\n","         -2.2992e-01,  1.3552e-02, -1.1038e+00, -2.0130e+00, -2.4110e+00,\n","         -1.4212e+00, -1.2743e+00,  1.0752e+00,  2.7046e+00, -6.0299e-01,\n","         -6.8162e-01,  7.6564e-01, -3.8851e-01, -2.8382e+00,  1.2964e+00,\n","         -8.1591e-01,  2.3841e+00, -1.8566e+00,  1.9962e+00,  2.6654e+00,\n","          5.8154e-01,  2.0497e+00,  2.8114e+00, -1.3410e+00, -6.6488e-01,\n","         -3.6739e+00, -2.5637e+00,  4.9979e-01, -1.1929e+00,  2.2305e+00,\n","          2.9417e+00,  2.5685e+00, -6.4450e-01, -2.5214e+00,  1.0003e-01,\n","          1.2752e+01, -1.1950e+00, -9.8908e-01, -2.2645e-02, -4.6834e-01],\n","        [-2.1342e-01, -1.9098e+00,  1.8945e+00,  3.1886e-01, -7.9184e-01,\n","          1.0154e+00, -6.8927e-01, -9.4164e-01, -2.7816e+00, -1.7103e-01,\n","         -1.3493e+00,  1.6400e+00, -1.6958e+00, -2.4813e+00,  3.4332e-01,\n","          1.1578e-01,  2.0977e+00,  2.1768e-01,  1.8476e-01,  8.9442e-01,\n","         -3.6986e+00,  2.8419e-01,  2.2217e-01, -3.0350e+00,  3.5348e-01,\n","         -7.7090e-02,  5.6007e-01,  1.1849e+01, -8.2226e-01,  2.9569e-01,\n","         -3.8938e-01,  1.4351e+00, -9.3798e-01, -2.3885e+00,  1.3376e-01,\n","          6.5788e-01, -2.4333e+00, -5.3219e-01,  1.8684e+00,  1.8438e-02,\n","          7.6984e-01,  9.6414e-01, -1.6922e+00, -7.9798e-01, -1.8815e-01,\n","         -1.9602e+00,  1.4825e+00, -1.7071e-01,  1.9531e-01, -1.9789e+00],\n","        [-9.0512e-01, -1.0773e+00,  1.1559e+00, -2.4885e-01, -1.3029e+00,\n","          9.8296e-01, -1.4901e+00, -3.4278e-01, -2.5904e+00,  1.7310e+00,\n","          2.4396e+00,  9.2066e-01,  1.4370e+01, -3.3996e+00,  2.4198e+00,\n","         -1.3952e+00, -3.0246e+00,  7.5094e-01, -7.4814e-02, -3.1984e+00,\n","          3.6235e-01,  2.2557e+00,  2.6787e+00, -2.3169e+00, -2.8623e+00,\n","          2.1698e-02, -5.2130e-01,  4.8438e-02,  3.2764e+00, -1.2638e+00,\n","          3.9299e-02,  8.7323e-01,  5.7475e-01, -3.8139e+00, -3.7215e+00,\n","         -6.6294e-01, -8.2536e-01,  6.2829e-01,  2.5492e+00, -2.7157e+00,\n","          4.7454e+00, -1.8039e-01,  1.4713e+00,  2.3662e-01, -4.2180e-01,\n","         -2.9566e+00,  2.0683e+00, -2.1786e+00,  8.9549e-01, -2.3269e+00],\n","        [-1.9443e+00, -6.8358e-01,  1.0308e+00, -1.3583e+00,  2.6515e-01,\n","          3.8783e-01, -2.2930e+00, -1.4107e+00, -9.5601e-01,  3.5895e+00,\n","          8.1697e-01, -4.0875e-01, -9.7250e-01, -2.2409e+00, -3.2733e+00,\n","         -1.8173e+00,  2.0691e+00, -2.1857e-02,  2.1543e+00, -1.5465e+00,\n","          6.7162e-01,  1.0781e+00, -1.5854e+00, -2.2068e+00,  1.4262e+00,\n","         -1.3845e+00, -1.2905e+00,  4.5075e-01,  2.3318e+00,  2.6753e-01,\n","          3.3702e+00,  1.5815e+00,  1.1671e+00, -1.8650e+00,  1.9037e+00,\n","         -2.3749e+00, -5.6052e-01,  7.8453e-01, -2.9907e-01, -2.0182e+00,\n","          1.0718e+00,  7.9003e+00, -4.7277e-01, -1.6142e+00,  3.6167e-01,\n","         -4.5784e-01,  2.5116e+00, -1.1841e+00,  3.0704e-01,  1.0740e+00],\n","        [ 9.5825e-01, -1.8565e+00,  4.6299e+00, -1.9357e+00, -3.3543e-01,\n","          1.6088e+00,  2.3880e+00, -3.7500e+00, -4.2656e+00,  7.8770e-01,\n","         -7.7196e-01,  1.6076e+01, -1.8532e+00, -2.3189e+00, -3.2035e+00,\n","         -3.3338e+00,  1.2833e+00,  1.5806e+00, -1.5757e+00,  3.6373e+00,\n","          3.9967e-01,  5.2093e-01, -3.9862e+00, -2.4964e+00,  7.4245e-01,\n","          1.4394e+00, -6.4065e-01, -4.7351e-01, -1.4422e+00,  2.9682e+00,\n","          7.3704e+00, -3.1813e+00, -1.2906e+00, -3.6805e+00, -1.2567e+00,\n","          4.7043e-01, -1.9867e+00, -4.3126e+00,  5.5414e+00,  6.4030e-01,\n","          5.1171e-01, -2.2440e-01, -3.5565e-01, -3.6145e-01, -2.4221e+00,\n","         -2.8564e+00, -7.8242e-02,  5.2476e+00, -1.6644e+00,  1.2800e+00],\n","        [ 2.4715e+00,  3.9176e+00, -4.0277e-02,  1.7101e+00, -1.1058e+00,\n","         -3.9157e-01, -1.0675e-01, -3.7929e+00,  1.0393e+01, -2.5409e+00,\n","         -1.3401e-01, -4.4918e+00, -2.5234e+00,  3.1714e+00, -6.8476e-01,\n","         -9.7619e-01, -9.1097e-01,  9.2764e-01, -1.7300e+00,  1.0478e+00,\n","          8.7274e-01, -2.4104e+00, -2.2172e+00,  2.4541e+00,  9.1144e-01,\n","         -1.8645e+00, -3.4883e-01, -1.7831e+00, -3.0580e+00, -6.5048e-01,\n","         -3.4036e-01,  1.5968e+00, -1.5336e+00, -9.7343e-01,  1.6402e+00,\n","         -3.2372e+00,  2.6583e+00,  1.7404e+00, -6.7926e-01, -2.3016e+00,\n","         -9.8111e-01, -1.9754e+00,  2.9203e+00,  5.3628e+00, -6.4869e-01,\n","         -2.9393e+00,  1.5124e+00, -2.2799e+00,  2.5456e+00,  1.4152e+00],\n","        [ 6.1274e+00,  1.4254e+00, -1.0769e+00,  4.9529e-01, -2.9370e+00,\n","          2.8363e+00,  2.4886e+00, -3.0804e+00,  1.0845e+01, -2.5535e+00,\n","         -1.0714e+00, -7.1469e-01, -2.2678e+00,  1.4555e+00, -2.9822e+00,\n","         -1.5289e+00,  6.8887e-01,  1.0081e-01, -1.4406e+00,  4.4679e-02,\n","          3.9870e+00, -1.1813e+00, -3.0172e+00, -6.6811e-01,  1.2697e+00,\n","         -2.7457e+00, -1.3347e+00, -3.2383e+00, -3.5267e+00, -1.4671e+00,\n","          1.5025e-01, -1.3347e+00, -6.5929e-01, -2.6175e+00,  2.8209e+00,\n","         -1.9981e+00,  3.1503e+00, -3.8790e-01,  1.6545e+00, -2.8989e+00,\n","          2.6881e+00, -8.1963e-01,  5.1649e+00,  4.5453e+00, -1.1700e+00,\n","         -4.0930e+00,  2.8284e+00, -9.7487e-01,  1.7424e+00,  1.2125e+00],\n","        [-6.8072e-01, -2.7968e-01,  2.0512e+00, -8.9117e-01, -1.7892e+00,\n","          2.8728e+00, -1.5939e+00, -3.0954e+00, -3.8441e+00,  2.8194e+00,\n","          2.4344e+00, -1.0708e+00, -3.1598e+00, -2.5126e+00, -6.3902e-01,\n","         -8.7636e-01,  7.6218e-01,  4.6658e+00, -2.3722e+00, -1.6587e+00,\n","          1.5689e+00, -1.2652e+00, -1.4091e-02, -7.2989e-01, -2.6290e-01,\n","          1.5585e-01,  3.3753e+00, -5.5471e-02, -1.7551e+00,  1.1436e+00,\n","          1.0199e+00,  6.4791e-02,  7.2400e-01, -2.7846e-01, -1.5729e+00,\n","         -5.8745e-02,  1.6513e-01, -1.7894e+00,  2.2529e-01, -2.1004e+00,\n","         -2.1921e+00, -3.4881e+00, -3.9611e-01,  8.2502e-01,  1.0947e+01,\n","         -2.7043e+00,  1.8949e+00, -1.3119e+00,  5.0587e+00, -1.4226e-01],\n","        [-1.9746e-02,  1.7836e+00, -7.3452e-02,  1.3825e+00,  3.1330e+00,\n","         -7.5341e-01, -1.2714e+00, -4.6349e+00,  1.5647e+00, -5.0741e-01,\n","         -2.8236e+00, -3.2756e+00, -1.9818e+00,  5.4301e+00, -9.3316e-01,\n","          5.2975e+00, -9.0043e-01, -3.9834e+00, -1.4246e+00, -1.2621e+00,\n","          4.7154e+00, -9.2170e-01, -1.6410e+00,  1.3738e+01,  1.1862e-01,\n","         -1.6704e+00, -1.5148e+00, -3.7801e+00, -2.7697e+00,  3.1615e+00,\n","         -4.4967e-01,  2.2024e+00, -1.2975e+00, -2.9322e+00,  3.5563e-01,\n","         -2.5289e+00,  2.9178e+00,  4.3764e+00,  1.6098e+00, -1.4982e+00,\n","         -5.7662e-01, -1.9218e+00, -1.7227e+00,  2.0425e+00, -8.1379e-01,\n","         -2.3512e+00, -2.6806e+00, -8.3931e-01, -2.0724e+00,  5.8385e+00],\n","        [-2.1567e+00, -9.6932e-01, -1.1345e+00, -1.3593e+00,  1.5578e+00,\n","         -6.6959e-01, -5.6885e-01, -7.9925e-01, -3.8116e+00,  3.5839e+00,\n","         -8.6600e-01,  2.6224e+00, -4.5873e-01, -1.8985e+00, -4.0271e+00,\n","         -1.7547e+00, -1.3116e+00, -1.1141e+00,  6.2210e+00, -1.4074e+00,\n","         -5.1550e-02,  1.8577e+00, -2.7385e+00, -3.2772e+00,  8.5716e-01,\n","          6.6881e-01, -1.0374e+00,  1.0055e+00,  2.2123e+00,  4.0479e+00,\n","          2.8399e+00,  2.6300e+00,  1.7864e+00, -2.1723e+00,  2.1970e+00,\n","         -1.7278e+00, -9.5040e-01,  8.4466e-01,  1.7104e+00, -1.8514e+00,\n","          7.5620e-01,  9.4156e+00, -9.5809e-01, -4.1949e+00, -8.7843e-01,\n","          6.3383e-01, -1.6168e+00,  1.6881e+00, -1.7109e+00,  7.1119e-01],\n","        [ 1.2924e+00,  1.7493e+00, -7.2705e-01,  2.0645e+00, -1.7455e+00,\n","          1.1862e-02,  3.4263e+00, -2.4878e+00,  7.7478e+00, -1.9513e+00,\n","         -4.1393e-01, -2.1775e+00, -2.3557e+00,  2.6062e+00, -5.5567e-01,\n","         -1.2787e+00,  4.5783e-01,  1.4962e-01,  2.5839e+00,  3.6898e+00,\n","          1.1120e+00, -1.1097e+00, -7.7270e-01,  1.5126e+00,  9.3221e-01,\n","          6.0739e-02,  4.4152e-01, -2.7663e+00, -2.8296e+00, -8.0588e-01,\n","          7.5059e-01,  4.8460e-01, -7.6215e-01, -1.7555e-01,  1.4752e+00,\n","         -1.6020e+00, -1.1250e-01, -9.2427e-01, -3.1608e-01, -5.3631e-01,\n","         -1.6756e+00, -2.2816e+00,  1.0133e+00,  2.4243e+00, -7.3850e-01,\n","         -1.9098e+00,  1.5583e+00,  3.7471e-01, -1.4327e-01, -1.6408e+00],\n","        [-1.2706e+00, -7.7996e-01, -5.9410e-01, -6.1159e-01, -1.2446e+00,\n","         -1.8220e-01, -1.0803e+00,  1.3754e+01, -3.4769e+00,  1.2074e+00,\n","         -5.8597e-01,  1.4650e+00, -4.6285e-01, -1.7735e+00, -1.1150e+00,\n","          1.3344e+00, -3.4137e-01,  3.0623e-01,  3.9708e-01, -4.6889e-01,\n","         -9.1598e-01,  6.8290e-01,  1.3947e+00, -3.3675e+00, -1.0907e+00,\n","          7.1382e-01,  9.9972e-01, -5.0433e-01,  2.7020e+00, -4.6979e-01,\n","         -1.7389e+00,  1.1057e+00,  3.0619e+00, -1.4038e+00, -8.0694e-01,\n","          1.9029e-01, -9.8396e-01,  7.6469e-01, -1.1000e+00,  3.0118e+00,\n","         -2.1606e-01, -1.8345e-01,  6.4511e-01, -1.3104e+00,  1.0546e-01,\n","         -1.0370e+00,  2.4298e-01, -8.8905e-01, -1.1336e+00, -2.2695e+00],\n","        [ 3.5171e+00, -3.3493e+00,  1.9485e+00,  8.4085e-01, -1.5608e+00,\n","         -1.1498e+00,  5.6907e+00, -3.1977e+00, -2.2082e+00, -7.7543e-01,\n","         -3.4640e+00,  1.1558e+00,  9.2865e-01, -8.9495e-01,  1.8414e-01,\n","         -3.8617e+00,  2.7745e+00,  2.6534e-01, -3.6703e+00,  3.2984e+00,\n","          7.7655e-01, -2.3459e+00,  3.0896e+00, -1.0373e+00,  3.6749e+00,\n","          5.9828e+00, -1.4995e+00,  2.2300e+00, -9.6328e-01, -2.6257e+00,\n","          1.3111e+00, -2.0593e+00,  1.0989e+00, -1.1061e+00, -2.4380e+00,\n","          1.3202e+01,  3.2871e-01, -3.9588e+00, -1.0104e-01,  2.9769e+00,\n","         -3.5684e+00,  1.9809e-01, -3.1737e+00,  1.0774e+00, -2.3854e-01,\n","         -3.1229e+00, -3.4389e+00,  3.5072e+00, -8.7883e-02, -1.1143e+00],\n","        [-2.0344e+00,  9.0468e-01,  7.2279e-01,  1.0820e+00,  1.2421e+01,\n","         -1.5205e+00, -1.8599e+00, -1.2687e+00, -2.3360e+00,  9.4048e-01,\n","         -6.2359e-01,  2.9961e-01,  1.7381e+00, -1.4915e+00, -2.5931e+00,\n","          8.1472e-01, -1.1593e+00, -2.8325e+00,  1.8221e+00, -9.9005e-01,\n","          1.1552e-01,  5.7887e-01, -1.5713e-01, -3.5590e-01, -3.7993e-01,\n","         -1.8864e+00, -1.3347e+00, -1.8733e+00,  1.2323e+00,  2.7748e+00,\n","          1.3095e+00,  2.4336e+00,  2.2074e+00, -1.9944e+00,  4.7208e-01,\n","         -2.5051e+00,  9.8911e-01,  4.8653e+00, -9.5898e-02, -8.6548e-01,\n","          1.0691e+00,  4.4815e-01,  9.3904e-01, -2.1089e+00, -2.1101e+00,\n","          2.1130e-01,  5.6718e-01, -3.1237e+00, -2.7299e+00,  1.4979e+00],\n","        [ 4.5003e+00, -9.3765e-01,  1.1131e+00,  9.0354e-01, -1.6671e+00,\n","         -1.3421e+00, -1.8338e+00, -3.6358e+00, -3.0012e+00, -9.0520e-02,\n","         -1.9755e-01, -1.0658e+00, -9.0263e-01, -1.0866e+00,  1.0880e+01,\n","         -1.9088e+00,  1.8940e+00, -2.7942e-01, -6.7411e-01, -6.6515e-01,\n","          7.1355e-01,  9.8913e-01,  2.6331e+00, -1.0081e+00,  2.1329e+00,\n","          1.8144e+00,  2.5447e+00, -1.0654e+00, -2.4912e+00, -1.8067e+00,\n","          8.5970e-01, -8.7545e-01,  2.6122e+00, -4.0327e+00, -1.7962e+00,\n","          1.1444e+00, -1.0060e+00,  3.5572e-01,  2.7014e+00, -1.3948e+00,\n","          1.5354e+00, -4.1616e+00, -8.7057e-01,  2.1389e+00,  2.5024e+00,\n","         -4.3079e+00, -4.8954e-01,  9.0974e-01, -3.2397e-01, -1.1936e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([33, 45, 27, 12, 41, 11,  8,  8, 44, 23, 41,  8,  7, 35,  4, 14],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8569,  8.2823, -0.8782,  ..., -1.7572, -2.1917,  2.5578],\n","        [-0.3017,  4.7155,  0.1088,  ..., -0.5436, -0.7881,  3.8341],\n","        [ 8.4088, -3.2048,  1.6185,  ...,  7.4452, -1.3035, -1.9739],\n","        ...,\n","        [ 2.0165,  0.3960, -0.7376,  ..., -2.1558,  1.6283, -0.4217],\n","        [-0.3355, 11.0025,  0.8870,  ..., -1.3143, -2.0449,  1.6836],\n","        [ 1.0980, -3.0273,  4.9704,  ..., -1.8522,  1.7471, -0.0929]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 386/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.2405, -2.6124,  2.6619,  ..., -0.0275,  1.0100,  0.9882],\n","        [ 0.5107,  0.9293,  1.3315,  ..., -0.7807,  0.9513, 13.8236],\n","        [-1.4251, -0.8563, -0.2773,  ..., -0.8124, -1.7319,  2.2388],\n","        ...,\n","        [-0.7052,  0.5472, -1.5917,  ..., -1.8777,  0.2661,  0.2321],\n","        [-1.8413,  0.8745, -1.5664,  ...,  0.8751, -2.4442,  1.3861],\n","        [ 1.3442, -2.2761,  0.0414,  ...,  4.6182, -1.3555, -2.2619]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([30, 49, 23, 27, 26,  1, 34, 27, 37,  0,  3, 42, 27, 14, 17, 29, 41, 33,\n","        15,  7, 36,  8, 43, 26, 30, 10,  3, 19, 33, 49, 47, 12, 37, 33, 18, 47,\n","        30,  1, 34,  8,  4, 37,  7, 16, 13, 22, 30, 17, 42, 10,  7, 28, 29, 25,\n","        25, 19,  2, 31, 45, 48,  7, 12, 46, 40, 40, 24, 35, 23,  9, 28, 32, 15,\n","        48, 14,  1, 36, 12, 14, 28, 12, 10, 19, 32,  7,  6, 16, 21, 41, 41,  9,\n","        19, 25, 23, 11, 14,  9, 49,  0, 11, 11, 29,  9, 10, 44, 38, 20, 13, 27,\n","         3, 38, 33, 44, 46,  9, 32, 32, 19, 48, 29, 42,  0, 17,  1, 40, 41,  8,\n","        13, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.6943,  2.5073,  0.8986,  ..., -1.9061, -2.4420,  0.5984],\n","        [ 2.1903,  0.3346, -1.1078,  ..., -2.3542, -2.0352, -0.4703],\n","        [-1.0528,  4.5312, -0.2799,  ..., -0.5682, -0.9618,  3.0633],\n","        ...,\n","        [ 0.4495,  0.4484, 14.2279,  ..., -0.1034,  1.5149,  0.1371],\n","        [-1.5617,  0.0386,  0.9117,  ...,  0.4366, -0.9017, -2.4026],\n","        [-3.3384, -1.5395, -2.4346,  ..., -0.3134, -1.4893,  4.2909]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([31,  5, 34, 18, 48, 15, 22, 36, 26, 44,  3, 36,  9, 17, 39,  5, 17, 17,\n","         1, 13, 17, 36,  0, 10, 22, 43, 20, 23, 46, 25,  1,  7,  0, 47, 36, 38,\n","        28, 45, 14, 10, 44, 26, 32, 45, 25, 24, 38, 26, 18,  4,  5, 21, 49, 18,\n","        21,  2, 47, 25, 20, 29, 36, 12, 24, 28, 18, 32,  6, 39, 30, 40, 31, 35,\n","        46, 48, 17, 39, 21, 15,  2, 10, 14, 41, 15, 20, 27, 47,  1,  3, 41, 30,\n","        35, 41, 42,  9, 20, 11,  9, 46, 40, 20, 10, 21, 35, 36, 17,  3, 27, 12,\n","        37,  4, 40, 16, 35, 33,  5, 16, 35, 15, 46, 18, 22, 11, 49, 22, 43,  2,\n","        27, 29], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0449,  1.4181, -1.8722,  ...,  0.9748, -3.4200,  0.9582],\n","        [-1.8943, -2.6745, -0.2133,  ..., -0.8456, -1.3739, -1.0146],\n","        [-2.7111, -1.5083, -0.9658,  ...,  0.1848, -0.9750, -1.4856],\n","        ...,\n","        [-0.5043,  1.9039, -0.5882,  ..., -1.1173, -1.6994, -1.0731],\n","        [ 3.7044,  6.4711,  0.1974,  ...,  3.3094,  0.3968, -1.3615],\n","        [-1.8232, -1.8084, -0.4070,  ..., -2.2671, -2.7595,  1.9221]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([13, 14,  9, 39, 23, 24,  1, 38, 15, 34, 14, 16, 28, 22,  1,  0, 19, 30,\n","         6, 46, 42,  2, 49, 47, 41, 16, 25, 11, 42,  8,  0, 23, 43, 36,  6, 37,\n","         9, 43, 24, 11,  5, 28, 37, 27, 28, 20, 45, 42, 40, 14, 39, 24, 26, 29,\n","        49, 31,  6, 45, 47, 20, 27,  4, 12,  8,  6, 48, 29, 10, 13, 22, 30,  0,\n","        35, 17,  2, 48, 12, 31,  2, 31,  2, 38,  3, 15, 20, 43,  7, 19,  8, 11,\n","         2, 29, 21, 16, 41, 44, 35, 32,  4, 26, 19, 45, 37, 27, 22, 34,  5, 24,\n","        33, 31, 26, 34, 16,  8, 47,  4,  3,  6,  4, 31, 40, 49, 44, 30, 12, 31,\n","        24,  4], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.2323e+00,  3.2331e+00, -1.2206e+00,  1.5374e-01, -7.7143e-01,\n","         -3.5213e-01, -3.2602e-01,  1.4281e+01, -2.5514e+00,  8.4514e-01,\n","         -1.3160e+00,  7.5740e-01,  1.2080e+00, -2.1720e+00, -1.4053e+00,\n","         -1.0656e+00, -2.6989e+00,  5.4777e-01,  5.8645e-01, -2.6377e+00,\n","         -1.0073e-01,  8.4264e-01,  1.4876e+00, -3.0841e+00, -1.5699e+00,\n","         -1.0962e+00,  7.0931e-01, -2.5203e-01,  3.9790e+00, -2.2744e+00,\n","         -2.1830e+00, -1.6067e-01,  8.4095e-01, -1.2673e+00,  2.9075e-01,\n","         -2.9287e-01, -1.4184e+00,  2.3098e+00, -1.7011e+00,  7.7940e-02,\n","          1.1178e+00,  2.3256e+00,  2.0852e+00, -1.7484e-01, -1.1727e+00,\n","         -9.1763e-02,  1.5402e+00, -1.4054e+00,  5.4310e-01, -1.4195e+00],\n","        [-1.8774e+00, -2.6821e+00, -4.7226e-01, -1.7055e+00,  4.0771e+00,\n","         -1.6171e+00, -1.6591e+00,  7.3630e-01, -9.6562e-01,  6.2029e-01,\n","          3.0926e-01,  1.8682e+00,  2.2207e+00, -2.5774e+00, -1.8182e+00,\n","         -2.9600e+00, -2.8014e+00,  4.8744e-01,  2.5420e+00, -1.4087e-01,\n","         -5.3280e-01,  2.2600e+00,  1.5916e+00, -2.6141e+00, -1.2140e-02,\n","         -8.6511e-01,  2.6591e-02, -6.4698e-01,  6.6312e-01, -1.0376e-01,\n","          1.9989e+00,  9.2287e-01,  2.7079e+00, -2.3651e+00, -9.5176e-01,\n","         -3.0826e+00, -9.6089e-01, -4.0711e-01,  6.7231e-01,  2.4607e+00,\n","          3.6851e+00,  2.6974e+00, -3.0805e-01, -1.7495e+00,  1.9240e-02,\n","          1.1502e+01, -1.6789e+00, -1.6011e+00, -1.4199e+00, -6.8523e-01],\n","        [ 6.0151e-01,  1.7580e-02, -6.2749e-01, -1.3930e+00, -2.7629e+00,\n","          1.0593e+00,  3.8137e+00, -3.1316e+00,  1.3170e+01, -2.1675e+00,\n","          5.7926e-01, -1.5697e+00, -1.2957e+00,  1.4976e+00,  4.0290e-01,\n","         -2.1591e+00, -3.0709e-01,  7.9602e-01, -2.1098e-01,  1.6339e+00,\n","          2.3909e+00, -1.8996e+00, -1.9998e+00,  2.4724e+00,  3.9481e-01,\n","         -9.5153e-01, -1.2008e+00, -2.4439e+00, -2.2807e+00, -2.3160e+00,\n","         -1.1784e+00,  9.1071e-01, -1.1612e+00, -3.6639e-01,  3.3932e+00,\n","         -1.2243e-01,  1.5303e+00, -1.1646e+00, -7.0073e-01, -1.4893e+00,\n","         -3.0058e-01, -1.7690e+00,  3.4604e+00,  4.4137e+00, -2.4179e-01,\n","         -2.7643e+00,  1.8349e+00, -1.6792e+00,  7.7725e-01, -1.8233e+00],\n","        [ 9.1830e-01,  8.8126e-02,  3.0117e+00,  1.6935e+00, -9.7015e-01,\n","         -1.7147e+00,  1.9560e-01, -3.0430e+00, -2.6318e+00, -1.3111e+00,\n","          1.5034e+00,  3.3010e+00, -1.1596e+00, -3.2784e+00, -1.1462e+00,\n","         -1.8858e+00,  3.7710e-01,  3.2221e+00, -1.0354e+00,  9.3413e-01,\n","         -2.7300e-01, -8.8533e-01, -7.2760e-01, -4.0943e+00, -5.7047e-01,\n","          2.3352e+00,  1.4856e+00, -1.5622e-01, -1.6536e+00, -5.4629e-01,\n","          1.3052e+01, -3.0470e+00, -4.6133e-01, -2.5396e+00, -1.0010e+00,\n","          1.3968e+00,  9.6372e-01, -3.2633e+00,  2.7638e+00, -1.9554e+00,\n","         -9.8512e-01, -2.0816e+00, -1.1134e-01,  6.6530e-01,  1.2950e+00,\n","         -2.8888e+00,  4.7754e+00, -2.0110e-01,  2.4517e+00, -3.3299e-01],\n","        [-1.9555e+00, -9.2400e-01, -9.3694e-01, -1.3229e+00,  9.9731e-01,\n","         -6.0142e-01, -4.6193e-01,  2.6988e+00, -1.6804e+00,  1.2128e+00,\n","         -2.8679e-01,  3.0125e+00,  2.4414e+00, -1.7107e+00, -1.9881e+00,\n","          4.8529e-01, -2.7871e+00, -2.0468e+00,  1.2359e+01, -3.6591e-01,\n","         -2.1807e+00,  5.6869e+00, -3.0999e-01, -2.1044e+00, -1.6096e+00,\n","         -7.0102e-01,  9.7373e-01,  3.3983e+00,  1.3111e+00,  3.0906e-01,\n","         -1.6598e+00,  1.2764e+00, -7.3102e-03, -1.4701e+00, -4.1944e-01,\n","         -5.9740e-01, -1.7530e+00,  8.5158e-01,  1.5041e+00, -1.1372e-01,\n","         -3.1856e-01,  3.4947e+00, -4.1202e-01, -3.7246e+00, -1.2878e+00,\n","         -4.0061e-02, -1.7202e+00, -8.2082e-01, -1.7800e+00, -1.6582e+00],\n","        [ 6.4892e+00, -2.9928e+00,  3.0426e+00,  8.3545e-02, -1.1352e+00,\n","         -1.0371e+00, -1.8127e+00, -2.6469e+00, -2.7516e+00,  3.6866e-01,\n","         -5.5249e-01,  3.2241e+00, -1.9447e+00, -1.5849e+00,  1.7278e+00,\n","         -3.3460e+00,  1.0836e+01, -9.7596e-01, -3.6455e+00, -1.7277e+00,\n","          8.7496e-01, -9.1030e-01,  8.7982e-01, -7.4951e-01,  2.8650e+00,\n","          4.3059e+00, -6.3638e-01,  5.5748e-01,  1.2984e-01, -1.6652e+00,\n","          1.5300e+00, -4.1922e-01,  4.4283e-01, -2.6973e+00, -2.5780e+00,\n","          3.2919e+00, -7.3282e-01, -2.2821e+00,  3.4878e+00,  2.8327e+00,\n","         -1.2511e+00, -8.6130e-01, -1.3431e+00, -4.5308e-01,  1.6055e+00,\n","         -4.4399e+00, -8.2694e-01,  8.8556e-01,  9.7174e-01, -9.1139e-02],\n","        [ 4.5473e+00,  2.4609e-01,  4.2655e+00,  2.1597e+00, -3.3493e+00,\n","         -5.6269e-01,  9.7935e-01, -6.7302e+00, -3.5897e+00,  8.6524e+00,\n","         -5.2692e+00, -6.8464e-01, -8.0065e-01, -4.6833e+00, -3.4181e+00,\n","         -3.3187e+00, -2.4767e-02, -5.6030e-01,  2.5098e+00,  4.0082e+00,\n","          4.4771e-01, -9.0459e-01, -3.2255e-02, -3.9592e+00,  1.6418e+01,\n","          3.7097e+00,  1.1364e+00,  2.9886e+00, -1.4904e+00,  1.5201e+00,\n","          2.3907e+00,  1.8283e+00, -2.5210e+00, -4.6772e+00, -1.6846e+00,\n","         -1.9432e+00, -3.3021e+00, -2.3767e+00,  5.8539e+00, -2.4228e+00,\n","         -1.6400e+00, -8.4311e-01, -2.1001e+00, -1.6124e+00,  1.1062e+00,\n","         -2.3432e+00, -3.1239e-01,  3.4718e+00,  2.4218e-01, -1.1851e+00],\n","        [ 2.3190e+00,  1.3594e+00,  2.0822e+00,  1.2293e+01, -2.0684e+00,\n","         -1.6791e+00,  2.8544e+00, -2.8801e+00, -1.2059e+00, -9.1177e-01,\n","         -3.1136e+00,  3.2777e-01, -1.9775e+00, -1.1479e+00, -1.1588e+00,\n","         -3.7457e+00,  1.5224e+00, -3.1711e-01,  4.1921e-01,  5.4607e+00,\n","          4.9446e-01, -8.6104e-01,  4.4987e-01, -1.6560e+00, -7.6778e-01,\n","          2.6996e+00,  7.2421e-01, -6.8842e-01, -3.6953e+00, -1.0007e+00,\n","          4.0655e+00, -1.6931e+00, -2.2387e+00, -2.3502e+00, -7.3024e-01,\n","          6.2398e-01, -1.2477e+00, -2.2308e+00,  1.3462e+00,  2.8789e+00,\n","         -1.8938e+00, -1.6596e+00, -1.6440e+00,  1.0352e+00, -2.2284e+00,\n","         -2.9719e+00,  3.8686e-01,  4.6330e+00,  1.1499e+00, -1.3188e+00],\n","        [-5.0769e-01, -2.3010e+00, -1.4332e+00, -3.2402e+00, -9.9584e-01,\n","          8.5095e-01, -1.5847e+00,  7.6606e-01, -2.6442e+00, -5.8932e-01,\n","         -7.7862e-01,  2.3697e+00,  2.6946e+00, -2.7942e+00,  1.5640e+00,\n","         -1.2889e+00, -3.9760e-01,  2.9948e+00, -7.9957e-01, -1.3497e+00,\n","         -6.3596e-01,  6.3462e-01,  3.9897e+00, -3.8078e+00,  2.5100e-01,\n","         -1.8606e-01,  5.3455e-01,  1.5341e+00, -1.3066e-01, -1.3394e+00,\n","         -1.5573e-01, -2.4361e-02,  1.3981e+01, -1.0098e+00, -1.4493e+00,\n","          2.3170e+00, -9.1743e-02, -3.1272e+00,  1.1837e+00, -2.2978e-01,\n","          8.1357e-01, -2.2936e-01, -3.1973e-01,  4.8526e-01,  1.4979e+00,\n","         -1.0475e+00, -1.6155e-01, -1.1440e-01, -4.5842e-01, -1.9854e+00],\n","        [ 3.1020e+00, -2.2188e+00,  4.1131e+00,  4.6962e+00, -2.1093e+00,\n","          6.3535e-01, -9.7680e-01, -4.1432e+00, -2.9853e+00,  3.4530e+00,\n","         -2.1953e+00,  1.3500e+00, -2.6261e+00, -2.5923e+00, -1.5918e+00,\n","         -1.8825e+00,  9.0949e+00, -6.6994e-01, -2.6481e+00,  3.0578e+00,\n","         -1.9253e+00, -8.9148e-01, -9.7719e-01, -3.8183e+00,  1.8500e+00,\n","          1.8190e+00,  1.2419e+00,  1.3606e+00, -4.8742e-01,  2.5331e+00,\n","          3.8914e+00, -1.1897e+00, -1.7949e+00, -1.3633e+00, -1.1806e+00,\n","         -4.3109e-01, -2.5387e+00, -8.1669e-01,  1.3564e+00, -1.6792e-01,\n","          7.9208e-01,  7.9321e-01, -1.6568e+00, -8.6131e-01,  3.7176e-01,\n","         -3.2518e+00,  2.1993e+00,  2.8761e+00,  6.5702e-01, -2.1102e-01],\n","        [-1.7692e+00, -4.6122e-01, -1.1171e+00, -1.9032e+00,  9.6908e-01,\n","         -9.9297e-02, -3.7359e-01, -2.6430e+00,  1.7770e+00, -6.9026e-01,\n","         -3.6002e-01, -2.7877e-01, -1.5712e+00,  8.3375e+00,  1.0663e+00,\n","          2.3550e+00, -2.2090e+00,  1.5269e-01, -1.3871e-01,  5.2583e-01,\n","          3.1585e+00, -5.4618e-01, -3.1320e+00,  1.4442e+00, -2.5200e-01,\n","         -1.8124e-01, -7.7820e-01, -1.7083e+00, -8.2394e-01,  4.0636e+00,\n","          1.6517e-01,  1.5348e+00,  5.5386e-02, -1.2419e+00,  4.8094e-02,\n","         -2.4421e+00,  3.1285e+00,  2.9232e-02, -7.1065e-01, -1.0028e+00,\n","         -2.5319e-01,  1.1705e+00,  1.2013e+00,  1.9298e+00, -8.9534e-02,\n","         -2.3723e+00, -1.8971e+00, -9.0030e-01, -1.3238e+00,  1.5521e+00],\n","        [-1.0574e+00,  2.0345e-02,  6.7931e-01, -2.1448e+00, -5.7589e-01,\n","          1.0478e+01, -9.2574e-01,  1.9545e-01, -1.9396e+00,  2.6251e+00,\n","          3.3858e+00,  8.1534e-02, -1.1842e+00, -4.1478e+00, -2.5357e+00,\n","          1.4210e+00, -1.4696e+00,  1.7183e-01, -7.4587e-01, -2.4775e+00,\n","         -1.9927e-01, -4.2516e-01, -3.8669e+00, -1.7150e+00, -2.3530e+00,\n","         -2.8941e+00,  2.3387e+00,  2.9621e+00, -1.6761e-01,  3.3614e+00,\n","         -1.9113e+00,  3.5568e+00, -6.3800e-02, -1.2876e+00,  2.3931e+00,\n","         -9.0217e-01, -2.8460e-01,  2.4093e+00, -7.7218e-01, -3.4539e+00,\n","          4.6320e-01,  1.9028e+00, -6.2731e-01, -4.0961e-02,  1.4151e+00,\n","         -1.3354e+00,  1.8111e+00, -6.8871e-01,  9.7559e-01,  5.6771e-01],\n","        [-9.7680e-01,  5.4799e-01, -9.0789e-01, -4.2866e-01, -1.2801e+00,\n","         -2.6611e-01,  9.2171e-01, -2.6604e+00,  2.5243e+00, -2.1508e+00,\n","         -9.6444e-01, -1.0723e+00, -2.6131e+00,  1.0062e+01,  1.6269e+00,\n","          4.3145e+00, -6.9940e-01, -6.0778e-01, -2.2052e+00,  2.6994e+00,\n","          1.4249e+00, -9.2077e-01, -1.9500e+00,  1.7343e+00,  4.2516e-01,\n","          5.0514e-01,  5.9174e-02, -2.3555e+00, -1.5947e+00,  2.7554e-01,\n","         -2.2535e+00,  1.8671e+00,  3.8645e-01,  1.7884e+00,  1.8312e+00,\n","         -5.8498e-01, -8.4066e-01, -5.4835e-01, -2.2090e+00, -1.3531e-01,\n","         -1.4667e+00, -1.5875e+00, -8.5510e-01,  2.3762e+00,  3.9029e-01,\n","         -1.6465e+00, -1.6909e-01, -4.1606e-01, -1.0528e+00,  1.8929e+00],\n","        [-1.5149e+00, -1.2065e+00,  2.3710e+00, -9.6880e-01, -7.9523e-01,\n","          2.1233e+00,  5.3997e+00, -2.2386e+00, -1.1386e+00, -1.5017e+00,\n","         -1.4293e-01,  1.6630e+00, -1.7130e+00, -1.5870e+00, -1.4889e+00,\n","          2.4103e-01,  5.1256e-01,  1.9339e+00, -1.3612e+00, -1.4696e+00,\n","         -2.2192e+00, -7.0335e-02, -1.9619e+00, -3.1044e+00, -1.7129e+00,\n","          1.2140e+00,  5.9453e+00,  7.7804e-01, -7.9502e-01,  2.2983e+00,\n","          1.2362e-01, -9.6690e-01,  9.4511e-01,  1.1405e+01, -1.5805e-01,\n","          3.4911e+00, -1.7201e+00, -2.0033e+00, -1.9748e+00, -7.2632e-02,\n","         -2.2600e+00,  6.7199e-02, -1.3413e+00,  1.3622e+00,  6.4658e-01,\n","         -1.3635e+00, -2.0568e-01, -2.0435e+00,  1.1307e+00, -1.7178e+00],\n","        [-1.7539e+00, -2.9926e-01, -2.2980e-01, -1.1845e+00,  4.0670e+00,\n","         -1.1388e+00, -6.6015e-01, -4.4712e+00,  2.9246e+00, -4.4442e-01,\n","         -9.2273e-01, -2.2957e+00,  7.8804e-01,  1.9816e+00, -1.2829e-01,\n","          2.8740e+00, -3.1078e+00, -1.1273e+00, -2.0291e+00, -1.7399e+00,\n","          5.0006e+00, -1.2282e+00, -2.7131e-01,  1.3090e+01, -1.3927e+00,\n","         -1.6073e+00, -3.0681e+00, -3.4292e+00, -1.2683e+00,  3.1005e+00,\n","         -5.9426e-01,  1.6967e+00, -3.2872e-01, -3.3252e+00, -8.8628e-01,\n","         -2.8574e+00,  4.4145e+00,  3.7749e+00,  1.9398e+00, -1.0858e+00,\n","          5.5234e-01, -7.1815e-01, -3.4444e-02,  2.0423e+00,  7.5548e-02,\n","         -2.2470e+00, -2.1866e+00, -2.5853e+00,  1.5325e-01,  4.9180e+00],\n","        [-3.0400e-01,  1.7956e+00, -1.1148e+00, -2.4391e-01,  5.3697e+00,\n","         -3.6789e-01, -2.7702e+00, -1.4072e+00, -5.3283e-01,  6.3062e-01,\n","          1.0509e+00, -3.1990e+00,  2.0286e+00, -4.0620e+00, -1.9719e-01,\n","         -5.8683e-01, -3.7509e+00, -2.1498e+00,  3.4296e-01, -2.9595e+00,\n","         -1.7925e+00,  1.6941e+00,  2.8650e+00,  3.2581e+00, -4.7813e-01,\n","         -2.6175e+00, -1.8785e+00, -8.4891e-01,  1.0194e+00,  2.1161e+00,\n","         -7.6830e-01,  9.1205e-01, -9.2076e-01, -4.3582e+00,  1.4513e+00,\n","         -3.0940e+00,  1.3983e+00,  1.1799e+01,  2.1807e+00, -2.8103e+00,\n","          4.2903e+00,  2.0073e+00,  1.8626e+00, -1.0553e+00,  2.2965e-01,\n","         -2.3235e-01,  1.0528e+00, -2.8235e+00, -1.3594e+00,  5.7255e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 7, 45,  8, 30, 18, 16, 24,  3, 32, 16, 13,  5, 13, 33, 23, 37],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8519,  8.2973, -0.8770,  ..., -1.7556, -2.1910,  2.5735],\n","        [-0.2939,  4.7335,  0.1038,  ..., -0.5399, -0.7845,  3.8341],\n","        [ 8.3805, -3.2129,  1.6314,  ...,  7.4542, -1.3026, -1.9882],\n","        ...,\n","        [ 2.0154,  0.3977, -0.7326,  ..., -2.1528,  1.6327, -0.4228],\n","        [-0.3298, 11.0104,  0.8916,  ..., -1.3157, -2.0434,  1.6864],\n","        [ 1.0892, -3.0287,  4.9751,  ..., -1.8518,  1.7506, -0.0986]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 387/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.8834, -0.9259,  0.0277,  ...,  2.5616, -0.6673, -2.3076],\n","        [-2.6097, -3.5663, -1.6014,  ..., -3.3166, -2.0728, -1.6130],\n","        [ 1.1850,  2.5048,  1.5368,  ..., -1.0444,  0.3841, -0.2803],\n","        ...,\n","        [ 3.0425, -2.9841,  3.3688,  ...,  1.8291, -0.6202, -0.8630],\n","        [-0.7585,  1.4509, -0.2803,  ..., -3.7950, -1.5008,  3.4550],\n","        [-0.4601,  3.0138, -2.4797,  ..., -2.3168, -1.5128,  1.1984]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([25, 28, 43, 25, 34, 13, 37, 19, 15, 44, 20, 37,  5, 16, 21, 10, 40, 33,\n","        45,  3, 28, 21,  7, 47, 12, 10,  7,  2, 10,  9, 27, 26, 19, 27, 36,  6,\n","        48, 35,  3, 20, 12, 40, 21, 16,  4, 15,  2, 45, 14, 25, 19, 41, 17,  7,\n","        22, 12, 47, 40, 29,  6, 44, 43,  5, 32, 42, 11, 20,  9, 10,  4, 37,  6,\n","        33,  5, 24,  3, 13, 26, 17, 44, 38, 11,  3,  0,  9,  3, 10,  0, 43, 11,\n","        40, 22, 47,  0, 10, 26, 34, 48, 28, 16, 11, 49, 12, 20, 38, 12, 16,  9,\n","        24, 28,  3, 47, 37, 13, 27,  2, 48, 31, 49, 33, 41, 15, 37, 41, 16, 35,\n","        23, 31], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.9577, -2.7223,  1.2493,  ..., -1.8984, -3.1589,  2.6873],\n","        [ 2.1655,  1.7145,  1.7504,  ..., -0.4811,  0.1564, -0.0179],\n","        [ 3.2651, -3.0602,  2.3929,  ...,  2.9229,  0.8538, -1.8403],\n","        ...,\n","        [-1.2922,  3.5985, -0.2001,  ..., -0.4305, -0.7086,  3.8240],\n","        [-2.9293,  0.9283,  1.2665,  ..., -0.8502, -0.9700, -1.2975],\n","        [-1.2577, -1.4321,  0.0456,  ..., -2.5693,  0.4824,  0.5812]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 4, 43, 39,  4,  9, 30, 47, 17,  4, 11,  8, 26,  8, 27,  8, 10,  6, 23,\n","        45,  4, 18, 41, 37, 20, 16, 18, 18, 35, 18, 23, 24,  4, 40, 31, 11, 22,\n","        12, 32, 17,  9, 15, 41, 36, 23, 11,  2, 47, 21,  3, 28, 32,  1, 14, 29,\n","         3, 34, 48, 38, 24, 24,  1, 17, 35, 22, 40,  1, 13, 12, 26, 12, 45, 29,\n","        27, 31, 33, 15, 20, 36, 49, 13, 30, 31, 14, 46, 27, 29, 14, 23, 31, 27,\n","        20, 34, 17, 19, 33, 19, 35, 14, 46, 47, 49, 30, 33, 36, 42, 46, 22, 39,\n","         8, 27, 16, 13,  0,  1, 27, 25, 14, 30, 38, 29, 32, 49, 17,  9, 46, 34,\n","        31, 44], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.9201, -2.4307, -1.3760,  ..., -3.7878, -2.3012,  0.1117],\n","        [ 0.3447, -1.5999, -2.1647,  ...,  1.3458, -1.3300, -1.5884],\n","        [ 0.2519, -3.3686, -0.0803,  ...,  8.5476, -0.8933, -2.3219],\n","        ...,\n","        [ 4.0073, -4.5338,  3.9093,  ...,  6.9687,  0.5511, -2.5342],\n","        [-3.0606, -1.4567, -1.3115,  ..., -0.6798, -1.8131,  3.0442],\n","        [-2.6712, -2.3594, -0.9360,  ..., -1.1952, -1.8817, -0.5234]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([28, 32, 25, 41, 16,  0, 28, 34, 35,  1,  8, 30, 48, 25, 21, 42,  7, 14,\n","        20,  2, 30,  7, 46, 44, 32, 42, 30, 49, 26, 37, 18,  4, 29, 48, 31,  1,\n","        42, 49, 21, 42, 13,  0, 19,  7, 32, 36,  1, 33, 41, 40, 47,  5, 26, 14,\n","         6,  5, 11, 31,  5, 40,  7,  2,  0, 16, 30, 18,  0, 30,  1, 15, 19, 48,\n","        10,  5,  8, 13, 39, 49,  6, 25,  2, 15, 44, 20, 45, 24,  9, 17, 18, 29,\n","        22, 36, 29, 12, 38, 41, 45, 23, 39,  9, 24,  6, 36, 24, 17, 26, 46, 10,\n","        36,  7, 37, 41, 43,  8,  2, 22,  2,  9, 46, 17, 29, 14, 16, 43, 42, 25,\n","        15, 45], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 7.8525e-01, -2.5270e+00,  1.9744e+00, -2.3837e+00, -1.3678e+00,\n","         -7.4646e-01,  4.8775e+00, -4.8582e-01, -2.7500e+00, -1.6281e+00,\n","         -1.5612e+00,  3.0599e+00,  1.6155e-01, -9.2753e-01,  1.6103e+00,\n","         -2.0806e+00,  2.2428e+00,  1.5313e-01, -1.8196e+00, -7.3812e-01,\n","          3.6336e-01,  2.0821e-01,  3.4287e-01, -2.0230e+00, -9.3830e-01,\n","          2.5515e+00, -4.3574e-01,  1.1291e+00, -4.9747e-01, -1.2967e+00,\n","          1.6729e+00, -1.3358e+00,  1.1949e+00,  1.0742e+00, -6.5835e-02,\n","          1.0353e+01, -9.8347e-01, -2.7310e+00,  3.3780e-01,  5.4801e-01,\n","         -2.9939e+00,  7.1691e-01, -1.7706e+00,  5.6771e-01,  1.2615e+00,\n","         -3.0684e+00, -1.1250e+00,  3.9665e+00, -2.3394e+00,  3.0029e-01],\n","        [ 1.8469e+00,  5.2281e-01,  3.6961e-01, -1.3875e+00,  1.9875e+00,\n","         -2.0568e-01, -1.5688e+00, -1.7519e+00, -2.0029e-01, -8.7494e-01,\n","          7.0396e-01, -2.8103e-01, -6.0503e-01, -5.6788e-01, -2.0505e+00,\n","         -2.4527e+00, -8.9936e-01, -6.1826e-01, -1.4007e+00, -2.4052e+00,\n","          2.3637e+00, -6.0950e-01, -1.3264e+00,  1.4674e+00, -3.4082e-01,\n","         -1.0921e+00, -2.7069e+00, -6.2451e-02, -7.8038e-01,  4.7844e-01,\n","          2.2685e+00, -2.6326e-01, -4.6202e-01, -3.1641e+00,  1.1732e+00,\n","         -1.1146e+00,  1.1610e+01,  5.8613e-01,  1.5169e+00, -1.2222e+00,\n","          5.9116e-01, -6.2995e-01,  2.4669e+00,  1.2811e+00,  9.0889e-01,\n","         -1.3874e+00,  8.6268e-01, -6.8638e-01, -1.3175e-01,  1.9127e+00],\n","        [-1.7708e+00, -4.3216e-01, -1.3663e+00, -1.4393e+00, -1.7562e-01,\n","          1.0366e+00,  3.5743e-01, -2.1184e+00,  1.2960e+01, -8.9110e-01,\n","         -3.9241e-01, -2.1775e+00, -1.3803e+00,  4.4682e+00,  9.3544e-01,\n","          6.6645e-01,  4.5724e-02, -3.8346e-01,  3.7723e-01, -1.4038e+00,\n","          4.0543e+00, -9.0345e-01, -4.2183e+00,  1.2427e+00, -1.9235e+00,\n","         -2.2154e+00, -1.3463e+00, -1.3278e+00, -1.7026e+00,  1.8234e-01,\n","         -2.0682e+00,  3.7149e+00,  2.2881e+00, -4.5051e-01,  4.2077e+00,\n","         -2.8372e+00,  1.2847e+00, -3.7050e-01, -1.9683e+00, -1.9417e+00,\n","          2.7072e-01,  2.3732e-03,  1.6569e+00,  2.6532e+00, -1.1453e-01,\n","         -9.6054e-01,  1.8221e+00, -3.0366e+00,  5.2043e-01,  7.2820e-01],\n","        [ 4.7087e+00, -1.1216e+00,  2.5228e+00,  4.8554e-01, -6.2476e-01,\n","          1.3901e+00, -1.6171e+00, -3.7418e+00, -1.5020e+00, -1.3698e-01,\n","          1.2351e-01,  2.9906e+00, -2.1154e+00, -2.6413e+00, -2.2356e+00,\n","         -2.4018e+00,  4.1106e+00,  8.4187e-01,  4.8695e-01, -3.1662e-01,\n","         -2.0579e+00,  2.2106e+00, -1.3043e+00, -2.6641e+00,  1.2030e+00,\n","         -1.3870e+00,  2.4984e+00, -2.8272e-01, -1.1817e+00,  4.5137e-01,\n","          1.8468e+00, -1.7357e+00,  1.6918e+00, -3.4004e+00, -1.1491e+00,\n","         -1.3017e+00, -1.9976e+00, -8.0827e-02,  1.0198e+01, -2.3572e+00,\n","          3.8347e-01, -1.6727e+00,  1.6319e+00,  5.1306e-01,  1.0099e+00,\n","         -2.8686e+00,  2.3754e+00,  1.0155e+00,  4.9397e-01,  6.7515e-01],\n","        [-7.4746e-02, -4.0179e+00, -1.3994e-01,  3.5406e+00,  3.9616e-01,\n","         -2.2907e+00, -1.3356e+00,  1.7724e+00, -1.5641e+00,  7.7453e-01,\n","         -1.3876e+00,  1.7416e+00, -8.2026e-01, -1.4351e-01, -1.2756e+00,\n","         -1.9470e+00,  1.6800e+00, -1.3192e+00, -4.0744e-01,  2.8758e-01,\n","          5.7725e-01,  1.6534e+00,  1.1720e+00, -2.6785e-01,  3.3439e-01,\n","         -4.0724e-02, -2.1935e-01, -2.5031e+00, -2.2026e-01, -1.6545e-01,\n","         -1.0464e+00,  1.3525e+00, -1.9260e-01, -2.0004e+00, -2.0714e+00,\n","         -1.0090e+00, -1.3571e+00, -1.4281e+00,  1.8349e+00,  1.3491e+01,\n","          1.3168e+00,  1.4282e+00, -1.3721e+00, -2.3605e+00, -4.8631e-01,\n","          2.5035e+00, -3.0067e+00,  8.9884e-01,  1.0645e+00, -2.0158e+00],\n","        [ 8.5375e-02, -3.3668e+00,  6.7407e-02, -2.1582e+00,  2.8856e-01,\n","          2.5333e+00, -2.4777e-01, -1.4095e+00, -1.6994e+00,  1.8089e+00,\n","         -2.0979e-02,  3.1800e-01,  8.2378e-01, -2.2077e+00, -4.1505e-01,\n","          2.1684e+00,  1.2032e+00,  2.4379e-01,  6.9956e-01, -7.2781e-01,\n","         -9.3946e-01,  1.0628e+00, -2.0004e+00, -9.2045e-01, -5.5395e-01,\n","         -6.6112e-01,  2.2750e-01,  1.0186e+01, -5.7762e-01,  1.8948e+00,\n","         -4.8978e-01,  1.2876e+00,  4.4159e-01, -8.6883e-01, -6.6490e-01,\n","          6.3520e-01, -6.2578e-01,  7.9810e-02,  6.1454e-01, -1.6028e+00,\n","         -4.9176e-01,  1.4476e+00, -8.3924e-01, -1.4572e+00, -6.3916e-02,\n","         -1.5150e+00, -1.4625e+00,  6.5560e-01, -6.4281e-01,  5.8276e-01],\n","        [ 2.3310e+00,  1.0957e+00,  8.3225e-01, -4.3701e-01,  3.9490e-01,\n","         -5.4769e-01,  9.1650e-01, -3.3188e+00,  7.2272e-02,  1.3059e+00,\n","         -1.6366e+00, -1.6557e+00, -3.8557e-01, -5.0324e-01, -2.3393e-02,\n","         -6.1620e-01,  7.3207e-01, -1.3977e+00,  1.2747e+00,  8.6340e-01,\n","          1.4693e+00, -5.6901e-01,  3.8412e-01, -4.6239e-01,  1.3721e+01,\n","          9.7317e-01, -6.1581e-01, -3.3938e+00, -1.1373e+00,  8.5790e-01,\n","          6.3623e-01,  1.4506e+00, -1.0062e+00, -2.9466e+00, -1.7806e-01,\n","         -2.2679e+00, -4.4332e-01,  3.7710e-01, -4.2546e-01, -1.8463e+00,\n","          1.5575e+00, -2.7607e-01, -1.7186e-01,  1.9673e-02,  9.1883e-01,\n","         -8.5966e-01, -2.8239e-02,  1.2079e+00, -1.2931e+00,  6.3556e-01],\n","        [ 2.5570e+00,  2.9267e+00,  2.4631e-01,  1.8787e+00, -3.8820e+00,\n","         -8.9818e-02,  3.6088e+00, -4.0463e+00,  1.6111e+00, -8.2845e-01,\n","         -3.4601e+00,  9.0314e-01, -2.8815e+00,  4.1772e+00, -1.9722e-01,\n","         -4.7778e-01, -1.6973e+00, -9.0249e-02,  3.2528e+00,  1.2334e+01,\n","         -1.5181e+00, -2.5372e+00, -1.8084e+00, -5.8190e-01,  4.5377e+00,\n","          2.0823e+00,  3.3507e+00, -1.7478e+00, -3.7373e+00,  6.3720e-01,\n","         -4.3371e-01,  7.4798e-01, -1.8861e+00,  8.5357e-01,  2.8883e-01,\n","         -1.3088e+00, -3.8109e+00, -1.4702e+00,  1.4249e+00, -4.8522e-02,\n","         -1.6900e+00, -1.3631e+00, -2.2215e+00,  1.3471e+00, -1.8714e+00,\n","         -2.3601e+00,  7.2221e-01,  1.1005e+00, -7.5096e-02, -1.8789e+00],\n","        [-1.0546e+00, -1.6190e+00,  2.5420e+00,  1.3639e-01, -7.7730e-01,\n","          1.3383e+00, -1.3034e+00, -2.1711e+00, -3.8244e+00,  8.6926e-01,\n","          6.7078e-01,  4.6530e+00, -1.1024e+00, -1.7040e+00, -2.6865e+00,\n","         -1.1682e+00,  8.2937e-01,  2.0938e+00, -4.7061e-01,  1.6545e+00,\n","         -1.2682e+00,  1.0039e-01, -1.6336e+00, -3.3305e+00, -4.9092e-01,\n","          1.4141e+00,  9.4870e-01, -5.4988e-01,  3.6127e-01,  3.2624e+00,\n","          1.3152e+01, -2.5494e+00, -1.6149e+00, -1.4539e+00, -8.0287e-01,\n","         -4.5465e+00, -2.1083e+00, -1.6993e-01,  1.7601e+00, -1.0088e+00,\n","          2.5307e+00, -7.4521e-01,  4.7090e-01, -7.7783e-01, -1.1002e+00,\n","         -1.0912e+00,  2.8431e+00, -4.2541e-01,  1.0830e+00,  8.4904e-01],\n","        [-1.0490e+00, -7.2828e-01,  1.2425e+00,  5.5589e-01,  3.0162e+00,\n","         -1.2496e+00, -1.2518e+00, -2.0731e+00,  2.5599e+00,  1.5451e-01,\n","          6.5129e-01, -3.9108e+00,  1.0628e-01,  2.2430e+00, -7.1505e-02,\n","          1.3067e+00, -1.4384e+00, -2.4143e+00, -8.2646e-01, -1.6206e+00,\n","          3.9083e+00, -3.5242e-01, -9.4082e-01,  1.1276e+01, -2.0569e-01,\n","         -2.5839e+00, -9.7565e-01, -3.0434e+00, -3.3984e-01, -9.6782e-01,\n","         -2.5674e+00,  4.8788e+00, -1.3665e+00, -2.7414e+00,  1.1261e+00,\n","         -2.2665e+00,  7.9714e-02,  6.3519e+00, -1.4195e+00, -2.0706e+00,\n","          6.9999e-01, -6.9398e-01, -5.5003e-01,  1.3083e+00,  3.1475e-01,\n","         -2.1368e+00, -9.4650e-01, -3.6564e+00,  1.4864e+00,  1.2477e+00],\n","        [ 1.4543e+00,  1.0499e+01,  8.1158e-01,  2.6331e+00, -1.6173e+00,\n","          1.2971e+00, -1.8324e-01, -1.6969e+00,  4.7848e-01,  1.2482e+00,\n","         -3.9224e-01, -8.6560e-01, -2.2148e+00, -2.2726e+00, -2.1011e+00,\n","         -1.5288e+00, -2.8215e+00, -5.8108e-02,  1.8435e+00, -1.6998e+00,\n","          3.1674e+00,  2.6355e-01, -2.8228e+00, -2.4201e+00,  1.2085e+00,\n","         -1.9819e+00,  1.1607e+00, -2.1375e+00, -3.0926e+00,  9.2324e-01,\n","         -1.0286e-02,  2.0088e+00, -1.4032e+00, -2.6464e+00,  3.5784e+00,\n","         -3.9826e+00,  1.6025e+00,  2.0122e+00, -4.4190e-01, -4.1307e+00,\n","          2.7925e+00, -4.0343e-01,  3.1223e+00,  2.0171e+00, -6.8447e-01,\n","         -3.2023e+00,  3.4263e+00, -4.6717e-01,  2.3659e+00, -3.2500e-01],\n","        [-4.1497e+00, -3.0714e+00, -1.1767e+00, -2.4385e+00,  1.0222e+00,\n","          6.7266e-01, -6.4878e-01,  1.0947e+00, -1.9942e+00,  2.7647e-01,\n","          9.8559e-01,  1.9014e+00,  2.8407e+00, -1.0844e+00, -1.4840e+00,\n","         -9.2200e-01, -1.1032e+00,  9.0222e-01,  4.5941e+00, -1.8904e+00,\n","         -1.6505e+00,  1.3750e+00, -1.6247e+00, -2.1930e+00, -1.8439e+00,\n","         -1.2280e+00, -1.1219e+00,  4.1134e+00,  1.2021e+01,  1.6252e+00,\n","          1.6097e+00,  1.1423e+00,  7.0576e-02, -2.7456e-01, -5.1627e-02,\n","         -1.5939e+00, -1.4637e+00,  2.2727e+00, -1.2497e+00, -3.5382e+00,\n","          2.3809e+00,  6.0623e+00, -7.5772e-01, -1.9202e+00, -1.9942e+00,\n","          1.8618e+00, -5.7527e-01, -2.8677e+00, -1.0481e+00,  2.9869e-01],\n","        [-1.3004e+00, -2.6530e+00,  4.3388e-01, -1.0687e+00,  9.2610e-01,\n","         -3.5177e+00, -1.4875e+00, -1.0291e+00, -1.5864e+00, -4.2917e-01,\n","          4.2018e-01,  2.4349e-01,  2.8072e+00, -1.4026e+00,  2.8355e+00,\n","         -8.2345e-01, -1.0891e+00,  1.6527e+00, -1.9104e+00, -7.2769e-01,\n","         -1.0499e-01,  3.6184e-01,  1.1080e+01, -7.9148e-01,  7.3178e-01,\n","          3.4351e+00, -3.3941e+00, -1.5992e+00, -8.2421e-03, -6.9237e-01,\n","          4.9539e-01, -1.5335e+00,  4.4428e+00, -2.5467e+00, -1.1060e+00,\n","          4.4295e-01,  1.3407e-01, -1.9979e+00,  1.1050e+00,  2.1640e+00,\n","          1.2941e+00,  2.8885e-01,  1.5067e-01,  1.6737e+00,  7.2160e-01,\n","         -1.3869e+00, -2.7797e+00,  4.5120e-01,  2.3315e-01, -1.4409e+00],\n","        [ 6.5671e-01, -1.3978e+00,  3.6718e+00, -1.8438e+00, -8.5930e-01,\n","          1.1282e+00,  4.9580e+00, -6.6587e-01, -1.2812e+00, -4.1860e-01,\n","         -1.5844e+00,  3.0965e+00, -1.3725e+00, -7.1449e-01, -1.1483e+00,\n","         -1.9763e+00,  2.3605e+00,  7.2038e-01, -3.1882e+00,  1.4833e-01,\n","         -7.9304e-01, -1.3247e+00, -1.2945e+00, -1.8886e+00, -9.2257e-01,\n","          3.5890e+00,  3.3689e+00,  2.7848e+00, -1.9981e+00, -4.1197e-01,\n","          7.1385e-01, -1.5984e+00, -4.5233e-01,  4.6828e+00, -2.0936e+00,\n","          1.1669e+01, -7.4760e-02, -2.9957e+00, -6.0882e-01, -2.6702e-01,\n","         -3.5620e+00, -1.2814e+00, -2.1652e+00,  1.1112e+00,  6.2757e-01,\n","         -1.5070e+00, -8.7726e-01,  1.1425e+00, -1.2779e+00, -3.6526e-01],\n","        [-2.3670e+00, -1.6287e+00, -1.9001e+00, -2.6365e+00, -2.4265e-01,\n","          3.0214e+00, -1.6347e+00,  2.4657e+00, -2.7306e+00,  2.9447e+00,\n","         -1.4672e+00,  6.7743e-01,  1.7464e+00, -2.2562e+00, -2.3381e+00,\n","          1.6923e+00, -5.1185e-01,  3.1196e+00,  7.8896e-01, -2.4660e+00,\n","         -4.9363e-01,  4.4323e-01,  7.9919e-01, -2.3675e+00, -1.6921e-01,\n","          5.7922e-01,  1.1087e+00,  7.5763e-01, -2.1383e-01,  2.1353e+00,\n","         -9.6924e-01,  3.7119e-01,  9.5998e+00, -1.0079e+00, -1.1576e+00,\n","         -3.6819e-01, -5.3055e-01, -5.3527e-01,  9.2031e-01, -5.6904e-01,\n","          3.1535e-01,  2.3921e+00, -7.2780e-01, -2.0676e+00,  3.2232e+00,\n","          1.1041e+00, -1.0178e+00, -1.6443e-01, -1.1615e+00, -7.9025e-01],\n","        [ 1.8388e+00,  2.7432e+00,  2.0386e+00,  1.0413e+01, -5.5654e-01,\n","          1.0472e+00,  4.8471e-01, -2.2666e+00, -1.4493e+00,  1.8028e+00,\n","         -8.2504e-01, -5.2287e-01, -8.0678e-01, -1.6056e+00, -9.1981e-01,\n","         -1.4105e+00,  1.8358e+00, -5.7924e-01,  1.0126e-01,  2.7017e+00,\n","         -2.9378e-01, -1.4640e+00, -1.0476e+00, -2.0660e+00, -1.2138e+00,\n","         -1.3218e+00,  3.1881e+00, -5.9200e-01, -2.1911e+00,  3.4354e-01,\n","          1.3143e+00, -9.3105e-01, -1.5324e+00, -1.4644e+00, -4.3073e-01,\n","         -1.6280e+00, -2.2056e+00,  6.1070e-01,  9.7549e-01, -9.3485e-01,\n","         -9.9270e-01, -2.3502e+00,  2.5414e-01,  6.3123e-01, -8.6812e-01,\n","         -1.8775e+00,  2.6090e+00, -4.5517e-01, -4.2656e-02, -1.5838e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([35, 36,  8, 38, 39, 27, 24, 19, 30, 23,  1, 28, 22, 35, 32,  3],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8543,  8.2731, -0.8797,  ..., -1.7572, -2.1945,  2.5800],\n","        [-0.2907,  4.7115,  0.1090,  ..., -0.5446, -0.7770,  3.8420],\n","        [ 8.3814, -3.2131,  1.6299,  ...,  7.4646, -1.3003, -1.9843],\n","        ...,\n","        [ 2.0134,  0.3987, -0.7325,  ..., -2.1491,  1.6297, -0.4248],\n","        [-0.3264, 11.0074,  0.8924,  ..., -1.3219, -2.0479,  1.6972],\n","        [ 1.0918, -3.0310,  4.9787,  ..., -1.8469,  1.7542, -0.0978]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 388/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.2790, -0.9369,  0.5668,  ..., -1.0001,  2.8150, -1.8857],\n","        [ 4.3431, -1.8017, -0.6728,  ...,  3.9820, -0.4134, -0.1984],\n","        [ 2.3822,  0.8296, -0.2704,  ..., -1.0916, -1.5447, -2.0006],\n","        ...,\n","        [ 0.5677,  2.5142,  0.8557,  ..., -1.4704,  1.5486,  0.8484],\n","        [-2.0294, -1.7739, -0.4799,  ...,  1.4382,  1.7757, -0.1171],\n","        [ 1.2138, -1.8302,  0.0577,  ...,  6.5571, -0.8694, -2.3256]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([17,  6,  5, 19, 28, 41, 16, 14, 37, 35,  9, 23, 29, 40, 32, 19, 10, 10,\n","        39,  2, 17, 34, 13,  1, 40, 14, 33, 20, 45, 48, 30, 20, 16,  3,  3, 15,\n","         1, 24,  6, 22, 41, 26, 28, 40, 10,  8,  5, 48, 15,  9, 32, 19, 20, 19,\n","         6, 39, 20, 44, 30, 43, 37,  3, 22, 46,  4, 13,  0, 30,  3, 38, 45, 46,\n","         5,  6,  1, 11,  3,  8,  6, 13, 30, 36, 45, 41, 44, 15, 27, 48, 42,  3,\n","        37, 21,  5, 18,  4, 13,  7, 19,  4, 40, 27, 46,  0, 23, 31, 44, 29, 47,\n","        42, 36, 27, 12, 17, 26, 21, 26,  7, 34, 20, 19, 49, 41, 47, 33, 49, 43,\n","        44, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.0461, -0.2419, -1.0755,  ..., -2.1124, -0.8507, -1.2661],\n","        [-2.3060, -0.1673, -1.5396,  ...,  4.8881, -1.6658, -1.6497],\n","        [-1.4775,  0.3064, -0.7065,  ..., -1.1043, -0.0663, -0.8566],\n","        ...,\n","        [ 2.3921,  2.8821,  1.7861,  ..., -0.0828,  0.4084,  0.6693],\n","        [-1.4226, -2.1305, -0.1031,  ..., -0.9463, -1.1851, -0.8095],\n","        [ 2.9651,  0.3923,  0.0314,  ..., -1.9776,  4.9149, -0.8819]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 18,  7,  1, 40,  1,  9, 17, 25,  3, 16, 14, 31, 11, 44, 32, 24, 10,\n","         5, 19, 17, 16, 11, 49, 47, 18, 32, 31, 23, 12, 42, 31, 29, 21,  0, 25,\n","        45, 31,  0, 22, 28, 11, 47, 42,  0,  8, 26, 21, 24,  9, 40, 12, 12,  3,\n","        29, 24, 14, 27, 17, 23, 43,  1, 11, 30, 32, 14, 31, 32,  2, 24, 16, 39,\n","        24, 27, 36, 26, 33, 21, 38, 49, 15, 12, 12, 48,  0, 20, 32, 24, 43, 27,\n","        27,  7, 42, 20, 49, 31, 30,  2, 24, 34, 35, 33, 11, 35, 41, 12, 39,  1,\n","        27, 30, 31, 43, 36, 22, 22, 22, 26, 40, 33, 28, 29, 10, 21, 16,  1,  3,\n","        14, 42], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.6873,  1.2551, -0.9325,  ..., -3.6958, -0.1981, -0.3626],\n","        [ 0.7297, -1.3342,  1.2780,  ..., -0.1835,  1.1940,  0.7309],\n","        [-1.0928, -1.4541,  0.3333,  ..., -2.9900, -0.0868,  1.4369],\n","        ...,\n","        [-1.2337,  1.4768, -1.6812,  ..., -3.8103,  0.1485,  2.0542],\n","        [ 3.4431,  2.8637,  0.8030,  ..., -0.2975,  0.0141,  1.1735],\n","        [ 1.0628, -3.0000,  1.7437,  ...,  0.1194, -0.1343, -1.1253]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 30, 44, 18, 34, 45, 14, 47,  7, 42, 38, 28,  1, 35, 15, 29,  2, 38,\n","        31, 26,  9,  7,  9, 10, 10, 23,  0, 35, 29,  2, 12, 25, 41, 47, 14, 46,\n","        39, 33, 15, 29, 25, 49, 30, 10, 11,  7,  9, 34,  5, 32, 49,  2, 20, 23,\n","        25, 37, 27, 23, 13, 18, 48,  9, 28, 11,  8, 33, 48,  2, 40, 47,  9,  4,\n","        37, 27, 41,  4, 38,  6,  4, 15, 46, 48, 45, 25, 26,  6, 18, 36, 16, 47,\n","        49, 16, 36,  2, 25, 13, 36, 46, 37, 16, 24, 15, 35, 20, 41, 28, 37,  9,\n","        13, 28, 17, 19, 17, 16, 12,  4,  2, 46, 38, 43,  7, 10,  8, 14, 29,  8,\n","        36, 30], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.4697e+00, -1.6842e+00, -7.5436e-01, -1.0756e-01,  2.6707e+00,\n","         -1.4957e+00, -8.4386e-01,  2.9229e-01,  7.6830e-01,  2.4224e+00,\n","         -3.3551e-01,  1.1171e-01,  4.9678e-01, -1.3788e+00, -2.6066e+00,\n","         -1.9057e+00, -7.4427e-01, -6.2749e-01,  3.1527e+00, -1.8922e-01,\n","         -1.3713e+00,  1.0303e+00, -5.2606e-02, -2.6193e+00,  1.8006e-01,\n","         -1.4212e+00,  7.0294e-01, -2.1888e-01,  8.6520e-01,  8.6206e-01,\n","          2.0466e+00,  1.2456e+00,  2.8380e+00, -2.3049e+00, -4.4584e-01,\n","         -3.4233e+00, -2.3931e+00,  3.2756e-01,  4.9345e-01,  5.1180e-01,\n","          4.2948e+00,  2.3906e+00, -1.0387e+00, -1.8716e+00, -9.0983e-01,\n","          1.2074e+01,  1.4188e+00, -1.5608e+00, -1.1458e+00, -3.7472e-01],\n","        [-2.0408e+00,  2.1961e+00, -9.8044e-01, -4.5910e-01, -3.9898e-01,\n","          1.6270e+00, -3.1698e-01, -4.3871e-01,  2.5897e+00, -3.2264e+00,\n","         -9.0964e-01, -8.3368e-02, -2.6713e+00,  2.2704e+00,  9.8118e-01,\n","          2.1381e+00,  4.5387e-02, -2.8373e+00, -7.2066e-02, -1.0743e+00,\n","          1.9490e-01,  5.2187e-01, -4.0592e+00,  8.2608e-01, -1.4627e+00,\n","         -2.9977e+00, -6.4441e-01, -7.8066e-01, -2.0093e+00,  7.5750e-01,\n","         -1.0419e+00,  1.4445e+00,  1.1246e+00,  1.7625e+00,  1.2403e+01,\n","         -2.2065e+00,  1.0798e+00,  2.8478e+00, -1.3920e+00, -1.8978e+00,\n","         -1.4117e+00,  7.6082e-01, -5.5480e-01,  1.5214e+00,  1.4201e+00,\n","         -2.3229e+00,  3.1112e+00, -2.1675e+00, -8.8136e-01,  1.9022e+00],\n","        [-2.7647e-01,  2.4211e+00,  9.2266e-01, -1.7845e+00,  5.3855e-01,\n","          1.4192e-01, -8.0186e-01,  5.7312e-01, -8.1299e-02, -2.3274e-01,\n","          2.8838e-01,  2.4999e-01,  2.0952e-01, -1.0264e+00, -2.0127e+00,\n","         -1.8269e+00, -2.3457e+00, -2.6160e+00, -1.5984e+00, -3.1098e+00,\n","          5.2480e+00, -1.1978e+00, -2.7239e+00,  6.9077e-01, -2.9512e-01,\n","         -2.1997e+00, -2.2459e+00, -1.7588e+00, -3.9319e-01,  1.4596e+00,\n","          1.0906e+00,  1.5725e+00,  1.2159e-01, -3.5633e+00,  2.1735e+00,\n","         -2.5364e+00,  1.2071e+01,  4.6783e-01,  2.1358e+00, -1.1055e+00,\n","          1.0814e+00, -5.7820e-01,  2.2658e+00,  2.0076e+00,  2.6971e+00,\n","         -3.3487e+00,  8.5744e-01, -1.7711e-01, -6.2081e-01,  2.1751e+00],\n","        [-1.2396e+00, -1.8343e+00,  1.4455e+00, -2.3786e-01, -1.2926e+00,\n","         -3.1077e-01, -3.4108e-01, -6.9249e-01, -4.8202e-01,  1.6890e+00,\n","          4.0841e+00,  2.0933e-01, -6.4583e-01, -2.2553e+00, -1.1060e+00,\n","         -1.8489e+00, -1.4616e+00,  1.2849e+01, -4.0358e-01,  1.7216e+00,\n","         -4.2830e-01, -9.5448e-01, -8.4617e-01, -1.8088e+00,  2.9795e-01,\n","          1.7033e+00,  5.9455e-01, -7.2850e-01, -1.0668e+00,  3.5058e-01,\n","          3.9170e+00, -2.0533e+00, -1.0403e+00, -1.3921e+00, -3.5178e+00,\n","         -2.6938e+00, -2.7656e+00, -2.6212e+00, -2.0489e-01, -1.6027e-02,\n","         -6.3399e-01, -2.1180e+00,  3.6546e+00,  1.0067e+00,  1.1628e+00,\n","         -1.4213e+00,  8.1704e-01,  3.1096e-01,  4.9504e+00, -1.4544e+00],\n","        [ 1.5060e+01,  1.7196e+00, -8.8219e-02,  4.0167e+00, -5.2068e+00,\n","         -2.2438e-01,  1.1621e+00, -3.5796e+00,  1.3628e+00, -8.7077e-01,\n","         -2.4248e+00,  6.6754e-01, -3.8745e+00, -6.4789e-01, -1.6180e+00,\n","         -3.0741e+00,  7.7203e+00,  3.0118e-01, -1.4073e+00,  2.3059e+00,\n","         -1.2613e+00, -1.6585e+00, -4.9258e+00, -3.1087e+00,  5.0116e+00,\n","          1.6274e-01,  5.4904e+00, -2.6571e+00, -5.1951e+00, -2.9372e-02,\n","          4.5922e+00, -2.5697e+00,  8.0505e-01, -3.7864e-01, -3.5560e-01,\n","         -1.4953e+00, -2.2835e+00, -2.8332e+00,  3.8765e+00,  3.4762e-01,\n","         -3.9695e+00, -3.3802e+00,  2.0456e+00,  6.2068e-01, -2.3891e+00,\n","         -4.9336e+00,  4.4436e+00,  3.7640e+00,  1.1654e+00, -1.9286e+00],\n","        [ 1.4731e+00, -4.1030e-01,  3.2284e-01,  4.6122e-01, -1.9009e+00,\n","         -1.1106e+00, -1.4232e+00, -1.0960e+00, -8.7759e-01, -5.8325e-01,\n","          3.3274e+00,  2.0131e-01, -1.9932e+00, -6.3491e-01, -4.6003e-01,\n","         -2.1191e+00, -4.7837e-01,  1.1463e+01, -1.1511e+00,  2.3104e+00,\n","          8.2913e-01, -7.5962e-01, -7.1905e-01, -1.1561e+00, -3.0295e-01,\n","          2.6302e+00, -2.7815e-01, -1.4859e+00, -1.3257e+00, -1.2025e+00,\n","          2.9476e+00, -2.1094e+00, -4.1424e-01, -5.6875e-01, -2.8082e+00,\n","         -1.3484e+00, -1.6083e+00, -9.7312e-01, -4.7254e-01,  6.5408e-01,\n","         -5.7634e-01, -2.3420e+00,  3.4567e+00,  1.8688e+00,  1.2172e+00,\n","         -2.6757e+00,  2.4029e+00, -1.6802e-02,  4.6524e+00, -1.3677e+00],\n","        [-2.3418e+00,  1.2550e+00, -1.3206e+00,  9.2989e-01, -8.9479e-01,\n","         -3.4008e-01,  3.1982e-01, -1.6694e+00, -1.5611e+00,  1.9556e+00,\n","         -3.4436e+00,  3.4562e+00, -3.8112e-01, -9.9588e-01, -1.6970e+00,\n","          2.1789e-01, -1.8502e+00, -9.6199e-01,  1.3123e+01,  1.4786e-01,\n","         -1.2709e+00,  5.0297e+00, -3.1542e+00, -2.2441e+00, -7.6034e-01,\n","          1.8565e-01,  1.8732e+00,  5.1564e+00,  2.5523e-01,  3.2030e+00,\n","          5.2087e-01,  1.4995e+00,  1.1884e+00, -2.1549e+00, -7.2652e-01,\n","         -2.7979e+00, -2.9371e+00,  1.8049e+00,  1.1252e+00, -2.4693e+00,\n","          1.6015e+00,  1.9943e-01,  3.6391e-01, -3.5945e+00, -4.9618e-01,\n","         -6.0699e-01, -7.2457e-01, -8.8210e-01, -2.3911e+00, -2.6497e+00],\n","        [ 1.9987e+00, -4.8651e+00,  1.7082e+00, -1.4064e+00, -1.6617e+00,\n","         -1.2649e+00,  6.6719e+00, -2.7646e+00, -5.8653e-01, -1.5289e+00,\n","         -3.3778e+00,  1.9903e+00,  2.5299e+00, -9.5940e-01,  1.5585e+00,\n","         -3.2806e+00,  1.4411e+00, -6.3797e-01, -3.2260e+00,  2.0887e+00,\n","          9.8613e-01, -1.6590e+00,  2.2140e+00, -2.2494e-01,  2.6503e+00,\n","          6.4492e+00, -1.9178e+00,  2.0734e+00, -4.9075e-01, -1.7926e+00,\n","         -2.6080e-01, -1.4295e+00,  7.8341e-01, -1.0861e+00, -2.2434e+00,\n","          1.4635e+01, -2.3449e-01, -4.3493e+00,  9.1465e-01,  1.9873e+00,\n","         -3.8898e+00,  4.0866e-02, -2.9806e+00,  1.2753e+00,  1.6424e+00,\n","         -3.3964e+00, -3.1024e+00,  3.0877e+00, -9.9106e-01, -6.0695e-01],\n","        [-1.4245e+00, -7.3990e-01,  1.5911e+00,  1.8257e+00,  1.2144e+00,\n","         -2.0723e+00, -1.1024e+00,  6.3017e-01, -1.1668e+00,  3.2184e-01,\n","         -2.1533e-01, -1.5830e+00,  3.2842e+00, -2.7565e+00,  2.5953e+00,\n","         -1.0516e+00, -1.8581e+00, -2.2388e+00, -1.9273e+00, -1.6990e+00,\n","         -2.0632e+00,  1.4493e-01,  1.1133e+01,  1.1236e+00,  1.4511e+00,\n","          2.3412e-01, -2.7353e-01, -8.3897e-01,  2.3470e+00, -3.8910e-01,\n","         -6.9626e-01,  1.9719e+00,  9.8438e-01, -2.5857e+00, -1.2678e+00,\n","         -4.5628e-01, -1.6011e+00,  1.6146e-01,  1.2038e+00,  1.5975e+00,\n","          1.8180e+00, -1.3330e-02, -9.0240e-01, -1.3367e+00, -1.1265e-01,\n","         -2.5967e-01, -1.8889e+00, -9.2791e-01,  6.7309e-01, -7.5489e-01],\n","        [-2.4746e+00,  8.8024e-01,  1.5189e+00, -6.7705e-01,  1.2036e+01,\n","         -1.0503e+00, -1.0621e+00, -1.0122e+00, -3.2453e+00,  8.6243e-01,\n","         -2.3448e-01,  7.8266e-01, -4.9316e-02, -2.3846e+00, -7.8176e-01,\n","          1.5178e+00, -2.5603e+00, -2.3453e+00,  8.7364e-01, -1.7164e+00,\n","         -8.0173e-01,  8.6894e-01,  6.4467e-02,  7.8243e-01, -7.1373e-01,\n","          2.1425e-01, -3.4902e-01,  4.5727e-02,  1.3647e+00,  3.0176e+00,\n","         -1.8272e-01,  2.6922e+00,  1.4068e+00, -4.0805e+00, -1.3050e+00,\n","         -1.5420e+00,  1.5302e+00,  1.9892e+00,  1.9523e+00, -2.0335e+00,\n","          5.5425e-01,  1.1758e+00,  3.2920e-01, -1.8101e+00,  3.4524e-01,\n","         -3.9651e-02, -7.7053e-01, -1.9480e+00, -2.2094e+00,  4.8780e+00],\n","        [-8.9964e-01,  8.2359e-01, -1.6893e+00,  7.1300e-01, -2.0600e+00,\n","         -8.5974e-01,  9.0538e-01, -4.4063e+00,  4.6608e+00, -2.4777e+00,\n","         -2.9681e+00, -1.4562e+00, -3.4875e+00,  1.5807e+01, -2.1157e-01,\n","          5.7890e+00,  9.1694e-02, -3.0711e+00, -7.2849e-01,  2.6716e+00,\n","          3.7508e+00, -8.4959e-01, -3.7924e+00,  5.7235e+00,  4.6095e-01,\n","          9.0206e-02, -7.6855e-02, -3.0155e+00, -1.9940e+00,  2.6412e+00,\n","         -7.5125e-01,  2.3610e+00, -2.8544e-01,  1.8750e-01,  3.2804e-01,\n","         -1.3886e+00,  1.7191e+00, -7.9038e-01, -1.6996e+00, -7.1132e-01,\n","         -1.0695e+00, -2.2815e+00, -1.2047e+00,  2.3178e+00, -1.2063e+00,\n","         -2.8388e+00, -8.8689e-01,  3.6823e-01, -3.3219e+00,  3.8378e+00],\n","        [ 7.7176e-01,  3.8073e+00, -1.4626e-01,  1.9332e+00,  1.8687e+00,\n","          6.9232e-01, -3.0061e+00, -3.5134e+00,  1.1221e+00,  2.1784e+00,\n","          1.6010e-01, -2.4259e+00,  4.0906e-01, -4.5182e-01, -2.4850e+00,\n","         -7.4562e-01, -3.4602e-01, -3.5967e+00,  1.0587e+00, -1.5213e+00,\n","         -9.3838e-01,  1.4852e+00, -1.6158e+00,  1.6681e+00,  1.1723e+00,\n","         -3.4227e+00, -8.4066e-01, -8.6074e-01,  3.9372e-01,  1.5346e+00,\n","          1.4690e-01,  3.4162e+00, -2.7406e+00, -3.2734e+00,  2.9222e+00,\n","         -4.8859e+00,  4.2971e-01,  1.2435e+01, -1.5681e-01, -2.7037e+00,\n","          3.8592e+00, -1.1187e-01,  1.9324e+00, -3.1529e-01, -1.7169e+00,\n","         -2.2675e+00,  2.8777e+00, -3.7084e+00, -1.3199e+00,  1.3985e+00],\n","        [ 2.1693e+00, -2.7097e+00,  4.1952e+00, -4.2368e-01, -8.0379e-01,\n","         -1.1420e+00,  2.8768e+00, -2.3143e+00, -1.4092e-01, -4.7648e-01,\n","         -4.5714e-01,  3.6261e+00,  1.1297e+00, -1.8713e+00,  3.4781e-01,\n","         -3.5598e+00,  1.4924e+00, -9.2674e-01, -1.3104e+00,  2.6834e+00,\n","          1.4901e+00, -1.1404e+00, -3.6451e-01, -7.4487e-01,  2.0894e+00,\n","          7.9828e-01, -1.4531e+00,  2.8814e+00, -1.7424e+00, -2.8683e+00,\n","          1.3265e+00, -9.8867e-01, -8.3182e-01, -6.4488e-01, -1.8304e+00,\n","          1.1577e+01, -7.9752e-01, -3.4584e+00,  1.7720e+00,  1.8971e+00,\n","         -2.5448e+00, -7.5998e-01, -2.3387e+00,  1.5940e+00, -2.1238e+00,\n","         -1.8797e+00, -1.0171e+00,  1.2828e+00, -5.6481e-02, -1.4771e+00],\n","        [ 9.7764e-01,  4.6683e-01,  2.7327e+00, -8.8552e-01, -3.2302e+00,\n","          1.3717e+01,  1.8899e+00,  9.5225e-01, -1.0430e+00, -2.4692e+00,\n","          1.5078e-01,  1.6163e+00, -3.1919e+00, -3.6296e+00, -2.5332e+00,\n","          2.1939e+00,  1.6336e+00,  1.2013e+00, -2.4087e+00, -1.6084e+00,\n","          4.7968e-01, -1.3369e+00, -5.0264e+00, -2.8973e+00, -2.1765e+00,\n","         -1.1850e+00,  5.7093e+00,  2.3214e+00, -2.2103e+00,  2.5663e+00,\n","         -8.3225e-01, -1.4575e+00,  4.0289e-01,  5.0399e+00,  1.3140e+00,\n","         -7.9216e-01, -1.5894e+00, -1.0986e+00,  3.3018e-01, -1.8139e+00,\n","         -7.0663e-01, -1.7926e+00, -1.5475e+00,  5.0058e+00,  9.9652e-01,\n","         -2.7182e+00,  9.3697e-02,  1.1803e+00,  6.5467e-01, -3.8882e-01],\n","        [-5.1892e+00, -3.9448e+00, -2.0251e+00, -3.5817e+00,  7.4989e-01,\n","          9.4838e-01, -2.0392e+00,  9.2473e-01, -2.0721e+00,  7.0252e+00,\n","          7.7904e-01,  7.3017e-01,  2.6294e+00, -3.4946e+00, -2.1376e+00,\n","          1.0743e+00,  1.3953e-01, -1.3098e+00,  8.8461e-01, -3.0968e+00,\n","          3.5991e-01,  4.0173e+00, -3.5019e+00, -2.6701e+00, -9.0015e-01,\n","         -1.1083e+00, -2.1969e-01,  2.3159e+00,  4.9307e+00,  3.8348e+00,\n","         -1.6131e+00,  3.9645e+00,  2.3504e+00, -1.0671e+00, -1.7303e+00,\n","         -1.7973e+00, -3.0620e+00,  1.0056e+00, -6.3428e-01, -2.3487e+00,\n","          1.0514e+00,  1.6544e+01, -5.1233e-01, -3.9605e+00,  2.3981e+00,\n","         -1.2268e+00, -5.5410e-01,  4.1150e-01, -3.8051e-01,  2.2420e+00],\n","        [ 6.2490e-02, -4.9507e-01,  9.8855e-01,  1.7621e+00, -1.5249e+00,\n","         -2.7907e+00, -2.1924e+00, -7.2337e-01, -2.3316e+00,  2.3302e+00,\n","         -2.2510e+00,  1.1031e-02,  1.9317e+00, -2.0485e+00,  1.9647e+00,\n","         -2.5019e+00, -2.0711e-01,  6.7655e-02, -6.4075e-01,  1.2020e+00,\n","          1.1623e+00,  2.2325e-01,  1.0453e+01, -1.0125e+00,  4.0198e+00,\n","          2.8751e+00,  5.6285e-01, -1.8061e+00, -4.2987e-01, -5.6816e-01,\n","          2.8191e+00, -1.5837e+00,  3.4007e+00, -2.5354e+00, -3.4400e+00,\n","         -1.5877e+00, -1.6944e+00, -2.1319e+00,  2.2080e+00,  1.3694e+00,\n","          2.7799e+00, -1.3643e+00, -2.2139e+00,  6.4834e-01,  5.3391e-01,\n","         -1.9784e+00, -6.7684e-01,  6.3956e-01,  5.3552e-01, -2.7792e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([45, 34, 36, 17,  0, 17, 18, 35, 22,  4, 13, 37, 35,  5, 41, 22],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8513,  8.2813, -0.8784,  ..., -1.7505, -2.1853,  2.5784],\n","        [-0.2940,  4.7210,  0.1131,  ..., -0.5420, -0.7727,  3.8426],\n","        [ 8.3829, -3.2040,  1.6244,  ...,  7.4677, -1.3017, -1.9824],\n","        ...,\n","        [ 2.0064,  0.3957, -0.7324,  ..., -2.1508,  1.6236, -0.4248],\n","        [-0.3281, 11.0178,  0.8881,  ..., -1.3133, -2.0455,  1.6865],\n","        [ 1.0907, -3.0400,  4.9779,  ..., -1.8384,  1.7508, -0.1046]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 389/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.3323,  3.7679,  0.6782,  ..., -0.0626,  1.5962,  2.0329],\n","        [ 2.7546, -1.0330, -0.9951,  ...,  0.5499, -0.1038,  1.9157],\n","        [ 1.2198, -4.1414, -1.4898,  ...,  0.4269,  1.1249, -2.4184],\n","        ...,\n","        [-2.5261,  0.8257,  0.1093,  ..., -2.0598, -1.1250, 13.8306],\n","        [15.0293,  0.2629, -0.0881,  ...,  2.8083,  1.8591, -0.5161],\n","        [ 0.7896,  0.9352,  0.5833,  ...,  2.7164,  1.3353, -1.9536]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([43, 36, 39, 40,  2, 13, 43, 18, 40,  8, 28,  9, 25,  4, 18, 35, 39, 36,\n","        10,  6, 47, 11, 29, 26, 47,  6, 20, 23,  2, 48,  6, 13,  9, 12, 23, 30,\n","        40, 27, 42, 29, 16,  5, 16, 42, 24, 10, 45, 25, 14, 37, 16, 49,  2, 24,\n","        16, 11, 24,  3, 19, 36, 21, 42, 41, 35,  0, 27, 43, 14, 33, 44,  4, 16,\n","         8, 27, 12, 28, 35, 16, 13, 45, 22, 34, 11, 49,  2,  7, 12,  8,  0, 28,\n","        24, 30,  9, 15, 14,  5,  7, 42,  3, 33,  8,  9, 37, 25, 10, 13, 24, 24,\n","        15,  6, 37, 46, 41, 10,  2, 27, 11, 34, 17, 12,  0, 16,  7, 21,  9, 49,\n","         0,  3], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.7488,  0.9920, -0.4619,  ..., -3.6679, -0.7467, -0.2868],\n","        [-1.8812,  0.4353,  0.1764,  ..., -1.0842, -0.8418,  2.8811],\n","        [-0.7264, -1.7286,  1.6274,  ..., -1.6996, -0.9527,  2.0403],\n","        ...,\n","        [-1.9945,  0.2107, -1.2455,  ..., -2.2733, -2.4805, -0.4977],\n","        [ 1.1931, -1.3589,  2.5463,  ...,  3.4326, -0.9946, -1.6643],\n","        [ 2.6534, -1.1667,  0.1903,  ..., -0.5270,  2.8930, -0.6961]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 34, 20, 47, 24, 36, 20, 17, 19, 10,  2, 30, 33, 39, 45, 49, 18, 15,\n","        39, 46, 31, 20, 17, 26, 41,  9, 23, 23, 48, 29, 38, 31, 22, 10, 16, 41,\n","        37, 19,  8, 18,  1,  1,  8, 10, 13, 23, 46,  5, 47, 15, 46,  6, 17, 32,\n","         3, 23, 20, 45, 26,  3, 30, 36, 40, 40, 27,  2, 25, 29,  0, 39, 25, 30,\n","        40, 38,  6, 44,  7, 12,  9, 22,  0, 48,  3, 36, 28,  7, 42, 16,  1, 47,\n","        32, 15, 44, 40, 47, 35, 13, 44, 32, 31, 33, 21, 48, 22, 27, 26, 44, 42,\n","        14, 31, 20, 22, 42, 33, 46,  4, 48,  9,  5,  1, 33,  3, 48, 37, 41, 31,\n","        11, 17], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.0585, -1.2211, -2.2453,  ...,  2.1703, -1.4649,  2.0494],\n","        [-2.2369, -1.9183, -1.0996,  ..., -1.7883, -1.5751,  0.8754],\n","        [-0.9007, -0.7416,  0.7968,  ..., -1.9416, -2.9291,  2.3294],\n","        ...,\n","        [-1.5885,  0.8190,  0.3783,  ..., -2.3943, -2.4509, 16.5345],\n","        [ 1.0567, -1.3854,  3.3295,  ...,  2.2546, -1.3647, -1.1981],\n","        [ 1.4427, 14.9626,  0.3574,  ..., -0.3960,  1.8016, -1.2501]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([29, 45,  4, 30, 25,  7, 41, 35,  3, 14, 20, 41,  1, 34, 43, 16, 21, 44,\n","        22, 41, 38,  7, 48, 32, 17, 20, 49,  2, 38, 38,  6, 26, 25, 22, 30,  1,\n","        29, 31, 45,  2, 11, 18, 14, 29,  8, 22, 46, 20,  5, 31, 21, 12, 14,  4,\n","        14,  9, 29, 37, 19, 15, 27, 32, 29, 14, 23, 43, 26,  0, 36, 40,  1, 18,\n","        15, 31, 37, 33, 30, 30, 36, 32,  1,  5, 46,  0, 17,  5, 28, 19, 13, 12,\n","        34, 17, 35, 27, 24, 13, 15, 28,  9, 24, 38, 27, 11, 49, 32, 32, 26,  4,\n","        21, 41, 28, 27, 19, 49, 17, 28, 31, 34, 10, 47, 37, 19, 30, 17, 26, 49,\n","        35,  1], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.8018e+00, -1.6855e+00, -5.9491e-02, -3.9270e+00, -1.7057e+00,\n","          1.3126e+00, -2.9640e+00, -3.6489e-01, -1.0050e+00,  1.8665e+00,\n","          1.8039e+00,  1.2793e+00,  1.3105e+01, -3.7696e+00,  5.4493e+00,\n","         -3.8765e-02, -2.0476e+00,  1.2637e+00, -2.2736e+00, -3.7158e+00,\n","          5.7240e-02,  2.2799e+00,  1.8097e+00, -2.5614e+00, -1.7342e+00,\n","         -1.3401e-02, -8.8293e-01,  5.7036e-01,  2.9464e+00,  5.0661e-01,\n","          5.8884e-01,  1.6573e+00,  2.7026e+00, -2.7500e+00, -3.2430e+00,\n","         -5.3198e-01, -3.4515e-01,  8.2982e-01,  7.2300e-01, -2.8805e+00,\n","          5.6837e+00,  7.3374e-01, -1.7489e-01, -6.5007e-01,  3.0345e+00,\n","         -3.6018e+00,  1.4382e+00, -2.4361e+00, -1.8808e-01, -1.0999e+00],\n","        [-1.6357e+00,  1.3133e+00,  1.4960e+00, -8.9021e-01,  1.0775e+01,\n","         -9.0119e-02, -1.7956e+00, -2.5007e+00, -2.2777e+00,  2.5865e+00,\n","         -1.3028e+00, -2.2569e+00, -7.3272e-01, -2.0447e+00, -1.5211e+00,\n","          9.6438e-01, -2.5165e+00, -2.9507e+00,  6.0275e-01, -3.1776e+00,\n","          5.5140e-01, -1.3722e+00,  1.0854e+00,  2.6574e+00,  2.2436e-01,\n","         -9.0983e-01, -1.3078e+00, -7.0137e-02,  1.1830e+00,  3.4429e+00,\n","          4.1577e-01,  4.3809e+00,  6.2215e-01, -4.8819e+00, -6.5171e-01,\n","         -1.1731e+00,  3.7057e+00,  3.2770e+00,  9.0589e-01, -1.9579e+00,\n","          6.9357e-02,  2.0258e+00, -1.6127e-01, -9.0068e-01,  1.9292e+00,\n","         -9.4771e-01, -2.1403e+00, -3.0345e+00, -4.2847e-01,  5.2665e+00],\n","        [ 4.3994e+00,  1.1267e+00,  2.3277e+00,  1.4998e+01, -1.8464e+00,\n","         -1.9146e+00,  4.1095e-02, -3.0451e+00,  8.2363e-01,  1.6263e-01,\n","         -1.7609e+00, -3.1240e+00, -2.2780e+00, -8.3582e-01, -2.0812e+00,\n","         -3.1607e+00,  3.9677e+00,  1.8440e-01, -1.0126e+00,  4.8764e+00,\n","         -4.4914e-01, -6.3485e-01, -1.1341e+00,  4.7067e-01,  1.2460e+00,\n","         -1.5258e+00,  7.4679e-02, -2.4169e+00, -2.7118e+00, -1.9179e+00,\n","          3.1681e+00, -5.3093e-01, -3.3603e+00, -7.8897e-01, -2.5921e-01,\n","         -1.2206e+00, -1.3793e+00, -3.4658e-01,  2.2861e+00,  4.6756e+00,\n","         -2.1012e+00, -2.2061e+00, -3.3269e-01,  7.0304e-01, -1.6570e+00,\n","         -2.8162e+00,  2.6809e+00, -6.0939e-01,  1.7709e+00, -2.1252e+00],\n","        [-2.6914e-01, -2.5670e-01,  1.9158e+00, -2.5364e+00,  1.4930e-01,\n","          1.2771e+00, -2.0650e-01, -2.1226e+00,  9.7552e-02,  3.8572e-01,\n","          1.4819e+01, -4.5994e-01, -5.5904e-01, -2.8555e+00, -2.1618e+00,\n","         -2.6636e+00, -2.4314e+00,  6.7437e+00, -1.9444e+00, -3.1207e+00,\n","         -5.1838e-01, -1.0585e+00, -1.0501e+00, -1.3240e+00, -1.2007e+00,\n","         -2.4995e+00,  6.6061e-01, -9.1837e-01, -1.1744e+00, -2.0423e+00,\n","          1.0536e+00, -1.0715e+00,  1.8928e-01, -5.2911e-01, -1.0192e+00,\n","         -1.8629e+00, -7.3970e-01,  4.4125e-01, -5.4209e-01, -2.9663e+00,\n","         -2.4596e-01, -2.7245e-01,  5.6802e+00,  1.2981e+00,  3.2100e+00,\n","         -1.2464e+00,  2.7739e+00, -2.2476e+00,  5.1035e+00, -2.2990e+00],\n","        [ 1.8015e+00,  2.6480e-01,  1.4228e+00,  1.8839e+00, -3.4121e+00,\n","         -1.8672e-01,  5.2725e-01, -4.6110e+00,  1.8706e+00,  6.1897e-01,\n","         -3.0423e+00, -1.1323e+00, -2.3143e+00,  2.0223e+00, -8.3743e-02,\n","         -9.9328e-01,  1.8837e+00,  8.0374e-01,  1.0504e+00,  1.1605e+01,\n","         -2.5895e+00, -1.7731e+00, -4.4381e-02,  8.2845e-01,  5.3296e+00,\n","          1.3291e-01,  3.3259e+00, -5.0639e-01, -2.6382e+00,  3.9569e-01,\n","          2.4947e+00, -6.8804e-01, -1.5946e+00,  6.7379e-01, -1.2119e+00,\n","         -6.4204e-01, -4.6416e+00, -1.5917e+00,  2.3435e+00,  5.4209e-02,\n","         -1.5614e+00, -1.7191e+00, -2.5570e+00,  3.2239e-01, -9.3326e-01,\n","         -1.7681e+00, -6.0319e-01,  4.8335e-01,  1.3679e+00, -7.0326e-01],\n","        [-3.3834e+00, -2.3558e+00, -2.2130e+00, -1.4353e+00,  1.5981e+00,\n","          8.5355e-02, -7.2012e-01,  8.7969e-01, -6.2234e-01,  2.4926e+00,\n","         -8.6192e-01, -2.0937e-01, -1.0591e+00, -8.2004e-01, -2.2349e+00,\n","         -5.8725e-01, -1.6285e+00,  8.0203e-01,  1.7474e+00, -1.9524e+00,\n","          3.1599e-01,  7.0646e-01, -1.3726e+00, -2.7056e+00,  7.8266e-01,\n","         -1.2068e+00,  1.7417e+00, -8.4424e-01,  1.0586e+00,  4.8274e+00,\n","          1.2132e+00,  2.4101e+00,  2.7980e+00, -6.4481e-01,  4.5198e-01,\n","         -3.5289e+00, -2.0061e+00,  7.7266e-01, -1.9241e+00,  5.9597e-01,\n","          3.5417e+00,  3.4007e+00, -3.4111e-01, -2.7986e+00,  1.7126e+00,\n","          1.3266e+01, -1.3019e+00, -1.5724e+00, -1.8820e+00,  8.9412e-01],\n","        [-2.9200e+00,  3.7423e-01,  4.1036e-01, -9.3040e-01,  1.1601e+01,\n","         -8.6597e-01, -1.5517e+00, -1.8242e+00,  3.0565e-01,  3.0369e-01,\n","         -6.8564e-01, -7.9375e-01, -2.6603e-01,  4.2730e-01, -2.4841e+00,\n","          3.0678e+00, -1.2617e+00, -2.1581e+00, -4.4926e-02, -1.5145e+00,\n","          9.1449e-01, -1.3029e-01, -1.6070e+00,  7.1052e-01, -9.1742e-01,\n","         -2.9387e+00, -1.1974e+00, -2.2174e+00,  7.2372e-01,  4.0230e+00,\n","         -2.9180e-02,  3.8823e+00,  1.9699e+00, -1.9966e+00,  1.4018e+00,\n","         -2.6011e+00,  6.4797e-01,  4.3282e+00, -1.0163e+00, -1.1742e+00,\n","          6.8083e-01,  3.0682e+00, -2.8919e-01, -1.2911e+00, -1.5800e+00,\n","          1.4400e+00,  4.6581e-01, -3.9649e+00, -2.5938e+00,  3.4181e+00],\n","        [ 7.7283e-01, -3.1730e+00,  2.5303e+00, -1.3736e+00, -1.9578e+00,\n","         -9.3364e-01,  3.0862e+00, -3.0882e+00, -2.9557e+00, -1.7228e+00,\n","         -3.0749e+00,  3.2134e+00, -2.4412e+00, -4.2062e-01,  1.4595e+00,\n","         -2.7635e+00,  5.0877e+00, -7.5674e-02, -2.7326e+00, -1.2257e+00,\n","         -1.0252e+00, -4.6953e-01,  1.7680e+00, -1.6681e+00, -4.9859e-01,\n","          2.4033e+00,  9.5081e-01,  3.2180e+00, -3.0724e-01, -7.2695e-01,\n","          4.5747e+00, -1.3253e+00,  1.7075e+00,  1.2231e+00, -5.7660e-01,\n","          1.3370e+01, -2.1032e+00, -2.9690e+00,  3.4649e+00,  1.2402e+00,\n","         -4.2059e+00, -8.2834e-01, -2.5003e+00,  4.0114e-01,  1.1667e+00,\n","         -5.0311e+00, -1.2929e+00,  3.2491e+00, -1.8003e+00,  1.0018e+00],\n","        [-5.0380e-01,  3.9140e+00, -1.5084e+00,  6.0689e-01, -2.1349e+00,\n","          4.4252e-01, -1.0608e-01,  1.4086e+01, -2.0174e+00,  9.2741e-01,\n","         -1.9732e+00, -3.4865e-01,  5.0982e-01, -1.2442e+00, -1.3067e+00,\n","          8.1908e-01, -1.5268e+00, -1.5686e-02, -3.5481e-01, -2.1631e+00,\n","         -6.1023e-01,  1.1120e+00,  2.2838e+00, -1.3490e+00, -5.9533e-01,\n","         -1.7698e+00,  1.0952e+00, -3.5214e-01,  3.3880e+00, -2.4305e+00,\n","         -3.0516e+00,  1.0489e-01,  3.6423e-01, -4.2291e-01,  9.3745e-01,\n","         -5.2797e-01, -1.9733e+00,  2.8715e+00, -1.5400e+00, -4.1998e-02,\n","          1.7903e-01,  3.0315e-01,  8.9505e-01, -3.9952e-01, -8.4603e-01,\n","         -8.7706e-01,  1.9535e+00, -1.8864e+00, -2.8173e-01, -7.6664e-01],\n","        [ 2.6462e+00,  1.2040e+00,  8.0062e-01, -1.6392e+00, -2.0972e-01,\n","          7.7980e-01, -9.5668e-01, -2.8705e+00,  1.4382e+00, -1.5893e+00,\n","         -1.7684e+00, -8.3951e-01, -2.4028e+00,  3.3847e-01, -2.5908e+00,\n","         -2.0799e+00, -5.8890e-01, -1.3585e+00, -1.4954e+00, -2.4677e+00,\n","          5.2702e+00, -1.2441e+00, -1.4179e+00,  4.6793e-01,  1.0937e+00,\n","         -1.1476e+00, -2.4504e+00, -2.2126e-01, -1.3895e+00,  1.2704e+00,\n","          3.0375e+00,  3.3514e-02, -1.6751e-01, -3.2638e+00,  2.5454e+00,\n","         -1.0871e+00,  1.3413e+01, -5.7478e-01,  1.6239e+00, -1.0656e+00,\n","          2.3290e-01, -5.8707e-01, -4.4617e-02,  2.7162e+00,  2.8444e-01,\n","         -2.7518e+00,  5.9596e-01,  4.1327e-01,  7.3793e-02,  2.3527e+00],\n","        [ 4.9582e-01,  2.9955e+00,  3.1867e+00,  1.4818e-01, -3.2788e+00,\n","          3.3525e+00,  9.6244e-02, -3.2128e+00,  5.8410e+00, -2.8702e+00,\n","          2.3087e-01, -7.4293e-01, -4.7124e+00,  3.2998e+00, -6.7365e-01,\n","         -3.1747e-01, -6.1823e-01,  1.2286e+00, -3.4553e+00, -1.3315e+00,\n","          3.1633e+00, -1.2569e+00, -2.0218e+00,  3.6102e+00, -9.5262e-01,\n","         -1.8288e+00,  7.2013e-01, -3.3177e+00, -2.8027e+00, -5.3977e-01,\n","         -1.4400e+00, -1.5600e+00, -3.5556e-01,  8.6243e-01,  2.9876e+00,\n","         -2.2875e+00,  9.8898e-01, -4.2625e-01, -1.2616e+00, -2.5916e+00,\n","          1.2489e-01, -3.8237e+00,  1.6296e+00,  1.2604e+01,  9.6765e-01,\n","         -3.4218e+00,  1.1171e+00, -1.7823e+00,  2.3006e+00,  7.9248e-01],\n","        [-2.7504e+00, -1.4066e+00, -1.3235e+00, -1.7511e+00,  2.3935e+00,\n","         -2.6620e+00, -2.6408e+00, -2.1785e+00,  1.9249e+00,  3.1954e+00,\n","          1.4481e-01, -1.6138e+00,  1.2541e+01, -2.6294e+00, -9.3740e-01,\n","         -1.3513e+00, -3.2482e+00, -1.5982e+00,  2.6530e+00, -2.0453e+00,\n","          1.8749e+00,  9.3498e-01,  3.1788e+00,  1.4408e-01, -1.0684e+00,\n","         -2.3643e+00, -2.0244e+00,  1.3310e+00,  2.9635e+00, -5.8779e-01,\n","         -2.2544e-01,  1.6880e+00,  2.3401e+00, -3.8107e+00, -1.0537e+00,\n","         -7.5960e-01,  3.9675e-01,  3.6598e+00,  2.3047e+00, -2.2015e+00,\n","          4.4327e+00,  3.4556e+00,  1.9430e+00, -1.1404e+00, -2.4984e+00,\n","         -1.9890e-01,  6.3526e-01, -2.7838e+00, -8.0533e-01, -1.3280e+00],\n","        [-2.2053e+00,  1.2772e+00, -3.7076e-01,  2.2630e-01, -1.0143e+00,\n","         -7.6304e-02,  1.0764e+00,  7.5109e-01, -1.2126e-01, -8.6437e-02,\n","         -1.8307e+00,  1.1249e+00, -2.7710e+00,  1.1323e-01, -2.5202e+00,\n","          5.1142e-01, -6.6073e-01, -2.6118e+00,  1.2603e+01,  5.1232e-01,\n","         -1.1496e+00,  7.9968e+00, -3.9339e+00, -2.5605e+00, -1.0877e-01,\n","         -2.5394e+00,  3.6558e+00,  3.5221e+00, -1.3312e+00, -6.8895e-02,\n","         -6.4067e-01,  1.8659e+00,  9.6996e-01,  5.3587e-01,  3.0507e+00,\n","         -1.2319e+00, -1.7886e+00,  7.0098e-01, -7.3214e-03, -5.6052e-01,\n","         -1.3575e+00,  9.1373e-01,  1.6796e-01, -3.0746e+00, -9.7905e-01,\n","         -1.0635e+00, -6.5981e-02, -1.7733e+00, -2.8742e+00, -8.7660e-01],\n","        [ 1.5904e+00, -2.1068e+00, -5.7587e-01,  2.7102e+00, -2.1827e+00,\n","         -8.4434e-01,  1.7232e+00, -3.6980e+00, -3.9011e+00,  1.1100e+00,\n","         -3.8506e+00,  8.9757e-01, -4.0648e+00,  6.6223e-01, -1.1504e+00,\n","          2.8669e-01,  3.1457e+00,  9.8859e-01, -1.2379e+00,  3.8393e+00,\n","          1.3607e+00, -1.0021e+00, -3.0485e-01, -1.4454e+00,  2.7238e+00,\n","          1.2623e+01,  2.2870e-01, -9.3699e-01, -2.3687e+00,  3.0320e+00,\n","          1.3030e+00, -7.2213e-01, -8.7091e-02,  3.8833e-01, -1.4132e+00,\n","          9.2499e-01, -3.2374e+00, -2.3254e+00,  7.7630e-01,  2.7534e+00,\n","         -2.5046e+00, -3.4696e-01, -2.8287e+00, -5.6670e-01,  1.7029e-01,\n","         -3.1866e+00, -6.6147e-01,  5.4735e+00,  5.8607e-01, -1.2022e+00],\n","        [ 2.9450e+00, -2.9568e+00,  4.0483e+00, -3.7394e+00, -2.1208e+00,\n","          2.0340e+00,  8.9211e-01, -1.2278e+00, -2.0561e+00, -1.0186e+00,\n","          1.7317e+00,  1.1070e+01, -9.9188e-01, -2.7543e+00,  1.1376e+00,\n","         -2.1581e+00,  1.7340e+00,  1.4811e-01,  2.6843e-01,  3.3809e-02,\n","         -2.2762e+00,  2.4087e+00,  9.0518e-01, -2.7639e+00, -1.3798e+00,\n","          2.6210e+00, -1.6387e-01,  3.1867e+00,  5.7006e-01, -3.5493e-01,\n","          4.1362e+00, -2.1304e+00, -5.8317e-02, -2.1508e+00, -2.6504e+00,\n","         -2.4816e+00, -2.4503e+00, -1.7731e+00,  5.1882e+00, -1.2452e+00,\n","          3.1423e+00, -8.0970e-01, -2.2398e-01, -8.9711e-01,  5.6675e-02,\n","         -1.8899e+00,  6.4091e-02, -4.1220e-01, -6.8365e-01, -2.2188e+00],\n","        [ 3.1336e+00, -2.8577e+00, -6.1882e-01,  8.9732e-01, -3.3350e+00,\n","          1.6508e+00,  3.4970e+00, -2.8469e+00, -1.9459e+00,  1.0609e+00,\n","         -3.1396e+00,  1.7298e+00, -3.4550e+00,  2.5753e+00,  2.9537e-01,\n","          1.5148e-01,  2.6412e+00, -1.7216e+00, -2.1922e+00,  3.3683e+00,\n","         -1.2746e+00, -1.1452e+00, -1.3806e+00, -2.3474e+00,  4.2531e+00,\n","          7.2808e-01,  2.8595e+00,  7.8653e-01, -3.3237e+00,  1.8410e+00,\n","          5.5773e-01, -1.8009e+00,  5.7742e-01, -3.5892e-01, -1.0705e+00,\n","          2.4240e+00, -2.2017e+00, -3.7126e+00,  1.6012e+00,  1.6309e+00,\n","         -1.8877e+00,  8.2660e-01, -1.6266e+00,  1.3842e-01, -2.8101e-01,\n","         -2.0455e+00, -2.3762e+00,  9.1257e+00,  3.4057e-02,  2.0545e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([12,  4,  3, 10, 19, 45,  4, 35,  7, 36, 43, 12, 18, 25, 11, 47],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8466,  8.3022, -0.8758,  ..., -1.7538, -2.1833,  2.5936],\n","        [-0.2850,  4.7465,  0.1125,  ..., -0.5439, -0.7703,  3.8471],\n","        [ 8.4135, -3.2001,  1.6146,  ...,  7.4655, -1.2967, -1.9736],\n","        ...,\n","        [ 2.0083,  0.3969, -0.7330,  ..., -2.1553,  1.6266, -0.4198],\n","        [-0.3244, 11.0196,  0.8834,  ..., -1.3080, -2.0424,  1.6882],\n","        [ 1.0880, -3.0418,  4.9791,  ..., -1.8454,  1.7518, -0.0916]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 390/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.1320,  2.4215, -1.3361,  ..., -0.9887,  2.3921, -1.1910],\n","        [-0.7404, -2.3724, -0.2181,  ..., -0.2198, -1.4693, -0.9477],\n","        [ 0.3326, -3.3944,  1.4905,  ...,  1.1243,  0.1167, -2.0328],\n","        ...,\n","        [ 0.5441, -2.1341,  1.0113,  ..., -0.3967, -1.1035, -1.3167],\n","        [-2.3328, -2.1381, -1.9785,  ..., -3.5317, -2.4544,  0.4000],\n","        [ 0.0973, -2.0216,  0.0211,  ..., -1.1701, -1.3925, -0.2921]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([42, 14, 25, 18, 35,  2, 31, 30, 39, 32, 22, 47, 45,  6, 39, 26, 23, 30,\n","        11, 10, 40, 21, 46,  6, 36, 13, 45, 29, 15, 25, 35, 15, 47,  0, 33,  9,\n","         5, 14, 29, 15, 41, 13, 36, 33, 30,  9,  1, 36, 10, 20,  3, 41, 29,  3,\n","        40, 26, 44, 17, 19,  2, 28, 18, 35, 19, 38, 23, 22, 31, 34, 41, 46, 17,\n","        33, 15, 24,  8, 17, 31, 46, 30, 23, 12, 10, 14, 42,  8, 23, 43, 23, 19,\n","        34, 24, 14, 19,  0, 20,  4, 16, 48, 48, 31,  5, 38, 10,  1, 36,  3, 16,\n","        42,  9,  2, 16, 45, 31,  2,  6, 29, 33, 25, 45,  7, 31,  7, 17, 12, 35,\n","        28, 14], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.1455,  1.8881,  1.7692,  ..., -2.3908, 14.1218, -0.5971],\n","        [-2.0504, -3.2607, -1.4816,  ..., -1.9339, -1.5106, -3.4809],\n","        [ 0.5425, 12.2158, -0.6653,  ..., -1.1537, -1.6794,  1.3933],\n","        ...,\n","        [ 0.2982, -3.0649, -1.8341,  ...,  0.0527, -1.7660, -0.2605],\n","        [-0.5244,  0.7204, 16.1186,  ...,  0.0505,  2.5083, -0.6197],\n","        [ 1.0543, -3.9208, -0.9392,  ..., -0.2694,  1.6951, -1.8419]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([48, 12,  1, 41,  0, 11, 47,  3, 30, 40, 11, 22,  3, 28, 17, 32, 46, 44,\n","        24,  6, 16,  9, 34, 38,  9, 39, 22, 33, 27, 22,  4,  1, 11, 30, 45, 29,\n","        11, 20, 25, 18, 34,  4, 27, 42, 48,  3, 44,  8, 25, 38, 33, 14, 29, 38,\n","        34, 25,  9,  4, 12, 22,  1,  1, 11,  9, 49, 17, 26,  0, 19, 30, 42,  5,\n","        27,  1, 29,  9,  6, 37, 21,  3, 12, 12, 46,  5, 13,  6, 32,  9, 35, 27,\n","        24, 15, 14,  5, 10, 21, 42, 26, 21, 18, 19,  0, 18, 26, 49, 37,  7,  7,\n","        13, 10, 28, 43, 41, 49,  2, 44,  6, 29, 36,  8, 27, 28, 36, 13, 48, 41,\n","         2, 39], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 4.4030,  0.6542,  1.6400,  ...,  0.8286,  0.9345, -1.5139],\n","        [ 0.2602, -1.3822,  1.7114,  ...,  1.0668, -0.4679, -1.1809],\n","        [ 4.1089,  2.0401, -1.5199,  ..., -0.4088,  1.7756,  4.1327],\n","        ...,\n","        [ 1.5864,  3.5700,  2.3920,  ..., -1.1969,  1.1114, -0.8680],\n","        [-3.5050,  3.3133, -1.0082,  ..., -4.8966, -3.4080, -0.8511],\n","        [-2.8513,  3.1173,  1.4861,  ..., -2.6558, -2.0693, 16.0719]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([24, 19,  8, 17, 27,  3, 28, 15,  8, 16, 39, 31, 19, 14, 30, 37, 36, 20,\n","        27, 47, 35,  5, 35, 40,  3, 27, 44, 11,  4, 11, 26,  0,  8, 20, 30, 41,\n","        16, 47, 48, 18, 37, 12, 40, 10, 28, 25, 22, 23, 13, 20, 31, 17, 35, 47,\n","         7,  2, 25,  1, 21,  4, 27, 40,  5, 42, 32, 21, 16, 47, 45, 49, 16, 45,\n","        10, 36, 44, 12, 15,  4,  0, 20, 41, 36,  1, 41, 32, 26, 17, 49, 26,  2,\n","        32, 37, 10, 43, 24, 24, 14,  7,  9, 13, 20, 29, 48,  7, 32, 27, 49, 43,\n","        38, 24, 33, 46, 43, 40,  2, 47,  8, 23, 13, 12, 16, 17, 18, 32,  4, 43,\n","        37, 49], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.5233e+00,  2.3112e+00,  2.2705e+00,  1.5622e+00, -2.1917e+00,\n","         -9.5976e-01, -7.4865e-01,  2.7534e-01,  8.4583e-01, -1.0164e-01,\n","          5.5999e-01,  1.4359e+00,  3.6225e-01, -1.8810e+00, -1.9545e+00,\n","         -1.2440e+00,  2.5321e-01,  8.4809e-01, -7.0998e-01,  1.8269e+00,\n","          2.3160e-01,  3.5767e-01, -2.0410e+00, -4.4532e+00, -3.9729e-01,\n","         -7.2655e-01,  8.2224e-01,  1.1731e-01, -1.4842e+00, -7.6158e-01,\n","          7.1007e-01, -1.8921e+00,  9.0261e-01, -8.7014e-01,  1.2687e+00,\n","          6.9509e-01, -1.3840e+00, -1.3974e+00,  1.0600e+00, -1.6448e+00,\n","         -1.2329e+00, -1.5077e+00,  2.0771e+00,  1.4831e+00, -8.4315e-01,\n","         -1.8424e+00,  1.3525e+01, -2.0549e+00,  6.6623e-01, -9.8089e-01],\n","        [ 7.4886e-01, -3.4701e-01,  6.3873e-01,  2.5953e+00,  2.6715e-03,\n","         -1.7289e+00, -1.2477e+00, -1.6637e+00, -2.2146e-01,  8.8072e-01,\n","         -1.1202e+00, -2.1731e+00,  3.0718e+00, -3.3276e+00, -1.0049e+00,\n","         -2.7482e+00, -1.3613e+00,  1.0716e+00, -8.7167e-01,  6.9305e-01,\n","         -1.4670e+00, -7.0244e-01,  1.2685e+01,  3.3757e-01,  1.3277e+00,\n","          2.9054e+00, -1.6226e+00, -8.1013e-01, -9.2933e-01, -2.1396e+00,\n","         -1.6822e-01, -1.1179e+00,  3.2719e+00, -1.9801e+00, -1.9604e+00,\n","          1.2639e+00, -8.4634e-01, -1.0835e+00,  2.6233e+00,  8.3107e-01,\n","          1.7308e+00, -1.0335e+00, -1.5143e-01,  7.5727e-01, -8.6291e-01,\n","         -8.8029e-01,  2.3790e-01,  2.9244e-01,  1.8023e+00, -3.5194e+00],\n","        [ 1.1607e+01,  1.9899e-01,  6.2494e-01,  5.9428e-01, -2.1552e+00,\n","          1.0043e+00,  6.8790e-01, -2.6165e+00, -5.0581e-01, -1.0322e+00,\n","         -3.4480e-02,  7.2396e-01, -2.6482e+00, -1.4752e+00, -1.5506e+00,\n","         -4.5973e+00,  1.6874e+00,  3.7169e+00, -1.2036e+00, -8.7125e-01,\n","          5.6077e-01, -1.2125e+00, -1.4526e+00, -9.7496e-01, -4.9686e-01,\n","          1.7195e+00,  1.8148e+00,  2.4971e-03, -2.7576e+00, -2.1678e+00,\n","          1.8227e+00, -1.8080e+00, -6.8225e-01, -2.1724e+00, -2.1120e+00,\n","         -1.5413e+00,  1.8561e+00, -9.4873e-01,  3.4507e+00,  9.8346e-01,\n","         -1.8532e+00, -1.9505e+00,  4.2294e+00,  2.1365e+00,  1.0798e+00,\n","         -3.1183e+00,  1.0712e+00,  7.9837e-01,  4.0313e+00, -1.8965e+00],\n","        [-2.0897e+00, -2.3080e-01,  6.7529e-01, -1.5099e+00,  8.0981e-01,\n","          6.0872e-02, -8.6353e-01, -2.1018e+00,  2.6743e+00,  1.7384e+00,\n","         -2.7808e-03,  9.2522e-01,  1.7352e+00, -1.8183e+00, -1.4690e+00,\n","         -2.1301e-01,  7.4320e-02, -1.1112e+00,  2.4603e-01, -1.3635e+00,\n","         -3.4442e-01,  1.6715e+00,  7.1492e-01, -1.5853e+00,  6.1365e-01,\n","         -2.1106e-01, -9.9121e-01, -5.6516e-01,  2.2817e-01, -3.7316e-01,\n","          2.0235e+00,  3.2318e-01, -1.9814e-01, -2.5829e+00, -3.8444e-01,\n","         -2.4351e+00,  1.2716e-01,  1.1979e+00,  6.8338e-01, -2.7675e+00,\n","          1.1711e+01,  2.2153e-01,  9.8912e-01, -1.5215e+00, -4.5949e-01,\n","         -3.6638e-01,  1.4514e+00, -8.9916e-01, -2.7292e-01,  2.6692e-01],\n","        [-1.7732e+00, -3.2123e+00,  4.1455e+00,  1.8014e+00, -1.5472e+00,\n","          1.8495e-01,  1.0260e+00, -4.1294e+00, -3.7298e+00,  8.3529e-01,\n","          4.4207e-02,  7.1686e+00,  3.2000e-02, -2.6155e+00, -2.4097e+00,\n","         -4.6916e+00, -4.7094e-01,  2.7823e+00,  5.4997e-01,  5.2288e+00,\n","         -1.6387e+00, -8.1262e-01, -5.6016e-01, -4.5606e+00, -6.0543e-01,\n","          3.9844e+00,  1.1508e-01,  1.6452e+00, -4.2994e-01,  3.9775e+00,\n","          1.4872e+01, -3.2195e+00, -1.0754e+00, -2.2799e+00, -3.0628e+00,\n","         -2.1673e+00, -2.4976e+00, -2.7273e+00,  3.5377e+00,  1.3557e-01,\n","          6.2710e-01,  1.2756e+00, -4.0371e-01, -1.6020e-01, -7.7330e-01,\n","         -1.5164e+00,  9.5307e-01,  6.4692e-01,  1.8502e+00, -2.4411e+00],\n","        [-3.0781e+00, -1.4076e+00, -1.0643e+00, -1.0733e+00,  6.4598e-01,\n","          4.0347e+00,  2.4306e+00, -2.7213e+00, -1.5205e+00, -2.0518e-01,\n","         -2.0933e+00, -4.6951e-01, -1.1936e+00,  3.5074e+00,  2.0669e+00,\n","          1.0585e+01, -9.8769e-01, -3.5695e-01,  8.3284e-02,  9.8588e-01,\n","         -1.0907e+00,  3.2675e-01, -3.9822e+00, -2.8405e+00, -6.1432e-01,\n","         -4.9792e-01,  4.4424e+00,  1.7901e-01, -1.9289e+00,  5.9308e+00,\n","         -1.7996e+00,  4.1666e+00,  3.6939e+00,  2.5331e+00, -5.0867e-01,\n","          1.0067e+00, -6.8594e-02, -1.5648e+00, -1.1642e+00, -1.6498e+00,\n","         -1.0756e+00, -1.4716e-01, -3.0055e+00, -1.3077e-01,  1.7208e+00,\n","         -2.0296e+00, -2.0550e+00, -1.6904e+00, -2.7110e+00, -2.8799e-01],\n","        [-9.0234e-01,  4.9707e+00,  1.6988e-01,  5.2471e-01, -2.2379e+00,\n","          3.2369e+00,  8.1798e-01, -2.2786e+00,  3.1946e-01,  1.3793e-01,\n","         -4.3389e-01, -3.0299e-01, -2.9217e+00, -3.2065e-01, -1.1344e+00,\n","         -4.1605e-02, -1.6885e+00, -1.2317e+00,  4.6271e-01, -2.4662e+00,\n","          8.1887e-01, -6.8634e-01, -2.3680e+00, -1.1271e+00, -8.6290e-01,\n","         -3.0020e+00,  2.1113e+00,  1.5170e+00, -2.5133e+00,  1.0163e+00,\n","          3.4836e-01,  8.0908e-01, -3.7434e-01,  1.1711e-01,  1.0867e+01,\n","         -5.7089e-01,  3.5925e-01,  7.2696e-01,  1.3319e-01, -3.3648e+00,\n","         -1.2906e+00,  7.8953e-03,  3.5247e-01,  1.2167e+00,  1.2650e+00,\n","         -2.7221e+00,  2.8246e+00,  1.5455e+00, -5.5497e-02,  1.0055e+00],\n","        [ 5.5768e-01,  1.3227e+00,  1.0129e+00, -2.1899e-01, -1.2320e+00,\n","          5.9294e-01,  2.6072e+00, -3.8017e+00, -1.8684e-01,  1.5940e+00,\n","         -2.7465e+00, -1.6344e-01, -2.1478e+00, -2.1688e-01, -1.5208e+00,\n","         -2.5935e+00, -3.5717e+00, -1.8620e+00,  3.7153e+00, -2.3624e+00,\n","          1.3921e+01,  1.7671e+00, -1.6877e+00,  1.4956e+00,  3.6451e+00,\n","          1.5660e+00, -3.5325e-01, -2.0407e+00, -4.5416e+00, -7.3104e-01,\n","          1.2010e+00, -3.4142e-01, -8.9477e-01, -3.2318e+00, -7.8580e-01,\n","         -1.4194e+00,  3.0016e+00, -3.0374e+00,  1.8885e-01, -3.6227e+00,\n","         -1.0275e+00,  1.6524e+00,  6.7680e-01,  4.1529e+00,  1.5291e+00,\n","         -2.6113e+00, -1.9408e+00,  1.9350e+00,  6.6862e-01,  3.2778e+00],\n","        [-3.3465e+00, -3.5171e+00, -5.9563e-01, -2.3344e+00,  2.1810e+00,\n","         -3.0148e-01, -7.7061e-02,  9.3326e-01, -2.5503e+00,  1.2947e+00,\n","          1.0295e+00,  3.3006e+00,  4.9270e+00, -3.3054e+00, -2.3274e-01,\n","         -2.3460e+00, -2.1091e+00, -3.3676e-01,  7.6259e-01, -1.6449e+00,\n","         -1.8072e+00,  1.0039e+00,  1.4861e+00,  2.4780e-02, -8.3400e-01,\n","         -8.4227e-01, -1.5622e+00,  3.6078e+00,  1.1220e+01,  1.3937e-01,\n","          1.4164e+00,  1.1009e+00,  7.9389e-01, -2.3666e+00, -1.4290e+00,\n","          3.6310e-01,  1.0248e-01,  5.0451e-01,  2.1029e+00, -5.0144e-01,\n","          5.5299e-01,  3.5296e+00,  5.3477e-01, -2.1092e+00, -6.6351e-01,\n","          2.7675e-01, -1.6489e+00, -1.3065e+00, -6.5771e-01,  2.1326e-01],\n","        [-1.2305e-01,  1.4213e+00, -2.8164e-01,  9.9882e-01,  1.9961e+00,\n","          3.0107e-01, -2.2930e+00, -2.4641e+00,  2.9171e+00,  8.1404e-01,\n","          9.0684e-01, -2.7138e+00, -4.7264e-01, -1.2510e-01,  6.7729e-01,\n","         -1.4789e+00, -2.0250e-02, -3.1494e+00,  1.2044e-01, -1.1730e+00,\n","         -1.2380e+00,  8.8998e-01, -1.1458e+00,  2.2025e+00,  7.2998e-01,\n","         -3.4171e+00, -1.0215e+00, -9.2713e-01, -3.2085e-01,  1.5203e+00,\n","         -1.6400e+00,  1.9018e+00, -1.4748e+00, -2.1515e+00,  2.9344e+00,\n","         -3.2107e+00,  1.7105e+00,  8.5355e+00, -4.6278e-01, -1.3773e+00,\n","          2.4766e+00,  1.3043e+00,  9.8636e-01,  1.2395e+00,  2.2165e-01,\n","         -1.4955e+00,  5.0951e-01, -2.9602e+00, -1.0004e-01,  3.5956e-01],\n","        [-1.5430e+00,  1.2873e+00,  7.4209e-01, -7.4503e-01,  2.9621e+00,\n","          5.2312e-01, -2.0398e+00, -2.8238e+00,  1.1500e+00, -2.2565e+00,\n","         -4.7850e-01, -4.9794e-03, -3.2456e+00,  2.1640e+00, -1.9308e+00,\n","          4.1532e+00,  5.6866e-01, -8.5179e-01, -1.9307e+00, -8.9327e-01,\n","         -9.1897e-01, -4.0848e-01, -3.2522e+00,  1.4537e+00, -9.7343e-01,\n","         -2.5067e+00,  5.9526e-01,  6.4311e-01, -1.9276e+00,  4.9394e+00,\n","          5.4275e-02,  5.0543e-01,  6.9899e-01, -1.8149e+00,  1.7473e+00,\n","         -1.6553e+00,  1.3800e+00, -5.0705e-01,  3.1925e-01, -2.3576e+00,\n","          4.5453e-02, -5.9916e-01, -2.7365e-01,  2.7852e+00,  1.4464e+00,\n","          8.7602e-02, -6.1943e-01, -9.8278e-01, -2.5025e-01,  1.1163e+01],\n","        [-1.9325e+00,  1.7839e+00,  6.9556e-02, -1.7368e-01,  3.5129e+00,\n","         -2.3521e-01, -4.7914e-01,  1.5285e+00,  1.0642e+00,  1.7602e+00,\n","          5.6978e-01, -2.4419e+00,  9.0912e-01,  1.0459e+00, -1.0988e+00,\n","         -2.8110e-01, -3.1585e+00, -2.4238e+00,  3.4404e+00, -1.1830e+00,\n","          1.6160e+00,  1.0077e+00, -1.5463e+00,  4.4241e+00, -2.2445e+00,\n","         -1.8037e+00, -3.7721e-01, -1.6787e+00,  3.8554e-01, -3.4129e-01,\n","         -1.8880e+00,  1.7033e+00, -1.4189e+00, -1.8831e+00,  1.1622e+00,\n","         -1.4795e+00, -1.2635e+00,  1.0892e+01, -8.0112e-01, -2.1116e+00,\n","          3.0113e-01,  1.2110e+00,  6.3703e-01, -4.0097e-01, -9.7181e-01,\n","         -1.2878e+00, -1.2034e-01, -2.8599e+00, -1.5423e+00, -2.1484e-01],\n","        [ 2.9737e+00,  1.4293e+00,  5.8268e-01,  2.4543e+00, -2.3987e+00,\n","         -2.2562e+00,  4.8282e-01, -2.4370e+00, -6.3341e-01, -4.7467e-01,\n","         -1.9844e+00,  1.1329e-01, -1.6905e+00,  1.9748e+00, -1.0130e+00,\n","         -2.5842e+00,  2.7598e+00,  4.6312e-01, -4.2027e-01,  3.7418e+00,\n","          5.9101e-02, -7.1208e-01, -9.9840e-01, -2.1997e+00,  1.1409e+01,\n","          1.0415e+00, -1.5966e+00, -2.3596e+00, -8.8464e-01,  5.8630e-01,\n","          1.8311e+00, -5.1337e-01,  9.8560e-01, -7.0136e-01, -9.7968e-02,\n","          1.9088e-01, -2.0717e-01, -2.0385e+00,  8.1206e-01,  2.0420e+00,\n","         -1.6759e+00, -5.9269e-01, -7.2793e-01, -4.3872e-02, -1.9559e+00,\n","         -9.2663e-01, -2.4829e-01,  4.0172e+00, -1.8543e-01, -1.9908e+00],\n","        [ 5.2283e+00, -3.3104e+00,  1.1527e+00,  2.7275e+00, -2.0887e+00,\n","          2.8835e-01,  8.9047e-01, -2.3328e+00, -6.2968e-01, -1.6395e+00,\n","         -2.8901e+00,  1.3816e+00, -3.4603e+00, -3.2152e-02, -2.5806e-01,\n","         -2.0531e+00,  1.3314e+01, -1.2703e+00, -2.2817e+00,  2.3601e+00,\n","         -5.5152e-01, -1.1461e+00, -2.3181e+00, -7.6733e-01,  6.7333e-01,\n","          4.3923e+00,  1.1763e+00,  8.0630e-01, -2.4948e+00, -6.9983e-01,\n","          1.9879e+00, -1.9369e+00, -6.3982e-01,  2.9287e+00, -1.1599e+00,\n","          3.2712e+00, -2.4738e+00, -2.1944e+00,  2.1463e+00,  3.5993e+00,\n","         -3.6485e+00, -1.7562e-01, -3.0385e+00, -4.7440e-01, -2.1382e-01,\n","         -2.9506e+00, -1.3860e+00,  3.8143e+00, -5.2831e-03, -1.0522e+00],\n","        [-1.8013e+00, -1.0471e+00,  1.7862e-01, -1.8132e+00, -1.9228e+00,\n","          4.1530e-01, -1.4689e+00,  1.0488e+01, -2.0355e+00, -2.5222e-01,\n","         -5.0689e-01,  1.3077e+00,  2.1422e+00, -2.0289e+00, -1.1915e-01,\n","          1.5328e+00, -9.2804e-01,  1.9542e+00,  1.1236e+00, -1.5471e+00,\n","         -2.3350e+00,  2.1125e+00,  2.0495e+00, -2.1183e+00, -7.1762e-01,\n","         -5.1015e-01,  1.7955e+00,  9.9125e-01,  5.3237e-01, -3.0900e-01,\n","         -1.8033e+00, -1.9566e+00,  2.0395e+00,  1.0443e+00, -2.4816e+00,\n","          3.9266e-02, -1.3841e+00, -6.2795e-01,  2.5888e-01,  2.8423e+00,\n","         -3.0222e-01, -9.3714e-01, -9.4954e-02, -1.2329e+00,  1.2436e+00,\n","          1.8593e+00, -8.6695e-01, -1.4016e+00, -7.5831e-01, -1.3784e+00],\n","        [-1.7268e+00, -1.5967e+00,  1.0205e+00, -1.0831e+00,  2.6788e+00,\n","         -8.1034e-02,  1.1738e+00, -4.0739e-01, -6.4576e-01,  1.6859e+00,\n","          3.4472e-01, -1.4614e+00, -6.0995e-01,  2.5191e+00,  1.7972e-01,\n","          4.0112e-01, -4.2374e+00,  4.2004e-01,  8.0093e-01,  1.3089e+00,\n","          2.8217e+00,  3.3814e-01, -1.3566e+00,  2.0618e+00,  1.3354e+00,\n","          1.1033e-02,  8.7877e-01, -1.6168e+00,  6.2305e-01,  5.6203e-01,\n","         -2.4841e+00,  1.1213e+01,  2.0567e+00, -1.2801e+00, -2.2021e+00,\n","          2.1549e+00, -1.6686e+00, -7.1245e-01, -2.3425e+00,  1.1988e+00,\n","         -1.3714e+00,  9.1064e-01, -2.3244e+00, -1.6217e+00,  4.3127e-02,\n","          1.3318e+00, -3.8247e+00, -1.8143e+00, -9.5538e-01, -1.7582e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([46, 22,  0, 40, 30, 15, 34, 20, 28, 37, 49, 37, 24, 16,  7, 31],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8474,  8.2915, -0.8737,  ..., -1.7449, -2.1774,  2.5697],\n","        [-0.2843,  4.7417,  0.1159,  ..., -0.5345, -0.7705,  3.8322],\n","        [ 8.4066, -3.2018,  1.6199,  ...,  7.4633, -1.2946, -1.9865],\n","        ...,\n","        [ 2.0078,  0.3975, -0.7317,  ..., -2.1503,  1.6286, -0.4254],\n","        [-0.3266, 11.0418,  0.8896,  ..., -1.3085, -2.0450,  1.6861],\n","        [ 1.0795, -3.0477,  4.9822,  ..., -1.8410,  1.7600, -0.1108]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 391/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.0208, -0.0742,  2.7095,  ...,  1.5344, -0.8101, -1.3746],\n","        [-0.2039, -0.8278,  0.1567,  ...,  0.2038,  4.4081, -1.8268],\n","        [ 3.9777, -0.5825, -0.1044,  ...,  0.4240, -0.8532, -0.0808],\n","        ...,\n","        [-3.0427, -1.7142, -1.9211,  ..., -4.6023, -2.3098,  1.1019],\n","        [-2.2513,  3.3980, -0.2591,  ..., -1.3181, -1.3732,  1.4196],\n","        [-0.2915, -2.0638,  1.1598,  ..., -1.6204,  0.5257,  1.3047]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([11, 17, 16, 22, 39, 44,  3, 10, 10, 28,  7, 49, 45, 46, 35, 16,  3,  3,\n","         9, 36, 27,  1,  5, 33, 13, 18, 21, 22,  4,  0, 48, 14, 23, 30, 16, 16,\n","        40,  9, 33, 35, 46, 16, 30,  7, 41, 30, 26, 41, 20, 15, 29, 11, 33, 19,\n","         2, 36,  1, 24, 17, 29,  9, 12, 26, 37,  0, 28, 44, 30, 46, 36,  2, 11,\n","        48,  7, 31, 44,  2, 26, 32, 28, 23, 23,  7, 36, 32, 34, 31, 44, 19, 26,\n","        32, 40, 32, 20, 18, 30, 28, 41, 27, 24, 16, 22,  6, 29, 29, 27, 47,  4,\n","        31, 42, 12,  9, 41, 21, 41, 46, 43, 20, 18, 47,  8, 11,  2,  0, 35, 28,\n","        34, 20], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.6227, -1.7308,  0.4987,  ..., -1.2061,  0.5718, -1.0808],\n","        [ 2.5189, -0.6944,  1.0191,  ..., -0.0312, 17.4206, -1.3161],\n","        [ 0.0662, -2.0686,  0.0202,  ...,  2.0540, -1.5933, -1.4398],\n","        ...,\n","        [-0.1796, -0.6051,  1.5751,  ..., -1.9947,  4.7911, -3.2347],\n","        [-3.4849, -1.9635,  0.7895,  ..., -3.4688, -1.8814,  0.1846],\n","        [-1.8801,  4.3723,  0.2554,  ...,  0.2166, -0.2499,  3.9367]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([14, 48, 25, 15,  5, 24, 37, 21,  0, 12, 23, 37,  7, 37, 45, 21, 31,  9,\n","        24, 49,  1, 11, 14, 29, 14, 17, 15,  5, 30,  1, 31, 30, 42, 14, 15, 10,\n","        20, 29, 28, 42, 15, 15, 18,  2, 19, 18, 13,  8,  8, 37, 46,  9,  4, 25,\n","        39,  8, 26,  4, 37, 13, 38, 17, 33,  5,  6,  3, 17, 31, 25,  3, 18, 17,\n","        40,  0, 45, 20, 38,  7, 11, 43,  5, 31,  2, 36, 17, 25, 32, 35, 10,  2,\n","        42, 36, 20,  1, 40, 42, 11, 14, 24, 23, 11, 48, 49, 17, 47, 43, 38,  0,\n","        28, 27,  4, 47,  4, 33, 13,  6,  3, 14,  0,  6,  1, 30, 27, 33, 39, 10,\n","        31, 34], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.1881e+00,  2.4808e+00, -7.5298e-01,  ..., -5.0798e+00,\n","         -2.9263e+00, -5.0165e-02],\n","        [ 1.2345e+00, -6.7610e-01,  2.1335e+00,  ...,  1.7638e+00,\n","          2.3372e-01, -1.0974e+00],\n","        [-5.3079e-01,  7.8743e-01, -4.2457e-01,  ..., -7.9543e-01,\n","         -5.0757e-01, -7.7042e-01],\n","        ...,\n","        [-3.1137e+00,  1.1769e+00,  1.3887e+00,  ..., -2.0313e+00,\n","         -2.8971e-01,  1.7086e+01],\n","        [ 6.1190e+00,  2.9604e+00, -1.0479e-02,  ...,  1.9937e+00,\n","         -1.3466e+00, -1.8016e+00],\n","        [ 4.5089e+00, -2.1974e+00,  1.5989e+00,  ...,  1.8579e+00,\n","         -1.2513e-01,  4.4376e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([31, 19,  7, 19, 44, 37, 10, 47, 25, 22,  8, 10,  1, 40, 14, 29, 23, 35,\n","        17, 32, 29, 27,  2, 30, 45, 35,  6, 34,  0, 49, 39, 35, 36,  5, 32,  9,\n","        28, 22, 26, 32,  9, 13, 38, 22,  6, 40, 24,  9, 13, 20, 47, 25, 45, 46,\n","        33,  7, 23, 18, 41, 41, 10, 49, 42, 40, 10, 21, 22, 12, 43, 38,  9, 27,\n","        15, 12, 19, 38, 15,  4, 48, 25, 47,  5, 43, 49, 45, 12, 45, 19, 47,  4,\n","         6, 25, 27, 24, 44,  1, 30,  8, 46, 24, 39, 17, 34, 42, 19, 48, 29, 13,\n","         1, 16, 12, 36,  3, 21, 27, 40, 12, 27, 43, 36, 12, 26, 41, 48, 34, 49,\n","        24, 16], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.2241e-01, -9.5271e-01,  1.1471e+01, -2.5401e-01,  8.3943e-01,\n","          2.5200e+00,  2.8706e+00, -4.9735e-01, -4.8999e+00,  6.6383e-01,\n","         -6.0435e-02,  3.6504e+00,  4.7408e-01, -4.8001e+00, -2.2698e+00,\n","         -2.5538e+00, -1.6269e+00,  2.0040e+00,  2.2540e+00, -6.7126e-02,\n","         -9.4636e-01,  9.9971e-01, -1.1227e+00, -3.1294e+00, -1.6483e-01,\n","         -1.4271e-01,  2.8448e+00,  2.0862e+00,  9.4779e-01,  3.6069e-01,\n","          2.1922e+00,  3.7643e-01, -6.9749e-02, -2.1253e+00, -2.6415e+00,\n","         -1.0576e+00, -1.9532e+00, -1.2444e+00,  3.5716e+00, -2.0770e-01,\n","         -9.8574e-01, -3.8255e-01, -1.0550e+00,  2.2595e-01, -8.9452e-01,\n","         -1.8376e+00,  2.1709e-01, -2.1972e+00,  4.2165e-01, -3.9334e-01],\n","        [-1.8499e+00,  2.3121e+00, -2.2060e+00, -1.8526e-01,  3.5255e+00,\n","          9.5458e-02, -2.5668e+00, -5.4588e-01, -1.7357e+00,  4.8996e-01,\n","         -5.3340e-01, -1.8558e-01,  8.3474e-01, -3.0716e+00, -2.0444e+00,\n","          4.2270e-01, -3.6731e+00, -3.5029e+00,  4.6055e+00, -2.6816e+00,\n","         -1.3743e+00,  3.3726e+00, -1.1175e+00,  2.8267e+00, -2.1671e+00,\n","         -2.9598e+00, -1.1190e+00,  1.8076e+00,  8.0821e-01,  2.2665e+00,\n","         -6.1414e-01,  9.0409e-01, -6.6494e-01, -2.8812e+00,  4.7476e+00,\n","         -3.4942e+00,  1.1686e+00,  1.4421e+01,  1.8031e+00, -2.7876e+00,\n","          4.9766e+00,  1.1660e+00,  2.0620e+00, -1.1923e+00, -7.1192e-01,\n","         -7.5379e-01,  1.6314e+00, -3.1797e+00, -2.1535e+00, -2.4704e+00],\n","        [ 5.3842e+00, -1.4499e+00,  1.3406e+00,  7.9027e-01, -1.7732e+00,\n","          3.6968e+00, -2.1411e+00, -1.4617e+00, -9.7495e-01, -3.6790e-01,\n","         -1.9992e+00,  2.6795e+00, -2.8098e+00, -9.1781e-01, -2.4513e+00,\n","         -1.7896e+00,  1.3179e+01, -1.5114e+00, -2.7561e+00, -1.4600e+00,\n","         -1.9705e+00, -7.4446e-01, -2.2126e+00, -2.5143e+00,  2.1334e+00,\n","          2.3993e-01,  1.9838e+00,  4.2959e-01, -1.7418e+00,  4.4403e-01,\n","          3.7290e+00, -1.2437e+00,  1.6110e+00,  1.0202e+00, -2.9729e-01,\n","          3.8257e-01, -3.2364e-01, -2.2632e+00,  1.0350e+00,  9.3229e-01,\n","         -1.4861e+00, -6.4552e-01, -1.0234e+00,  6.1076e-02, -3.7326e-02,\n","         -2.3277e+00,  2.1084e-01,  7.7083e-01,  1.0974e+00,  1.3979e-01],\n","        [ 9.2324e-01,  6.9896e-01,  1.8001e-01, -2.8405e+00,  1.8208e+00,\n","          8.9916e-02, -2.3275e+00, -2.2892e+00, -1.4643e+00,  1.6262e+00,\n","          1.2733e+00, -8.8060e-01, -1.0495e+00, -1.3131e+00, -3.1646e+00,\n","         -2.6270e+00, -4.1911e+00,  1.9769e+00,  5.1484e-01, -3.0260e+00,\n","          1.4746e+01, -1.1213e+00, -2.7157e+00,  3.2005e+00,  2.2260e-01,\n","         -2.3865e-01, -3.7049e+00, -3.4474e+00, -1.8119e+00,  2.9525e-01,\n","          1.6517e+00,  4.5519e+00,  1.4046e+00, -4.7442e+00, -3.9759e-01,\n","         -3.2138e+00,  5.3521e+00,  7.2688e-01,  5.3303e-01, -1.4262e+00,\n","          1.6316e+00, -4.4560e-01,  3.3008e+00,  1.1691e+00,  2.4650e+00,\n","         -3.1996e+00,  9.8643e-01, -2.2912e+00,  2.7321e+00, -1.1317e-02],\n","        [ 6.7089e+00, -2.6504e+00,  6.4779e-01,  4.9101e-03, -3.1561e+00,\n","          6.9332e-01, -8.3105e-01, -2.3997e+00, -5.6720e-01, -2.5208e-01,\n","         -9.2842e-02,  2.0133e+00, -2.2835e+00, -7.8357e-01,  6.9188e-01,\n","         -2.6929e+00,  1.2044e+01,  3.4245e-01, -3.8102e+00, -1.5080e+00,\n","          9.4608e-02, -1.5100e+00, -6.0686e-01, -6.9436e-01,  2.4114e+00,\n","          2.6177e+00,  6.0325e-01, -1.2810e+00, -1.2696e+00, -1.4060e+00,\n","          3.0670e+00, -2.5848e+00,  4.2921e-01, -7.7704e-01, -1.7021e+00,\n","          1.8668e+00, -1.3555e+00, -2.3781e+00,  3.2305e+00,  1.2114e+00,\n","         -1.2401e+00, -7.9961e-01, -1.0574e+00,  7.5592e-01,  1.4997e+00,\n","         -3.0882e+00, -2.0656e-01,  2.7307e+00,  1.4138e+00, -4.5865e-01],\n","        [-2.0572e+00,  2.2298e+00, -2.3658e+00, -1.2237e-01, -3.0130e-02,\n","         -8.0931e-01, -2.6106e-01, -3.6976e+00,  1.0082e+01, -1.1012e+00,\n","         -1.1179e+00, -3.4278e+00, -7.6679e-01,  4.1387e+00, -5.5196e-01,\n","          8.5243e-02, -2.7297e+00, -1.5908e+00,  1.0501e+00, -1.3828e-01,\n","          1.7946e-01, -6.9663e-01, -2.6979e+00,  4.5930e+00, -1.2543e+00,\n","         -2.4280e+00, -1.4170e+00, -1.1728e+00, -1.5602e+00,  2.9555e+00,\n","         -2.7945e-01,  1.4142e+00,  1.3134e-01, -2.1932e+00,  4.0963e+00,\n","         -2.5811e+00,  3.3953e+00,  3.1607e+00, -7.1433e-01, -2.3562e+00,\n","          1.5278e+00,  6.3131e-01,  5.4496e-01,  2.4905e+00, -1.0334e-01,\n","         -1.5065e+00,  1.1606e+00, -3.1171e+00, -5.8685e-01,  1.8715e+00],\n","        [ 1.0860e+00,  1.9253e+00,  7.8585e-01,  9.2330e+00, -1.4782e+00,\n","         -1.2875e+00, -1.5973e+00, -2.2182e+00, -1.2866e+00,  6.0591e-01,\n","         -1.5527e-01,  9.5947e-01, -2.2361e+00, -1.3587e+00, -2.2617e+00,\n","         -2.5294e+00,  1.1226e+00,  2.4569e-01,  2.0255e+00,  7.5507e+00,\n","         -1.8907e+00, -1.1945e+00, -1.7158e+00, -3.0564e+00,  2.2297e+00,\n","         -3.3572e-01, -1.6822e-01, -1.1469e+00, -3.1558e-01, -6.9974e-01,\n","          6.3625e+00, -2.5585e+00, -1.3380e+00, -1.1230e+00, -3.8230e-01,\n","         -1.2340e+00, -2.4001e+00, -1.3417e+00,  2.6879e+00, -3.8036e-01,\n","         -1.1515e+00, -2.3905e+00,  5.8088e-01, -3.9811e-02, -1.3470e+00,\n","         -1.2535e+00,  4.6601e+00,  3.6762e+00,  7.0234e-01, -1.6077e+00],\n","        [-2.2114e+00, -3.6090e-01, -5.9837e-01, -2.3494e+00,  3.6737e+00,\n","          1.4116e-02, -7.8263e-01, -4.9166e-01, -1.2589e+00, -4.9745e-01,\n","         -1.2171e+00,  9.0466e-01, -2.8168e+00,  4.5139e-01, -2.4883e+00,\n","          3.3051e+00,  9.6185e-03, -2.4926e-01, -1.0479e+00, -1.8103e+00,\n","          1.0197e+00, -3.5971e-01, -3.4930e+00,  1.7411e-01, -1.5285e-01,\n","         -1.5998e+00, -7.0066e-01, -3.0502e-01,  1.1431e-01,  5.0154e+00,\n","          2.2724e+00,  1.2832e-01,  1.6535e+00, -6.0423e-01,  1.1008e+00,\n","         -1.3631e+00,  8.2648e-01, -1.1573e+00, -7.3187e-01, -1.0023e+00,\n","          3.9237e-01,  9.2688e-01, -1.9523e-01,  4.8486e-02,  2.1786e+00,\n","          5.3120e-01, -2.6597e-01, -1.2996e+00, -1.3121e+00,  1.0723e+01],\n","        [-1.6203e+00, -3.8004e-01, -1.0655e+00, -2.2632e+00, -9.8121e-01,\n","          4.8679e-01, -3.8852e-01, -1.7319e+00, -6.6583e-01,  2.4766e-01,\n","         -3.2431e-02,  1.1398e+00, -2.6158e-01,  1.2569e+00,  1.0151e+01,\n","          1.7074e+00, -1.0619e+00,  1.4343e+00,  3.5824e-02,  3.2959e-01,\n","         -4.7041e-01,  5.1585e-01, -6.3947e-01, -1.1279e+00, -4.2858e-02,\n","          4.5958e-01,  7.5489e-01,  1.0552e+00, -2.1802e+00,  1.0617e+00,\n","         -7.6713e-01,  1.3739e+00,  2.1030e+00, -1.5594e+00, -3.3342e-01,\n","         -5.6145e-01, -8.2688e-01, -1.2036e+00, -3.6455e-02, -1.0871e+00,\n","          2.0605e+00, -1.4324e+00, -1.9645e-01,  1.5543e-01,  1.9713e+00,\n","         -1.8246e+00,  1.0112e-01,  7.3973e-01, -1.0903e+00, -5.0408e-02],\n","        [-1.0658e+00,  6.3977e-01, -8.1154e-01, -1.8473e+00, -1.0129e+00,\n","          1.0695e-01, -1.3001e-01, -1.0240e+00,  1.0095e+01, -6.3487e-01,\n","          5.5267e-01, -2.1382e+00,  3.3537e-01,  2.3363e+00, -3.7167e-01,\n","         -2.9355e-01, -7.9085e-01,  9.6556e-01, -7.7586e-02,  3.6533e-01,\n","          1.2914e+00, -7.5519e-01, -3.2475e+00,  4.1923e-01, -3.6869e-01,\n","         -2.4862e+00, -1.7754e+00, -1.5639e+00, -1.0237e-01, -1.7177e+00,\n","         -1.4310e+00,  3.5548e+00,  1.9825e+00, -5.1267e-01,  3.0737e+00,\n","         -1.9954e+00,  3.6337e-01,  8.9666e-01, -8.9046e-01, -1.2879e+00,\n","          7.5107e-02, -1.6788e+00,  2.4565e+00,  2.7106e+00, -3.5950e-01,\n","         -1.3917e+00,  3.7228e+00, -2.4395e+00,  4.2067e-01, -1.0558e+00],\n","        [ 1.3974e+00, -2.7419e+00,  2.1450e+00, -1.7594e+00, -3.4744e-01,\n","         -1.9796e+00,  5.6942e+00, -1.4585e+00, -2.4163e+00, -1.7127e+00,\n","         -2.4269e+00,  4.2068e+00,  2.4561e+00, -2.3097e+00, -5.3780e-01,\n","         -2.8825e+00, -8.3579e-01,  2.4269e+00, -3.4810e+00,  1.5378e+00,\n","         -3.2862e-01, -2.1414e+00,  4.6917e+00, -1.0995e+00,  2.1721e+00,\n","          6.0954e+00, -2.4016e+00,  1.3858e+00, -7.0897e-01, -2.4125e+00,\n","          1.7589e+00, -2.6794e+00,  2.1915e+00, -1.3953e+00, -2.0886e+00,\n","          1.2430e+01,  2.7591e-01, -4.5184e+00,  1.6445e+00,  1.9318e+00,\n","         -2.4259e+00, -7.8943e-01, -1.3298e+00,  1.2460e+00,  2.8806e-01,\n","         -3.1585e+00, -2.2111e+00,  2.8586e+00, -1.0846e+00, -2.1588e+00],\n","        [-4.1912e-01,  2.2469e-01, -1.3299e+00, -8.2108e-01, -1.0750e+00,\n","          5.6541e-01,  1.3720e-01, -2.9751e+00,  3.6104e+00, -1.9111e+00,\n","         -2.3152e+00, -2.5805e+00, -2.5623e+00,  1.2941e+01, -1.2880e+00,\n","          3.3295e+00, -1.0507e+00, -1.6608e+00, -6.2661e-01,  2.5506e+00,\n","          3.1150e+00, -1.7197e+00, -2.1613e+00,  3.4767e+00,  1.9958e+00,\n","         -7.1513e-01, -1.1452e+00, -3.5813e+00, -2.3947e+00,  9.9591e-01,\n","         -1.3415e+00,  2.6022e+00, -8.1349e-01, -7.9640e-02,  1.9000e+00,\n","         -2.2187e+00,  1.6894e+00,  3.8601e-01, -7.2485e-01, -5.9614e-01,\n","          9.7020e-02, -8.1414e-01, -9.2538e-01,  3.3919e+00, -2.0005e-01,\n","         -4.1165e-01, -8.0831e-01, -8.9878e-01, -1.5270e+00,  2.2004e+00],\n","        [ 1.9489e+00,  5.2658e-01,  3.2413e+00,  5.4200e-01, -1.8517e+00,\n","          3.2447e+00,  3.1109e+00, -1.8844e+00, -2.9433e+00,  1.9548e+00,\n","         -1.3613e+00, -1.9162e-01, -1.6357e+00, -1.5772e+00, -4.4150e-01,\n","         -8.4070e-01, -6.8554e-01,  6.9509e-01,  7.1070e-01,  1.4800e+00,\n","         -1.2604e+00, -8.2606e-03, -6.1692e-02, -3.2979e+00,  8.7900e-01,\n","          3.4511e-01,  1.2938e+01,  7.4091e-01, -2.8989e+00,  1.3272e+00,\n","          1.3915e+00,  1.4515e+00, -1.7365e+00,  2.0932e+00, -4.1631e+00,\n","          4.3573e-01, -3.8263e+00, -1.4052e+00, -2.7199e-01, -6.1407e-01,\n","         -7.9930e-01, -2.2906e+00, -1.0864e+00, -2.5946e-01,  2.5061e-01,\n","         -8.1694e-01, -4.5489e-01, -5.3941e-01,  2.4299e+00, -1.9641e+00],\n","        [-1.1664e+00, -1.7063e+00,  3.0520e-01, -2.8752e-01,  2.6636e+00,\n","         -1.8101e+00, -7.2243e-01,  2.2188e+00, -2.3838e+00,  1.2575e+00,\n","          3.3832e-01, -5.6454e-01,  4.6429e+00, -2.9610e+00,  1.6723e+00,\n","         -6.9994e-01, -2.0495e+00, -1.2345e+00, -1.3701e+00, -1.6415e+00,\n","         -2.1396e+00,  9.3339e-01,  1.1333e+01,  1.6820e-02,  9.7692e-01,\n","          6.2474e-01, -9.9077e-01, -1.3231e+00,  1.8664e+00, -1.5289e+00,\n","         -1.2197e+00,  7.6300e-02,  8.0757e-01, -2.0130e+00, -1.8358e+00,\n","          8.5310e-02, -9.2663e-01,  1.5847e-01,  1.3013e+00,  1.6431e+00,\n","          2.5847e+00,  6.4227e-01, -6.4608e-01, -1.2139e+00,  6.5879e-02,\n","          1.5272e+00, -1.9898e+00, -7.7269e-01, -1.6508e-03, -9.7178e-01],\n","        [ 2.4738e+00,  2.2586e+00,  2.2706e+00,  1.1001e+01, -1.6064e+00,\n","         -1.3938e-01,  3.1190e+00, -9.8138e-01, -2.3876e+00, -1.0438e-01,\n","         -2.9651e+00,  2.0965e+00, -2.3444e+00, -1.7748e+00, -1.6344e+00,\n","         -2.1904e+00,  1.9502e+00, -1.3296e+00,  5.8779e-01,  4.4774e+00,\n","         -1.9981e+00,  1.6225e-01, -1.1321e+00, -2.3509e+00,  1.2192e+00,\n","          2.8947e+00,  1.8790e+00,  1.3480e+00, -2.7060e+00,  1.3034e+00,\n","          2.2783e+00, -1.4482e+00, -2.3392e+00, -8.1469e-02, -5.4449e-01,\n","         -4.9001e-01, -1.5515e+00, -1.5806e+00,  2.1527e+00,  9.4976e-01,\n","         -1.3309e+00, -2.1353e+00, -2.0661e+00,  3.2976e-01, -2.9022e+00,\n","         -2.8701e+00,  1.4051e+00,  3.4496e+00, -5.8544e-01, -2.6504e+00],\n","        [-3.5025e+00, -3.6241e+00, -1.8317e+00, -2.9769e+00,  1.9603e+00,\n","          2.2841e-01, -1.1248e+00,  2.1925e+00, -2.0087e+00,  4.3019e+00,\n","          9.7591e-01,  8.6679e-01,  1.9521e+00, -3.5561e+00, -3.1588e+00,\n","         -9.1788e-01, -2.1078e+00, -1.0426e+00,  5.0494e+00, -1.5804e+00,\n","         -9.9275e-01,  5.2582e+00, -2.3338e+00, -2.4471e+00, -5.8125e-01,\n","         -2.2592e+00, -7.0230e-01,  3.4971e+00,  4.7120e+00,  1.5457e+00,\n","         -1.1684e+00,  2.4916e+00,  1.0813e+00, -8.3289e-01, -5.8155e-01,\n","         -1.4902e+00, -2.0165e+00,  2.0295e+00, -1.1791e+00, -9.8018e-01,\n","          9.5718e-01,  1.3574e+01,  5.1476e-01, -3.0147e+00,  1.5446e-01,\n","          3.3482e+00, -9.1807e-01, -6.8890e-01, -1.3277e+00, -3.2599e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 2, 37, 16, 20, 16,  8,  3, 49, 14,  8, 35, 13, 26, 22,  3, 41],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8413,  8.2955, -0.8774,  ..., -1.7315, -2.1748,  2.5476],\n","        [-0.2816,  4.7237,  0.1114,  ..., -0.5242, -0.7670,  3.8140],\n","        [ 8.3739, -3.2073,  1.6274,  ...,  7.4702, -1.2960, -2.0023],\n","        ...,\n","        [ 2.0090,  0.4010, -0.7320,  ..., -2.1459,  1.6290, -0.4274],\n","        [-0.3300, 11.0314,  0.8886,  ..., -1.3028, -2.0443,  1.6720],\n","        [ 1.0748, -3.0475,  4.9812,  ..., -1.8346,  1.7589, -0.1164]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 392/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.3332,  1.1182,  1.0947,  ...,  1.3263,  0.1946,  2.2914],\n","        [-2.6672, -1.2849,  2.8889,  ...,  1.6033, -0.3174, -0.7241],\n","        [ 2.2612, -0.6803,  0.4486,  ..., -1.3476,  3.5097, -1.2022],\n","        ...,\n","        [ 0.6097, -0.0732,  0.7354,  ..., 14.8751, -0.5964, -1.1731],\n","        [-0.8260,  0.4951,  0.5251,  ..., -0.9818,  0.2562,  0.5495],\n","        [ 1.5426, -2.9764,  3.0089,  ..., -0.0247,  0.0371, -1.8729]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([36, 11, 17,  5, 40, 36, 46, 21,  8, 14, 36, 23, 33,  3,  0, 15,  4, 46,\n","        17, 38, 18, 30, 35,  7, 12, 17, 29, 20, 42, 22,  0, 32,  9, 35, 37, 48,\n","        25, 25, 35, 42, 33,  2,  5, 21, 18,  2,  5, 47, 12, 19, 48, 41, 14, 41,\n","        15, 22, 36, 43,  4, 37, 35, 20, 29, 44, 12,  9, 30,  9, 27, 40, 12, 25,\n","         8, 16, 15, 48, 49, 32, 16, 49, 24, 41, 23, 27, 15, 40, 30, 43, 29, 21,\n","        18,  6, 27, 28,  3,  9,  2, 42,  1,  3,  4, 16,  6, 25, 29, 31, 11, 20,\n","         2, 46, 31, 32,  8, 24, 16, 16,  1, 13, 30, 20,  4,  6, 47, 31, 18, 47,\n","        43, 30], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.3625,  0.0511,  1.5812,  ..., -2.1367,  4.1167, -3.0369],\n","        [-0.2832,  1.1213,  3.8390,  ..., -0.5291,  0.8408,  0.7636],\n","        [-1.2392, -0.3107,  0.8787,  ..., -1.2421, -0.5348, -2.2314],\n","        ...,\n","        [-1.3367,  4.5765, -1.5832,  ..., -2.5631, -1.9816,  3.4740],\n","        [-0.3643, -0.6342,  0.6681,  ..., -1.6730,  4.5845, -2.2781],\n","        [-1.5176, -1.0777, 14.3374,  ..., -2.6850,  1.3440, -0.6140]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([10, 26, 33, 26, 40,  2, 44, 10, 32,  8, 14, 20, 31,  0, 29, 39, 11,  1,\n","        41, 11, 27, 13, 30, 45, 36,  1, 13, 30,  6, 46, 28,  2, 42, 14, 17, 23,\n","         4,  3, 34, 27, 27, 23, 42, 28, 19, 47,  9,  3, 26, 38, 31, 24, 19, 49,\n","        31, 18,  0, 28,  4,  4, 14,  2, 46, 43,  5,  0, 29, 16,  0, 28, 45, 46,\n","        49, 28,  5, 34, 48, 36, 14, 41, 40, 32, 36, 40, 12, 31, 10, 45,  9, 19,\n","        17, 45, 35, 46, 14, 10, 18, 48, 29, 44, 26, 42, 23, 12, 16, 49, 37,  7,\n","        20, 49, 24, 19, 15, 32, 31, 18, 47, 19,  5, 33,  5, 22,  1, 13,  7, 34,\n","        10,  2], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 4.0854, -0.3938,  0.9095,  ..., -0.6293,  1.7302, -2.2966],\n","        [16.3472,  1.5756, -1.2326,  ...,  1.8050,  0.1713, -2.1818],\n","        [-1.7805,  5.1800, -0.4014,  ..., -3.5672, -2.7160,  2.1626],\n","        ...,\n","        [-0.5847,  2.9677,  2.0509,  ..., -0.0825,  2.6947,  1.6854],\n","        [ 1.9651, -1.6788, -0.6554,  ..., 15.6005, -1.5154,  0.7951],\n","        [ 3.2488, -0.2257,  2.1006,  ...,  2.9945, -0.4848, -0.7379]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 3,  0, 37, 41, 48, 11, 10,  1, 26, 33,  7, 34, 24, 20, 17, 34, 30, 41,\n","        11, 12,  6, 22, 44, 19,  7, 22, 35, 25,  8, 41,  6,  8, 38, 17, 24, 15,\n","        16, 28, 32, 37, 47, 23, 33, 38, 41, 47,  1, 37,  8, 39, 39, 22, 39, 34,\n","        30, 28,  9, 31, 14,  6, 12, 12,  7, 17, 20, 21,  9, 19, 26, 29, 33, 37,\n","         8, 17, 40,  9,  7, 45, 22, 10, 48, 10, 27, 14, 17, 45, 16,  4, 24,  2,\n","        36, 32, 38, 44, 25, 39, 43, 16, 30,  9, 25, 20, 42, 49, 24, 27, 22, 13,\n","        27,  3, 15, 36,  3, 27, 49, 10, 11, 29,  1, 24, 13, 13, 35, 21, 15, 43,\n","        47,  3], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.0614e+00, -3.7878e+00,  4.0023e+00, -2.4012e+00,  3.2459e+00,\n","          3.0837e-01,  1.0847e+00, -5.3811e-01, -4.4677e+00,  1.2487e+00,\n","         -2.6899e-02,  1.3628e+01, -5.9137e-01, -4.7370e+00, -2.9624e+00,\n","         -3.0644e+00, -7.7036e-01, -2.4634e-01,  1.5816e+00,  2.0313e+00,\n","         -2.9047e+00,  8.0966e-01,  6.9059e-01, -4.6184e+00,  7.6035e-01,\n","          2.0702e+00, -3.6290e-01,  3.5954e+00,  2.5726e+00,  2.3232e+00,\n","          1.8881e+00, -3.2747e-01,  1.7957e+00, -2.8372e+00, -2.0311e+00,\n","         -1.3814e+00, -8.5278e-01, -3.0695e+00,  6.4114e+00,  1.4335e+00,\n","         -2.2354e-01,  1.5151e+00, -8.5718e-01, -2.9339e+00, -1.3160e+00,\n","         -3.3106e-01, -2.3764e+00,  3.4750e+00, -2.0037e+00, -9.0997e-01],\n","        [ 9.8215e-01, -2.0801e+00,  2.8724e+00,  8.0884e-01, -1.5072e+00,\n","         -1.6657e+00,  3.4061e+00, -2.2258e+00, -3.0881e+00, -1.1844e+00,\n","         -4.5368e-01,  3.2674e+00, -9.3895e-01, -1.5446e+00,  1.2748e-01,\n","         -2.3678e+00,  4.0320e+00,  2.1749e+00, -1.8904e+00,  9.3120e-01,\n","          1.0218e-01, -1.5170e+00,  7.1041e-02, -2.5384e+00, -1.2647e+00,\n","          1.5560e+00, -7.5398e-01,  5.2310e-01,  1.4510e-01, -2.1613e+00,\n","          5.0041e+00, -1.6586e+00,  9.9593e-01,  9.6292e-01, -7.8092e-01,\n","          9.9696e+00, -1.0320e+00, -3.0234e+00,  5.7923e-01,  6.7040e-01,\n","         -3.0966e+00, -6.0806e-01, -8.8962e-01,  5.2169e-01, -7.8306e-01,\n","         -4.3709e+00,  1.5904e+00,  4.6274e+00, -6.2915e-01, -2.8579e-01],\n","        [-2.5666e-01,  8.8344e-01, -1.6403e+00,  4.2358e-01, -1.0276e+00,\n","         -1.4164e+00, -1.4359e+00,  6.5248e-01, -1.5152e+00, -5.6276e-02,\n","          4.2186e-01,  1.5873e+00,  1.4640e+00,  2.4612e-02, -1.7071e+00,\n","          9.7099e-01, -1.4258e+00, -4.2399e-01,  5.7835e+00, -2.2008e+00,\n","         -5.0599e-01,  1.0960e+01, -2.4058e-01, -1.8537e+00, -9.1163e-01,\n","         -1.7539e+00, -1.7253e+00,  1.6730e+00,  1.3621e+00, -4.6813e-01,\n","         -2.8246e-01, -4.0428e-01, -8.3161e-01, -1.2807e+00,  9.2971e-02,\n","         -2.4055e+00, -1.2646e+00,  3.8950e+00,  1.3411e-01, -9.1565e-01,\n","          1.2896e+00, -5.2073e-01,  2.6373e+00, -7.6468e-01, -2.2057e+00,\n","         -1.1802e+00,  1.4496e+00, -4.7073e-01, -1.0336e+00, -2.1279e+00],\n","        [-1.9010e+00, -1.1799e+00, -6.6393e-01, -1.2155e+00,  2.6895e+00,\n","         -1.9035e+00,  3.1136e-01, -4.1080e+00,  6.0729e+00, -2.0579e+00,\n","         -1.3436e+00, -2.2733e+00, -1.4536e+00,  6.2255e+00, -2.2520e-01,\n","          1.6954e+00, -2.2022e+00, -1.2199e+00, -3.3305e-01,  7.0818e-01,\n","          5.8140e+00, -5.5688e-01, -1.8036e+00,  1.4348e+01,  2.1607e-01,\n","         -7.0643e-01, -3.7661e+00, -3.4146e+00, -1.9695e+00,  5.9343e-01,\n","         -5.1683e-01,  1.1158e+00, -5.8789e-01, -1.4184e+00,  8.6524e-01,\n","         -2.8800e+00,  1.4287e+00,  2.3755e+00, -3.6145e-01, -1.4411e+00,\n","         -1.1770e+00, -2.2310e+00,  6.9655e-01,  5.3236e+00, -1.0598e+00,\n","         -2.0094e+00, -2.3836e+00, -2.1976e+00, -8.0234e-01,  2.6659e+00],\n","        [ 1.0406e+00,  1.5714e+01,  1.1726e+00,  2.6598e+00, -1.6739e+00,\n","          1.4373e+00, -1.8550e-01, -2.9990e+00,  1.9644e+00,  1.7083e+00,\n","         -1.6222e+00, -2.6091e+00, -1.5884e+00, -1.1692e+00, -2.3318e+00,\n","         -1.1670e+00, -4.0679e+00, -3.0298e+00,  3.4297e+00, -3.7568e-01,\n","         -1.0210e-01, -1.1890e+00, -2.7292e+00, -2.4134e+00,  9.8600e-01,\n","         -3.1572e+00,  1.6201e+00, -1.0957e+00, -2.4855e+00, -3.1292e-01,\n","          2.5107e+00,  2.2444e+00, -2.0610e+00, -4.1858e+00,  5.5742e+00,\n","         -2.7868e+00,  1.0172e+00,  2.4716e+00, -8.4924e-03, -5.8820e+00,\n","          2.1390e-01, -2.0424e+00,  5.2699e-01,  2.7032e+00, -4.0346e-01,\n","         -2.9728e+00,  7.2257e+00, -7.4523e-01, -8.6878e-01,  2.4714e+00],\n","        [ 1.5965e+00,  9.0834e-01,  9.1337e-01,  1.6068e+00, -8.6812e-01,\n","          3.3982e+00,  2.5554e+00, -1.1340e+00, -3.7206e-01,  3.4163e-01,\n","          4.9121e-01, -1.2810e+00, -2.0847e+00, -7.9115e-01, -4.5020e-01,\n","         -9.5261e-01,  7.6069e-01,  1.2992e+00,  4.8631e-01, -4.5046e-01,\n","         -1.1696e+00, -1.6576e+00, -2.4547e+00, -2.4377e+00, -1.5540e+00,\n","         -7.6355e-01,  9.8927e+00, -6.4912e-01, -1.9778e+00,  1.4863e+00,\n","          1.2618e-01,  1.1880e-01, -2.3455e-01,  2.7585e+00, -1.3656e+00,\n","          9.3998e-01, -1.4282e+00, -1.7188e+00, -7.9723e-01, -1.9582e+00,\n","         -2.4712e+00, -1.3239e+00,  7.7488e-02, -7.8397e-02,  1.5465e+00,\n","         -1.4168e+00, -6.1875e-01, -3.7237e-02,  2.5564e+00, -3.1527e-01],\n","        [ 1.1804e+01, -2.3849e-01, -4.3453e-01,  4.0660e+00, -2.1214e+00,\n","         -1.3769e+00,  3.2780e-01, -2.5106e+00, -1.9812e-01, -1.8219e+00,\n","         -2.1578e+00,  8.7620e-02, -1.9021e+00, -1.9647e-01,  6.0235e-01,\n","         -2.8835e+00,  5.4168e+00,  3.1830e-01, -2.1016e+00,  2.7807e+00,\n","          3.5513e-01, -1.2330e+00, -5.6386e-01, -3.0648e-01,  1.7175e+00,\n","          2.7756e+00,  4.7296e-01, -1.2572e+00, -2.0834e+00, -1.9664e+00,\n","          7.0933e-01, -5.1204e-01,  7.3453e-01, -1.6365e+00, -2.0914e+00,\n","          5.1995e-01, -1.4782e+00, -1.1111e+00,  4.4927e+00,  2.8025e+00,\n","         -1.7488e+00, -1.6547e+00, -9.0611e-01,  1.3651e+00, -2.2162e+00,\n","         -2.9610e+00,  2.4692e-01,  9.1738e-01,  6.1414e-01, -2.3662e+00],\n","        [-2.6074e+00, -1.3382e+00, -9.9832e-01, -1.1458e+00, -4.4674e-01,\n","         -1.9885e-01, -8.5280e-01,  1.4005e+01, -2.4883e+00,  1.4511e+00,\n","         -1.0824e-01,  1.1246e+00,  1.0630e+00, -2.7074e+00, -1.2952e+00,\n","          3.4948e-01, -1.0876e-01,  1.4872e+00, -9.2603e-01, -1.7720e+00,\n","         -1.8831e+00, -2.5347e-01,  2.3329e+00, -3.0383e+00, -8.6847e-01,\n","          7.9953e-01, -1.0813e-01, -6.5293e-01,  2.7495e+00, -4.4222e-01,\n","         -1.1946e+00,  7.1252e-01,  4.0594e+00,  2.0274e-01, -1.0552e+00,\n","          7.6008e-01, -3.5121e-01,  8.2463e-01, -1.6162e+00,  3.1343e+00,\n","         -7.8496e-01,  1.0705e+00,  1.9572e-01, -1.3248e+00,  1.1942e+00,\n","         -3.3934e-01, -2.2141e-01, -1.7626e+00,  5.8147e-02, -1.2631e+00],\n","        [-1.1579e+00, -9.6721e-01, -1.5442e+00, -6.8357e-01, -1.5888e+00,\n","         -2.8448e-01,  1.2431e+00, -4.5170e+00,  7.2210e+00, -2.4891e+00,\n","         -2.4194e+00, -1.3403e+00, -2.1677e+00,  1.2114e+01, -1.0216e+00,\n","          2.3595e+00, -3.4112e-01, -4.3795e-01, -3.3741e-01,  2.5550e+00,\n","          5.0361e+00, -1.9533e+00, -3.5240e+00,  2.5167e+00,  1.0647e+00,\n","         -1.0413e+00, -2.2988e+00, -2.7666e+00, -1.8300e+00,  2.1031e+00,\n","          1.7263e-01,  1.8245e+00,  1.2884e+00, -6.0099e-01,  4.3808e-01,\n","         -5.9584e-01,  3.5603e+00, -1.7864e+00, -1.3959e+00, -1.0991e+00,\n","         -8.9929e-01, -1.0952e+00,  3.8634e-01,  2.7554e+00, -1.1242e+00,\n","         -2.7018e+00, -4.0446e-01,  1.6984e-01, -2.4377e+00,  2.9593e+00],\n","        [ 1.5457e+00, -8.6907e-01,  8.1221e-01, -6.3169e-02, -1.8204e+00,\n","          4.4744e+00,  2.4471e+00, -9.3286e-01, -1.1817e+00, -1.9229e-01,\n","         -6.1727e-01, -3.7502e-01, -9.5963e-01, -1.2096e+00,  1.3140e+00,\n","         -1.0068e+00, -3.4680e-01,  7.2165e-01,  5.3747e-01, -8.0523e-01,\n","          6.0624e-02,  3.3382e-01, -2.6500e+00, -3.4878e+00, -8.9108e-01,\n","         -1.6356e+00,  1.1213e+01,  1.8375e-01, -2.2914e+00,  1.8291e+00,\n","         -3.1359e-01,  6.9681e-01,  1.0074e+00,  1.2245e+00, -1.0062e+00,\n","         -1.0522e-02, -2.0853e+00, -1.9042e+00, -2.0009e-01, -1.7376e+00,\n","         -9.4514e-01, -3.8236e-01,  2.7440e-01,  1.0883e+00,  2.0975e+00,\n","         -2.5545e+00, -6.1067e-01, -4.6801e-02,  2.1470e+00,  1.7097e-01],\n","        [ 2.2681e+00, -1.5108e+00,  2.3557e+00,  2.1468e+00, -8.3489e-01,\n","         -9.1674e-01, -7.8257e-01, -3.3466e+00,  4.6705e-01,  2.7112e+00,\n","         -2.2509e+00,  3.9885e-01,  1.6190e+00, -4.4036e+00, -1.8763e+00,\n","         -3.7340e+00,  1.0440e+00,  2.2372e-01, -2.0656e-01,  2.3171e+00,\n","         -1.0233e+00, -7.1268e-01,  3.9074e+00, -4.6362e-01,  4.3921e+00,\n","         -1.1548e+00, -2.9005e+00,  3.8266e+00, -1.1471e+00, -2.6294e+00,\n","          2.2869e+00, -2.3068e+00,  5.3973e-01, -4.2309e+00, -5.1541e-01,\n","          3.0938e+00,  9.7390e-01, -2.5403e+00,  1.0161e+01, -9.2244e-03,\n","         -1.4608e+00,  7.6300e-01, -1.1041e+00,  6.5600e-01, -5.2805e-01,\n","         -2.2891e+00, -1.5415e-01,  1.5124e+00,  4.9394e-01, -1.2487e+00],\n","        [-1.9817e+00, -8.4708e-01,  1.8781e+00, -7.7826e-01, -1.9849e-01,\n","          3.6839e-01, -1.0201e+00, -2.0488e+00,  1.0600e+00,  9.4205e-01,\n","          8.7953e-01, -1.8007e-01,  2.5021e+00, -1.5314e+00,  1.8033e+00,\n","         -1.0312e+00, -1.1030e+00, -4.7878e-01, -1.1725e+00, -1.2838e+00,\n","          2.3722e-01,  8.2803e-01,  2.0977e+00, -2.2160e+00,  1.5991e+00,\n","          9.2509e-01, -1.7760e+00,  2.6564e-01,  3.7604e-01,  5.4202e-01,\n","          2.6917e+00,  5.1017e-01, -1.0102e+00, -2.3101e+00, -9.3346e-01,\n","         -2.5725e+00, -9.3230e-02,  1.5190e+00, -1.7084e-01, -2.6289e+00,\n","          1.1789e+01, -5.1397e-02,  8.5600e-01, -6.1336e-01, -1.1454e+00,\n","         -9.9372e-01,  9.5085e-01, -1.7029e+00,  2.6690e-01, -3.9363e-01],\n","        [-2.7112e+00, -2.0486e+00,  1.4785e+00, -2.1878e+00, -1.0930e+00,\n","          4.2518e+00, -1.2200e+00, -3.1788e+00, -1.5582e+00,  3.4783e+00,\n","          3.2706e+00, -2.0567e+00, -6.1167e-01, -3.6766e+00,  4.5233e-01,\n","         -1.2801e+00, -2.7866e-01,  3.1007e+00, -3.0940e+00, -2.0585e+00,\n","          1.0888e+00, -1.0205e+00, -1.5629e+00, -1.2358e+00,  2.5823e-01,\n","         -2.4893e+00,  3.2243e-01,  1.0334e+00, -6.8574e-01,  1.6829e+00,\n","          1.1331e+00,  1.3117e+00,  1.0963e-01, -1.7118e+00, -8.5788e-02,\n","          2.7701e-01,  1.4703e+00, -1.3723e+00, -2.1505e-01, -2.0206e+00,\n","         -1.1502e+00,  2.2943e-01,  1.0780e+00,  1.5345e+00,  1.1689e+01,\n","         -2.2952e+00,  1.3541e+00, -2.4821e+00,  4.9012e+00,  3.3541e-01],\n","        [ 2.6786e+00, -2.8508e+00,  2.3661e+00, -2.6035e-01, -1.3069e+00,\n","         -1.5758e+00,  2.1893e+00, -3.3636e+00, -2.2745e+00, -8.6246e-01,\n","         -1.5927e+00,  8.6947e-01, -1.5088e+00, -2.2946e-01,  1.5757e+00,\n","         -2.6253e+00,  2.7784e+00,  1.6418e+00, -2.7726e+00,  2.8341e+00,\n","          5.3973e-02, -1.9068e+00,  3.2404e+00, -9.6066e-01,  3.9132e+00,\n","          1.0395e+01, -6.8600e-01, -7.6275e-01, -1.2607e+00,  1.7482e+00,\n","          2.1966e+00, -1.1859e+00,  3.7798e-01, -6.7342e-01, -2.9308e+00,\n","          1.4298e+00, -1.3090e+00, -2.9203e+00, -7.3957e-01,  3.7362e+00,\n","         -6.5350e-01,  1.7222e-01, -2.3254e+00,  1.6410e+00, -3.6637e-01,\n","         -2.8679e+00, -2.7763e+00,  3.4987e+00,  1.6408e+00, -1.6504e+00],\n","        [-4.4038e+00, -2.9400e+00, -1.2879e+00, -7.6182e-01,  3.9592e+00,\n","         -1.0692e+00, -1.0835e+00,  2.9499e+00, -1.4083e+00,  1.8990e+00,\n","         -2.9691e-01, -7.6932e-01,  6.9027e-01, -2.0621e+00, -1.9000e+00,\n","         -1.5529e+00, -2.3756e+00,  6.7563e-01,  3.3952e+00, -4.3148e-01,\n","         -7.6078e-01,  1.7494e-01,  5.0826e-01, -2.9819e+00,  4.2057e-01,\n","         -1.4796e+00, -8.7696e-02, -1.1308e-01,  3.4722e+00,  1.4967e+00,\n","          7.8893e-01,  2.6695e+00,  3.1738e+00, -1.3534e+00, -1.1379e-01,\n","         -2.9294e+00, -1.9214e+00,  8.8317e-01, -1.7236e+00,  1.1678e+00,\n","          2.9707e+00,  5.2520e+00, -5.6269e-01, -2.9929e+00, -3.1237e-01,\n","          1.3036e+01, -9.9756e-01, -2.8232e+00, -1.8734e+00,  3.4987e-01],\n","        [-2.8533e+00,  3.8878e+00, -1.3098e+00,  9.9304e-01,  5.3835e+00,\n","          6.1918e-01, -2.7291e+00, -2.9948e+00,  9.9008e-01, -6.1706e-01,\n","         -5.6113e-01, -2.2914e+00, -4.7445e-02, -1.1190e+00, -1.7950e+00,\n","          2.4331e+00, -1.6044e+00, -4.9045e+00,  1.5930e+00, -2.8101e+00,\n","          4.7043e-01, -4.7373e-01, -1.4576e+00,  4.0416e+00, -2.3027e+00,\n","         -4.7017e+00, -2.6992e+00, -3.9844e-01, -4.0397e-01,  4.5436e+00,\n","         -1.2429e+00,  3.6400e+00, -7.3881e-01, -1.9100e+00,  7.8247e+00,\n","         -3.8533e+00,  1.3102e+00,  1.3622e+01, -1.7251e-01, -3.6919e+00,\n","          3.0635e+00,  2.9281e+00,  3.1856e-01, -6.7391e-01, -5.3657e-01,\n","         -2.0737e+00,  1.3050e+00, -4.3145e+00, -2.4552e+00,  2.8044e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([11, 35, 21, 23,  1, 26,  0,  7, 13, 26, 38, 40, 44, 25, 45, 37],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8389,  8.3010, -0.8719,  ..., -1.7315, -2.1745,  2.5549],\n","        [-0.2815,  4.7010,  0.1209,  ..., -0.5247, -0.7629,  3.8077],\n","        [ 8.3765, -3.2013,  1.6202,  ...,  7.4637, -1.2909, -1.9984],\n","        ...,\n","        [ 2.0063,  0.4000, -0.7279,  ..., -2.1464,  1.6346, -0.4299],\n","        [-0.3336, 11.0281,  0.8923,  ..., -1.3024, -2.0429,  1.6711],\n","        [ 1.0556, -3.0396,  4.9687,  ..., -1.8361,  1.7555, -0.1187]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 393/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 4.3511,  2.7271,  1.1905,  ..., -3.8014, 15.4471, -2.1490],\n","        [-1.4304,  0.5805, -1.4930,  ..., -1.4888, -2.3334,  1.9229],\n","        [-0.2963,  0.9898,  1.2509,  ...,  0.1459,  0.1345, -0.6715],\n","        ...,\n","        [ 0.8629, -3.1582,  2.6599,  ...,  4.9841, -1.9060, -1.2608],\n","        [-1.7639,  2.3790, -0.1390,  ..., -4.4599, -3.2317, -1.0519],\n","        [ 3.1790,  2.6214,  2.1816,  ...,  1.3602,  0.2790, -2.7994]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([48, 13,  5, 39, 48, 11, 36, 23, 43, 47, 14, 47, 30, 38, 28,  0, 32, 33,\n","        34, 37, 40, 20, 35, 49, 30, 12, 20, 46, 16,  5, 19, 20, 26,  8, 45, 15,\n","        34, 12, 10, 26,  7, 47, 31, 21, 36, 11, 43,  5, 49, 17, 27, 25, 32, 35,\n","        19,  9, 18, 28, 15, 49,  9, 35,  5, 29, 12, 16,  0, 18,  3,  7, 47, 44,\n","        18,  8, 13,  2, 13, 30, 15, 16,  6,  9, 45, 28, 26,  7, 41, 17, 36,  9,\n","        46, 33, 27, 24,  0,  1, 15,  1, 41,  4, 48,  6, 15, 36, 44, 30, 46, 32,\n","        17, 19,  1, 20, 37, 31, 29, 23, 10,  8,  3, 21, 49, 14,  8, 20,  8, 35,\n","        37,  3], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.6261,  0.6648,  0.1726,  ...,  0.7933,  0.2126,  1.6220],\n","        [ 0.5012, -0.2375, -1.5901,  ..., -0.6398, -1.0442, -2.4460],\n","        [ 1.7635, -0.9152,  0.6822,  ..., -0.9128, 12.9704, -0.7419],\n","        ...,\n","        [ 6.6538,  4.5591, -0.2088,  ...,  4.0919, -1.2805, -3.7191],\n","        [-0.6671, -1.2118,  1.7834,  ..., -0.5764, -0.2671, -0.5322],\n","        [ 2.2533,  0.1811, -0.1881,  ..., -1.2517,  4.1345, -0.9222]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([36, 21, 48, 23, 18, 37, 37, 33, 29,  4, 43, 17, 39, 31, 26, 30, 16, 46,\n","        49, 32, 11, 10, 28, 24, 23, 42, 48, 34, 31, 42, 22, 39,  1, 27, 15, 28,\n","        43, 27, 22, 31, 26, 37, 29, 10, 14, 15, 40,  1, 13, 24, 16,  9, 11, 43,\n","        26, 25,  4, 30,  5, 42, 36,  6, 40, 13, 33, 24,  8, 47,  6,  4, 29, 22,\n","        39, 46, 38, 27, 40,  2, 44, 40, 33, 27, 11, 10, 18,  6, 20, 44, 10, 35,\n","         7, 27, 19, 49, 20, 12,  4, 29, 22, 13, 45,  2,  2, 15, 19, 39,  8, 24,\n","        25, 11, 35, 38, 19, 28, 30, 49, 25, 26, 37, 21,  4,  9, 14, 42, 16, 24,\n","        33, 17], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8500, -0.2618,  0.2351,  ..., -0.6757, -0.4872, -0.9818],\n","        [ 0.3910,  2.2101, -0.1287,  ..., -0.0317, -1.2240,  7.0484],\n","        [-1.4234, -2.7658,  1.8905,  ..., -0.6085, -0.2965,  1.0626],\n","        ...,\n","        [ 2.2028,  2.1254,  0.6155,  ..., -3.9522, -0.5934,  0.6977],\n","        [-0.9549, -2.2195,  0.2366,  ..., -2.5446, -1.3688, -2.2203],\n","        [ 5.2883,  6.2983,  0.4364,  ...,  3.7061,  1.1661,  0.3082]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([33, 20, 10, 36, 18, 29,  5,  3, 22,  0,  0, 22,  0,  2, 41, 12, 40,  9,\n","         4,  2, 30, 40, 17, 48, 41, 45, 44, 29,  7, 30, 17, 27,  3, 31,  1, 21,\n","         1, 30,  6, 25, 11,  9, 22, 14, 47, 31,  1, 11, 14, 26, 13, 42,  7, 21,\n","        32, 23,  3, 32, 38, 10, 16, 24, 34,  0, 25, 38, 36, 19, 16,  2, 22, 25,\n","        41, 12, 41, 43, 12, 36, 31,  3,  2, 41, 44, 23, 10,  6, 28, 12,  3, 42,\n","        17,  4,  0, 18, 28, 32, 41, 34, 41,  7, 35, 25,  2,  8, 16, 17, 40, 45,\n","        42, 38, 49, 45, 37,  3, 14, 29, 17,  9,  7,  5, 14, 46,  9, 48, 47, 46,\n","        12, 24], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 6.5865e+00,  1.8787e+00,  1.3718e+00,  2.0731e+00, -1.1522e+00,\n","         -5.8825e-01,  2.0261e+00, -3.0270e+00,  9.2340e-01, -1.5868e+00,\n","         -7.4482e-01, -1.4094e+00, -1.1000e+00, -6.8671e-01, -2.4508e+00,\n","         -2.9555e+00,  2.1021e+00,  1.1032e+00, -1.3764e+00,  1.3531e+00,\n","         -2.5054e+00, -2.9694e+00,  4.6418e-01, -1.3340e+00,  1.2804e+01,\n","          1.2351e+00, -5.6963e-01, -3.1213e+00, -1.9494e+00, -3.3291e-01,\n","          2.8395e+00, -1.9091e+00, -3.4828e-01, -2.1879e+00,  8.9786e-02,\n","         -5.6273e-01,  1.4883e+00, -2.1090e+00,  2.4030e+00,  4.7896e-01,\n","         -1.7715e+00, -1.3244e+00, -2.5969e-01,  1.9143e+00, -3.5067e-01,\n","         -1.9571e+00, -2.9636e-02,  2.0025e+00,  9.9569e-01, -1.4885e+00],\n","        [-5.1505e-01, -2.2745e+00,  3.6563e+00, -1.9762e+00,  9.4982e-01,\n","          8.0000e-01, -1.5276e+00, -5.8165e-01, -2.2674e+00,  1.3003e-01,\n","          2.4269e+00,  3.3203e+00,  2.7148e+00, -3.3066e+00,  1.7289e+00,\n","          1.0019e+00, -1.6110e+00, -1.3844e+00,  1.8461e-01, -1.0776e+00,\n","         -3.6728e+00,  2.1984e+00,  2.2718e+00, -3.0588e+00, -1.3005e+00,\n","         -5.3566e-01,  1.0286e+00,  8.6376e+00, -2.1141e-01, -5.0177e-01,\n","         -7.6322e-01,  1.1128e-02, -5.9652e-02, -2.6585e+00, -7.6031e-01,\n","         -5.1088e-01, -9.5558e-01, -9.8123e-01,  3.2160e+00, -7.8028e-01,\n","          5.8525e-01,  7.9693e-01, -3.0492e-01, -1.4540e+00, -2.9240e-01,\n","         -1.2216e+00,  1.4830e+00, -1.1306e+00, -5.5314e-01, -7.7849e-01],\n","        [ 3.1908e+00, -2.4192e+00, -1.1255e+00,  1.8787e+00, -2.3712e+00,\n","          1.8563e-01,  8.0077e-01, -1.5013e+00, -2.5194e+00,  2.0974e-01,\n","         -1.1315e+00,  2.9904e+00, -3.1834e+00, -5.2544e-01, -2.2079e+00,\n","         -1.8724e+00,  3.8654e+00,  1.5352e+00, -1.8781e-01,  1.4069e+00,\n","         -5.7320e-01, -6.9638e-01, -7.9597e-01, -1.3531e+00,  4.8641e-01,\n","          4.1185e+00,  1.1447e-01, -1.8772e+00, -1.0683e+00,  5.1827e-01,\n","          4.0414e+00, -2.3470e+00,  1.3403e-01, -6.3664e-01, -9.8082e-01,\n","          1.0982e+00, -9.5099e-01, -3.8644e+00,  3.2641e+00,  2.2547e+00,\n","         -2.7669e+00, -2.6973e-01, -5.9808e-01, -5.7732e-02, -6.9089e-02,\n","         -2.9581e+00, -7.8090e-01,  1.1112e+01, -6.7772e-01,  3.3189e-01],\n","        [-3.2221e-01, -1.8996e+00,  1.1952e+00, -2.0191e+00, -1.3155e-02,\n","          9.6606e-01, -1.1974e+00, -6.4864e-01, -4.5354e-01, -1.8890e+00,\n","          1.5563e+00, -3.4270e-01,  6.2030e+00, -2.0820e+00,  9.7597e+00,\n","         -1.8533e+00, -7.0070e-01,  1.6859e-01, -2.1183e+00, -1.8028e+00,\n","         -5.1444e-02,  2.2520e+00,  2.1033e+00,  2.6892e-01,  8.6770e-02,\n","         -6.7071e-02,  1.3559e+00, -7.0903e-01,  2.4910e-01, -9.1446e-01,\n","         -3.4673e-01, -1.0268e-01,  8.7688e-01, -2.7835e+00, -2.5460e+00,\n","         -7.8238e-01, -7.7305e-01,  1.5503e+00,  7.8023e-01, -2.1750e+00,\n","          2.2878e+00, -2.8972e+00,  7.7101e-02,  1.4285e+00,  3.4003e+00,\n","         -2.5298e+00,  9.0113e-01, -2.3943e+00, -3.1352e-01, -7.2585e-02],\n","        [-2.0319e+00, -5.2518e+00,  9.8147e-02, -2.4758e+00, -1.6899e+00,\n","          3.4875e+00, -3.5308e-01, -1.5579e+00, -3.3868e+00,  3.4347e+00,\n","          1.3645e+00,  5.0422e+00,  2.9029e+00, -4.9231e+00, -1.5847e+00,\n","         -2.1698e+00, -1.1668e+00, -2.4043e-01,  1.9989e+00, -7.5967e-01,\n","         -1.1950e+00,  1.2961e+00, -1.1247e+00, -3.2598e+00, -2.1145e+00,\n","          2.8781e-01, -1.1535e+00,  1.4966e+01,  4.0752e+00,  1.4038e+00,\n","          2.7259e+00, -3.2177e-01, -8.2838e-01, -2.2706e+00, -1.0539e+00,\n","          1.0872e+00, -1.3730e+00, -3.8541e-01,  1.4759e+00, -1.8623e+00,\n","          1.8766e+00,  4.5385e+00,  3.1417e-01, -2.5825e+00, -4.6772e-01,\n","         -1.2214e+00, -1.4404e+00, -2.4569e-01,  1.1980e+00, -3.4634e+00],\n","        [-5.5855e-01, -6.5650e-01, -1.1861e+00, -8.3592e-01, -3.5325e-01,\n","         -1.5546e+00, -2.1775e-01,  1.4615e+00, -1.0733e+00, -5.7955e-01,\n","         -1.1785e+00,  6.1028e-01,  2.3349e-01, -1.5156e+00, -1.4974e-01,\n","         -2.4957e+00, -4.9512e-01,  1.1074e+00, -3.2139e-01,  4.8323e-01,\n","         -6.8236e-02,  1.6614e+00,  3.9521e+00, -1.9540e+00,  1.2389e-02,\n","          1.8645e-01,  7.3772e-01, -6.8109e-01,  6.2835e-01,  4.4023e-01,\n","         -4.2548e-01, -3.4711e-01,  9.7967e+00, -2.1831e-01, -1.2502e+00,\n","         -1.0420e+00,  1.0256e-01, -5.3117e-01,  1.1365e+00,  1.9001e+00,\n","          2.3958e+00,  6.5700e-01, -2.5597e-03,  4.4366e-01,  1.2286e-01,\n","         -7.1206e-01, -1.3514e+00, -1.0652e+00, -1.0027e+00, -2.0971e+00],\n","        [ 1.2224e+00, -3.8480e+00,  4.9198e+00, -1.0795e+00,  2.0256e-01,\n","         -1.0428e+00,  3.3728e+00, -1.7535e+00, -5.0286e-01, -5.5469e-01,\n","         -7.1619e-01,  3.1357e+00,  5.1945e+00, -2.8856e+00, -1.3436e+00,\n","         -4.1372e+00, -1.4086e-01,  1.2324e+00, -2.4730e+00, -7.1306e-02,\n","          2.3894e+00, -2.4412e+00,  2.6542e+00, -9.0580e-01,  3.9543e-01,\n","          9.9485e-01, -1.0013e+00,  7.4642e-01,  3.5126e-01, -3.7667e+00,\n","          1.7131e+00, -1.0809e+00, -4.1586e-01, -1.1372e+00, -2.9704e+00,\n","          1.4947e+01,  1.1847e+00, -3.3938e+00,  9.9747e-01,  1.9018e+00,\n","         -2.0741e+00,  2.9320e-01, -1.9004e+00,  8.8943e-01, -7.1036e-01,\n","         -2.2059e+00, -1.9723e+00, -1.3514e+00,  2.3526e+00, -1.7435e+00],\n","        [-3.5071e+00,  4.9108e-01, -1.2779e-01, -2.3641e+00,  5.9987e+00,\n","         -5.5099e-01, -4.0761e+00, -1.0259e+00, -1.8965e+00,  7.9182e+00,\n","          3.6104e-01, -2.4048e+00,  6.7305e-01, -1.4589e+00, -1.9691e+00,\n","          2.5831e+00, -3.1269e+00, -3.8704e+00,  5.2899e+00, -3.6463e+00,\n","          1.4064e+00,  2.8915e+00, -2.6933e+00, -6.8837e-01,  3.8620e-01,\n","         -3.8351e+00, -2.8273e-01, -1.9844e+00,  3.3026e+00,  3.1553e+00,\n","         -6.5445e-01,  1.2392e+01,  2.6988e+00, -5.0212e+00,  2.7438e-01,\n","         -3.1939e+00, -5.0304e-01,  7.3315e+00, -9.0779e-01, -3.6904e+00,\n","          4.7228e+00,  2.4731e+00,  1.3593e+00, -4.6277e+00,  3.4597e-01,\n","         -1.1267e+00,  1.3373e+00, -4.1844e+00, -2.7158e+00,  1.2271e+00],\n","        [ 1.4455e+00,  1.2164e+01,  3.3654e-02,  3.8000e+00, -2.0845e+00,\n","         -5.3853e-01, -1.4488e+00,  2.4634e+00,  1.0641e+00, -3.9505e-01,\n","         -7.8118e-02, -1.7679e+00, -2.0454e+00, -2.2363e+00, -1.8573e+00,\n","         -1.9668e+00, -4.4470e+00,  1.9974e+00,  1.8498e+00, -1.7033e-02,\n","          2.7752e-01, -5.5572e-01,  1.2592e-01, -1.3726e+00, -1.0457e+00,\n","         -1.6693e+00, -1.9944e-01, -1.4934e+00, -2.8930e+00, -1.2331e+00,\n","         -5.8319e-01, -1.2278e+00, -1.4297e+00, -2.7971e+00,  2.0825e+00,\n","         -3.9228e+00,  1.7907e+00,  2.4690e+00,  1.0009e+00, -2.7304e+00,\n","          6.6998e-01, -2.1987e+00,  4.4928e+00,  3.8251e+00, -1.0304e+00,\n","         -3.3611e+00,  3.9450e+00,  3.2312e-01,  2.7978e+00, -1.9951e+00],\n","        [-2.2364e+00,  8.6056e-01, -1.6359e+00,  2.9077e-02, -7.8355e-01,\n","         -3.2133e-01,  8.8042e-01, -3.5886e+00,  3.0056e+00, -1.4103e+00,\n","         -2.2734e+00,  9.6713e-02, -3.7112e+00,  1.3336e+01,  4.4374e-01,\n","          6.1820e+00, -1.1880e+00, -2.3892e+00, -3.4205e-01,  2.4626e+00,\n","          2.3517e+00, -5.8733e-01, -3.5733e+00,  1.5230e+00, -1.1519e+00,\n","          5.5445e-01,  4.9855e-01, -2.2375e+00, -1.5246e+00,  3.3928e+00,\n","         -4.3925e-01,  2.2260e+00, -3.6893e-01,  4.2916e-01,  1.1374e+00,\n","         -1.1793e+00,  2.9202e-01, -1.6359e-01, -1.0951e+00, -1.3479e+00,\n","         -7.6506e-01, -1.0984e+00, -1.3178e+00,  1.8588e+00, -1.1129e+00,\n","         -2.6082e+00, -6.3291e-02,  1.8557e-02, -2.8719e+00,  2.5647e+00],\n","        [ 4.1175e-01, -6.5142e-01,  1.8725e+00,  4.0569e+00, -2.0312e+00,\n","         -4.2443e-01,  1.9506e+00, -2.8271e+00, -1.8687e-01,  1.0927e+00,\n","         -3.2976e+00, -9.8088e-01, -1.9455e+00,  8.6338e-01, -1.5641e+00,\n","         -1.4955e+00, -3.3964e-01,  2.0975e+00,  1.7811e+00,  1.2136e+01,\n","         -1.6277e+00, -1.7189e+00, -1.6746e+00, -6.7216e-02,  1.4298e+00,\n","          1.1479e+00,  1.6253e+00, -2.0316e-01, -1.6748e+00,  3.3449e-01,\n","          1.7646e+00, -6.0095e-01, -1.5775e+00,  1.6319e+00, -2.3090e+00,\n","         -1.6466e+00, -3.8243e+00, -2.0515e+00,  2.0299e+00,  1.5037e+00,\n","         -1.7807e+00, -1.2628e-01, -2.5854e+00,  4.9974e-01, -5.7105e-01,\n","         -1.5017e+00, -8.9046e-01,  1.2513e+00,  4.4738e-01, -1.4246e+00],\n","        [ 1.1441e+00, -3.4333e+00,  3.0039e+00, -1.1079e+00,  1.5043e-01,\n","          3.4718e+00,  3.8628e+00, -4.2039e+00,  4.8595e-01,  1.5512e+00,\n","          1.0526e+00, -2.4379e-01, -3.9242e+00,  9.9953e-01, -2.7647e+00,\n","         -2.1543e+00, -1.5965e+00,  1.3098e+00, -1.6687e-02, -3.9693e+00,\n","          1.5458e+01,  5.9237e-01, -1.7819e+00,  1.9866e+00,  1.1452e+00,\n","          1.2804e+00, -5.6483e-01, -4.5552e+00, -3.3226e+00, -6.2059e-01,\n","          8.7805e-01,  1.6120e+00,  1.4138e+00, -9.8980e-01, -5.4196e-01,\n","         -2.3666e+00,  1.9414e+00, -2.3975e+00, -2.2342e+00, -2.2493e+00,\n","         -1.2267e+00, -7.3330e-01,  2.4368e+00,  3.4033e+00,  3.1373e+00,\n","         -4.5795e+00, -1.2826e+00, -4.9879e-01,  4.1278e+00,  7.0856e-01],\n","        [-1.0636e+00,  4.0609e+00, -1.4126e+00, -6.0024e-01,  9.7454e-02,\n","          3.1347e+00, -1.8650e-01, -8.8597e-01,  4.2540e+00, -2.4168e+00,\n","         -9.8396e-01,  8.9786e-02, -2.2458e+00, -6.5119e-01, -1.9942e+00,\n","         -2.8505e-02, -1.3443e+00, -2.4865e+00,  1.1673e+00, -1.9116e+00,\n","         -1.1284e+00, -7.7913e-01, -4.7305e+00, -6.2128e-01, -1.8328e+00,\n","         -4.2591e+00, -6.2399e-01, -8.7207e-01, -1.5704e+00,  1.1672e+00,\n","         -1.8343e+00, -6.7275e-02,  5.5036e-01,  1.0329e+00,  1.4155e+01,\n","         -1.5008e+00,  2.7196e+00,  5.6700e+00, -1.2624e+00, -3.9241e+00,\n","         -5.4556e-01,  2.5302e+00,  7.7124e-01,  1.7834e+00,  4.7981e-01,\n","         -1.7601e+00,  3.7652e+00, -2.8419e+00, -1.1781e+00,  2.6731e+00],\n","        [-8.7719e-01,  2.2072e+00,  6.9550e-01,  7.7700e-01,  3.4949e+00,\n","         -2.0270e+00, -1.8668e+00, -3.4693e+00,  2.4325e+00,  3.2465e-01,\n","         -2.7512e+00, -2.4785e+00, -4.2728e-01,  3.7283e-01, -1.0254e+00,\n","          2.1185e+00, -5.5641e-01, -2.6662e+00, -3.9458e-01, -1.4915e+00,\n","          3.0592e+00,  1.4134e-02,  1.5159e-01,  1.0735e+01,  3.8599e-01,\n","         -1.2640e+00, -2.3337e+00, -3.0706e+00, -3.0371e-01,  2.3389e+00,\n","          5.5841e-01,  1.0751e+00, -2.8245e+00, -2.5151e+00, -2.4456e-01,\n","         -2.9033e+00,  2.8096e+00,  5.0686e+00,  1.0223e+00, -8.4327e-01,\n","          1.2438e+00, -1.5192e+00,  2.5489e-01,  1.0555e+00, -3.9661e-01,\n","         -1.8272e+00, -1.0282e+00, -2.5085e+00, -1.3246e-01,  4.3249e+00],\n","        [ 2.2810e+00, -2.2287e+00,  2.4377e+00,  4.2225e+00, -2.8527e+00,\n","          1.4165e+00,  6.1038e-01, -1.2363e+00, -4.6139e-01, -4.6523e-01,\n","         -2.1553e+00,  5.4028e-01, -3.6836e+00,  7.3267e-01, -8.7974e-01,\n","          7.3557e-02,  1.4314e+01, -3.4185e-01, -2.1505e+00,  2.4681e+00,\n","         -2.4268e+00, -1.1335e+00, -2.8253e+00, -3.7793e+00, -6.2381e-01,\n","          1.6037e+00,  5.9423e+00, -5.4601e-01, -2.2412e+00,  1.3026e+00,\n","          3.0454e+00, -2.5165e+00, -1.0693e+00,  3.3876e+00, -8.3224e-01,\n","          1.6094e+00, -2.2106e+00, -2.5790e+00,  7.2940e-01,  1.2821e+00,\n","         -3.7080e+00, -6.9022e-01, -2.4394e+00,  2.1724e-01, -7.0556e-01,\n","         -2.7128e+00,  1.9498e+00, -1.2614e-02, -3.6384e-01,  3.9368e-01],\n","        [-2.2926e+00, -2.2333e+00, -2.2812e+00, -3.0206e-01,  2.1138e+00,\n","         -3.5117e-01, -8.8339e-01,  3.3172e+00, -1.6631e+00,  1.6184e+00,\n","         -6.2986e-01,  1.7619e-02, -5.1986e-01, -2.1675e+00, -2.6553e+00,\n","         -1.7030e+00, -1.2281e+00,  1.2683e+00,  2.2128e+00, -7.6515e-01,\n","         -1.6388e+00,  1.9418e+00, -1.5144e-01, -2.7143e+00,  2.0814e-02,\n","         -1.2262e+00,  6.2890e-01, -1.1743e+00,  1.8239e+00,  1.7624e+00,\n","          5.5201e-01,  1.2702e-01,  2.6149e+00, -7.0634e-01, -1.4696e+00,\n","         -2.8766e+00, -2.2878e+00,  4.6870e-01, -1.3380e+00,  2.0631e+00,\n","          3.4664e+00,  2.3690e+00, -4.2357e-01, -2.1402e+00, -3.8004e-01,\n","          1.2816e+01, -2.6091e-01, -1.5498e+00, -7.4230e-01,  6.6747e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([24, 27, 47, 14, 27, 32, 35, 31,  1, 13, 19, 20, 34, 23, 16, 45],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8380,  8.2828, -0.8688,  ..., -1.7316, -2.1722,  2.5496],\n","        [-0.2852,  4.6794,  0.1172,  ..., -0.5256, -0.7605,  3.7909],\n","        [ 8.3845, -3.2074,  1.6337,  ...,  7.4446, -1.2844, -1.9982],\n","        ...,\n","        [ 2.0086,  0.3988, -0.7278,  ..., -2.1480,  1.6379, -0.4281],\n","        [-0.3305, 11.0102,  0.8934,  ..., -1.3015, -2.0388,  1.6621],\n","        [ 1.0541, -3.0527,  4.9649,  ..., -1.8406,  1.7691, -0.1187]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 394/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 0.8274,  2.7827,  1.5080,  ..., -1.6537,  1.4892,  0.3022],\n","        [-1.1337, -1.0886,  0.8813,  ..., -1.0678, -0.4724, -0.7927],\n","        [ 3.1801,  0.9955, -0.3123,  ..., -1.6462,  0.7946, -1.6105],\n","        ...,\n","        [-2.1805,  1.7486,  2.5692,  ..., -0.3743,  2.1610, -0.3241],\n","        [-1.7745, -3.9341,  1.5939,  ..., -0.4064, -0.5351,  0.0867],\n","        [ 0.7895, -1.2404, -0.4374,  ..., 18.1018, -1.5743,  0.0690]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([43, 14, 42, 41, 30, 17, 20,  9, 27,  1, 27, 19, 25, 44, 37, 34,  0, 10,\n","         2, 28,  1, 16, 11, 26, 41, 49, 17, 48, 36, 24, 12, 12,  9,  0,  9,  8,\n","        11, 17, 26, 30, 17, 30, 28,  5,  1,  1, 24, 32, 38,  4, 48,  3,  6, 43,\n","        27, 20, 42, 13, 45, 35, 10, 18,  0, 18, 46, 30, 47, 31, 21, 23, 19, 36,\n","        49, 45, 25, 47, 29,  3, 24, 40, 20, 17, 10, 35,  7, 11, 43,  8, 29, 40,\n","         0, 12, 41, 32, 22, 30,  4, 36, 41, 23, 12, 37, 13,  3, 12, 30,  5, 18,\n","        44, 37, 10, 35,  7,  0,  9, 13, 11, 14, 21, 38, 47, 44,  5, 30, 14, 40,\n","        27, 47], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 4.7371e-01, -2.7750e+00,  2.4668e+00,  ...,  2.1925e-01,\n","          1.1445e+00,  1.0906e+00],\n","        [-2.3514e-01,  1.1164e-01,  1.5911e+01,  ...,  9.6429e-01,\n","          1.7658e+00,  3.3466e-01],\n","        [-2.1168e+00, -2.0149e+00,  1.3756e-01,  ..., -2.1740e-01,\n","         -2.1895e-01, -7.0808e-01],\n","        ...,\n","        [ 1.7058e+00, -3.8791e-01,  1.4986e-01,  ..., -1.2990e+00,\n","          3.6558e+00, -1.2964e+00],\n","        [-6.8876e-02, -6.6420e-01, -1.5203e+00,  ..., -5.8901e-03,\n","         -1.3820e+00, -2.3994e+00],\n","        [ 2.1444e+00, -1.3781e+00,  7.1342e-01,  ...,  1.3249e+00,\n","          2.4547e-01,  4.3816e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 5,  2, 40,  3,  1, 22, 34,  4,  6, 10, 17, 31, 24, 26, 15,  2, 14, 27,\n","        47, 46, 35, 40, 40, 30,  2,  0, 10,  4,  2, 34,  6, 20, 49, 17, 42, 38,\n","        22,  8, 36, 33, 48, 28, 12, 23, 14, 16, 11, 37, 34, 44,  8,  7, 43, 48,\n","         7, 28, 37, 10,  5,  2, 25, 10, 38,  3, 25,  6,  1, 49, 28, 41, 25,  6,\n","         5, 23,  0, 49, 37, 41, 46, 29,  9, 27, 32, 32, 18, 18, 33, 13, 46,  7,\n","        22, 36, 26, 29,  7, 31, 19, 21,  0, 14, 26, 38, 25, 22, 15, 45,  4, 39,\n","        35, 24, 26,  1, 32, 41, 26, 17, 11,  7, 42, 15,  1,  7, 30, 28, 20, 17,\n","        21,  5], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.8036, -0.6857, -0.5282,  ..., -2.0431,  2.0889,  0.9792],\n","        [-1.7273,  2.2808, -0.9973,  ..., -3.7433, -1.8752, -0.1337],\n","        [ 6.0663,  1.4172,  1.0203,  ...,  5.0179, -1.1730, -2.2608],\n","        ...,\n","        [ 0.3613, -3.1771,  1.3540,  ...,  1.3739,  0.8779, -2.8797],\n","        [ 2.9406,  2.4732,  0.4801,  ..., 15.0314, -0.3339, -1.4515],\n","        [ 3.2985,  0.6573,  1.6331,  ...,  4.0817,  0.3782, -0.7872]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([ 8, 37, 24,  6,  4, 14, 17, 13, 33, 13, 26, 19, 15, 45, 41, 19, 27, 16,\n","        23, 20,  8, 48, 48, 16, 32, 16, 28, 29, 20,  8, 22, 33, 27, 19,  1, 25,\n","        46, 11, 13, 23, 36,  2, 29, 29, 42, 24,  8, 32, 40, 31, 10, 21, 28, 27,\n","        34, 18, 15, 45, 15, 46,  9, 15, 36, 36, 35,  9, 35, 47, 42, 31, 12, 41,\n","        20, 23, 39, 16, 33, 43, 14,  4, 11, 35, 40, 27, 29, 20, 33, 16, 18, 16,\n","        45, 31, 42, 31, 39,  4, 34, 33, 31, 21, 49, 44, 19, 43, 46, 15,  2, 44,\n","        48, 31, 39, 37, 49, 38, 39,  3,  3, 45, 19, 24, 22, 47,  3, 13, 16, 25,\n","        47,  3], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 4.8354e-02, -2.0760e+00, -1.1800e+00, -1.4897e+00, -1.6414e+00,\n","         -1.4304e+00, -9.2903e-01,  4.0518e-01, -4.7884e-01, -1.4730e+00,\n","          5.0414e-01,  1.1871e+00,  4.3014e-01, -5.1996e-01,  1.5452e+00,\n","         -1.5122e+00, -8.2758e-01,  1.4495e+00, -9.5264e-01, -4.4969e-01,\n","          1.8300e+00, -1.8729e-01,  2.4860e+00, -1.9721e+00, -8.3869e-01,\n","         -7.1861e-02, -1.5332e-01, -4.5707e-01, -7.0292e-01, -1.6857e+00,\n","          2.6464e-01,  1.0469e+00,  9.9976e+00, -1.1679e+00,  3.7053e-01,\n","          2.7014e-01, -2.2612e+00, -1.8670e+00,  7.5295e-01,  3.1158e+00,\n","          9.2065e-01,  8.3659e-01, -4.8952e-01,  8.2270e-01, -1.4322e+00,\n","          1.8722e-01,  7.9159e-01,  3.9602e-01,  2.8775e-01, -1.4926e+00],\n","        [ 6.0957e-01, -5.1256e-01,  1.8943e-01,  1.9270e+00, -6.3743e-01,\n","         -3.1410e+00, -1.4556e+00, -4.0242e-01, -2.0513e+00, -1.0718e-01,\n","         -1.5230e+00, -1.5281e+00,  9.6725e-01, -1.6158e+00,  1.2201e+00,\n","         -2.9991e+00, -9.6189e-01,  1.2237e+00, -4.0256e-01,  1.8507e+00,\n","          1.0007e+00, -4.9512e-01,  1.2015e+01,  3.0459e-01,  2.6298e+00,\n","          2.4029e+00, -1.2247e+00, -1.9970e+00, -5.2573e-01, -2.0935e+00,\n","          8.3206e-01, -1.3360e+00,  3.5177e+00, -1.9690e+00, -2.2157e+00,\n","          3.1049e-01, -6.9632e-01, -1.1708e+00,  1.9971e+00,  1.7898e+00,\n","          1.3399e+00, -7.9960e-01, -8.2399e-01,  2.3103e-01, -4.1426e-01,\n","         -4.5383e-01, -7.1405e-01,  3.3324e-01,  8.2293e-01, -2.6536e+00],\n","        [-1.4243e+00, -3.2575e-01, -2.8852e-01, -1.8997e+00, -1.4575e+00,\n","          8.2488e-01, -9.2045e-01,  9.7774e-01,  1.3892e-01, -6.9232e-02,\n","          1.4943e+00,  1.3451e+00,  1.0970e+01, -3.1108e+00,  1.3023e+00,\n","         -7.0692e-01, -3.3238e+00,  2.1787e+00, -1.2173e-01, -2.9903e+00,\n","          2.1077e-01,  2.5512e+00,  1.1225e+00, -1.8681e+00, -2.7738e+00,\n","         -3.4242e-01, -1.1022e+00,  1.2675e-01,  2.6805e+00, -7.6912e-01,\n","          4.4625e-01,  2.0948e-01,  8.3100e-01, -2.0916e+00, -2.8542e+00,\n","         -9.6287e-02, -1.0190e+00,  1.4419e+00,  5.0004e-01, -2.7051e+00,\n","          4.7898e+00,  4.5683e-01,  4.2478e-01,  7.4625e-01,  5.5080e-01,\n","         -1.4599e+00,  1.0776e+00, -2.6581e+00,  8.0022e-01, -1.7958e+00],\n","        [ 1.7197e+00, -7.1484e-02,  2.6634e+00,  2.1207e+00, -1.5461e+00,\n","          1.9928e+00,  1.1910e+01, -2.1842e+00,  1.7474e+00, -2.7238e+00,\n","         -2.2930e+00, -1.2129e+00, -3.2238e+00,  3.8247e-01, -1.5609e+00,\n","         -2.3993e+00, -3.9698e-01,  8.5651e-01, -1.0350e+00,  1.5767e+00,\n","          2.2217e-01, -1.7308e+00, -2.4038e+00, -5.1755e-01, -5.3868e-01,\n","          5.8459e-01,  5.2060e+00, -8.7278e-01, -2.4665e+00, -1.1277e+00,\n","         -6.1407e-02, -9.3000e-01, -1.4126e+00,  6.3446e+00, -2.7522e-01,\n","          3.8418e+00, -8.3373e-01, -2.4483e+00, -1.4593e+00,  8.8145e-01,\n","         -2.7950e+00,  6.5336e-01, -2.0452e+00,  1.8284e+00, -5.3305e-01,\n","         -1.8792e+00, -1.4181e+00,  8.0021e-01,  1.3980e+00, -1.1250e+00],\n","        [ 7.7651e+00, -2.8567e+00,  1.1182e+00,  2.1453e+00, -2.9719e+00,\n","          7.6946e-01, -7.8644e-01, -3.0368e+00,  3.0061e-01, -1.8918e+00,\n","         -1.8034e+00,  1.7710e+00, -4.3175e+00,  1.8722e-01, -1.0090e-01,\n","         -3.2571e+00,  1.4654e+01, -7.2569e-01, -3.9036e+00,  2.1701e-01,\n","          4.9078e-01, -1.1326e+00, -1.9634e+00,  5.2404e-01,  1.1393e+00,\n","          2.9478e+00,  1.4789e+00,  7.3905e-01, -1.7286e+00, -1.4058e+00,\n","          2.2711e+00, -1.8695e+00, -2.7288e-02, -7.1470e-01, -1.3201e+00,\n","          3.0592e+00, -2.8772e-01, -2.3175e+00,  2.4841e+00,  2.2475e+00,\n","         -2.4443e+00, -1.2703e+00, -1.0447e+00,  1.1259e+00,  5.1515e-01,\n","         -4.6320e+00, -1.2655e+00,  1.5803e+00,  9.6739e-01, -2.9938e-01],\n","        [-3.0979e+00,  7.9426e-01, -5.0977e-01,  1.3298e-01,  1.4552e+00,\n","          1.5837e+00, -8.6538e-02, -5.1468e-02, -1.5499e+00,  1.0603e+01,\n","          3.7282e-01, -1.4357e-01, -2.1482e-01, -1.3501e+00, -2.6537e+00,\n","          9.3989e-02, -6.2441e-01,  7.6207e-01,  2.4052e+00,  9.7101e-01,\n","         -8.3045e-02,  2.5365e-01, -1.3755e+00, -1.7853e+00,  1.6278e-01,\n","         -8.8950e-01,  1.0030e+00,  3.1356e-01,  7.5274e-01,  8.0604e-01,\n","         -7.8901e-01,  2.5885e+00, -3.6923e-01, -4.8491e-01, -1.9288e+00,\n","         -1.7313e+00, -3.0343e+00,  8.8378e-01, -9.2619e-01, -1.8346e+00,\n","          2.3717e+00,  1.7191e+00, -5.4283e-01, -2.7028e+00,  2.3530e+00,\n","          7.3227e-01,  1.1763e+00, -1.2418e+00, -1.3259e+00, -1.3439e+00],\n","        [ 9.4218e-02, -7.8884e-01,  1.5078e+00,  2.8861e+00, -1.7609e+00,\n","         -6.4365e-01,  7.4266e-02, -1.7698e+00, -1.8555e+00, -1.6042e+00,\n","         -3.8786e-01,  4.4720e+00, -2.7678e+00, -7.9312e-01, -2.7949e+00,\n","         -1.8635e+00,  1.2818e+00,  4.4205e+00,  1.0734e-01,  6.0566e+00,\n","         -1.1101e+00, -1.3707e+00, -2.2370e+00, -3.9803e+00,  1.9181e-01,\n","          2.6206e+00,  6.7338e-01, -1.4070e+00, -9.1782e-01,  2.5098e+00,\n","          1.3366e+01, -3.3170e+00, -1.7995e+00, -8.4398e-01, -1.2767e+00,\n","         -2.4130e+00, -2.3833e+00, -2.1629e+00,  3.8951e-01, -5.4799e-01,\n","          6.5714e-02, -1.9350e+00,  4.9630e-01,  5.5720e-02, -1.2194e+00,\n","         -1.3858e+00,  3.9183e+00,  1.5908e+00,  1.7448e+00,  1.9813e-01],\n","        [-5.1747e-01, -5.9291e-01,  6.9874e-01, -1.4653e+00,  7.6691e-01,\n","         -4.4482e-01, -4.7198e-01, -1.2756e+00,  1.2439e-01, -2.4935e+00,\n","          6.8294e-01, -1.2560e+00,  1.5844e+00, -6.3298e-01,  1.0593e+01,\n","         -1.5332e-01, -1.5800e+00, -2.0844e-01, -1.3219e+00, -6.5077e-01,\n","         -9.5541e-01,  1.6937e+00,  2.2539e+00,  8.6719e-01,  2.6501e-01,\n","          4.2037e-01,  5.1627e-01,  6.8567e-01, -1.0055e-01, -1.0208e+00,\n","         -1.5217e+00, -2.8636e-01,  7.3925e-01, -2.9767e+00, -1.3034e+00,\n","          2.8623e-01, -3.9724e-01,  2.3716e+00,  1.2547e+00, -1.7583e+00,\n","          1.9181e+00, -3.0857e+00, -9.0402e-01,  1.7675e+00,  2.9583e+00,\n","         -2.2018e+00,  1.0803e+00, -1.5620e+00, -8.9529e-01, -1.2656e-01],\n","        [ 3.5952e+00,  1.9414e+00, -7.5544e-01,  3.4086e+00, -1.6797e+00,\n","         -9.7681e-02,  1.6185e+00, -1.1243e+00,  2.9026e-01, -2.0442e+00,\n","         -2.0548e+00, -8.7095e-01, -2.8915e+00,  1.0963e+00, -2.8819e+00,\n","         -2.3681e+00,  3.0357e+00, -2.1858e+00,  1.8778e+00,  3.3590e+00,\n","         -1.3089e+00, -1.5672e+00, -1.3992e+00, -7.3794e-01,  9.9760e+00,\n","         -5.7166e-01,  9.4662e-01, -1.0622e+00, -1.1772e+00,  4.6637e-01,\n","          1.1361e+00,  7.5645e-01, -9.3773e-01,  1.3292e+00,  2.6709e+00,\n","         -2.6692e-02, -6.5544e-01, -8.3432e-01,  1.6590e+00,  1.4093e+00,\n","         -3.1551e+00, -9.2322e-01, -3.7378e-01, -7.1034e-01, -2.2559e+00,\n","         -9.1021e-01,  9.1093e-02,  2.7577e+00, -1.3335e+00, -2.4085e+00],\n","        [-2.9484e-01,  4.0314e+00,  6.1288e-01,  4.4668e-01, -6.1310e-01,\n","          1.4548e+00, -3.6401e-01, -4.1571e+00,  6.7395e+00, -3.0710e+00,\n","         -2.9800e+00, -2.7114e+00, -4.2895e+00,  6.3102e+00, -7.0807e-01,\n","          3.0947e+00, -7.1864e-01, -2.1576e+00, -3.5395e+00,  2.7113e-01,\n","          2.8959e+00, -2.6379e+00, -3.7191e+00,  4.4527e+00,  2.3987e-01,\n","         -2.2472e+00,  5.4058e-01, -2.8627e+00, -3.5056e+00,  2.1606e+00,\n","         -1.9656e-01,  1.1611e-01, -2.7460e+00, -1.9135e+00,  2.2269e+00,\n","         -1.3511e+00,  3.3214e+00,  6.9619e-01, -3.6171e-01, -3.4715e+00,\n","         -6.3216e-01, -4.5276e-01,  1.1941e-01,  6.2370e+00, -1.4313e-01,\n","         -3.1008e+00,  3.0829e-02, -1.5169e+00, -8.4557e-02,  1.0543e+01],\n","        [-1.6171e+00, -1.8729e+00,  9.0286e-01, -2.1461e+00, -1.4519e-02,\n","          1.0801e+00, -1.2999e+00, -2.6533e+00, -1.8138e+00,  1.1148e+01,\n","          2.9372e-01, -3.1432e-01, -1.0670e+00, -2.0415e+00, -2.2126e+00,\n","          1.5438e-01, -7.5164e-01, -7.2384e-01,  5.9588e+00, -2.1321e+00,\n","          2.2302e+00,  2.5194e+00, -1.9600e+00, -3.1641e+00,  2.5989e+00,\n","         -1.0602e+00,  3.0216e+00,  1.3814e+00, -9.8095e-01, -1.5965e-01,\n","         -3.4226e-01,  4.0282e+00, -1.3994e-01, -3.6406e+00, -1.0027e+00,\n","         -4.7279e-01, -2.6704e+00,  1.2545e+00,  5.4321e-01, -3.6360e+00,\n","          1.0982e+00,  3.4379e+00,  1.3277e+00, -3.6424e+00,  2.4624e+00,\n","         -8.3470e-01,  1.8541e+00, -6.4178e-02, -1.2230e+00, -1.0117e+00],\n","        [ 2.1178e+00,  2.2654e+00, -1.5346e+00, -7.9749e-01,  7.7936e-01,\n","          5.6894e-01, -1.2524e-01, -1.2894e+00,  2.1771e+00, -1.3269e+00,\n","         -4.1297e-01, -3.1011e-01, -1.3986e+00, -5.3071e-02, -2.1356e+00,\n","         -2.5965e+00, -4.2361e-01, -1.6008e+00, -1.4050e+00, -1.3595e+00,\n","          1.6867e+00, -1.3238e+00, -1.7706e+00,  1.7599e+00, -4.5926e-01,\n","          1.9274e-01, -2.1031e+00, -8.4524e-01, -1.2689e+00, -3.0492e-01,\n","          9.7494e-01, -1.1002e+00,  5.2856e-01, -2.0777e+00,  1.5876e+00,\n","         -1.9754e-01,  1.1733e+01,  4.8510e-01,  5.4610e-01, -6.7555e-01,\n","         -1.7997e-01,  4.2393e-01,  1.8958e+00,  1.9558e+00,  2.3017e-01,\n","         -1.5959e+00,  8.7654e-01,  9.6594e-02,  2.7157e-02,  1.2234e+00],\n","        [-2.1366e-01,  1.9296e+00, -2.1540e-01,  8.1670e-02,  1.3684e+00,\n","          2.4191e+00, -3.9346e+00, -2.0334e+00, -3.2162e+00,  9.0436e+00,\n","         -2.0257e-01, -6.3334e-01, -2.3229e+00, -3.0171e+00, -2.5027e+00,\n","          1.1770e+00,  9.3174e-01, -2.1841e+00,  3.3891e+00, -3.0823e+00,\n","         -9.3064e-01,  1.5779e+00, -4.3294e+00, -2.6911e+00,  1.4595e+00,\n","         -3.5796e+00,  2.6721e+00,  2.3090e+00,  6.9212e-01,  4.1791e+00,\n","          5.4182e-02,  5.7975e+00,  8.6528e-01, -4.4633e+00,  2.4902e+00,\n","         -1.6743e+00, -1.3658e+00,  3.1867e+00,  1.2851e+00, -4.4747e+00,\n","          1.0465e+00,  7.9269e-01,  4.6009e-01, -2.7859e+00,  2.6689e+00,\n","         -2.1010e+00,  3.5093e+00, -1.0314e-01, -1.2333e+00,  1.3200e+00],\n","        [-3.1469e+00, -9.6359e-01, -2.2884e+00, -2.3260e+00,  3.0691e+00,\n","          8.4961e-01, -1.0552e+00, -2.5033e+00, -1.1982e+00, -2.2241e+00,\n","         -1.6962e+00,  1.5929e+00, -3.0349e+00,  3.2983e+00, -2.3089e+00,\n","          6.8577e+00, -2.1546e+00,  1.2909e+00, -5.1653e-01, -2.2940e-01,\n","          2.0035e+00,  1.7447e-01, -4.1829e+00,  2.1716e+00, -6.7428e-02,\n","          1.6703e+00, -1.5781e+00, -5.5785e-02, -1.8336e+00,  1.1394e+01,\n","         -3.5979e-01,  1.4496e+00,  2.2678e+00, -2.9131e-01,  1.7716e+00,\n","         -3.0450e+00, -3.8093e-01,  8.4633e-01, -1.6220e+00, -1.6097e+00,\n","          5.3149e-01,  3.0499e-01, -2.6284e-01,  6.1363e-01,  2.0725e+00,\n","          1.2381e+00, -2.2643e+00, -1.2411e+00, -1.3867e-01,  3.1022e+00],\n","        [ 7.5764e-01, -1.6258e+00,  1.0164e+01,  8.4018e-01,  2.2818e+00,\n","          9.3875e-01,  2.1512e+00,  2.4559e-02, -3.6841e+00, -1.0758e+00,\n","         -2.3379e-01,  5.2358e+00, -1.5779e+00, -3.3120e+00, -2.9661e+00,\n","         -2.1008e+00, -4.6853e-01,  5.3905e-01, -2.8455e-01,  2.5458e-01,\n","          1.1394e-01,  4.2522e-01,  4.4293e-01, -1.0319e+00, -1.0273e-01,\n","         -1.0687e-01,  3.1121e-02,  1.7998e+00,  1.0800e+00, -2.2179e+00,\n","          2.8076e+00,  1.7152e-01, -2.3569e+00, -1.5286e+00, -8.3588e-01,\n","          1.2836e+00, -6.9410e-02, -2.0697e+00,  3.0177e+00,  1.8860e+00,\n","         -9.2174e-01, -1.2079e+00, -1.7270e-01,  2.4837e-01, -1.8046e+00,\n","         -5.2227e-01, -1.2049e+00,  1.4030e-01, -5.1498e-01, -1.5561e+00],\n","        [-1.4686e+00, -9.3930e-01, -1.2443e+00,  3.9183e-02,  3.5043e+00,\n","         -1.6460e+00, -2.1585e+00,  1.6870e-01,  1.7725e+00, -2.4692e-01,\n","          2.7860e-01, -9.2715e-01,  9.2327e+00, -2.9592e+00, -2.0375e+00,\n","         -1.7798e+00, -2.8212e+00, -1.0404e+00,  3.7169e+00, -3.4829e-01,\n","         -1.5086e+00,  1.4093e+00,  1.9583e+00, -1.3876e+00, -1.8087e+00,\n","         -1.2262e+00, -1.8670e+00,  2.7818e+00,  3.5981e+00, -1.2603e+00,\n","         -1.0862e+00,  1.6102e+00, -7.1028e-01, -3.1199e+00,  1.5319e+00,\n","         -2.6760e-02, -5.5862e-01,  4.7766e+00,  1.2664e+00, -1.6199e-01,\n","          1.7841e+00,  2.4077e+00,  2.1306e+00, -1.0563e+00, -3.1200e+00,\n","          1.7069e+00, -1.9871e-01, -2.6500e+00, -1.3719e-01, -3.2246e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([32, 22, 12,  6, 16,  9, 30, 14, 24, 49,  9, 36,  9, 29,  2, 12],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8438,  8.2797, -0.8722,  ..., -1.7320, -2.1657,  2.5280],\n","        [-0.2986,  4.6902,  0.1106,  ..., -0.5310, -0.7645,  3.7743],\n","        [ 8.3976, -3.1995,  1.6219,  ...,  7.4528, -1.2821, -1.9947],\n","        ...,\n","        [ 2.0073,  0.4027, -0.7283,  ..., -2.1438,  1.6392, -0.4312],\n","        [-0.3345, 11.0115,  0.8866,  ..., -1.3010, -2.0345,  1.6573],\n","        [ 1.0596, -3.0416,  4.9794,  ..., -1.8393,  1.7820, -0.1140]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 395/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.2757, -1.8746, -1.5777,  ..., 15.8203, -1.7929, -0.9814],\n","        [-1.0213, -0.1802,  2.0516,  ..., -4.7472, -2.0176, -0.0516],\n","        [-1.6941, -0.9965,  0.1471,  ..., -2.3564, -0.0910, -0.6247],\n","        ...,\n","        [-1.1048, -3.5197, -2.6557,  ..., -0.3104, -1.0164, -1.9480],\n","        [-2.3888, -2.2680,  0.6334,  ...,  1.1135, -1.5539, -0.9472],\n","        [-1.9372, -0.3098, -0.3210,  ..., -2.2623, -2.1359,  2.3625]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([47, 31, 44, 40, 35, 13, 49, 12, 37, 28,  6, 15, 48, 15, 37, 12, 44, 10,\n","        33, 19,  6, 27, 29, 27, 31, 43, 47,  3, 34, 41,  8, 19, 11,  6, 39, 47,\n","        29, 14, 24,  4, 38,  5,  5, 33, 21, 25, 10, 17, 28, 45, 36, 25, 29,  4,\n","        31, 37,  7, 35,  4, 16, 37,  5,  3, 23, 22, 29, 30, 11, 12, 43, 34, 41,\n","        35, 26, 14, 22,  3, 44, 13, 25,  8,  4,  0, 45, 10, 41, 26, 22, 13,  6,\n","        17,  2, 18, 31, 32, 18, 16, 34, 13, 25, 20, 17,  1, 40, 24, 12, 36, 25,\n","         2, 42,  1, 11, 48,  0,  9, 48, 24, 35, 30, 41, 21, 45, 39, 14, 26, 32,\n","         9,  4], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.0737, -0.3290,  0.6376,  ...,  0.3413, 13.8306, -1.5016],\n","        [-2.5025,  2.5129, -0.7340,  ..., -2.5263, -2.2001, 14.5869],\n","        [-2.2058, -2.1023, -0.7395,  ..., -1.0438, -1.0769, -0.8547],\n","        ...,\n","        [-0.4402, -0.3353,  0.6459,  ..., -1.0168, -2.2800, 14.2590],\n","        [ 1.6097,  0.1601, -0.9310,  ..., -0.4016, -0.2780,  1.8313],\n","        [-0.9420,  0.3746,  0.4086,  ..., -1.7855, -0.4507, -1.8066]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([48, 49, 45,  9,  2, 10, 31, 15, 30, 10, 40, 19,  3, 45, 29, 25, 28, 36,\n","         5, 46, 30, 39, 34, 43, 27, 28, 40, 26,  2, 15, 47, 27, 29, 16, 16,  1,\n","        11, 41, 17, 43, 33, 29, 12, 41, 20, 27, 30, 28, 14,  8, 36, 37, 34, 42,\n","        19, 15,  9,  1, 47, 37, 35, 41,  9, 32, 22, 19, 11,  7, 21, 40, 21, 30,\n","         9, 24,  3, 31, 36, 42, 47, 19,  7, 14, 17,  0, 35, 38, 14, 33, 24, 23,\n","        22, 47, 31,  4,  9, 44, 14, 44, 37, 41, 10, 30, 32, 46, 33, 49,  9, 24,\n","        36, 26,  3, 35, 16, 21, 17,  7,  6, 12, 11, 20, 30, 48, 14,  2, 39, 49,\n","        36, 33], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.2117, -1.7000, -1.5919,  ..., -1.6299, -1.3876, -0.3652],\n","        [ 0.1989,  0.9946,  3.9638,  ...,  0.1411,  0.4426,  0.0637],\n","        [-3.7093, -0.4098, -0.8190,  ..., -2.0892, -3.0662,  1.9157],\n","        ...,\n","        [-0.9098,  0.7916, -0.8201,  ..., -1.2200, -0.4635, -0.9779],\n","        [ 3.0050,  0.1394,  2.0846,  ...,  5.9236, -0.9137, -1.4723],\n","        [-1.0051, -1.8499,  1.0791,  ..., -0.9056,  0.5953, -0.7418]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([45,  5, 31, 18, 28, 17, 13,  8, 35, 27,  8, 42, 19, 18, 23, 46, 18, 38,\n","        16, 40, 10,  4, 19, 22, 18, 21, 32, 44,  8,  8, 27, 26,  1, 47, 23, 49,\n","         8,  7, 13, 28,  7, 24, 48, 16,  0, 27,  2,  1,  2, 20, 32,  5, 36, 17,\n","        49,  0, 33, 49,  1, 10,  9, 42, 13,  0, 23, 25, 12, 12, 38, 30, 13, 20,\n","        14, 16, 29, 40, 12,  3, 25, 46, 45, 24,  2, 32, 42, 26, 20, 16, 22, 28,\n","        17,  1, 22, 38, 23, 43,  6, 32, 20, 49, 27, 39, 11, 15,  9,  2,  6,  0,\n","        31, 15, 24,  7, 36,  5, 42, 29, 46, 38, 40, 17,  4, 48, 43, 37, 18,  7,\n","         3, 30], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.6608e+00,  2.4205e+00, -9.1578e-01, -4.9334e-03, -1.3724e+00,\n","          1.6814e+00,  2.5615e-01, -5.1187e-01,  4.1224e+00, -2.7114e+00,\n","         -1.8121e+00, -8.6579e-01, -2.3345e+00,  2.2995e+00,  4.9244e-01,\n","          1.9053e+00, -2.3610e-01, -1.9617e+00,  1.0124e+00,  7.6571e-01,\n","         -2.0449e+00,  1.1826e-01, -8.5898e-01,  4.4510e-01,  7.3601e-01,\n","         -3.0990e+00, -8.4322e-01,  2.9899e-01, -2.4305e+00,  5.7612e-01,\n","         -1.1304e+00,  8.6975e-01,  1.3736e+00,  1.7800e+00,  1.1379e+01,\n","         -5.3121e-01,  3.1796e-02,  1.7682e+00, -1.3502e+00, -1.2569e+00,\n","          1.7090e-01, -2.2413e+00, -1.2611e+00,  2.7710e+00, -2.8016e-01,\n","         -9.0298e-01,  1.2644e+00, -1.6078e+00, -1.6240e+00,  4.3160e-01],\n","        [ 5.3706e+00, -2.8385e+00,  1.5514e+00,  1.5352e+00, -2.5684e+00,\n","          5.4121e-01, -9.0983e-01, -1.7497e+00, -4.7996e-01, -3.3166e-01,\n","         -1.6761e+00,  9.0452e-01, -2.6326e+00, -1.1880e-03,  8.3658e-01,\n","         -2.5606e+00,  1.1329e+01, -2.0186e-01, -3.7042e+00, -1.6628e-01,\n","         -5.1109e-01, -1.0948e+00,  1.1549e-01, -1.9958e-01,  2.7616e+00,\n","          2.7426e+00,  1.1081e+00, -8.1912e-01, -1.0160e+00, -1.6759e-01,\n","          1.5417e+00, -7.6861e-01,  5.6674e-01,  5.0662e-01, -2.3454e+00,\n","          3.0246e+00, -1.5635e+00, -2.4997e+00,  2.5752e+00,  2.4654e+00,\n","         -1.7099e+00, -1.0374e+00, -2.1448e+00, -3.1023e-02,  6.9485e-01,\n","         -2.7529e+00, -2.8101e+00,  1.4506e+00,  9.6213e-01, -4.5440e-01],\n","        [-4.0760e+00, -1.1648e+00, -1.0555e+00, -2.0912e+00,  1.1500e+00,\n","          3.0758e-01, -2.9714e+00,  4.3266e-01, -1.0471e+00,  4.8438e-01,\n","         -2.3566e+00, -6.6444e-01,  4.5680e-01,  2.5491e+00,  1.5986e+00,\n","          1.5879e+01, -1.0872e+00, -1.8291e+00, -1.5043e+00, -2.1527e+00,\n","          3.3760e-01,  6.0538e-01, -6.7339e-01,  5.4882e-01, -9.5623e-01,\n","         -4.6555e-01, -3.9245e-01, -5.7856e-01,  4.9919e-01,  4.9451e+00,\n","         -1.3896e+00,  4.0129e+00,  1.5324e+00, -1.4292e+00,  1.0147e+00,\n","         -3.4482e+00, -1.7351e+00,  2.2059e+00, -1.7058e+00, -2.2676e+00,\n","          3.3246e+00, -5.2083e-01, -9.7783e-01, -6.6965e-01, -9.1634e-01,\n","         -1.3399e+00, -1.2433e-01, -3.0779e+00, -1.8494e+00,  3.6141e+00],\n","        [ 4.8095e-01,  1.5970e+00,  1.4925e+00,  1.2785e+01,  7.9153e-01,\n","         -6.2822e-01,  1.2114e+00, -1.6639e+00, -1.4367e+00,  5.3059e-01,\n","         -2.6441e+00, -5.2942e-02, -1.4608e+00, -6.7663e-01, -1.7031e+00,\n","         -2.8266e+00,  1.3231e+00, -1.5022e+00,  1.0190e+00,  4.2713e+00,\n","         -9.7818e-01, -2.3285e+00, -1.5677e-01, -1.5114e+00,  1.2507e+00,\n","          4.8403e-01,  1.9961e+00, -1.0394e+00, -9.8768e-01,  1.2024e+00,\n","          2.2938e+00, -6.5155e-01, -4.8109e-01, -2.4210e+00, -2.1261e+00,\n","          3.2674e-01, -1.5115e+00, -8.5409e-01,  1.9753e+00,  2.3674e+00,\n","         -1.5856e+00, -3.1861e+00, -3.1126e-01, -6.2901e-01, -1.5485e+00,\n","         -1.6388e+00, -1.1178e+00,  3.1899e+00,  8.5908e-02, -9.5762e-01],\n","        [-1.6674e+00,  2.6667e-02,  9.0703e-01, -1.0356e+00, -9.3339e-01,\n","         -9.0214e-01,  7.5002e-01, -4.0469e+00,  1.3236e+00,  2.2301e+00,\n","         -2.9880e+00, -7.7462e-01, -4.6474e-01,  1.2131e+00, -2.2367e+00,\n","         -1.4508e+00, -3.2164e+00,  4.5880e-01,  3.0638e+00, -1.8732e+00,\n","          1.3241e+01,  9.2300e-01, -1.5830e+00,  2.2410e+00,  2.9661e+00,\n","          1.8974e+00, -1.5870e+00, -2.7152e+00, -2.6120e+00, -7.8978e-01,\n","          3.3849e+00,  3.4718e-01, -4.2411e-01, -4.2674e+00, -9.9375e-01,\n","         -3.2660e+00,  3.4920e+00, -1.5884e+00,  1.1118e+00, -2.8994e+00,\n","          9.6619e-01, -4.0271e-02,  1.3658e+00,  2.6363e+00,  1.4227e+00,\n","         -2.8415e+00, -1.0442e+00,  1.9618e-01,  3.1911e-01,  2.6965e+00],\n","        [-6.9109e-01, -2.0336e+00,  1.0434e+00, -1.9996e+00,  8.1958e-02,\n","          2.4681e+00,  1.3980e+00, -1.4637e+00, -1.4569e+00,  1.1036e+00,\n","         -1.9786e-01,  4.2468e-01, -1.6239e+00,  1.6734e+00, -3.6962e-01,\n","         -1.2590e+00, -2.8696e+00, -3.4890e-01, -8.3656e-01, -1.2279e+00,\n","          1.0823e+01, -1.2470e+00, -2.5407e+00,  1.2676e+00,  6.4458e-01,\n","         -6.0369e-01, -1.3869e+00, -2.8116e+00, -1.9839e+00,  1.2062e+00,\n","         -8.8014e-01,  4.0349e+00,  1.3340e+00, -1.0148e+00, -6.8776e-01,\n","          5.5427e-01,  3.0030e+00, -1.7605e+00, -1.6811e+00, -6.8004e-02,\n","         -1.3566e+00,  1.2320e+00, -8.4708e-01,  2.9540e+00,  2.6181e+00,\n","         -1.4409e+00, -2.2254e+00,  1.1097e-02,  1.2445e-01,  1.4176e-01],\n","        [-8.5994e-03, -2.8006e+00,  3.2992e+00, -3.1963e+00, -7.1913e-01,\n","          3.6617e-02,  7.1024e-01, -1.8650e-01, -3.3061e+00, -1.2272e+00,\n","          1.6172e+00,  1.3020e+01,  6.1941e-01, -3.1061e+00, -1.3680e+00,\n","         -3.0139e+00,  6.2354e-01,  5.7062e-01,  7.6368e-01,  1.1352e+00,\n","         -2.7360e+00,  2.5702e+00,  1.6783e+00, -4.1093e+00, -8.4016e-01,\n","          1.4699e+00, -1.1059e+00,  2.5140e+00,  1.7910e+00, -1.0638e+00,\n","          4.1019e+00, -1.7803e+00,  5.3968e-01, -1.2885e+00, -1.6856e+00,\n","         -1.4339e+00, -2.2244e+00, -1.5471e+00,  4.7048e+00,  1.5321e+00,\n","          2.7102e+00,  4.6233e-01,  4.2518e-01, -1.3760e+00, -2.0219e+00,\n","         -5.4680e-01, -6.4439e-01,  1.9732e-01, -3.0707e-01, -3.1389e+00],\n","        [ 1.7528e+00,  3.9741e-01,  3.9141e-01,  1.2081e+00, -1.6330e+00,\n","          3.6751e+00,  3.3897e+00, -5.0904e-01,  1.4460e-01, -5.2791e-01,\n","         -4.4887e-01, -3.1201e-01, -2.0330e+00, -7.6473e-01, -9.0489e-01,\n","         -1.7951e+00, -1.1110e-01,  1.7150e+00,  2.7176e-01,  5.7669e-02,\n","         -2.2465e+00, -1.5047e+00, -2.3070e+00, -1.5588e+00, -1.8711e+00,\n","          7.4985e-02,  1.1907e+01, -1.0270e+00, -1.9533e+00,  1.9508e+00,\n","          2.7673e-01, -6.9825e-01, -2.1472e-01,  4.2930e+00, -2.2859e+00,\n","          9.6215e-01, -1.6796e+00, -1.9570e+00, -1.1232e-01, -1.8168e+00,\n","         -2.5562e+00, -1.9679e+00, -2.7076e-01,  7.5149e-01,  1.7158e+00,\n","         -1.3739e+00, -6.3056e-01, -8.5154e-02,  2.7502e+00, -7.3667e-01],\n","        [-2.0643e+00,  2.8933e-01,  6.7629e-01,  3.7228e-01,  4.6258e+00,\n","         -2.3642e+00, -2.7208e+00, -3.9520e+00,  2.1979e+00,  1.3065e+00,\n","         -2.0209e+00, -3.0122e+00,  8.8913e-01,  5.2033e-01, -4.5082e-01,\n","         -1.0050e+00,  2.8953e-01, -1.8888e+00, -4.3667e-01, -2.8531e-01,\n","          1.8184e+00,  4.0121e-01,  1.7744e+00,  1.0242e+01,  4.4102e-01,\n","         -1.1456e+00, -2.7878e+00, -2.7322e+00, -1.7737e-02,  2.1483e+00,\n","          1.3335e+00,  2.7890e+00, -1.7390e+00, -3.3793e+00, -6.0972e-01,\n","         -1.7464e+00,  2.5166e+00,  5.0630e+00,  1.5647e+00, -3.8207e-01,\n","          1.0211e+00, -2.4620e+00, -4.3383e-02,  9.0747e-02,  7.7527e-01,\n","         -7.4537e-01, -2.0784e+00, -2.5477e+00, -4.5553e-01,  3.2861e+00],\n","        [ 8.5957e-01,  1.0645e+00, -5.4892e-01,  9.8398e-01, -9.3703e-01,\n","         -1.0150e+00, -1.6396e+00, -1.0403e+00,  7.4282e-01,  1.5072e+00,\n","          1.3977e+00, -1.3005e+00, -1.2424e-01, -8.8998e-01, -1.5434e+00,\n","         -8.9349e-01,  1.1486e+00,  3.3845e+00,  1.7429e+00,  3.7779e+00,\n","         -2.3585e+00, -5.3241e-01, -2.8401e+00, -3.7990e+00,  9.3592e-02,\n","         -1.0655e+00, -7.6642e-01, -4.3882e-01,  8.6218e-01, -7.4522e-01,\n","          1.9034e+00, -7.9091e-01, -7.4891e-02, -2.2431e-01,  6.8069e-01,\n","         -1.5928e+00, -2.2732e+00,  3.3591e+00,  8.5922e-02, -2.6331e+00,\n","          1.0064e+00, -6.4138e-01,  2.9152e+00, -9.5110e-01,  4.0152e-01,\n","         -2.0949e+00,  1.1031e+01, -2.8391e+00, -1.9220e-01, -7.7348e-01],\n","        [-1.4774e-01, -3.9242e+00, -1.4548e+00, -3.1093e+00,  3.3777e+00,\n","         -2.2666e+00,  3.2343e+00,  6.7067e-02, -1.0206e+00,  1.7195e+00,\n","         -2.2898e+00,  2.3795e-01, -7.4346e-01, -5.3532e-01, -2.0300e+00,\n","         -4.0971e+00, -1.5488e+00, -4.2385e-01,  1.5144e+00, -3.9256e-01,\n","          1.8841e+00,  1.0250e+00,  3.8823e-01, -1.4807e+00,  1.6194e+00,\n","          1.9026e+00, -1.4235e+00, -5.1430e-01,  2.4179e-01,  3.1403e-01,\n","          4.6200e-02,  2.0502e+00,  3.6066e+00, -2.6115e+00, -6.8352e-01,\n","          2.2572e+00,  1.2219e+00, -1.1866e+00,  3.0527e-01,  3.3505e+00,\n","         -2.8012e-01,  1.2444e+01,  1.3700e-01, -2.2385e+00,  9.8020e-01,\n","          3.2925e-01, -2.1807e+00,  1.2865e+00, -1.8148e+00, -8.7468e-01],\n","        [-7.2314e-01,  1.5249e+00,  9.6041e-01,  1.2438e+00, -1.7998e+00,\n","         -1.3028e+00, -1.2902e+00, -3.1499e-01, -7.3703e-01,  1.7324e+00,\n","          2.9925e+00, -5.4514e-01, -3.7127e-01, -8.3325e-01, -1.9515e+00,\n","         -1.1932e+00,  9.4218e-01,  1.8883e+00,  1.3196e+00,  1.0334e+00,\n","         -2.2515e+00,  1.0411e+00, -2.7459e+00, -4.0274e+00,  7.2970e-01,\n","         -1.6720e+00,  4.7570e-01,  1.8997e-01,  2.9775e-01,  5.1235e-02,\n","          4.9140e+00, -1.6162e+00,  1.7006e-01, -7.0581e-01,  1.6634e+00,\n","         -1.7174e+00, -1.3273e+00,  3.2782e-01,  6.0605e-01, -2.9524e+00,\n","         -7.9261e-01, -9.9091e-01,  2.0494e+00,  1.6286e-01,  1.0266e-01,\n","         -1.8349e+00,  1.1929e+01, -6.8006e-01, -6.2257e-02,  3.9300e-01],\n","        [-1.6098e+00, -4.2079e+00,  8.4308e-01, -1.9752e+00,  5.8925e-01,\n","          1.5281e+00, -3.3521e-01, -1.3384e+00, -1.9129e+00,  1.9691e+00,\n","         -1.4380e+00,  9.5999e-01,  2.4077e+00, -2.0814e+00, -8.9285e-02,\n","          4.8911e-01,  1.9087e-01, -2.7888e-01,  2.5753e-01, -5.0901e-01,\n","         -1.6994e+00,  1.1384e+00, -2.0194e-01, -1.2675e+00, -5.7002e-01,\n","          8.3081e-01, -3.0533e-01,  1.2794e+01,  4.6121e-01,  9.9120e-01,\n","         -1.2511e+00,  1.3306e+00,  1.1405e+00, -1.2396e+00, -9.9546e-01,\n","          2.7407e+00, -9.2077e-01, -4.5551e-01,  1.4615e+00, -1.0416e+00,\n","         -1.0012e-01,  1.9974e+00, -1.2515e+00, -1.8408e+00,  6.2131e-01,\n","         -1.8891e+00, -2.6137e+00,  9.4575e-02, -6.4253e-01, -4.6811e-01],\n","        [-1.7345e+00, -3.1641e+00,  1.6623e+00, -2.5385e+00,  1.3897e+00,\n","          2.0579e+00, -4.2795e-01,  1.5201e-01, -1.9956e+00,  6.0334e-01,\n","          9.0705e+00,  1.0123e+00,  4.4275e+00, -2.5315e+00,  1.1644e+00,\n","         -8.1936e-01, -3.1942e+00,  9.5078e-01, -2.2940e+00, -2.5180e+00,\n","         -4.2329e-01,  7.6875e-01, -1.6909e-01, -2.3890e+00, -1.7412e+00,\n","         -1.2176e+00,  1.5545e-01,  5.6604e-01,  1.4719e+00,  6.3318e-01,\n","         -4.1288e-01,  2.0322e+00,  1.4110e+00, -2.6559e+00, -1.9282e+00,\n","          2.3038e+00, -1.3701e+00,  1.1400e+00,  1.5055e-01, -1.6180e+00,\n","          1.3251e+00,  1.0123e+00,  1.5045e+00, -1.0748e+00,  1.8734e+00,\n","         -1.0217e-01, -7.3725e-01, -5.3510e-01,  3.9171e-01, -5.7823e-01],\n","        [ 1.3026e+01, -5.5794e-01,  8.3945e-01,  3.5757e+00, -2.7097e+00,\n","         -2.1982e+00,  2.5268e+00, -4.2960e+00,  2.1688e+00, -1.9252e+00,\n","         -5.1577e+00, -5.6059e-01, -2.5282e+00,  1.7205e-01,  8.1898e-01,\n","         -2.5226e+00,  3.5708e+00,  2.8354e-01, -1.7380e+00,  4.7837e+00,\n","         -3.6940e+00, -1.0049e+00,  2.4065e+00,  5.3084e-01,  6.9429e+00,\n","          4.0706e+00,  1.4128e+00, -1.6908e+00, -4.0415e+00, -2.6578e+00,\n","          1.8336e+00, -2.0911e+00, -1.6937e-01, -2.6506e+00, -2.6774e+00,\n","          9.6562e-01, -1.8458e+00, -4.5320e+00,  4.3994e+00,  1.0371e+00,\n","         -1.2929e+00, -2.1298e+00, -2.4716e+00,  2.3735e+00, -2.6436e+00,\n","         -2.4092e+00, -1.1581e+00,  3.9792e+00,  1.0383e+00, -1.3040e+00],\n","        [ 3.0968e-01,  9.2168e+00,  2.9867e+00,  1.7773e+00,  2.4432e-01,\n","          1.5863e+00, -6.2590e-01, -1.2391e+00, -3.5780e-01, -7.6100e-01,\n","         -6.3663e-01, -9.3774e-01, -1.1594e+00, -3.0191e+00, -2.8082e+00,\n","         -2.2151e+00, -3.3823e+00, -5.5749e-01, -2.8929e-01, -2.2433e+00,\n","          1.3816e-01, -1.2735e+00,  6.8988e-01, -1.3812e+00,  2.2985e-01,\n","         -1.9575e+00, -3.3396e-01, -1.3171e+00, -5.6027e-01,  9.9878e-01,\n","          1.0009e+00,  9.9947e-01, -1.7359e+00, -2.4227e+00,  2.7360e+00,\n","         -2.2344e+00,  3.3325e+00,  2.5568e+00,  1.4572e+00, -1.8329e+00,\n","          3.3281e+00, -7.4817e-01,  1.4163e+00,  2.8178e+00, -1.0312e+00,\n","         -6.7978e-01,  7.9968e-01, -1.2585e+00,  2.4178e+00,  6.4491e-02]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 16, 15,  3, 20, 20, 11, 26, 23, 46, 41, 46, 27, 10,  0,  1],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8512,  8.2643, -0.8734,  ..., -1.7323, -2.1672,  2.5191],\n","        [-0.3086,  4.6799,  0.1150,  ..., -0.5304, -0.7621,  3.7674],\n","        [ 8.3677, -3.2009,  1.6260,  ...,  7.4472, -1.2780, -1.9961],\n","        ...,\n","        [ 2.0106,  0.3995, -0.7291,  ..., -2.1429,  1.6435, -0.4325],\n","        [-0.3417, 11.0082,  0.8913,  ..., -1.3029, -2.0410,  1.6579],\n","        [ 1.0430, -3.0477,  4.9712,  ..., -1.8364,  1.7805, -0.1136]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 396/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.6847, -2.1123, -1.1976,  ..., -1.5252, -0.9681, -0.3732],\n","        [-1.1692, -0.2675,  2.6786,  ...,  2.3210, -0.7919, -1.4716],\n","        [12.2192,  1.4856, -1.5529,  ...,  1.1067,  0.2697, -0.7819],\n","        ...,\n","        [-2.3503, -2.3642, -1.5302,  ..., -1.1959,  1.7906, -0.5740],\n","        [ 3.3106,  1.8971, -0.8092,  ..., -2.1142,  1.9977,  4.3263],\n","        [-2.9498, -2.5140, -0.6205,  ..., -3.1235, -1.7096, -0.6806]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([45, 11,  0,  4, 20, 26, 18, 28, 13, 34,  9, 40,  8, 17, 21, 28, 11, 17,\n","        17, 49, 36, 14, 15, 27, 33, 32, 31,  2, 36, 22, 29, 37,  9, 45, 23, 30,\n","        34, 20, 35,  3, 25, 41, 26, 45, 43, 41, 24, 27, 34, 43, 24, 18, 33, 25,\n","         3, 20, 25, 31, 49, 43, 28,  7, 10, 12, 33, 28, 13,  7, 46, 19, 13,  2,\n","        49, 17,  7, 39, 17, 48, 24, 23, 34, 45, 30,  2,  1,  8, 36, 24, 47, 32,\n","        23, 19,  6, 26, 22, 44,  0, 28, 25, 10,  1, 37,  6, 21, 29, 40, 30, 49,\n","        44, 31, 33, 44, 12, 20,  4, 40, 32, 24, 31, 22, 15, 19, 25, 40, 12, 41,\n","         8, 12], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 2.2543,  0.1627,  2.2997,  ...,  0.2382, -0.5652, -2.5517],\n","        [ 0.5723, -0.3639,  2.8137,  ...,  1.6071,  0.8821, -0.4213],\n","        [ 1.0387,  0.7256,  0.5295,  ..., -3.2093, -0.2742,  0.6541],\n","        ...,\n","        [-3.3898, -1.2870, -1.8558,  ..., -1.0810, -2.3253,  6.3343],\n","        [ 4.5228,  1.6652, -0.4924,  ..., -1.3162,  2.6373, -1.0019],\n","        [14.8424,  2.0594, -0.6167,  ...,  1.0503,  1.1030, -1.4344]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([38, 30, 46,  6,  2, 30, 38,  9, 45, 24,  5, 37,  1, 36, 12, 28, 48, 45,\n","        24,  8, 13, 47, 11,  8, 15, 13, 33, 11, 44, 27, 35, 47, 41, 31, 43, 39,\n","        36, 23, 29, 28, 48, 13, 40, 30, 21, 16, 44, 11, 10,  3,  8, 48, 48, 19,\n","         4,  9,  9,  3, 35,  2, 14, 11, 18, 16, 28, 47, 44, 30,  9,  9,  6, 26,\n","        11, 38, 32, 36, 46, 10, 35, 41, 13,  0,  6,  7, 18, 21, 35,  8, 37,  9,\n","         1,  7, 42,  7, 22, 19, 26, 14, 29,  5, 29,  7, 39, 31, 20, 27, 26,  0,\n","        16, 40,  1, 27, 16, 16, 15, 22, 39, 49,  6,  7, 45,  2, 18, 16, 40, 29,\n","        42,  0], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.6181, -1.1014, -2.7255,  ...,  1.0210, -2.0058,  2.0903],\n","        [-3.0171,  0.2303, -1.3581,  ..., -2.6143, -1.6988,  3.3084],\n","        [-2.2511,  0.2588, -1.9694,  ..., -1.7637, -2.3107,  4.8803],\n","        ...,\n","        [14.1901,  0.5163,  3.2507,  ..., -0.9426,  5.4192, -1.8045],\n","        [-1.8157, -2.5533,  0.2197,  ...,  0.5394,  0.1695, -2.0633],\n","        [ 6.6516, -2.4554,  3.6810,  ...,  2.1331, -1.0824,  2.3735]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([29, 15, 15,  3, 22, 22, 29, 20, 46,  5, 30, 47, 31,  1, 27, 15, 49, 14,\n","        32, 10, 21, 11,  1, 41, 23, 12, 47,  2,  2, 17, 19, 36, 39,  3,  5, 20,\n","        13, 20, 42, 10, 14, 19, 41, 33,  4, 16, 10, 36, 26,  8, 35, 18, 16, 47,\n","        31, 25, 17,  5, 20, 40, 30,  5, 14, 14,  0, 25,  3,  5, 29, 38, 48, 12,\n","        17, 34, 27, 33, 24, 42, 25,  3, 41,  6, 38, 10, 17, 32, 37, 48, 49, 34,\n","        12,  0,  9, 31, 32,  4,  2, 17,  3, 27,  9, 27,  4, 18, 37, 19, 15, 46,\n","         1, 21, 23, 46, 42, 32, 37, 38, 47, 14, 12, 41, 43,  1, 35, 37,  4,  0,\n","        22, 16], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 9.1763e-01,  1.2141e+00,  1.6953e+00,  1.0706e+00, -1.9502e+00,\n","          3.4199e+00,  4.0565e+00, -5.5097e-01, -1.6420e+00,  3.9518e-01,\n","         -2.6400e+00,  1.1753e-01, -1.3678e+00, -1.3610e+00, -5.9064e-01,\n","         -1.4234e+00, -5.8205e-01, -6.5752e-01,  2.0783e+00,  6.3579e-01,\n","         -1.4017e+00,  1.2557e+00, -2.8864e+00, -3.0902e+00, -1.4724e+00,\n","         -7.7823e-01,  1.3087e+01, -3.4810e-01, -1.7333e+00,  1.8250e+00,\n","         -1.3046e+00,  1.3204e+00,  4.4148e-01,  2.6572e+00, -2.3525e+00,\n","          8.2645e-01, -3.2290e+00, -1.6775e+00,  6.6317e-01, -5.6568e-01,\n","         -8.8616e-01, -2.4466e-01, -1.7590e+00, -5.9033e-01,  1.8103e+00,\n","         -2.0374e+00, -2.3565e+00,  5.5471e-01,  8.2271e-01, -4.9373e-01],\n","        [-1.6498e+00, -1.8629e+00, -7.4307e-01, -2.0273e+00, -1.0798e+00,\n","         -7.4666e-01, -1.2670e+00, -1.2195e-01, -7.6281e-01, -7.2105e-01,\n","         -1.1646e+00, -1.1509e+00,  1.7274e+00,  8.7074e-01,  1.3502e+01,\n","          1.7257e+00, -1.1349e+00, -2.2901e-01, -1.2664e+00, -2.0501e-01,\n","         -1.9399e-01,  6.0006e-01,  3.9251e+00, -2.0370e+00,  5.0866e-02,\n","          7.8677e-01,  8.4970e-01,  1.1392e-01,  1.0251e-01, -3.3785e-01,\n","         -2.2676e+00,  1.1409e+00,  2.7715e+00, -1.2751e+00, -1.6391e+00,\n","         -1.8413e-01, -2.0551e+00, -8.4775e-01,  7.0918e-01,  8.8608e-02,\n","          2.0058e+00, -1.5240e+00, -1.2600e+00, -1.1975e-01,  3.5956e+00,\n","         -1.8437e+00, -1.0750e+00, -2.5840e-01, -1.1766e+00, -1.2347e+00],\n","        [ 3.2123e+00,  1.8794e+00,  9.9114e-01,  1.7709e+00, -1.5902e-01,\n","         -8.7370e-01,  1.7961e+00, -3.0648e+00, -1.7615e+00,  1.9259e+00,\n","         -3.0154e+00, -1.8138e+00, -1.2641e-01, -1.0949e+00, -1.0811e+00,\n","         -1.0485e+00,  4.7660e-01, -2.3790e+00,  1.7721e+00,  2.5375e+00,\n","          3.6986e-01, -7.9609e-01,  4.3581e-01, -1.5612e+00,  1.4810e+01,\n","          1.4421e+00,  5.7999e-01, -3.4425e+00, -1.6649e+00,  1.9226e+00,\n","          1.7276e-01,  2.2220e+00, -3.9633e-01, -1.8235e+00, -8.3847e-01,\n","         -1.0111e+00, -1.8203e+00, -4.4776e-01, -7.4398e-02, -8.9702e-01,\n","          2.2101e-01, -9.0552e-01, -2.1045e+00, -1.3974e+00,  1.7396e-02,\n","         -2.9900e-01, -1.1444e+00,  3.3305e+00, -1.7643e+00,  2.4439e-01],\n","        [-1.9827e+00, -1.5070e-01,  1.1306e-01, -1.8301e+00,  1.8324e+00,\n","         -3.3806e+00,  1.7771e+00, -3.1212e+00,  4.5731e+00, -9.8246e-01,\n","         -3.7145e+00, -7.5784e-01, -1.4364e+00,  7.9099e+00, -6.2523e-01,\n","          1.6838e+00, -2.7239e+00, -2.2722e+00,  1.5877e+00,  2.5155e+00,\n","          4.4709e+00, -9.1693e-02, -3.6522e-01,  1.4810e+01,  3.4600e-01,\n","          8.8074e-01, -2.5681e+00, -3.9531e+00, -1.7707e-01,  1.1100e+00,\n","         -1.1110e+00,  1.8062e+00, -1.6140e+00, -1.4641e+00,  2.6803e-01,\n","         -2.3040e+00, -7.5777e-01,  3.7675e+00,  4.8882e-02, -4.9675e-01,\n","         -9.9989e-01, -2.1979e+00, -1.8017e+00,  1.9772e+00, -1.4701e+00,\n","         -1.2472e+00, -3.4924e+00, -1.4998e+00, -2.2333e+00,  1.1483e+00],\n","        [ 1.2401e+00,  1.0049e+00,  1.1419e-01,  4.6759e-01, -6.6979e-01,\n","         -1.3899e+00, -2.5596e+00, -9.8128e-01,  1.9706e+00,  1.0650e+00,\n","          1.4939e+00, -1.2501e+00, -7.1938e-01, -4.9562e-01, -2.4705e+00,\n","         -2.8811e+00, -2.3142e+00,  8.6047e-01,  2.5167e+00, -1.0506e+00,\n","          3.0570e+00,  7.9833e-01, -8.4256e-01, -3.4804e-02,  3.6653e-01,\n","         -1.9655e+00, -3.1283e-01, -1.0601e+00, -1.2106e+00, -1.5626e+00,\n","         -2.2311e-01,  5.6693e-01, -2.6276e-01, -3.2920e+00,  5.4284e-02,\n","         -3.8033e+00,  4.8292e-01,  1.6478e+00,  6.0692e-01, -5.7543e-01,\n","          1.6038e+00, -4.2548e-01,  9.8274e+00, -2.4431e-01,  2.0103e-01,\n","         -1.7643e+00,  1.9837e+00, -7.3799e-01,  4.7300e+00, -8.2408e-01],\n","        [ 2.6967e+00,  2.8950e+00, -6.7150e-02,  1.1837e+00, -1.0414e+00,\n","         -9.7040e-01, -1.5890e+00, -1.3940e-01, -1.5798e-02, -1.3272e-01,\n","          2.8524e+00, -1.7085e+00,  1.1455e+00, -1.2881e+00, -2.8625e+00,\n","         -2.2043e+00, -3.0085e+00,  5.5261e+00,  1.4526e+00, -1.4786e+00,\n","          1.8142e+00,  7.4024e-01, -4.7952e-01, -7.3600e-01,  1.6821e-01,\n","         -2.2881e+00, -1.4584e+00, -1.3965e+00, -1.3505e+00, -1.8788e+00,\n","          1.8575e-01, -1.8027e+00, -6.7526e-01, -2.6255e+00, -4.2775e-01,\n","         -3.5715e+00, -2.6639e-02,  1.4097e+00,  1.0866e-01, -1.2824e+00,\n","          5.9158e-02, -1.7228e+00,  1.0392e+01,  1.8950e+00,  3.6483e-01,\n","         -2.1127e+00,  2.1092e+00, -1.0507e-01,  4.6587e+00, -1.6815e+00],\n","        [-2.0784e+00, -4.2943e+00, -4.4192e-01, -3.2807e+00,  1.6037e+00,\n","          1.9779e+00, -5.9430e-01, -9.5313e-02, -2.8342e+00,  2.9618e+00,\n","         -3.3399e-01,  3.2197e+00,  2.7091e+00, -3.7633e+00, -1.1140e+00,\n","          1.5880e+00, -7.6070e-01, -3.9392e-01,  9.7577e-01, -6.7911e-01,\n","         -2.3032e+00,  1.5987e+00, -1.1921e+00, -2.4116e+00, -1.0763e+00,\n","          6.0990e-01, -6.3161e-01,  1.2574e+01,  2.0006e+00,  2.0118e+00,\n","         -1.4369e+00,  2.6902e+00,  2.0357e+00, -1.8123e+00, -6.3909e-01,\n","          1.6817e+00, -1.4933e+00,  5.5709e-01,  1.3958e+00, -1.2626e+00,\n","          6.0924e-01,  3.8351e+00, -1.6959e+00, -2.5939e+00,  5.2718e-01,\n","         -8.3721e-01, -1.8009e+00,  4.1044e-01, -1.0924e+00, -6.9788e-01],\n","        [ 3.8501e+00,  1.0365e+00,  6.4331e-01,  5.8482e+00, -2.8065e+00,\n","          1.4000e+00,  5.5568e-01, -3.5640e+00, -5.5391e-01,  5.1841e-01,\n","         -4.2588e+00, -2.7987e-01, -4.1525e+00,  6.4594e-02, -2.7653e+00,\n","         -2.0304e-01,  1.2911e+01, -1.4559e+00, -1.0025e+00,  4.3881e+00,\n","         -3.1166e+00, -1.9867e+00, -1.0834e+00, -2.4856e+00,  4.0828e+00,\n","          1.3000e+00,  2.2695e+00,  8.8738e-01, -2.7122e+00,  1.6047e+00,\n","          2.8379e+00, -7.5230e-03,  2.0322e+00,  3.1804e-01,  4.5169e-01,\n","          2.1964e+00, -2.1712e+00, -2.4713e+00,  2.5885e+00,  1.2204e+00,\n","         -4.0518e+00, -7.8949e-01, -3.7605e+00, -1.0355e+00, -1.7939e+00,\n","         -3.6832e+00, -1.0300e+00,  2.8154e+00, -7.8480e-01, -2.3332e+00],\n","        [-2.6544e+00, -1.1528e+00,  2.4385e-01, -2.7754e+00,  2.6977e+00,\n","          3.1054e-01, -4.7570e-01, -2.7026e+00,  4.3898e-01,  9.0734e-01,\n","         -2.8557e+00,  8.5994e-01, -7.8516e-01,  1.4370e+00, -1.5970e+00,\n","          4.5828e+00, -2.7088e-01, -1.7533e+00, -6.2521e-01, -3.7013e+00,\n","          3.5050e+00,  3.8548e-02, -1.9021e+00,  3.3280e+00, -2.1680e-01,\n","         -1.4047e+00, -1.1857e+00, -1.0587e+00, -7.2842e-01,  3.7972e+00,\n","         -3.4637e-01,  1.5006e+00,  1.8982e+00, -2.6595e+00,  9.2904e-01,\n","         -1.2796e+00,  7.0381e-01,  7.7436e-01,  1.8762e+00, -2.0171e+00,\n","          2.2045e+00,  2.8093e+00, -1.6224e+00, -9.0869e-01, -7.3385e-01,\n","          9.8943e-03, -1.6549e+00, -9.2841e-01, -2.2766e+00,  1.1294e+01],\n","        [-4.4151e-01, -9.7584e-01,  2.2253e+00, -1.2843e+00,  1.4143e+00,\n","          9.2751e-01, -3.1382e-02, -5.5340e-01, -5.3398e-01,  1.4228e+00,\n","          1.1144e+01,  6.7079e-01,  8.0744e-01, -3.0203e+00, -2.3105e+00,\n","         -3.0377e+00, -1.1985e+00,  3.9029e+00, -1.3194e+00, -2.1957e+00,\n","         -9.6061e-01, -8.2262e-01, -4.1520e-02, -1.6876e+00, -1.0349e+00,\n","         -1.2822e+00,  5.3604e-02, -4.6001e-01, -6.7279e-01, -1.8324e+00,\n","          1.3091e+00, -2.6714e-01,  1.0443e+00, -1.0855e+00, -1.5700e+00,\n","         -6.6348e-01, -6.7640e-01,  1.0809e-01, -1.0649e+00, -1.2831e+00,\n","          2.7198e-01,  1.4016e+00,  2.3141e+00,  2.2214e-01,  1.5338e+00,\n","          4.4427e-01,  1.1087e+00, -8.9098e-01,  3.9391e+00, -2.7718e+00],\n","        [-3.6401e+00, -3.4925e-01, -2.2467e-01, -6.3148e-01,  1.0726e+01,\n","         -1.8719e+00, -1.3654e+00, -2.8574e-01, -3.4642e-01, -5.7938e-02,\n","         -1.0496e+00,  2.9668e-01,  1.0175e+00, -2.1295e-01, -2.7017e+00,\n","          1.0316e+00, -2.7332e+00, -2.9007e+00,  4.7896e+00, -7.1008e-01,\n","          3.7723e-01,  2.3983e+00, -2.9910e-01, -4.2361e-01, -7.1549e-01,\n","         -1.8842e+00, -1.2504e+00, -1.4386e+00,  7.1702e-01,  3.2058e+00,\n","          5.6774e-01,  2.3514e+00,  1.5117e+00, -1.8354e+00,  2.5529e+00,\n","         -2.9270e+00, -6.9895e-01,  4.2023e+00, -6.3930e-01, -3.5332e-01,\n","          1.5017e+00,  3.2545e+00, -9.1636e-01, -1.9754e+00, -2.3195e+00,\n","          4.6969e+00, -1.3974e+00, -3.0352e+00, -3.5904e+00,  1.7142e+00],\n","        [ 3.6931e-02,  1.9604e+00,  1.0588e+00, -1.7618e+00,  7.6467e-01,\n","          4.9185e-01, -1.3544e+00,  1.2539e+00, -1.0099e+00,  1.0486e-01,\n","         -1.2382e+00, -1.9082e-01,  1.9964e-01, -1.6944e+00, -2.2402e+00,\n","         -1.7951e+00, -1.7344e+00, -2.0016e+00, -1.4111e+00, -2.5474e+00,\n","          3.7652e+00, -7.4527e-01, -1.8487e+00,  5.8046e-01,  3.5946e-01,\n","         -1.9560e+00, -3.0354e+00, -1.1399e+00,  1.4590e-01,  1.9066e+00,\n","          9.2210e-01,  2.6153e+00,  1.0905e+00, -3.3432e+00,  3.1656e+00,\n","         -1.7951e+00,  1.2422e+01,  1.8358e+00,  2.1824e+00, -5.6929e-01,\n","          1.3763e+00,  4.5828e-01,  3.9795e-02,  1.2202e+00,  5.5946e-01,\n","         -2.9778e+00, -5.3792e-01, -4.6811e-01, -1.1987e+00,  1.8618e+00],\n","        [-1.6062e+00, -7.1139e-01,  6.4343e-01, -1.2636e+00, -2.6611e+00,\n","          3.5498e+00,  2.0009e+00, -2.0607e+00,  4.1773e+00, -2.9535e+00,\n","         -3.0936e-01, -4.2396e-01, -2.6227e+00,  2.2742e+00,  9.9156e-01,\n","         -1.1662e+00, -2.2977e-01,  8.9442e-01, -3.4009e+00,  5.6353e-01,\n","          2.4543e+00, -8.5593e-01,  9.1838e-01, -6.2667e-01, -1.4881e-01,\n","          1.6249e+00, -1.5828e+00, -1.9114e+00, -2.1236e+00, -8.1562e-01,\n","         -4.4359e-01, -1.8075e+00,  1.3213e+00,  1.8280e+00,  3.1157e+00,\n","          2.2334e+00,  1.7188e+00, -2.0885e+00, -1.1342e+00,  2.3987e-01,\n","         -1.4021e+00, -5.7241e-01, -2.2789e+00,  1.1417e+01,  2.2339e+00,\n","         -2.4611e+00, -1.5365e+00,  2.2844e-01,  1.4091e-01, -1.2499e+00],\n","        [ 9.5494e-01, -1.1651e+00,  4.3969e+00, -7.5131e-01, -4.8353e-01,\n","          5.9180e-01,  4.0959e+00,  1.9889e-01, -1.8068e+00,  2.9754e-02,\n","         -2.8056e+00,  3.8563e+00, -5.8560e-01, -1.8593e+00, -1.7797e+00,\n","         -1.7062e+00,  2.1832e+00, -1.5809e-02, -3.2810e+00,  6.9697e-01,\n","         -7.3963e-01, -1.6324e+00, -2.1185e-01, -1.9668e+00, -1.3851e+00,\n","          4.7653e+00,  1.0921e+00,  1.5488e+00, -1.1299e+00,  4.3839e-01,\n","          2.7972e-01, -8.4961e-01,  4.4664e-01,  1.9666e+00, -1.7547e+00,\n","          1.1645e+01, -3.5819e-01, -2.0625e+00,  7.8377e-01,  7.4553e-01,\n","         -3.0892e+00, -1.2220e+00, -2.8997e+00, -1.9653e-01,  7.3172e-01,\n","         -1.9516e+00, -1.5796e+00,  1.7228e+00, -1.4396e+00, -9.7123e-01],\n","        [ 4.7087e-01, -3.1119e+00,  2.7234e+00,  1.3656e+00, -2.9264e+00,\n","          7.1863e-01, -8.7822e-01, -2.4490e+00, -1.5253e+00,  1.4044e+00,\n","         -2.6830e-01,  4.8259e+00, -3.0009e-01, -2.0265e+00, -2.1821e+00,\n","         -3.5368e+00,  3.6454e+00,  1.1338e+00,  1.1907e+00,  4.1426e+00,\n","         -1.6158e+00,  8.7300e-01, -1.6968e+00, -4.0923e+00,  1.0277e+00,\n","          1.9182e+00, -4.7325e-01,  2.5677e+00,  2.4844e+00,  4.2602e-01,\n","          1.2305e+01, -1.6189e+00, -1.6095e+00, -1.0196e+00, -1.4729e+00,\n","         -2.0666e+00, -2.7686e+00, -1.1860e+00,  2.1912e+00, -8.5377e-01,\n","          1.6724e+00,  2.6272e+00, -1.6421e+00, -1.9159e+00, -1.6114e+00,\n","         -8.3365e-01,  2.1743e+00, -1.2303e-01, -4.0942e-01, -2.8685e+00],\n","        [ 2.5660e+00,  9.5039e-01,  2.8715e-01,  5.7717e+00, -2.8614e+00,\n","         -7.9337e-01, -1.9917e+00, -2.0616e+00, -1.7547e+00,  1.4561e+00,\n","          4.6413e-01,  1.0803e+00, -1.3407e+00, -9.3713e-01, -2.7725e+00,\n","         -6.4017e-01,  1.0502e+00,  2.2727e+00, -3.4258e-01,  1.0914e+00,\n","         -1.3762e-01,  8.3183e-01, -2.0664e+00, -3.7354e+00, -3.2809e+00,\n","          1.0740e-01, -2.7671e-01, -1.7269e+00, -4.2569e-01, -6.5335e-01,\n","          6.4359e+00, -9.8382e-01, -8.1807e-01, -1.6987e+00, -5.2686e-01,\n","         -2.5162e+00, -2.9673e+00,  2.8028e-01,  2.7301e+00, -9.3042e-01,\n","          1.8734e+00, -7.6639e-01,  3.6508e-01,  1.1500e+00, -1.2745e+00,\n","         -3.1020e+00,  1.3126e+01, -8.9643e-01,  1.3497e+00,  8.9941e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([26, 14, 24, 23, 42, 42, 27, 16, 49, 10,  4, 36, 43, 35, 30, 46],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8518,  8.2595, -0.8814,  ..., -1.7291, -2.1717,  2.5039],\n","        [-0.3118,  4.6966,  0.1130,  ..., -0.5302, -0.7641,  3.7517],\n","        [ 8.3539, -3.2056,  1.6438,  ...,  7.4488, -1.2832, -1.9982],\n","        ...,\n","        [ 2.0131,  0.4029, -0.7293,  ..., -2.1421,  1.6436, -0.4365],\n","        [-0.3455, 10.9913,  0.8837,  ..., -1.2962, -2.0376,  1.6432],\n","        [ 1.0396, -3.0491,  4.9579,  ..., -1.8293,  1.7672, -0.1142]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 397/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.3365, -0.8310,  1.1519,  ..., -0.7697, -0.9661, -1.2862],\n","        [ 0.3905, -2.0443,  1.5191,  ...,  3.6007, -2.3497, -0.4395],\n","        [-1.5334, -4.0494, -2.3369,  ..., -0.1973, -2.9032, -3.5627],\n","        ...,\n","        [ 0.5263,  0.4896,  0.7690,  ..., -2.7195,  4.5239, -1.6944],\n","        [ 0.6661, -0.2139,  0.4231,  ..., 13.0270,  0.0838, -0.9013],\n","        [ 5.4065, -3.5463,  1.9519,  ...,  4.3793,  1.0797, -2.5795]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([19, 35, 32, 21, 20, 47, 19, 32, 12,  8, 42,  8, 25, 22, 31, 12, 15, 41,\n","        35,  6, 24, 15, 34, 31, 49,  2, 23, 18,  2, 30, 47, 17, 26,  4,  1, 23,\n","        17,  3, 16, 11, 49, 35, 21, 10, 15, 23, 15, 45, 32, 12, 33, 24, 19, 49,\n","        27,  0,  9, 29, 13,  5, 12, 39, 39, 17,  8,  0, 18, 17,  2,  8, 26, 30,\n","        29, 27, 34, 40, 24, 49, 35, 13, 41, 21, 30, 17, 46, 16,  6, 25, 20, 36,\n","        27, 22,  5, 39,  9,  3,  0, 48, 12, 10, 16, 31, 24,  9, 24, 28,  5, 37,\n","        22, 49, 34,  0, 33,  7, 13,  4, 32, 37, 19,  7, 38, 16, 12, 15, 20, 10,\n","        47, 25], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.6051, -0.3887,  2.7706,  ...,  0.2229, -0.9006, -2.2374],\n","        [ 0.4625, -0.3667,  0.9288,  ..., -2.0568,  2.7606, -2.0923],\n","        [ 2.5568, -0.4838,  2.6013,  ..., -0.3613,  0.9695,  1.4074],\n","        ...,\n","        [14.7035, -1.4675, -0.1878,  ...,  1.1786,  0.5100, -2.4084],\n","        [-0.8064,  0.0348, -0.1019,  ..., -0.4092,  0.1271,  1.8558],\n","        [ 5.2777,  1.2066,  0.6932,  ...,  4.8960, -1.9158, -2.1768]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([38, 10, 11,  1, 30, 18,  5, 43, 31, 29,  8, 19, 48, 49, 42, 27, 28, 29,\n","        47, 16, 26, 36, 27, 23,  7,  1, 18, 28, 27, 47, 14,  8, 16, 13, 22,  1,\n","        26, 42, 21, 38,  9,  7, 45, 14, 10,  9, 12, 20,  4, 25, 36,  2, 36,  8,\n","        44, 43, 11, 10, 26, 30, 34, 13, 18, 14, 14, 20, 28, 10, 22, 39,  0, 48,\n","        37,  9, 44, 41, 22,  6,  2,  1, 27, 37, 16, 20,  3,  5, 14,  3,  0, 19,\n","         6,  5, 36,  7, 46, 30, 45, 20, 30,  5,  9, 31, 16, 26, 41,  6, 35, 49,\n","         8, 15, 44, 19, 37, 41,  1, 33, 36, 27, 38,  2, 43, 28, 32, 46, 49,  0,\n","        40, 24], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.9097e+00, -1.0818e+00,  1.8142e+00,  ..., -9.0191e-01,\n","          1.3226e+01, -9.5064e-01],\n","        [-3.3306e-03, -5.1663e-01,  1.5797e+01,  ..., -7.8746e-01,\n","         -7.7602e-01, -4.3700e-01],\n","        [-3.2876e+00, -3.5689e+00, -2.1335e+00,  ..., -1.9823e+00,\n","         -2.4971e+00, -5.3546e-01],\n","        ...,\n","        [-1.9867e+00, -2.7931e+00,  3.1837e-01,  ...,  2.0739e+00,\n","          1.0831e+00,  2.8941e+00],\n","        [ 1.9282e+00,  1.9346e+00,  2.0455e+00,  ..., -3.8038e+00,\n","         -4.4234e-01,  5.0023e-01],\n","        [-1.3737e+00,  3.0581e-01, -4.1210e-02,  ...,  3.4911e+00,\n","         -3.8298e-01, -1.6996e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([48,  2, 28,  0,  3, 43, 40, 43, 34, 13, 32, 29, 16, 19, 36, 23,  4,  9,\n","        40,  2,  3, 22, 35,  3, 24, 45, 13, 42, 36, 12, 48, 32, 41, 11, 17, 34,\n","        39, 31,  6, 20, 11, 14, 32, 21, 11, 30, 33,  7, 12, 33, 37, 48, 13, 30,\n","         6, 15, 18, 40, 11, 21, 22, 28, 45,  7, 26, 29, 11, 43, 45, 41, 35, 47,\n","        44, 47,  4, 42, 14, 31, 33, 40, 25, 31, 38, 29, 44,  3,  7, 40,  4,  1,\n","        17, 47, 42,  2, 17, 31, 30, 38, 24, 36, 29, 17, 42,  4, 16, 23, 27, 25,\n","        10, 44, 15, 46, 37, 45, 10, 20,  3, 14, 26, 14, 37,  9, 28, 41,  1, 29,\n","        46, 18], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 1.9351e+00, -2.9298e+00,  1.0270e+00, -1.6525e+00,  1.0690e+00,\n","         -9.5130e-01,  3.1812e+00, -6.1812e-01, -3.0640e-01, -1.2255e+00,\n","          2.7566e-01,  5.0811e+00,  2.4494e+00, -1.2410e+00, -1.5291e+00,\n","         -1.4905e+00,  5.0595e-01, -2.0572e-01, -2.0499e+00, -5.5056e-01,\n","          5.6382e-01, -1.7150e+00,  1.0420e+00, -1.9911e+00,  7.7263e-01,\n","          1.1973e+00, -1.4576e+00,  3.0482e-01, -1.0273e-01, -9.8089e-01,\n","          9.1940e-01,  4.3709e-01,  3.3078e+00, -2.2039e+00, -1.5215e+00,\n","          1.0080e+01,  4.9368e-01, -3.0152e+00,  1.4894e+00,  1.0770e+00,\n","         -2.8607e+00, -1.0874e-01, -9.8836e-01,  2.1622e-01, -3.9885e-03,\n","         -2.5614e+00, -1.2009e+00,  2.1147e+00, -1.0293e+00, -9.8593e-01],\n","        [ 3.5793e+00,  1.4852e+00,  1.0819e+00,  9.5133e-01, -1.7053e+00,\n","          1.2771e+00, -1.7866e+00, -6.2745e-01,  1.6601e+00, -1.2423e+00,\n","          1.4138e+00, -4.8072e-01,  1.2171e-01, -3.8104e+00, -2.0948e+00,\n","         -3.4386e+00, -4.0543e-02,  5.8369e-01, -3.1233e+00, -2.9217e+00,\n","          3.1774e+00, -1.5646e+00,  3.4427e-01, -1.0283e+00,  1.8944e-01,\n","         -1.4323e+00,  2.6138e-01,  2.1537e-01, -2.4087e+00, -1.4903e+00,\n","          1.4357e+00, -7.6738e-01, -1.1885e+00, -3.8062e+00,  1.5701e-01,\n","         -2.7617e+00,  4.0521e+00, -2.6971e-01,  4.6633e-01,  1.1169e+00,\n","          2.4399e+00, -7.4973e-01,  3.8641e+00,  1.1905e+00,  2.5415e+00,\n","         -2.8279e+00,  1.3105e+00, -2.9988e+00,  1.2195e+01, -7.9728e-01],\n","        [-1.9190e+00,  1.6132e-01, -7.0708e-01, -6.0063e-01,  6.0349e-01,\n","          1.2337e+00, -2.5931e+00,  4.7892e-02, -9.7514e-01,  1.4673e+00,\n","         -6.6221e-01,  4.3572e-02, -6.6141e-01, -1.8386e+00, -5.5579e-01,\n","         -8.9493e-02, -2.3341e+00, -7.7705e-01, -1.2939e-01, -1.7363e+00,\n","          2.4059e+00,  1.0516e+00,  2.6355e-01, -3.0816e+00, -6.1533e-01,\n","         -2.0701e+00, -2.4358e-02, -1.8440e+00, -5.6909e-01,  3.8146e+00,\n","          1.4779e+00,  1.4065e+00,  8.1728e-01, -2.7308e+00,  1.4766e+00,\n","         -4.2438e+00, -9.0551e-01,  1.8721e+00, -3.5098e-02,  2.8257e-01,\n","          1.2296e+01,  1.0181e+00, -7.3615e-01, -3.5270e-01, -7.9180e-02,\n","          2.5210e+00,  4.8768e-01, -1.1770e+00, -7.3315e-01,  1.5532e+00],\n","        [-4.5089e+00, -3.1948e+00, -1.5305e+00, -3.9826e+00,  1.1347e+00,\n","          2.9586e-01, -1.6047e+00,  1.2082e+00, -1.9128e+00,  4.0030e+00,\n","         -9.3778e-02,  4.8908e-01,  3.3392e+00, -2.7666e+00, -1.5712e+00,\n","          8.6962e-01, -1.5686e+00,  3.8012e-01,  1.4672e+00, -3.3083e+00,\n","          6.1848e-01,  2.9470e+00, -1.5280e+00, -1.5352e+00, -1.9481e+00,\n","         -2.1681e+00, -3.1907e-01,  4.5712e-01,  4.3949e+00,  2.7056e+00,\n","         -1.6717e+00,  3.1942e+00,  1.7443e+00,  1.0548e-01, -3.6878e-01,\n","         -2.7626e-01, -1.1613e+00,  2.8909e-02, -7.1830e-01, -4.0518e-01,\n","          7.9130e-01,  1.3119e+01, -8.9734e-01, -2.4887e+00,  1.8731e+00,\n","          2.0717e+00, -1.9123e+00, -9.6472e-01, -1.4564e+00,  1.8429e+00],\n","        [-2.8122e+00,  1.8493e-01,  1.4662e+00, -1.4004e+00,  1.3352e+01,\n","         -1.3566e+00, -1.8462e+00, -1.8806e+00,  9.6961e-01, -1.3663e+00,\n","         -1.0851e+00, -1.7073e-01, -7.4832e-01,  1.1351e+00, -1.6486e+00,\n","          2.4917e+00, -7.5679e-01, -2.8021e+00,  1.5095e+00, -4.8825e-01,\n","          2.3845e+00,  1.3538e+00, -2.1517e+00,  1.3641e+00, -1.1343e+00,\n","         -2.7799e+00, -1.9104e+00, -2.7282e+00, -2.1599e-01,  4.1155e+00,\n","          1.0777e+00,  1.6845e+00,  1.3659e+00, -3.1832e+00,  2.2674e+00,\n","         -2.9344e+00,  1.4138e+00,  4.4941e+00, -5.7971e-01, -1.0790e+00,\n","          7.9694e-01,  1.1218e+00,  1.8242e-01, -2.3418e-01, -1.1279e+00,\n","          1.7440e+00, -1.9377e-01, -3.4790e+00, -4.3055e+00,  6.4042e+00],\n","        [ 3.8116e+00,  3.6774e+00,  1.2671e+00,  3.6510e+00, -2.8536e+00,\n","          3.6983e+00,  9.0596e-01, -3.3418e+00,  4.4535e-01,  7.8728e-01,\n","         -1.3150e+00,  9.0519e-02, -3.2980e+00,  1.1258e+00, -1.3842e+00,\n","          3.7830e+00,  2.9959e+00, -1.9356e+00, -1.1943e+00,  2.8584e+00,\n","         -1.9644e+00,  5.0607e-01, -3.2447e+00, -2.6449e+00,  9.4226e-01,\n","         -2.6754e+00,  2.3163e+00, -9.3038e-01, -2.1212e+00,  2.4067e+00,\n","          3.3107e+00,  2.4142e+00, -2.2163e+00, -7.2097e-01,  1.3791e+00,\n","         -3.4104e+00, -2.8490e+00,  8.6436e-01, -2.0733e-01, -2.3364e+00,\n","         -1.2588e-02, -1.6228e+00, -7.6272e-01, -3.7279e-01, -1.8530e+00,\n","         -3.0026e+00,  6.9775e+00, -8.0773e-01, -1.1706e+00,  1.4515e+00],\n","        [-4.1770e+00, -2.4377e+00, -4.6603e-01,  2.6222e-01,  1.2778e+00,\n","         -1.2030e-01, -2.7680e+00, -8.8234e-01, -3.4548e+00,  1.4420e+01,\n","         -1.0008e+00, -7.5862e-01,  2.8154e+00, -1.7472e+00, -1.6662e+00,\n","          8.4983e-02, -1.3956e+00, -1.5857e+00,  4.9618e+00, -2.2038e+00,\n","          2.2170e+00,  1.0311e+00, -6.6681e-01, -7.4692e-01,  7.7191e-01,\n","         -2.8286e+00,  3.1377e-02, -5.5918e-01,  1.7141e+00,  4.7554e+00,\n","         -1.9625e-01,  4.2502e+00,  1.2861e+00, -3.9976e+00, -2.6400e+00,\n","         -3.9495e+00, -2.3728e+00,  2.2772e+00,  1.3426e+00, -1.0078e+00,\n","          3.0225e+00,  1.4824e+00,  1.2545e+00, -4.8670e+00,  2.5060e+00,\n","          8.0938e-01, -7.9318e-01, -9.8711e-01, -2.2597e+00, -1.0103e+00],\n","        [ 1.6416e+00,  1.1038e+01, -5.6160e-01,  2.7947e+00, -1.7095e+00,\n","          2.0035e-01,  7.6138e-01,  5.3710e-01,  2.7796e+00, -1.3455e+00,\n","         -3.1538e+00, -1.6378e+00, -8.6794e-01, -1.5780e+00, -1.5432e+00,\n","         -2.0830e+00, -4.1981e+00, -1.7670e+00,  3.3258e+00,  5.8312e-01,\n","          1.0480e+00, -1.0682e+00,  6.8701e-01,  5.5686e-01,  2.5423e-01,\n","         -2.8758e+00, -7.2688e-01, -1.1573e+00, -2.3424e+00, -2.1045e+00,\n","          3.3307e-01, -1.4409e+00, -1.2035e+00, -3.0473e+00,  4.3437e+00,\n","         -2.9970e+00,  2.4964e+00,  2.5367e+00,  2.0161e+00, -2.7422e+00,\n","          1.3148e-01, -2.3286e+00,  3.3249e+00,  4.1456e+00, -1.9995e+00,\n","         -1.8534e+00,  2.1076e+00,  5.9639e-01,  4.3019e-01, -6.7039e-01],\n","        [-2.0370e+00,  4.6597e-01,  2.3514e+00,  9.1166e-01, -1.9645e+00,\n","          2.5867e+00,  6.2839e+00, -4.5448e-01, -1.1753e-01, -1.8663e+00,\n","         -2.1349e+00,  2.2653e-01, -3.1774e+00,  2.1977e+00, -7.3005e-01,\n","          9.3373e-01,  3.9997e-01, -1.0276e+00, -1.9715e+00,  9.4499e-01,\n","         -2.3561e-02, -7.5941e-01, -2.2671e+00, -8.8808e-01, -2.0132e+00,\n","         -1.0254e-01,  6.1580e+00, -5.9213e-01, -1.4585e+00,  1.1800e+00,\n","         -7.2209e-01, -9.4347e-01,  4.0444e-02,  1.2057e+01,  6.0843e-01,\n","          1.4629e+00, -1.0555e+00, -1.9640e+00, -1.8305e+00, -4.5568e-01,\n","         -2.3782e+00, -1.0133e+00, -2.3920e+00,  1.4197e+00, -2.8527e-02,\n","         -1.6033e+00, -6.3984e-01, -7.7090e-01, -5.4365e-01,  1.3681e-01],\n","        [-2.7576e-01, -2.6240e+00,  1.1001e+00,  1.6781e+00, -1.1751e+00,\n","         -1.0031e+00,  9.4598e-01, -4.2450e-01, -1.8127e+00,  2.1959e-01,\n","         -2.2547e+00,  1.9625e+00, -1.4046e+00, -8.9248e-01, -8.3131e-01,\n","         -8.1483e-01,  1.7517e+00,  1.7069e+00, -2.2833e-01,  2.6420e+00,\n","          1.0057e+00, -6.3072e-01,  1.1454e+00, -1.4377e+00,  5.6612e-01,\n","          1.1111e+01, -1.0114e+00, -4.5480e-01, -1.3451e+00,  2.2936e+00,\n","          1.5058e+00, -1.1833e+00,  5.3643e-02, -1.2696e+00, -1.7346e+00,\n","          1.6642e+00, -7.7582e-01, -1.7893e+00,  8.3253e-01,  1.6105e+00,\n","         -1.6781e+00, -1.3707e+00, -1.9261e+00, -8.7965e-01,  8.8495e-01,\n","         -1.3933e+00, -2.4555e+00,  3.2183e+00, -9.7937e-01, -1.4721e+00],\n","        [-2.1191e-01, -3.2716e-01,  2.9010e-01,  2.1169e-01,  1.1099e+00,\n","         -4.6078e-01,  1.8546e-02, -2.2818e+00,  3.9101e+00, -2.8073e+00,\n","         -1.3275e+00, -2.8061e+00, -4.7530e-01,  3.6068e+00,  7.0438e-01,\n","         -5.1515e-01, -1.1189e+00, -2.9948e+00, -1.8759e+00, -1.0417e+00,\n","          2.6155e+00, -1.4496e+00, -2.1409e-01,  1.2554e+01, -4.5963e-01,\n","         -2.2320e+00, -1.0622e+00, -2.7163e+00,  4.0547e-01, -8.5638e-01,\n","         -1.7873e+00,  4.4791e+00, -8.5489e-01, -2.2942e+00,  2.4438e+00,\n","          3.1716e-01,  2.1057e+00,  4.0945e+00,  1.5470e-01, -1.2152e+00,\n","         -1.5012e+00, -2.2424e+00, -1.4467e+00,  2.7750e+00, -1.3963e-02,\n","         -2.5366e+00, -1.9181e+00, -2.7958e+00, -3.9579e-02,  1.5234e+00],\n","        [ 9.7519e-01, -8.2357e-01,  3.3818e-01, -1.9571e+00, -1.5262e+00,\n","         -7.7983e-02,  3.4824e-01, -1.2430e+00, -3.6815e-01,  1.5239e-01,\n","          6.4434e+00, -2.5005e-02, -7.4685e-02, -1.1387e+00, -6.8762e-01,\n","         -1.4192e+00, -2.6377e+00,  1.4451e+01, -2.4697e-01, -1.7552e-01,\n","          1.7779e+00, -8.4287e-01, -1.3432e+00, -1.7167e+00, -9.8717e-01,\n","         -2.1063e-01, -7.9738e-01, -3.0341e-01, -1.4620e+00, -1.9862e+00,\n","          1.4261e+00, -2.3733e+00,  4.1160e-01, -1.0450e+00, -3.3222e+00,\n","         -9.8148e-01, -1.5435e+00, -7.4455e-01, -8.0839e-01, -1.7090e+00,\n","         -5.1430e-01, -1.7356e+00,  5.3732e+00,  1.1112e+00,  2.1042e+00,\n","         -1.7435e+00,  5.5323e-01, -1.0009e+00,  2.6480e+00, -1.7824e+00],\n","        [ 6.4667e-01, -3.0323e-01,  1.4557e+00,  2.4607e+00, -2.2900e+00,\n","         -4.3968e-01, -2.0669e+00, -8.2867e-01, -1.2861e-01,  4.7747e-01,\n","          2.2839e+00,  5.4992e-01,  2.2802e-01, -8.1993e-01, -1.3825e+00,\n","         -1.1926e+00,  3.4018e+00,  4.8569e-01,  6.2940e-01,  1.8338e+00,\n","         -1.8238e+00,  1.4923e+00, -2.4355e+00, -3.6047e+00, -1.3216e+00,\n","         -2.5631e+00,  8.8070e-01,  7.3802e-01,  1.2906e+00, -1.3645e+00,\n","          4.7517e+00, -2.1004e+00,  3.5940e-01, -4.1978e-01,  1.7647e+00,\n","         -9.1084e-01, -1.0698e+00, -4.9992e-01,  7.2351e-02, -2.9476e+00,\n","         -1.2570e+00, -9.0965e-01,  1.0178e+00,  1.1697e+00, -1.5670e-02,\n","         -2.2548e+00,  1.1567e+01, -1.6683e+00, -5.1835e-01,  6.2342e-01],\n","        [ 6.9748e+00, -4.1775e+00,  3.0752e+00, -5.3735e-01, -2.1176e+00,\n","         -1.5467e+00,  2.1933e+00, -4.7180e+00, -2.4920e+00, -2.2831e+00,\n","         -2.8480e+00,  4.1133e+00, -3.7710e+00,  1.0445e+00,  2.0131e+00,\n","         -4.1882e+00,  4.8341e+00,  9.7861e-01, -3.5993e+00,  3.6944e+00,\n","          4.0515e-01, -1.8925e+00,  2.5122e+00, -7.2847e-01,  3.1471e+00,\n","          1.3075e+01,  9.8224e-01, -2.3781e+00, -3.2456e+00,  6.5337e-01,\n","          3.3211e+00, -1.9163e+00,  1.3100e-01, -1.5425e+00, -4.3635e+00,\n","          1.7796e+00, -1.7991e+00, -4.1742e+00,  3.0857e+00,  5.5724e+00,\n","         -1.5448e+00, -1.5984e+00, -3.3476e+00,  1.8006e+00, -3.6748e-01,\n","         -3.4254e+00, -3.4607e+00,  4.8635e+00,  4.9525e-01, -1.6665e+00],\n","        [-2.6822e+00, -3.5200e+00,  2.1066e+00, -2.6464e+00,  1.9131e-01,\n","          2.1996e+00, -1.1224e+00, -4.8607e-01, -3.0532e+00,  1.5644e+00,\n","          2.6388e-02,  2.8578e+00,  1.2961e+00, -3.5807e+00, -1.8315e-01,\n","          1.0762e-01, -4.6355e-01, -6.1592e-01,  2.5999e+00, -2.1391e-01,\n","         -2.7801e+00,  2.5962e+00,  1.5739e-01, -3.0009e+00, -1.9343e+00,\n","         -1.4280e-01,  9.9775e-01,  1.3256e+01,  1.6418e+00,  1.5166e+00,\n","         -3.4647e-01,  5.4977e-01,  1.0792e+00, -1.7376e+00, -1.4194e+00,\n","          9.4604e-01, -1.7350e+00,  1.9349e-01,  1.7285e+00, -2.7517e+00,\n","         -6.3399e-01,  1.6715e+00, -5.8462e-01, -2.0234e+00,  6.5512e-01,\n","         -8.8226e-01, -1.4695e+00, -3.9680e-01, -8.8157e-01,  1.9493e-01],\n","        [ 4.5145e+00,  1.7403e-01, -1.0637e-01,  2.2340e+00, -2.5035e+00,\n","         -6.1471e-01,  2.7608e+00, -2.9103e+00,  1.7162e-01, -2.1789e-01,\n","         -3.9871e+00, -1.3497e+00, -2.3027e+00,  7.0883e-01, -1.1021e+00,\n","         -2.4945e+00,  3.4978e+00, -8.2638e-01,  5.3730e-01,  4.0589e+00,\n","         -1.4377e+00, -1.9881e+00,  5.6549e-01, -2.8338e+00,  1.4090e+01,\n","         -2.0604e-01,  2.2091e-01, -1.8089e+00, -1.6324e+00, -1.2964e+00,\n","          3.1216e+00,  5.2232e-01,  8.9453e-01, -2.5445e+00,  4.3584e-01,\n","          1.2949e+00, -3.1942e-02, -3.5647e+00,  3.2628e+00,  1.8311e+00,\n","         -2.7162e+00, -2.3459e-02, -2.0568e+00, -3.4331e-01, -1.8838e+00,\n","         -6.8301e-01, -4.2282e-01,  4.1569e+00, -1.4501e+00, -1.7599e+00]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([35, 48, 40, 41,  4, 46,  9,  1, 33, 25, 23, 17, 46, 25, 27, 24],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8520,  8.2435, -0.8818,  ..., -1.7204, -2.1705,  2.5056],\n","        [-0.3148,  4.6968,  0.1127,  ..., -0.5309, -0.7656,  3.7651],\n","        [ 8.3556, -3.1992,  1.6454,  ...,  7.4338, -1.2864, -1.9894],\n","        ...,\n","        [ 2.0158,  0.3953, -0.7330,  ..., -2.1446,  1.6419, -0.4375],\n","        [-0.3481, 10.9726,  0.8854,  ..., -1.2949, -2.0403,  1.6531],\n","        [ 1.0460, -3.0580,  4.9553,  ..., -1.8280,  1.7571, -0.1180]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 398/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.0483, -2.6789,  1.6293,  ..., -1.4211,  0.5102,  1.4375],\n","        [-2.9357, -0.6214,  1.3920,  ..., -0.0759,  1.2955,  1.2378],\n","        [-5.5736, -3.7453, -1.4283,  ..., -3.5256, -1.8185,  2.7606],\n","        ...,\n","        [ 1.9729, -0.6187,  0.9908,  ..., -0.6350,  4.4663, -1.6624],\n","        [ 2.9077, -4.9433, -0.4164,  ...,  3.6433,  1.7942, -3.3630],\n","        [-0.6586, -1.6657,  1.8654,  ..., -0.4336,  1.9333,  0.8403]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([20, 29, 41, 42, 21,  7, 20,  1,  3,  9,  2,  4, 36,  3, 38, 42, 37, 16,\n","         8, 12, 17, 43,  0, 25, 24, 37, 34, 16, 41, 36,  1, 20, 18, 47, 48, 23,\n","        32, 45, 47,  0,  2, 40, 16, 13, 22,  6, 36, 14, 30, 37, 43, 15,  9, 49,\n","        12, 36, 11, 27, 30, 41,  9, 45, 43, 41, 20, 27, 13, 26, 48, 30, 46, 16,\n","         9, 31, 40, 27, 40,  3, 42, 33, 11, 19, 36, 35, 31,  1, 16, 36, 47, 20,\n","        10, 48, 24, 39, 25,  1, 18,  3, 23,  8, 22, 21, 34, 34,  9, 24, 29, 40,\n","         2,  1, 10, 44, 32, 28, 12, 37, 14, 32, 45, 24,  4, 41, 10,  7,  8, 17,\n","        39, 26], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-3.3658, -1.5632, -1.1093,  ..., -0.6519, -1.8244,  4.8242],\n","        [-2.0117,  0.1619, -0.9040,  ..., -0.9438, -2.2907,  5.2937],\n","        [ 1.9450,  1.2015, -0.2177,  ..., -1.3674,  3.4760, -0.2585],\n","        ...,\n","        [ 7.3860, -4.0739,  3.0624,  ...,  6.6406,  1.1598, -1.9073],\n","        [ 4.4580, -1.5899,  1.3447,  ...,  3.6771, -0.2296, -2.6131],\n","        [ 1.3466,  2.0395, -0.4704,  ..., -2.0981,  0.0764,  3.5349]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([41, 15, 42, 11,  9, 10,  1, 28, 18, 32, 14, 29, 48, 27,  9, 35, 17, 31,\n","        18, 25, 29,  2, 30, 27, 12, 37,  3, 20, 44, 29, 26, 10, 31,  3,  6, 30,\n","        12, 35,  9, 40, 11, 35,  4, 30,  7, 21, 38, 14, 28, 28, 29,  8, 48, 15,\n","        12, 15, 33, 19, 19,  0, 28, 16, 33, 22, 10, 26, 43, 11, 26, 29, 19, 42,\n","        30, 17, 10, 19,  6, 43, 48, 36,  2, 33,  1, 13, 18, 40, 22, 19, 36,  8,\n","        33,  5, 12, 34, 14, 45, 12, 14,  4,  4, 30, 29, 24, 40, 42, 15, 46, 27,\n","        25, 31, 20,  5, 32, 11, 19, 18, 23, 35, 24, 37,  2, 28, 13, 49,  4, 25,\n","        38, 23], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-2.9648, -1.2117,  0.4023,  ..., -4.2314, -1.3172, -1.4997],\n","        [-3.7662,  2.2553, -0.5280,  ..., -1.3372, -2.1252, 15.8832],\n","        [-1.4491, -1.3407,  0.6767,  ..., -2.3111,  0.0367,  0.2992],\n","        ...,\n","        [ 4.7142,  1.8798,  0.7870,  ...,  3.9003, -0.8883, -2.1829],\n","        [ 5.4819, -2.8698,  4.8951,  ..., -0.4738,  0.2945, -0.4124],\n","        [ 4.0165, -0.2968,  4.8028,  ...,  3.2704,  1.6649, -0.5774]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([31, 49, 44, 47, 22, 32, 33, 25, 38, 39, 46, 17, 43,  6, 24, 28, 38, 19,\n","         4, 39,  7, 16, 27,  3, 10, 49, 46, 25, 47, 46, 26, 34, 35, 12, 27, 49,\n","         5, 17,  5, 49, 37, 15,  9, 24, 32, 37, 48,  7, 47, 46, 49, 13, 13, 25,\n","         3,  4, 23, 21, 31, 45, 16, 31, 35,  8, 45, 33, 31, 22, 27, 35, 27, 18,\n","        22, 23,  0, 26, 44,  6,  7, 17, 32,  5,  3,  2, 14, 41, 14,  1, 13, 47,\n","         0,  8, 20,  0, 23,  5, 11, 17, 15, 10, 42, 39,  0,  8, 44, 34, 47, 16,\n","        29,  1, 14, 41, 15, 13, 45, 28, 41,  0, 40, 21,  5, 30,  6, 46, 36, 24,\n","        16,  6], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 7.0800e-02, -1.1795e+00, -8.0463e-02, -8.2182e-01, -1.3905e+00,\n","         -8.3490e-01,  8.1867e-01, -1.1910e+00,  1.0397e+00, -3.6201e-01,\n","          3.1136e+00, -1.1043e+00,  8.7243e-01, -9.7103e-01, -1.5693e+00,\n","         -2.0548e+00, -1.1579e+00,  9.5041e+00, -7.9261e-01,  6.7165e-01,\n","         -4.8926e-01, -2.0426e+00,  3.0397e-01, -4.7722e-01,  9.6301e-01,\n","          1.1595e+00, -1.1674e+00, -1.7783e+00,  2.9991e-01, -1.1234e+00,\n","          1.5538e+00, -9.7997e-01,  3.3139e-01, -2.0967e-01, -2.0309e+00,\n","          5.2601e-01,  3.8442e-01, -1.3684e+00, -1.7675e-01,  1.1263e+00,\n","         -7.4473e-01,  8.9400e-02,  2.4409e+00,  6.8255e-01,  1.6127e+00,\n","         -7.4842e-01, -7.8231e-01,  9.2004e-01,  2.6106e+00, -2.2591e+00],\n","        [ 2.4400e+00, -1.1007e-01,  1.4221e+00,  3.7536e+00, -2.3918e+00,\n","         -1.5183e+00, -2.2553e-01, -5.1404e+00, -3.1877e+00, -3.9125e-01,\n","         -2.2886e+00,  2.0597e+00, -2.0705e+00, -7.2619e-01, -1.3525e+00,\n","         -3.7083e+00,  5.3696e+00,  4.8780e-01,  1.5949e-03,  4.1097e+00,\n","         -1.1915e+00, -7.4605e-01, -1.8299e+00, -2.8508e+00,  4.7323e+00,\n","          2.5622e+00,  1.0672e+00, -1.5133e+00, -7.6563e-01,  1.8477e+00,\n","          1.2901e+01, -1.8651e+00, -1.1374e+00, -1.3482e+00, -5.8174e-03,\n","         -2.6870e+00, -6.7932e-01, -1.3138e+00,  8.2125e-01,  4.3468e-01,\n","          2.1500e-01, -1.2730e+00, -1.4173e+00,  1.4541e-01, -1.2204e+00,\n","         -1.9719e+00,  2.8507e+00,  1.7919e-01, -4.8640e-03, -8.0440e-01],\n","        [-6.1333e-01, -1.5346e+00, -5.0080e-01,  5.7112e-01,  2.0181e-01,\n","         -1.6573e+00,  6.5281e-01, -1.6545e+00, -6.3005e-01,  4.6884e-01,\n","         -1.0127e+00,  1.1685e+00,  2.8939e-01, -3.7639e-01, -7.1069e-01,\n","         -4.6238e-01,  2.7358e-01, -2.6636e+00,  5.9029e+00, -1.7055e+00,\n","         -3.4114e-01,  1.0746e+01, -4.7604e-01,  6.1489e-01, -9.2168e-02,\n","          7.7636e-01,  4.8365e-01,  3.1276e+00, -2.1774e+00,  4.8543e-01,\n","          1.6760e-02, -1.7714e+00,  3.4091e-01, -1.9404e+00, -4.0545e-01,\n","         -3.4866e-02, -1.2004e+00,  4.4813e-01,  6.8230e-01, -6.7940e-01,\n","          1.2457e+00,  1.4111e+00, -2.6648e-01, -9.2890e-01, -1.8355e+00,\n","         -1.2808e+00, -3.8458e-01,  1.1948e+00, -1.5866e+00,  3.0445e-01],\n","        [-2.7337e+00,  3.0038e-01,  1.0096e+00,  4.1457e-01,  1.9723e+00,\n","         -6.6394e-01,  1.9143e-01, -5.7314e-01, -2.3168e+00, -7.7129e-01,\n","         -2.7952e-02,  9.4381e+00, -7.0964e-01, -1.4390e+00, -1.6968e+00,\n","         -4.8293e-01, -2.9090e+00, -6.2163e-01,  1.9362e+00,  1.8674e+00,\n","         -1.0664e+00,  6.0597e-01, -2.4855e+00, -2.5127e+00, -1.6796e+00,\n","          1.4250e+00,  6.8940e-01,  1.6472e+00, -9.4377e-01,  3.5566e+00,\n","          1.1609e+00,  5.3933e-01,  1.2999e+00,  1.8294e-01,  8.3985e-01,\n","          2.0788e-02, -2.2084e+00, -5.4158e-01,  1.0237e+00, -8.3364e-02,\n","          5.2896e-01,  1.8294e+00, -2.7747e-01, -1.3106e+00, -1.6729e+00,\n","         -5.4324e-01, -5.5956e-01,  1.9589e+00, -1.7075e+00, -1.1693e+00],\n","        [ 3.0193e+00,  1.2776e+00, -6.4078e-01,  2.0644e+00, -1.9718e+00,\n","          3.3892e+00,  1.7762e+00, -3.8421e+00,  8.3732e-01, -2.1016e-01,\n","         -7.5346e-01, -1.5849e+00, -3.6470e+00, -6.1973e-01,  8.9185e-01,\n","         -1.6825e+00,  2.0922e+00, -2.4160e+00,  1.0909e-01, -1.2559e+00,\n","         -1.9075e+00,  8.3146e-02, -2.6574e+00, -1.0126e+00, -7.3427e-01,\n","         -1.8147e-01,  1.1447e+01,  1.6763e+00, -3.4508e+00,  2.8618e+00,\n","         -8.9937e-01,  1.4350e+00,  5.1247e-01,  2.7878e+00,  7.1802e-02,\n","         -5.5440e-01, -2.2612e+00,  9.3035e-01, -1.7820e+00, -5.9652e-01,\n","         -1.8626e+00,  2.0255e-01, -6.4292e-01,  2.0842e-01,  1.0201e+00,\n","         -3.1667e+00, -1.0377e+00, -4.7699e-01,  4.2995e+00, -1.7761e+00],\n","        [-7.8579e-01, -1.0170e+00, -1.1441e+00, -5.1436e-01, -1.2067e+00,\n","          2.8669e+00, -1.4805e+00, -2.7458e+00, -1.5407e+00,  7.2008e-01,\n","          1.0961e+00, -5.1892e-01, -1.4426e+00, -1.0187e+00,  3.7049e+00,\n","         -1.1045e+00,  3.5334e-01,  4.3018e-01, -1.1315e+00, -1.3606e+00,\n","          4.9134e-01, -2.9211e-01, -1.6023e+00, -1.0004e+00, -6.8755e-01,\n","         -3.9195e-01,  1.9595e+00,  1.2915e+00, -1.9641e+00,  1.3598e+00,\n","         -5.5184e-01,  6.2878e-01,  1.6209e+00, -1.6504e+00,  1.7059e+00,\n","         -1.1196e+00,  3.4505e-01,  1.1214e+00,  1.4865e+00, -1.8426e+00,\n","         -8.3999e-02, -5.3451e-01, -4.5714e-01,  2.6475e-01,  1.0847e+01,\n","         -2.0368e+00, -7.0295e-01,  7.3488e-02,  5.1374e-01,  2.4020e-01],\n","        [-2.5657e+00,  2.0253e-01, -2.3489e+00,  3.9231e-01,  2.5779e+00,\n","         -8.4871e-01, -3.0085e+00, -2.1981e+00, -1.7778e+00,  1.0042e+01,\n","         -1.9097e-01, -2.2080e+00,  1.9644e+00, -8.9772e-01, -1.7388e+00,\n","          1.2881e+00, -1.8240e+00, -2.8331e+00,  4.2987e+00, -1.8650e+00,\n","         -9.3385e-02,  2.6380e-01, -1.3757e+00,  6.6430e-01,  2.2421e+00,\n","         -2.4050e+00, -3.0942e-01, -3.0284e-01,  2.8536e+00,  4.4114e+00,\n","         -1.0527e+00,  5.9364e+00,  1.0077e+00, -3.8844e+00, -1.1825e+00,\n","         -3.8244e+00, -2.0802e+00,  4.1831e+00,  7.2985e-01, -1.7806e+00,\n","          2.9063e+00,  3.1089e+00,  7.6772e-01, -4.4883e+00, -3.2889e-01,\n","          2.9167e-01,  7.1153e-01, -7.7805e-01, -2.3169e+00,  2.4057e-01],\n","        [-6.4787e-01,  1.5529e+00, -1.4482e+00,  1.0686e+00,  4.2259e-01,\n","          5.5250e-02, -2.1682e-01,  9.1526e+00, -1.5390e+00, -5.1528e-01,\n","         -1.3427e+00,  1.4834e-01,  4.5896e-01, -5.4334e-01, -5.6402e-01,\n","          1.4017e-01, -1.1821e+00, -1.0051e+00,  1.9250e-01, -1.1394e+00,\n","         -5.2750e-01, -3.4204e-01,  1.7860e+00, -6.0306e-01, -5.9781e-01,\n","         -1.0430e+00, -6.1762e-02,  4.9358e-01,  3.2151e+00, -1.8646e+00,\n","         -1.1505e+00,  7.4809e-01,  1.1351e+00,  3.4938e-01,  7.0986e-01,\n","          9.7964e-01, -4.2830e-01,  8.7732e-01, -1.8112e+00,  1.1179e+00,\n","          2.8415e-01, -1.0305e-01, -5.3282e-02, -5.9011e-01, -1.1950e+00,\n","          4.1395e-01, -1.0771e-01, -1.6274e+00, -6.5071e-01, -8.5089e-01],\n","        [-2.7467e-01, -6.0075e-01, -9.6346e-01, -1.8389e+00, -7.4714e-01,\n","          5.0284e-01,  2.4738e-01, -2.0434e+00,  1.2623e+00, -6.0218e-01,\n","          4.1142e+00, -7.6197e-01, -3.8101e-01, -2.9863e-01, -7.6375e-01,\n","         -4.1939e-01, -1.8473e+00,  1.1746e+01, -1.3270e+00,  1.6887e-01,\n","         -4.0424e-01, -1.3557e+00, -2.2846e+00, -1.0831e+00, -3.8222e-01,\n","         -1.1575e-02, -3.5791e-01, -8.3939e-01, -1.0425e+00, -3.6588e-01,\n","          1.1674e+00, -4.0394e-01,  7.5735e-01,  2.5065e-01, -1.9843e+00,\n","         -1.9817e-01, -5.2105e-01, -1.4782e+00, -1.4544e+00, -1.5855e+00,\n","          2.3459e-02,  1.2004e-03,  3.3852e+00,  5.6646e-01,  2.6366e+00,\n","         -1.0269e+00,  6.5618e-01, -4.5530e-01,  2.9955e+00, -9.7512e-01],\n","        [ 2.8040e-01, -9.7762e-01,  1.0305e+01,  4.0030e-01,  2.4395e-01,\n","         -3.0492e-01,  4.1990e+00, -3.1760e+00,  1.2043e-01, -1.5820e+00,\n","         -8.0178e-01,  2.4485e+00, -1.9029e+00, -2.3623e-01,  3.1363e-02,\n","         -2.2267e+00,  1.1989e+00, -7.6196e-01, -1.6869e+00,  1.5091e+00,\n","          2.2569e+00, -9.6849e-01, -1.8387e+00,  7.6727e-01,  2.1017e+00,\n","          1.5699e-01, -8.7669e-01,  2.9550e-01, -1.8411e+00, -1.4875e+00,\n","          1.6144e+00,  7.0130e-01, -2.6288e+00, -1.4195e-01, -9.2128e-01,\n","          2.5468e+00,  1.9399e+00, -2.2676e+00,  4.7779e-01,  1.6218e+00,\n","         -8.6862e-01, -1.7902e+00, -1.9028e+00,  2.3469e+00, -3.9824e-01,\n","         -2.4092e+00, -1.6722e+00,  3.7274e-01, -2.4474e-01, -7.7621e-01],\n","        [ 6.4768e+00, -4.1982e-01,  9.8113e-01,  3.2338e+00, -1.4748e+00,\n","         -1.4849e+00, -1.4673e+00, -4.1655e+00, -1.5574e+00, -1.1674e-01,\n","         -3.3816e+00,  3.3514e+00, -1.5943e+00, -1.6454e+00, -1.7245e+00,\n","         -2.9308e+00,  4.7449e+00, -1.8432e+00, -2.7422e-01,  2.7289e+00,\n","         -1.7618e+00,  3.2431e-01, -2.0273e-01, -1.9754e+00,  2.7188e+00,\n","          1.1055e+00,  1.3847e-01,  1.1985e+00, -2.1858e+00, -6.6105e-01,\n","          2.3243e+00, -9.2466e-01,  2.6396e+00, -3.9581e+00, -1.1323e+00,\n","          1.8536e+00, -1.3034e+00, -1.3787e+00,  1.2926e+01,  8.1553e-01,\n","         -8.9530e-01, -1.6789e+00, -2.0269e-02, -7.1521e-01, -1.0169e+00,\n","         -3.6271e+00,  2.2793e+00,  2.4233e+00, -1.0635e+00, -9.9594e-01],\n","        [ 1.1756e+00,  7.0877e-02, -1.0912e+00, -2.1818e+00,  6.8409e-01,\n","          3.6593e+00,  1.5598e+00, -3.6473e+00,  2.2477e+00,  1.1204e-01,\n","         -7.9470e-01,  2.4414e-01, -1.5450e+00,  1.5098e+00, -9.5872e-01,\n","         -7.1860e-01, -2.8181e+00, -2.4547e+00,  2.6860e-01, -3.0753e+00,\n","          1.2004e+01, -1.1037e+00, -4.1380e+00,  2.9315e+00, -6.2807e-01,\n","         -1.0843e+00, -2.7915e+00, -1.0662e+00, -2.5965e+00,  5.6546e-01,\n","          8.3401e-01,  1.5069e+00, -9.6326e-01, -3.2356e+00,  2.8836e+00,\n","         -1.9523e+00,  5.6384e+00,  5.8870e-01, -9.3853e-01, -2.0300e+00,\n","          4.1064e-01,  1.3194e+00,  7.2250e-01,  4.0817e+00, -6.2908e-01,\n","         -2.3938e+00, -1.6916e-01,  6.2208e-02,  1.7117e-01,  2.7780e+00],\n","        [ 7.9565e-01, -2.2614e+00,  9.7017e+00,  8.7717e-01, -1.0567e+00,\n","          1.4125e+00,  9.0882e-01, -2.9415e+00, -1.2551e-01, -1.0782e+00,\n","          2.1538e+00,  8.9026e-01,  1.8913e+00, -2.8026e+00, -1.3916e+00,\n","         -2.0584e+00,  3.0349e+00, -8.9829e-01, -1.7408e+00,  1.5053e+00,\n","         -2.4805e+00, -8.2466e-01,  1.0782e+00, -2.0656e+00,  7.1153e-01,\n","         -1.5503e-02,  4.8145e-01,  2.0105e+00, -5.5970e-02, -1.2153e+00,\n","          3.3748e+00, -7.5093e-01, -1.3795e+00, -7.6563e-01, -2.3718e-02,\n","          5.0832e-02, -2.1435e+00, -5.2273e-01,  2.2410e+00, -1.2502e+00,\n","          2.1837e-01, -9.5204e-01, -9.6379e-01,  1.8971e+00, -2.7309e+00,\n","         -1.8513e+00,  2.7358e+00, -6.6490e-01,  1.3259e-01, -1.2070e+00],\n","        [ 1.4092e-01, -1.4071e+00, -5.0323e-02, -1.6911e-01,  6.9879e-01,\n","         -3.0335e+00, -1.1880e+00, -1.2883e+00, -1.1806e+00, -6.1229e-01,\n","         -1.8333e+00, -1.4726e+00,  3.6499e+00, -2.2979e+00,  4.3666e-01,\n","         -1.2681e+00, -1.2710e+00, -8.9173e-01, -9.0131e-01,  1.7526e+00,\n","         -5.9329e-02, -2.6725e-01,  1.2327e+01, -3.3690e-01,  2.1716e+00,\n","          2.3599e+00, -2.4915e+00, -1.4161e+00,  1.0823e-01, -2.4198e+00,\n","         -1.2566e-01, -8.4123e-01,  4.7564e+00, -1.3615e+00, -1.6203e+00,\n","          3.3811e+00, -5.8116e-02, -1.6149e+00,  1.6768e+00,  1.5452e+00,\n","          1.2733e+00, -1.0301e+00, -9.3344e-01,  7.6964e-01, -1.6949e+00,\n","          4.7850e-01, -8.9055e-01, -5.6027e-02, -1.1903e-01, -3.1223e+00],\n","        [ 3.7836e-01,  3.3520e+00, -7.2312e-01, -5.3754e-01,  2.2083e+00,\n","         -4.0675e-02,  3.4406e-01, -4.6387e+00,  5.1659e+00, -1.5691e+00,\n","         -4.2041e+00, -2.5281e+00, -3.0108e+00,  5.8566e+00, -6.9528e-01,\n","          5.6034e+00, -5.4521e-02, -3.7296e+00, -2.3055e+00, -3.5827e-01,\n","          2.2597e+00, -2.7580e+00, -3.1299e+00,  5.3098e+00,  1.7934e+00,\n","         -1.1021e+00,  1.2341e-02, -3.5736e+00, -2.5756e+00,  3.5613e+00,\n","          1.4880e-01,  1.4823e+00, -1.8910e+00, -3.2681e+00,  1.7810e+00,\n","         -2.2404e+00,  2.3924e+00,  1.1481e+00, -9.3628e-01, -2.6507e+00,\n","         -6.3750e-02, -8.2603e-01, -1.4872e+00,  2.6219e+00, -4.4253e-01,\n","         -1.9036e+00, -4.7133e-01, -1.6334e+00, -1.2060e+00,  1.2546e+01],\n","        [-2.3219e+00,  1.5480e+00, -6.3135e-01, -8.3479e-01, -5.2672e-01,\n","          1.2323e+00, -4.2265e-02,  9.7085e+00, -9.4880e-01,  1.1476e-01,\n","         -8.8256e-01, -3.6687e-01, -8.6937e-01, -6.6223e-01, -8.0067e-01,\n","          8.4371e-01, -1.0867e+00, -5.4637e-01,  6.8293e-01, -8.8792e-01,\n","         -6.5007e-01,  8.3210e-01, -8.2173e-01, -2.2970e+00, -1.5524e+00,\n","         -1.6803e+00,  4.9564e-01, -6.7169e-01,  2.6246e+00, -5.6741e-01,\n","         -2.1790e+00,  7.4594e-01,  1.4323e+00,  1.0209e+00,  1.3859e+00,\n","         -1.1228e+00, -8.3610e-01,  2.1783e+00, -2.5264e+00,  2.9673e-01,\n","          2.0948e+00,  1.9089e+00,  1.6392e-01, -2.6453e-01, -6.1160e-01,\n","          2.0920e+00,  1.7229e+00, -1.7179e+00, -1.6239e+00, -5.8060e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([17, 30, 21, 11, 26, 44,  9,  7, 17,  2, 38, 20,  2, 22, 49,  7],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8574,  8.2269, -0.8875,  ..., -1.7287, -2.1749,  2.5249],\n","        [-0.3124,  4.6933,  0.1019,  ..., -0.5358, -0.7686,  3.7717],\n","        [ 8.3682, -3.2009,  1.6175,  ...,  7.4543, -1.2900, -1.9914],\n","        ...,\n","        [ 2.0155,  0.3941, -0.7383,  ..., -2.1487,  1.6411, -0.4386],\n","        [-0.3480, 10.9502,  0.8782,  ..., -1.2999, -2.0362,  1.6565],\n","        [ 1.0532, -3.0591,  4.9403,  ..., -1.8298,  1.7422, -0.1139]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Epoch 399/399\n","----------\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.7900, -1.8556, -1.1777,  ..., -1.9826, -1.9060,  0.6423],\n","        [-2.2492, -1.8224, -0.3084,  ..., -2.5356, -0.6938, -1.2266],\n","        [ 1.8597, -1.5081, -0.6372,  ..., 16.9509, -1.0455, -0.1300],\n","        ...,\n","        [ 1.0722, -4.5593,  3.8550,  ...,  4.4484, -1.4859, -0.7796],\n","        [ 4.2262,  2.9350,  1.1934,  ..., -4.5204, 15.9100, -2.2148],\n","        [-0.9835, -2.5197,  0.5648,  ..., -0.9960, -0.2173,  0.6505]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([45, 12, 47,  8, 32, 49, 43,  7, 21,  1,  2,  7, 23, 37, 48, 47, 17, 16,\n","        41, 23, 12, 21,  8, 47, 34, 27, 43, 30, 49, 17, 10, 40, 36,  5, 18, 28,\n","        34, 24,  3, 44, 36, 14, 19,  3, 35,  1, 10, 12, 47,  9,  1, 29, 29, 23,\n","        10, 11, 30, 18, 47, 15, 22, 36, 10, 13, 44, 38, 15, 36, 43, 26, 13, 38,\n","        12,  5,  4, 11, 31, 16, 22, 10, 22, 45, 11, 37,  7,  0, 11, 31, 25, 46,\n","        30, 23, 48, 32, 16,  6, 26,  2, 10, 10, 31, 15, 42, 13, 29, 32, 14, 14,\n","        20,  1, 45, 15, 19, 14, 42,  0, 43, 22,  7,  2, 29, 21, 13, 27,  8, 11,\n","        48, 20], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 6.3358,  0.5614,  3.7728,  ...,  4.2685,  0.3398, -1.1021],\n","        [ 2.0022, -0.1449,  0.1640,  ..., -1.3266,  3.8735, -1.2495],\n","        [-2.4444,  0.4189,  1.9104,  ..., -2.3387, -1.9995,  4.3988],\n","        ...,\n","        [-1.6017, -2.4710, -0.4939,  ..., -1.1372, -1.4268, -1.1436],\n","        [-3.0420, -1.1966,  0.1521,  ...,  0.5771, -1.1660, -0.2387],\n","        [ 0.0683, -0.4163,  1.4227,  ..., -0.2088,  0.0355, -2.3985]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([24, 17,  4,  3,  6, 16, 44,  9, 42, 19, 31, 26, 24, 16, 24, 41, 31,  0,\n","        34, 29,  8,  0,  3, 29, 19,  2, 30, 22,  8, 19, 30, 27, 41,  6,  8, 38,\n","        35, 45, 27, 22, 13, 31, 14, 44, 36, 39, 41, 43, 31, 25, 41, 14,  8, 15,\n","        17, 17, 38, 28, 26,  1, 48, 24, 37, 10, 16, 42, 42, 10, 18, 42, 30, 38,\n","        37, 37, 27, 21,  4, 14,  8, 15, 12, 18, 29, 26,  3,  5,  1, 17,  1, 32,\n","        35, 37, 27, 25, 26, 20, 49,  3, 32, 35, 40, 40,  4, 39, 28, 48, 22, 36,\n","        20, 14,  2,  5, 36, 31,  7, 16,  6, 28, 17, 40, 45, 21, 24, 33, 39, 14,\n","         9, 22], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[-1.1074, -2.8668, -1.9467,  ..., -0.2823, -0.4009, -2.0322],\n","        [-3.9399, -2.7219, -0.7852,  ..., -0.3519,  0.4408, -1.5966],\n","        [ 3.6826,  1.8368, -0.2273,  ...,  3.2987, -1.6042, -2.7213],\n","        ...,\n","        [-0.1399,  1.7615, -0.9745,  ..., -0.8203, -0.9011, -0.6365],\n","        [ 0.9006,  0.2032, 13.9399,  ..., -1.5970,  0.9342,  2.0989],\n","        [ 1.8007, 16.3397, -0.1680,  ...,  0.9191,  1.5203, -2.0328]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  128  shape of outputs!!! :  torch.Size([128, 50])\n","checking process in train models!! ___________________ preds :  tensor([32,  9, 24, 29, 20, 33, 28,  0, 25,  4, 21, 20, 48, 28, 24,  2, 46, 12,\n","        25,  5,  1, 16, 33, 30, 31, 20,  9,  6, 15, 33, 36, 27, 49, 28, 19, 46,\n","        35, 18, 17, 30,  6, 17, 25, 34, 41, 23, 45,  5, 35, 28, 30,  7, 13, 48,\n","        40, 37, 13, 11, 45, 13,  2,  0,  9, 25, 19, 35, 12,  9, 44, 26,  3, 26,\n","        49, 32, 20, 34, 43, 11, 46, 47,  3,  3,  7, 27,  9, 40,  0,  0, 18, 20,\n","        16, 38, 19, 49, 40,  2, 29, 35, 49,  4,  9, 41,  4, 41, 41, 39, 40, 44,\n","        16, 46, 49, 47, 37, 15, 25, 23, 12, 39, 46, 33, 36, 18,  6,  9,  4,  7,\n","         2,  1], device='cuda:0')  shape of preds :  torch.Size([128])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","checking process in train models!! ___________________ outpusts :  tensor([[ 3.5146e+00,  6.9816e-01,  1.3577e-01, -1.4394e+00,  8.3525e-01,\n","         -8.5852e-01, -4.3211e-01, -9.0574e-01,  2.2081e+00,  9.9079e-01,\n","          3.2927e+00, -5.2271e-02, -5.6440e-02, -1.7736e+00, -3.0079e+00,\n","         -2.9442e+00, -1.4119e+00,  2.3312e+00,  1.4661e+00, -1.2559e+00,\n","          2.3001e+00,  8.4019e-02, -1.8357e+00, -1.6024e-01, -5.6041e-01,\n","         -1.4054e+00, -1.1292e+00, -2.4495e+00, -8.0499e-01, -1.9603e+00,\n","          2.1367e-01, -1.5862e+00, -1.1685e+00, -3.8408e+00, -1.3373e+00,\n","         -2.2038e+00,  1.1806e+00,  2.8403e+00,  2.0650e-01, -1.9126e+00,\n","          1.3944e+00, -9.9733e-01,  1.2469e+01,  2.9746e-01,  8.7667e-01,\n","         -2.1937e+00,  2.8569e+00, -6.3854e-01,  1.8576e+00, -8.0823e-01],\n","        [-6.5444e-01, -2.1986e+00,  2.5339e+00, -1.9370e+00, -3.1184e-01,\n","          1.2526e+00, -1.3865e+00, -3.8818e-01, -2.0967e+00,  9.4064e-02,\n","         -1.0047e+00,  2.6494e+00, -2.6517e-01, -2.0468e+00,  1.7626e+00,\n","          1.9776e+00,  9.5419e-01, -1.1636e+00,  4.6619e-01,  5.6939e-02,\n","         -2.9154e+00,  5.3116e-01,  5.8779e-01, -3.4034e+00,  6.1571e-01,\n","         -7.8744e-01,  4.8969e-01,  1.0395e+01, -3.7963e-01,  1.0456e+00,\n","         -9.6168e-01,  1.8676e+00, -1.7037e-01, -2.5292e+00, -5.9037e-01,\n","          3.7903e-01, -2.3319e+00, -1.7772e+00,  2.5220e+00, -1.4817e+00,\n","          1.9727e+00,  2.1059e+00, -1.3434e+00, -6.4202e-01, -2.9908e-01,\n","         -1.7851e+00,  1.8239e+00, -7.6611e-01,  4.0119e-02, -4.9431e-01],\n","        [-6.5245e-03,  2.7231e+00,  1.0887e+00,  5.5946e+00, -1.2764e+00,\n","         -1.2382e+00, -2.7710e+00,  1.1953e-01, -5.9019e-01,  1.5167e+00,\n","          1.2141e+00, -1.5940e+00, -1.0410e+00, -9.4419e-01, -2.7991e+00,\n","         -1.1972e+00,  2.5750e+00, -5.8426e-01,  1.3678e+00,  1.7913e+00,\n","         -1.8998e+00,  1.4046e+00, -2.3549e+00, -4.1754e+00, -1.8919e+00,\n","         -2.2770e+00,  6.8206e-01,  5.6253e-02,  8.4069e-01, -1.3705e+00,\n","          3.8961e+00, -2.4587e+00,  8.7145e-01, -1.5428e+00,  2.8070e+00,\n","         -2.3295e+00, -1.4191e+00,  2.3367e+00,  3.3356e-01, -2.3924e+00,\n","         -1.2104e+00, -3.1879e-01,  6.4788e-01,  1.7035e+00, -4.0146e-01,\n","         -1.8893e+00,  1.5542e+01, -2.0477e+00, -9.0562e-02,  1.0047e+00],\n","        [ 2.1794e+00, -3.8399e+00,  6.8653e-01,  8.3170e-01, -1.2443e+00,\n","         -1.3396e+00,  5.4861e+00, -2.3663e+00, -2.7445e+00,  1.7615e-01,\n","         -2.9269e+00,  3.5526e+00, -1.9598e+00,  2.3831e+00,  1.1012e+00,\n","         -2.8683e+00, -5.8073e-01, -2.1578e+00, -5.0112e-01,  3.7266e+00,\n","          2.8752e+00, -4.7453e-01,  3.3887e-01,  9.9964e-02,  2.6660e+00,\n","          3.3153e+00,  1.5476e-01, -2.7281e+00, -1.1789e+00,  6.8481e-01,\n","          1.7114e+00, -9.5317e-01,  1.0606e+00, -3.3041e+00, -2.6089e+00,\n","          2.9356e+00, -8.4414e-01, -4.6441e+00,  3.7862e+00,  3.4900e+00,\n","         -3.0655e+00,  2.3829e+00, -1.2278e+00, -7.8767e-01, -4.9401e-01,\n","         -2.8368e+00, -4.0350e+00,  1.0648e+01, -1.1038e+00,  1.9072e-01],\n","        [-1.1354e+00, -2.6291e+00,  1.2998e+00, -2.6478e+00,  9.7575e-01,\n","          1.1081e+01,  3.1471e-01, -1.7149e+00,  1.1458e-01,  7.0694e-01,\n","          2.0723e+00,  8.7835e-01, -2.6957e+00, -2.2387e+00, -3.2384e+00,\n","          1.2693e+00, -7.5750e-01, -4.1876e-01, -7.9351e-01, -2.9997e+00,\n","          1.7286e+00,  6.1508e-01, -3.6116e+00, -1.2475e+00, -1.5890e+00,\n","         -1.1180e+00,  3.7882e+00,  2.1974e+00, -2.1257e+00,  4.9634e+00,\n","          5.3913e-01,  2.1740e+00, -1.8554e+00, -2.4240e+00,  6.6203e-01,\n","         -2.3105e+00,  1.9080e+00, -6.0620e-01, -9.7008e-01, -2.3566e+00,\n","          1.2120e+00,  1.2750e+00,  1.0801e-01,  2.5627e+00,  2.4337e+00,\n","         -1.1208e+00, -1.9090e+00, -1.0556e+00,  8.3916e-01,  1.2479e+00],\n","        [-5.5792e-02, -7.0976e-01,  4.3989e-01,  1.0464e-02, -1.6679e+00,\n","          1.7124e+00,  3.7545e+00, -1.4639e+00,  5.9943e-01, -1.0780e+00,\n","         -1.3416e+00, -2.8453e-01, -2.3286e+00,  1.2631e+00, -5.7656e-01,\n","          4.5078e-01,  1.2134e+00,  9.8933e-01, -5.7333e-01, -5.7974e-01,\n","         -8.1961e-01,  5.3883e-01, -1.8587e+00, -1.1208e+00, -1.5040e+00,\n","          1.7208e+00,  4.7151e+00, -4.5023e-02, -1.3327e+00,  1.5670e+00,\n","         -2.7703e-01, -5.8177e-01,  4.5108e-01,  8.2050e+00, -7.2590e-01,\n","          2.8210e+00, -1.4980e+00, -1.0564e+00, -1.7827e+00, -2.0405e-01,\n","         -1.9141e+00, -1.0745e+00, -1.9861e+00,  1.6553e+00,  6.1539e-01,\n","         -5.4913e-01, -9.0302e-01, -1.4480e+00,  9.8199e-01, -1.1344e+00],\n","        [-2.2665e+00,  4.0290e+00, -9.1858e-01,  2.3968e-01,  3.6593e-01,\n","          8.0800e-01, -6.8902e-01,  6.4966e-01,  4.3281e+00, -1.8486e+00,\n","         -1.2926e+00, -1.5195e+00, -2.9473e+00,  4.1028e+00,  1.7228e-01,\n","          2.2912e+00, -7.5043e-01, -2.1642e+00,  2.9503e-02,  3.1375e-01,\n","          1.2390e+00, -1.1350e+00, -2.7595e+00,  1.7482e+00,  3.4744e-02,\n","         -3.1804e+00, -1.8280e+00, -1.2988e+00, -2.1618e+00, -4.8102e-01,\n","         -1.4863e+00,  1.9047e+00, -4.1317e-01,  6.0781e-01,  1.0727e+01,\n","         -1.3332e+00,  9.2269e-01,  3.7777e+00, -1.7831e+00, -4.3352e-01,\n","          8.3034e-02, -1.9867e-01, -1.7824e+00,  3.1290e+00, -1.0098e+00,\n","         -5.4895e-01,  6.1043e-01, -1.8911e+00, -2.0790e+00,  1.3956e+00],\n","        [-1.4125e+00, -9.8352e-01,  9.8027e-01, -7.9026e-02, -7.4937e-01,\n","          2.0456e+00,  2.1078e+00,  4.9169e-01, -1.6610e-01, -8.9304e-01,\n","         -1.3474e+00, -1.2374e+00, -1.3697e+00, -1.2289e-01, -6.8348e-01,\n","          1.2009e+00,  2.9563e+00, -5.3957e-01, -1.5631e+00, -7.1820e-01,\n","         -5.8990e-01, -5.3893e-01, -7.5044e-01, -2.7727e-01, -1.1358e+00,\n","          5.2493e-01,  3.0066e+00, -9.4744e-01,  2.2391e-01,  3.2969e-01,\n","         -1.5364e+00,  6.6515e-02,  8.2340e-01,  1.1186e+01, -3.2065e-01,\n","          1.3573e+00, -6.9885e-01, -8.5238e-01, -1.9228e+00,  6.8389e-01,\n","         -1.8663e+00, -7.5244e-01, -1.8458e+00,  5.9595e-01, -1.7341e-01,\n","         -7.3200e-01, -1.3189e+00, -1.8891e+00, -2.0244e-03,  2.4030e-01],\n","        [ 2.2969e-01, -3.3799e+00,  1.1376e+00, -2.6915e+00,  3.7225e-02,\n","         -1.0868e+00, -4.9243e-01, -4.7475e-01, -3.0831e+00, -4.6488e-02,\n","         -1.3141e+00,  1.1612e+01, -1.0885e+00, -1.8996e+00, -1.1210e+00,\n","         -2.2492e+00,  2.1687e+00, -1.5197e+00,  2.2156e+00,  1.9166e+00,\n","          1.1416e-01,  3.3129e+00, -1.5339e+00, -1.9696e+00,  2.5480e-01,\n","          8.2135e-01, -3.9156e-01, -7.8944e-01, -4.5176e-02, -7.3880e-01,\n","          3.1161e+00, -9.7866e-02,  1.3985e+00, -2.4022e+00, -7.6006e-01,\n","          1.1621e+00, -3.0272e+00, -2.4189e+00,  6.3650e+00,  4.0316e+00,\n","          7.9742e-01,  3.8752e+00, -1.3202e+00, -2.8961e+00,  6.4589e-02,\n","         -3.2992e-01, -1.7717e+00,  2.5425e+00, -1.6405e+00, -1.2860e-01],\n","        [ 7.0356e-01, -7.9664e-01,  2.4320e-01,  1.8552e-02, -3.6010e-01,\n","         -2.3198e+00, -7.7110e-01, -6.7728e-01,  9.7264e-02,  8.4246e-01,\n","          4.4426e+00, -2.0293e+00, -7.0577e-01, -7.4559e-01, -1.1702e+00,\n","         -1.8443e+00, -1.2164e+00,  1.3376e+01, -4.9800e-01,  5.8223e-01,\n","          5.0484e-02, -5.3735e-01,  1.6223e+00,  7.8255e-02,  4.3310e-02,\n","          5.2871e-01, -1.0108e+00, -2.7186e+00, -1.0082e+00, -2.2859e+00,\n","          1.3979e+00, -2.2557e+00,  4.6356e-02, -9.4833e-01, -3.5284e+00,\n","         -2.1841e+00, -1.0763e+00, -1.5637e+00,  9.0338e-02,  1.8626e-01,\n","         -6.9812e-01, -2.6849e+00,  3.8553e+00,  1.7568e+00,  1.2687e+00,\n","         -6.8672e-01,  6.1574e-01, -5.6902e-01,  4.4855e+00, -1.3797e+00],\n","        [-2.1702e+00, -1.7271e+00,  6.2141e-02, -1.6272e+00,  1.9744e+00,\n","         -8.3953e-01, -8.8924e-01,  3.3961e-01, -8.8005e-01,  1.7856e+00,\n","          8.9955e-01,  1.4542e-01,  1.3661e+01, -3.1604e+00,  2.7483e+00,\n","         -9.4669e-01, -3.2241e+00, -8.5646e-01, -5.9129e-01, -2.9744e+00,\n","          1.0399e+00,  4.9883e-02,  4.6772e+00, -2.0320e+00, -1.4264e+00,\n","         -7.3705e-01, -7.1349e-01, -3.2588e-01,  3.4596e+00, -1.9669e+00,\n","         -1.0336e+00,  1.6647e+00,  2.2489e+00, -3.7969e+00, -2.1933e+00,\n","          2.7163e+00, -1.7607e-01,  1.3625e+00,  5.7062e-01, -1.9964e+00,\n","          3.0092e+00,  1.7464e+00, -5.1480e-01, -4.7023e-01,  1.2723e-02,\n","         -1.1237e+00, -6.4158e-01, -2.6477e+00, -1.4810e+00, -1.4810e+00],\n","        [ 4.0421e+00,  5.5155e+00,  1.9030e+00,  6.1817e+00, -1.8460e+00,\n","         -7.5309e-01, -3.8846e-01, -4.9700e+00, -6.9333e-01,  2.1881e+00,\n","         -4.8533e+00, -1.6311e+00, -1.4502e+00, -1.6663e+00, -1.9596e+00,\n","         -2.4928e+00,  6.2083e-01, -2.1195e+00,  1.0172e+00,  4.1875e+00,\n","          1.3903e+00, -6.3304e-01,  2.5969e-01, -2.2303e+00,  1.4684e+01,\n","          6.8684e-01, -4.9344e-01, -3.6884e+00, -2.8533e+00,  4.6470e+00,\n","          1.7406e+00,  2.5682e+00, -1.6139e+00, -5.8290e+00,  5.2427e-02,\n","         -3.4588e+00, -1.2914e-01,  4.1913e-02,  3.3249e+00, -1.5699e+00,\n","          9.7501e-01, -2.7105e+00, -2.3536e+00, -6.7736e-02,  4.0400e-01,\n","         -2.1819e+00, -2.3412e-02,  1.0431e+00,  5.9848e-01, -7.7624e-01],\n","        [-7.2580e-01,  1.4363e+00, -3.7370e-01,  1.2173e+00,  4.1836e+00,\n","         -1.1074e+00, -1.4340e+00, -2.4908e+00,  4.5410e+00, -1.9809e+00,\n","         -1.5427e+00, -3.0538e+00, -2.1876e+00,  5.2657e+00, -1.1880e+00,\n","          1.8717e+00, -1.0071e+00, -4.3076e+00, -2.0419e+00, -2.6182e+00,\n","          3.0059e+00, -7.3997e-01, -1.4107e+00,  1.5079e+01, -2.1269e+00,\n","         -1.8537e+00, -2.6484e+00, -3.3068e+00, -1.2099e-01,  2.7346e+00,\n","         -2.4620e+00,  3.4446e+00, -1.9635e+00, -2.4395e+00,  1.9278e+00,\n","         -1.5146e+00,  2.9960e+00,  6.2011e+00,  4.0674e-01, -9.6346e-01,\n","         -1.8521e+00, -6.2190e-01, -1.0106e+00,  2.5742e+00, -1.7659e-01,\n","         -1.7974e+00, -2.5202e+00, -2.6948e+00, -9.3751e-01,  5.5488e+00],\n","        [-7.5259e-01, -3.4341e+00,  3.4207e-01, -1.1281e+00, -4.0762e-01,\n","          1.8748e+00,  8.4668e-02, -1.4556e+00, -1.1679e+00,  2.2304e+00,\n","          2.8651e-01,  1.6732e+00,  2.5352e+00, -2.7283e+00, -2.5510e-01,\n","         -2.1349e+00, -7.3554e-01, -1.0966e+00,  1.9457e+00,  6.5590e-01,\n","         -5.7891e-01,  8.4244e-01,  2.3016e-01, -1.3621e+00, -1.3923e+00,\n","         -3.7373e-01, -1.1219e+00,  1.0657e+01,  2.2057e+00, -3.4400e-01,\n","          1.6797e+00,  3.9296e-01, -1.8882e-01, -1.6898e+00, -1.3737e+00,\n","          1.9894e+00, -3.0212e-01,  1.7176e-01,  1.3209e+00, -7.0533e-01,\n","          7.5292e-01,  1.9188e+00, -9.2117e-01, -1.4778e+00, -7.1424e-01,\n","         -1.0336e+00, -1.2759e+00, -2.7131e-02,  2.6805e-02, -2.3809e+00],\n","        [-1.5871e-01, -1.1100e+00, -1.3861e+00, -1.1284e+00,  1.4503e+00,\n","         -2.0143e+00, -1.0969e+00,  6.0154e-01, -5.7175e-01,  3.9500e-01,\n","         -1.7680e+00,  6.4585e-01, -5.6330e-01,  2.1113e-01,  1.4618e+00,\n","         -2.6757e-01, -3.1182e-01, -2.6256e-01, -7.0176e-02, -7.8306e-01,\n","         -9.0722e-01,  6.9602e-01,  2.1056e+00, -2.3489e+00,  2.5615e-02,\n","         -8.0430e-01, -4.9685e-01, -4.1484e-01, -2.3343e-01,  2.3134e+00,\n","         -7.7261e-01, -2.5408e-01,  8.7067e+00, -2.4794e+00, -1.5699e+00,\n","          7.8816e-01,  1.4702e-01, -9.6671e-01,  8.2978e-01,  2.6106e-01,\n","          7.2102e-01, -5.6768e-01,  1.8981e-01, -1.2220e+00,  2.5541e+00,\n","          1.7773e+00, -8.9677e-01, -1.3225e-02, -2.1811e+00,  1.7722e+00],\n","        [ 2.2689e+00,  2.7771e+00,  3.0196e+00,  4.0430e+00, -1.4243e+00,\n","         -1.8457e+00,  6.3807e-01, -3.1525e+00, -2.5698e+00,  4.6104e-02,\n","         -3.5647e+00,  3.9914e-01, -1.7024e+00, -1.9810e+00, -1.7346e+00,\n","         -3.2522e+00,  3.4256e+00,  2.3358e-01,  1.0102e+00,  2.6113e+00,\n","          1.4052e+00, -1.8422e+00,  1.1099e+00, -1.6882e+00,  4.9790e+00,\n","          5.5816e+00,  8.8117e-01, -2.6925e+00, -2.4861e+00,  1.1771e+00,\n","          1.2030e+01, -1.4227e+00, -1.5902e+00, -3.0416e+00, -1.7031e+00,\n","         -2.5852e-01, -5.0612e-01, -1.9995e+00,  2.0669e-01, -8.3180e-01,\n","          9.8121e-01, -1.1588e+00, -2.2713e+00,  5.0630e-02, -2.0959e+00,\n","         -2.6988e+00,  1.1467e+00,  7.5484e-01, -2.1217e-02, -2.6899e-01]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>)  length of outputs!! :  16  shape of outputs!!! :  torch.Size([16, 50])\n","checking process in train models!! ___________________ preds :  tensor([42, 27, 46, 47,  5, 33, 34, 33, 11, 17, 12, 24, 23, 27, 32, 30],\n","       device='cuda:0')  shape of preds :  torch.Size([16])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","train Loss: 0.00 Acc: 100.0\n","checking process in train models!! ___________________ outpusts :  tensor([[-0.8608,  8.2380, -0.8906,  ..., -1.7346, -2.1738,  2.5176],\n","        [-0.3212,  4.7236,  0.0976,  ..., -0.5458, -0.7717,  3.7724],\n","        [ 8.3731, -3.2020,  1.6250,  ...,  7.4372, -1.2879, -1.9884],\n","        ...,\n","        [ 2.0150,  0.3953, -0.7376,  ..., -2.1529,  1.6359, -0.4391],\n","        [-0.3426, 10.9733,  0.8818,  ..., -1.3068, -2.0450,  1.6653],\n","        [ 1.0479, -3.0607,  4.9333,  ..., -1.8317,  1.7444, -0.1095]],\n","       device='cuda:0')  length of outputs!! :  50  shape of outputs!!! :  torch.Size([50, 50])\n","checking process in train models!! ___________________ preds :  tensor([34, 34, 11, 15, 44, 35, 28, 22, 15, 13, 39, 29,  8, 18, 40, 41, 38,  3,\n","        44, 36, 33, 22, 48, 48, 26, 40, 22,  7, 14, 46, 45, 28,  8, 46,  6, 48,\n","        20, 41, 40, 23,  6, 18, 34, 39, 38,  0, 12, 46,  1,  5],\n","       device='cuda:0')  shape of preds :  torch.Size([50])\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","valid Loss: 0.83 Acc: 83.8\n","Training complete in 29m 55s\n","Best valid Acc: 110 - 88.2\n","model saved\n"]}],"source":["#재학습\n","model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=400) \n","#torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/image_model_210110.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_sg9IdaO8R4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1642158796197,"user_tz":-540,"elapsed":18704,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"}},"outputId":"a9d853f4-8abc-4794-fe9a-ad8a5125840c"},"outputs":[{"output_type":"stream","name":"stdout","text":["iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","iii is 0      divison by zero???  :  1.0\n","iii is 1      divison by zero???  :  0.6309297535714574\n","iii is 2      divison by zero???  :  0.5\n","iii is 3      divison by zero???  :  0.43067655807339306\n","iii is 4      divison by zero???  :  0.3868528072345416\n","test done : loss/acc : 1.51 / 60.2\n"," dcg_mean : 1.14\n"," MAP@K    : 0.71\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAHEAAACBCAYAAAD37FXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eaxtWXrY9VvDHs50x3ffffPrrqqudrucdMV0W91xYgeSYAZbiohEArFwJBD/gQQSAoGEECiAEEIQEEIREgKEEiHEH4AShBRk05673W237a4eaq5683CHM+1hDfyx9t5nn/Ge+6paSUpvPZ13zt177TV83/rmb60tvPe8LP9oF/kPegAvyycvL5H4GSgvkfgZKC+R+BkoL5H4GSgvkfgZKC+R+Bkol0aiEGLU+jghxLT191/7cQxyy3H9VSHED4QQZ0KIx0KI/1EIsbOizltCiLEQ4h0hxJ/9MY/pihDiN4QQz4QQp0KI3xJC/OxCnVeEEP+XEGIohHgqhPjPLt2R9/6FP8D7wF9Yc09/krZfYCy3gSvV7z7wvwB/s3X/LwIfAF8jLN6bwM1LtH/8AmNKgS9W/QngLwHPa9gAMfAO8G8Cvar+n7x0P58WEoE/B3wM/NvAQ+B/Bv468OsLz3jgtep3AvznwIfAI+C/AzqfAkL7wP8E/N3Wtd8E/uVP0Ob3gL8P/DLQfYHnJfBL1fyvVtf+VeAbn3S+n7ZMvAYcAHerAV5U/lPgdeBN4DUCdfz7qyoKIe5ULOnOusaEEH9GCHEGDIG/DPyX1XUFfAU4EkK8LYT4WAjx3wghOttPja8A/wPwK8A9IcTfEkJ8fZsHhRDfBTLg/wD+e+/94+rW14D3hRB/r2KlvyqE+BOXGFMonzIlFkDauv/XWUOJBPYyBl5t3fs68N6nQIk3gf8AeL36+0bV77eA68AV4DeAv/GC7d8G/l3gB8D3gX9+i2dS4F8AfqV17f8BSuCfJrDWfwt4F4j/QVLiE+99tmXdI6AL/F5FYafA/11d/0TFe3+vauvvVJem1fd/7b1/4L1/CvwXwD+z6nkhxB+3lLVVys8D4LvAHxAWzK0txpR57/828O8IIb7cGteve+//nve+IIiWQ+BLW020KvoylbcoiyGRMQFRAAghrrXuPSVM4o0K6J920cCrAN77EyHExwvjWxu+8d6/seq6EOJPAf8SgaLeJbDXf8V7f36JcUXAK4QF8F3gZzdX36J8yuz044X7rwM5QealBMWlrdj8V8D/ykzQ3wR+4QXH8teAO9Xvu8CvAf976/5/CHwTuArsA98A/qNLtP//EhS3/4SKTW/xzNeAP0NglR2C0jcEblT3vwhMgL8AKODfIGirl2KnP1YkVtf/PQLVfUTQ7NpITIH/mLCqz4G3gH99TV93gFGNqBX3/0YF5HH1/beAw9b9CPhvgVOC9vw3acnvLeb6dUBeEj4/T6C4IcG0+DXg5xbq/HPA29X8f5XAmS6FB1E19LL8I1xeut0+A+UlEj8D5SUSPwPlJRI/A+UlEj8DZaOx/4v/4r/mdaSJ4gSBJ+11cWVJHGmElFjjiNIOXmqeP36I93D7819AaE1RWkZnJ5gi4/Ov/wT5ZEpZWv7Zf+Kn+cqXbuMBIQQIsbZ/USvOjbeuubNxUiubFCyb96L+qn9U42k/39behQhjqq6tVOwFeCrVv9V2MAc2DrsZ96p6Bwf7aye9EYk379yhyKdIFeGswQM6SYkijbEWoRVlYfBY9vav0h0MiOOY0pQo6Tl9+oDPfeEnMcZhvUBqzccPT3nz9ZtorUInzgegLUBeVJPejK7LFVEjaCMwfYWoUE3Q+q+1mGamWWuEwjfPiBUj37BeX6heXTYiMZtMwHuUktjSYL1HCM90OgEhiaMYj8BZh7OeIs9xHga9Licnj4niiG5/wHg0xZiStNPh2XBCXpgZEldNwlcQ9H7NjHxACMurtl1dCDEDtgcvNi0K0dRbuNL0Wd9btK0bCkIEQq4w2a4nLoGZ+rnZHDeT8EaZWJY5SaeLB6z3RLHGWw8ooihBqRgpNVJFWGuwRUkkPdl0Qq+7y+e/8JNYYzFliSkKAEbjKWfjfMYq67kF99HsejWJVZNvX2s4oIBFEluavPd4t9KzEp6txuC9xwvm8dogcD28FocaxrnqM1dr5fwaBHIxO9qIROscUiqEcOhIo3WEFxAnCVGkkVJgjUUIT55P6HRSnLUUeUFRWvACZwxFniOkIIo0RWl4cjquqCLImHqMS9O7LF9h5kZ0zq1cwfOIm782d8/NEI5r32uvvsCbm2fdrO7msojQdQjermxkp1JonHPk0xyhFMZ4ysKQpBFCamxZ4pzHOwOuREYRzliiSBHHMdl0ipCSPM842DnCWosxjsfPh3h3rUlaECzIqpVsa1ZhNZAWZOrCAvDetX57FpfOHOu9oIS2Vy+QDU9t1faCVrVSti6WjZQYRRoBxJ2UJE7AeyId0ekkRErhEOgo4tH9j4jTAVpJvHfEkcZ7S6wVcaS5eeM6nW6gUingbDjFODfT8mpW1nyzTBmbtZEWAOY/7TZmsmZWv8266t8XfV6sLI+/LQpWfbYtG5EokDjAWYdSCoFHaYlSMdZa8BZcjjEZhweHlKUBL/DOIwU459BSYssS5UFKgfOes/GUorDza8wzJ69WguESzvplQAiEqPOV6m9Ri8E5WTc/hkX1Zr2ps4hoX/2bm+SlynYLZyMSkzRBKYF3lrSTopWkk3bQWuK9odOJGZ4+YW//iG6vh9Ya6wxZET5KSZwLyPauRApBHEdMpgWTrKRW29tycWkac0rM/O/ZBBeBycp6y1S3fuXP+lrQRC8ht0T1D1YvwE0L9jJls8fGe7LplLIwSCGZTs5xOKaTMUVRYq3j7PSU6zfvYKsBRVGEc57SBMVCa9U4BpSURErjnOd8klVaX1irXoCQ61jXZqF/WTb0YixztamzXGe1Nrrc5uzZVdzg4r5nZaNiM9jbwZQlZVnQ7SYIKen3+xTG0e/3mY5OSLt90m6PSCuySUacpAgRHAPZNCeKI8BjihxfFEihQGhOh9MwkWqe7WEuKyU1cgQzc3p13dkzF9toi/bYRfVXAXO+nzWPNdS44s4mj1VzazO1bkTi6PSM0pSURYEpDePhOUIour0BUawZDU/Y3z/EO0dZFqSdiChWZFODkpLzzJDlhm4aURYFpfX4yZi9ZI/np+MwKVEznNXsq23v+7pehVBa7KgNDN9yBjRNNyIuPHehrBEE9nABAC+n1S528OmUjey0MxhweHSVtD8g7Xbp9vuA5+q1azz48H0e3LtHpz9ARYqiMFgLOI+1DucdQoQOxtMMKSRJpIm1JJtOOZ9kQUPFz6YjZkBpUg/mSHRWZ+XfdWnrJHLGZxs5KEXzrF+EZcMB5zXWOfY41946FjzPTrcv61nyurIRiWdn50wmGUVRMjwbcfb8OcOzc05Pzjl5/ozj67eZDM/J85xeP6XT6VAUBhUphudDhHMkcQQeyspHKmVwADx69JyPH50EpAGwbCjPIUuK5WuNIFwxz/r+YqnlT2XMt7xpWwGt7q5qqhnTsndmaTBrrm2DrE+ARIkHbxHOgndYGzTK0eicvMhIuh2Orx1z+uQ+ugKyrwzhaTYhTtOgZDuPsxaEwBQG5xzTbMpvfPsdzkZ1SujyCm+7UFdNS0CFlIUIwaLGWjXSaIN+GW2XLi/04ItS5+ayEYnOGZzzSCmJY413jjiOmY7P0FFCnKQ8fHgPax3j0YgkjYljxXg0ItKSXq9LaSwqUmgtMcZiRUB0kZfcf/SM3/r9dymNm5tfA+KayFpmga8wW1PTEqZblDmnwq9QXZuoxoI50QylLVYXHl9JW1vgZlGLXqVVL9//BA7w6WRKXuRMphNG4wnWOoSSnJ89Z2f3gJNnT3n66CFCJyAlZZkxHk8x+RQVRQil0HGMKQ2mMEgRIh4KKIsSYyzff/s+33v3QVBUF2TdqoU75/Kq5Z0ULdm3QkbOibJQt5aLswUj5rGyst+FslLbXP+5qCzbqhc/AxexU+GC9wUHrkRJAd6TTyc4W/L80X16/T06nS4P7t9DAr1uTJrEdJMuJi9xRYHAo2ONloJIhcElSYLCY73jd/7gHe49Oa0GXsmXmq1KOa95Vupqg5A5rrnoXmspHGuQUF8NOBNtnaZBUiO3xVxnly4viqSLykYkxnFCkmqECO6jKEkwpsQ5x+nTB+goprezy/PHH4M3nA9HnDx7jPWOpNvBWEtZFiRxhJYCpRUeT1kUOG8Ah1aC8bTg17/9Q0aT/MIBz1xaK+w8v2C3USNGzIe46gZmDS3I3erJNWbIWpNiS6xsZxu2LlzQ7uZQlLU4W3D96iE/9cVXee2VV3j17g1uXL9Or9env7vPs0cfc/r8Cb3eDqfPnnLy/Ixurw9C0Omm6EjhvKncd54iNxhr8Ai8EJS5AWN576NHfOP3fhDkY6t4vwpoYqHOnIq5xjvi5xHXfpZFOHkWSW0mJ5cR25gZi32vMEXm+9zCse49Fy2Njcb+X/lLv8Dx0T6Hezt00jQg1UOe5/z6b3+Tv/2//Z+cn55wdP02piyZjM7p9gZIIUhjjXWeKFJMJgXWG9JuHwBngwhzHqSWZFmGEIK33r7P0cEuP/2l20hZr6/V3v91GutSxaqJOvo0Y5/LC6FN0eHLz2G3eXYBGWtLE6VZGM+achnHQbtspMSvfvknuHP9mG4nRQjQWpPEmt2dPl/7ypvs9xO6vT7dbsp0OkbHMUUxpchz8nxKWUwRUkNFdVJSsWaHKQ3OFBR5gQMQ4Jzlt7/zI9567yHOrZ/MLOVi5nQMsmye9TROg/pWc2MNO17spxpX/WBo62Igr6WsFbJ6UXdbRZmfKD3DOTc36Pa4dncGvPHlN9nZPwzB3jJnePqUPJvinOfp48cUeYYzJVpLkiRpsgCsNcRRRBxpjDFopRBCYEvHdDrlN7/zNu989GRlaGo5zlipI4va5arS5pILgFnpr62emdOaEU0z24SJLmKXvvVZNFu2jWFeMu90NnEdaX7pn/x5+t2YoigYj4Z454iSDlk+ZTIM6YpKgVSSJI3xOMqyRCuF8xYAJTwSjxSCsiyxzjOd5nzjOz/ivftPZ6ytccO1JlZpqUsI3IojzWhgVRRhDm9QRVhkc2HRn1B3O+9zWKamFw8qry+bg8JtedC2zwg/rxzs0U0UUgpAIoRCSsV4eEaR54zHIz6+dw9nCrz3SCkQLiCiNJaiCDFG7yxZnoOS4MAZy2Q45f/7vR/x8OnZWnbSMKS2SdB2AEArP2bx6TmyZBHzbbk3Y8t+Fvvc5EVa7GlLOfcCVguwBRLnyXneZkuSlBvXjynynE7aQSDJx2Mmo3Occ2TTKSbPcM5RZDkISa/XodsJUQ2BxPvAXoW3CB8Sspz3GGt49vyMX/v2O5wOs4Z9tce20kCvDH8haMyKTUHnedAtp3JUf4Q2FqG8BdSXHlkSB6vrz2m8F/RxITtdJ2SFEEgpuX58xNnzZ5TFFC8F03yKKQt0FFFMM/LplMl4inOW6WSCVzK48vDkRUZhTGVWCMoiJ5tOMKbEO4dwnsdPT/j133+HybRYzZIaBWF1zH0bmVLPq41AP4/bOSVpkW5Xbv5kJue26XtxzNWNLZ6+AIntiS1Fvyu31dWjI6QUPHvyhDiKkBKklFjnQHjiOKLMcz587z0moxE4V8kXj7MlxhR4PFrrYHbYkiIzZFmJkhJnHPcePOeb3/uA0thVg6x/hHGynqVtYmtzGmMla1c909YmN7a5JlTf7mPxWvN7c5h/qWwtE+eooHJDWe+5enyVbrdDWRacnz2n0+kglSKfTkM9bxmePcdbQxxrlBIY64jiCCEg0hodKawzSBmywpXyGFNyejas0kMKvv/uI7711kcYuzqfNAySjSxuWQO9vBRayW637GOjC7BVfxW1bypbUeLcgFs2kwD2d3fY3dlBKcX5yXNGZ6coKZFCBAfAZEI2naAVjIdDjLGkaUycxEglKcuScpqRZwVlWYT8nLLElEUziSLPwVr+6If3+YMf3se6GdXVyoxftCuFmDnGWQ/cdTJqXbbbpmcuKpdBzGXKhUisy4yFzisTe7s73L51Hakk3sPJs2eEBClNkWfgPDqKcD6Ets5Ozzh5/gxnDVEUIfAh5GUMRWGRUpAVBcYYvC3IJhPyvCDPJhRFwbf+6D3eeu9RcAYEi32GsGpsvr2U3cICFGIuRb+ZW4NksXB9M1wWry/BbEUDm+TkZakQXmR/op/5KgWCKIr4/OfuECdxA8Qnjx+DUsRJQmlKjDMUZYkpQ0p/Ns2JIhWUEQFKSuJEo7QIWXI2yD4pIIo1piwZDUfYImM6mfI7f/geHz48rSIa7aEteGcqgDYp/bW2yow618nCTWWdEX6Rs3zx7krq935Orm+D0Msh0YPzbr4jD1949XN0O1201iDAmpzJ6JwoipFSUpYmsEhrEd4ClmfPTpBYdnZ6OGdxziGxeFsgpAcs1gXnAHiyrGA8GoEzjIZjfvO77/HwZDTHGeYmv44iGkDNs9lVzukXKdtqw6v6uMyz7bK1TGxYhfMVBYlmhd+4dsxg0ENHGqWCr3R4eoopMzqdFCUVOAdCYB1k04LHj54wPB8RxwmDnT4CMNbhvA+BY61wDqbTKWVZoCNJURryLMPkGaen53zj22/ztM6aW/gsatb1fFogW1DcZgrhtu6udtuL9ZsYJIETbIQzn0xWXko7rZFmrQ0RjervnZ0drl45RCpV1bNYZ3n65AnWWeIkDka8LbG2DGxSS4qi4Px8iI40/X6XTiclTZNqy4BESY9SAoQE7zDGkGU51pTYMuPpyTm/+d33GY7XHyfXHvci6OYRV3/mPTWLvxcAtFZbbefy1BGZWhlcarf6rOrjU/CdrkZi/bsucaS5dfs6SgdKVEojBJiy5PnTp2glQQhMUVAWJaLqtSgKzs9Ow8TwdLspHhvkkrMhYzzSCOGwxoK1FNMp08kYbyzCljx4csJv/9EHZHk5D8AVv9fFGVca62sM8DlqW2xtC611HdKXZfP2rPUCJC52OL9Hb+aUlrxy9xZRHIU7HkTlosumE85PT4ijiqX6kjzLwDniOMJ6x3vvfUCW5eR5iZYKgQt7H51DhPAx1jmMtSA8RWW6eGNwRcEH95/yu3/8EVlplihoEVCbykp/qZ9H4IvYlhf1uYklb4PIjUHh5RW9yL0ldWThxvFVYh0hpEBqhXchP0cIwdnJCcJ7dvYPsKVFRhJQ5EWOtBrnLKPzc65dv0aRezqdDtOsIEkSptMJAkGsFCIOPlePw5qS8WRK2g2TfeeDRxhr+JOvXefKXn8OEPX3InK31TBXwWObchHS1/dV8aZPw+1mrV1QDtoGcDvy7jk8OGDQ76CUrGpUq5qwHe7s9Bnj4Vm1Vc6gpMeZkjLPiJRGCkmWjRHCk3ZTet0O1jqkkEilSdKYNNFIrcF78nzKcDgiz0ucNThX8vYHj/jODx+Esxwq3+46RK26PuMsbRfj7N5iuch7s66vTazzx6Cdukr9D59lL8aMMnvdLlcO9qiDqPUqbH4D77/9PbLpCCEgzzO8D0FipRRpp8PZ6TmPHj4gn4wZ9LsMeilKaaSSGOcahBWFYTzJKYuMIssoC8N0kjOZZHxuR6Imz9f6HtsA28Rum3orWN1FgF9r5F/KhJh5aT+hYuMr5NXaXWh0XoCHDrTWXD26giAY78GZEhQg54LZkEQJ995/B1sGj0xZFngXfLBFWVAWBaPzc85Pz8imE/K8pNtJQr6qhyhN8d4hCIvLGsNkMibLcobn57xy1OWNA0/3/AHy7D7e1Q7zeQVtneIDK7TTDYiuF+lFZZ2ze339je7VpXKBTKz5+ryaPD8gX91XHO7voaSiyAtMxYqVh0TClcM9tEnYTTUx5zxzuxTGIBCUuaaIEkxpETJimmUMh2f0+j3STgcP5HmJNYZOmmKKHIEjL0KKY5kkfO7WNf7in7xFGgEK0vFzclNi926C0ksR97aYmOMYGyj4MmWxrZWI/JSUpM0HL0jJTA4GqlvFcnxlXMdJwtXjI8ajMcoUXOkIrh0dsBMZ0sE+08cPEM4wnmTIfMiTaJciL4AJQkikUug0wXnBw/uPGOwMuHk7ZTIZI6UmL0qiKCLt9ZmOzsEYTFlwNYV//E99nt3Y1Sl0qCglzUYUT96l3LuBSPtLrNH7ynHexs8isi6Qd5tMmAsRv+J+u7tt182FZ4D7yr+8yDrmHcbh3s//6a9x9/YNEAJ5+pCPv/u7FEmfJD9DpNA92KGYjHC2ZDAdkSN5Socsm4KQRHGKiiKc94HKhmGbXBQpkiQkI49GI7z3RHECpuTrrx7y5qGjO35M0T0ituEELLRGJQlpkSOfvEsxOMLvXMUhOD99zpN7H/Lko/c4f/aEV3/qy7z65a+G59awyG3Mlc3sta1HrC+Lj39KJkYt92ZKjKis9cUO+v0eP/WlLzHNM/KTPo/e+n2scyjv0TZHxhJhNEmkSeOI7vA5/fiQUxczmQzpAF0d1VYo2WTMw4ePuHnnDqOzM4ajCZ1Ol9OTp+ykMX/5q3f5wlEXZ0rk+UNMN6HQEFuDFB28jhAJxNkUefKA6dlT/vCtt/jmr/19Hn38EWWWkaQpx8fHZM8e0Tm4BkpTL8oZDOYBug3LXfbBznSKRUSuQ9SnYuwLIZmdOFFrq476TJiaLbVVeSEEnSSlf3CF3sEBUZIgZNi3r6RAK00cRaRxTKolg/w5PeXAOUyRYUyBkJIoSSit4fzsOaPRiL3DAw73+ijhuNUV/OIXOtzqhzN0kjhGODDPn5DnJSab4qYjKHIQApF2iOKYvjd8+fY1rh9e5cMnIx4MS774M3+WO6++Tj4ecf74Y2wxXYDBesTMAXmFmFkWPfPw3eRmC8/Wptxm/fNCSpzZh7L5XbPYdUUIgY4TDq7dJHvvPYhilPAIqdA6bHNL44hukmDtBGFPkfEhE1sGRDqLsw7vBdPROQ/vfUyn2yfR8LU3XqN78i5xcc5oHJKqbGSJhMRkE5ASFevqkD2BJAnUlaQIJel4x/HBHl+8fZ39z7/Omz/7c2RZRpIkeOc4f3SP3eNbqCRdiaxVvtVNYmbxfvveMqJl67l2O5vLFjKxHkh7AKG0/aertLu9G3d58P3vEsUxispMcZ40tZTG0StTrHVoaxiklveLhDyboHSEI5x5UxaW4ckznt6/xy//1V/iS5+/TjF5g0c/+EPO3/9hOFMuTUmiiDiKkUVGjgYckXcoHCqKkFEMUUI+zXn65DGvv/kVXv/HvgpehKy8siRNU7RznN3/gJ1rt4g6vTllaBVrXbw+v/DbSN8M53minlHeNgrsRiRaa5cMXAha6ypWUCO1ZgWDK9dIez3cZEja6xHFKc45ktE41LcO7xxZVrCTCG79xOv86rffosimCCmwZUG/1+drX/0Kf/7PfZ27t44RQpD0drj95tc5v3GXx3/8Lc6HJyRRSSex9PAhZlm5/bRzeGtQ1mKl5L0f/pDOtdscv/aTKBUCzt57ijw457vdLt5PKbIfsXf9Np29Q4SUczDY1j5cT0WXMS0u7msjEo0xczx6lZdik1odJ112r93m+bvfQ2vNYDAgSRLKA0Ov10eJ+3hjiYXg1VvX+Ymf/QrvPHrGD975kJ3BDl//mZ/hF/78z3Ln5jWUkvM2nZTsHN+ks7vPkx/9IafvfJ8iH1KWBTv9LimADzmtZVnimPDRvfs8nhgO7n4hUHlZIqVEKYXWGiEE0+k09JNlePchtizoXTlG6WjlHOfAfSFy18lUP/d9WfNxIxLLMg/2m5TVaYuiMfpX2Ys1hbZdVvu3XuXJj/4YU5RI7+nECYP+gF6vT5wkaC/o9/r89Nf+NLqf8Cu//Fe4/+gZd29d5/jqYTgXtRXkXeQMUdrl+hs/w+DqTR78we/y/OQh4/GYq4cH9Ad9bOmYnI9474OPsf09BldvNJyiRh7QILM0JdZYoijClAXjp48wRUHv4Apxt4eQy+e0rkbcTH+oy7ZInvdRt/9eXTYiMc/zBoHhI5vJzg1XBIA45xaoFfpXrqG7fbLxBDMowDpiqUh3OsRJwu7OLrHU7OzsYHzBrePbHF+7RhoFIV9nsXnvGy14sQgp2Dm+Tffnr3D/re9w/w+/yXD4IdevHYPS/PDdD0iPb7F3cBXvacbatCcDZVvnkDoKu6OrxVqWJfb0GePTZ8SdPr2DQ7q7+0gdsWguzI9ttea5XNY71meOnU/ATrM8Q0kVIu0i7LmQ1d/1AIQISF0U6AFAEqlj+se3eP6D7zKdTiiKPkknRUtJt98jihPK3DIuChye/PQZNk7J8glSKgZXriKlXimP5uSyAJWm3PgTX+F3f/t3ePz2Dxi8+xF7x8cMjm8SdQcYY5qxJ0nStOGsC54jAZGOQvJzlazlnMOXJUIIssmE0dnzcK5Pf4fOYIek20fqaA5BzgdZb4qS8egc4SxpkpB0u8ikQ619hthrSKQOY6lh2laaNuLvYiRaG9LpA4WZiuI0xtR2YUCiMTKc4SaCm07KeYD3j2/y4Xd/D30+pJCa8skJE+MYW0EvTbh+8waxGaGTmOL0fZCSKEmJtaK3u4eMg515UcReConQMQe37vLOu+/Q3TnAd3bJ8hI5mRBHEXV6Se2cL4qCKIrwrj5Jkib9pN22ECJs/rGG7PyMydkp1lmSbp/+zh4yjoO/2DnyLGMyGTEdjTl9/pS+KdlzUz735psMe8d4KVA6otMbECcJKopYPr1KXEiBWyHRGBfyb+VMzs00UDnH3qyt5ea8Juu943w85YyEzGgKl+C84zvf+x7p7iF3bx5zS8dEcRISqqKQHOWtJdndwRUFLkoRFauuEdjWlGsg19d/7p/6Ra5eu8YP/uDbZPm00S7zPCeKIqRWFEWBlLJJOanFhK8UnvZiqZWekH6iyPM89Gcdw+fPyEdDlNYIFRZblk3Js5zSGCIpcZMRWo6YPLrPr/7W38VoRXf/gFd/4kvcunuV3RtfArEKFWGPykW24mZj33m8nBm1zrm5Fdr21DgnkdKAqFdt2Ms3HQ353re/SSkkPR1WaxLHSOGYTEKDdMEAABWlSURBVEZgDnEVZdRtp50kLBZnsWUJlZZcy+RVXpQaERAOjHjjK18nShJ+8Hu/g1AB2aUxREkcFqi1yGpB5nnesNm2gmaMAYJcTJJkbozW2ga5YQE5cKJKenazaKAQdA/26KsuyjiOj6/wzgcfs390xP5As7s7AGpvzjoD/xMoNm1jvgZeDbQ62625ryRSzqik/pRlidIKMo9QQZ5OsylSCHYGA/Z2d5u+aiRopTEE06DMJ5Q6QkmNVDMNWSCWjtZcjMzffvWLfPijH5CNThmNhkRxjFSKTrcTxlUtioYalUT4gIia5dZytNZitdYNtdaIt9YiUSgJ1hiKoqAoirC4raVUknw0Zb+/Qz9N2dkZcOeVOxxdP8R3jgPSVvpat7M1LnS7NR9mK6tGqqvkZT0RhGs945AIrAm2mPOOsiig2yPPc6yxFaBcSIiqNNywODxSBIR5U2CyKYWQ1ULRqPpeFTwVQqKkrM68kY1WF8UJn/viT/LWN7/BaHSOkjocUeYckVJYEZKxtNboKi/I+hDErhepq+7Xi6e+blvcw1pLEkVzSHCVo8SUJVMvifaPeDopuHfvHp9/4w3ufv6YePcWTiZzdNdORNvOobDt62hFyDlzBOEuq0OJ2nLSOhtegFIh0LuQY2nKEutBRzFpmiKVJE1T7t65zTgrEc4G5UIHWRUUGIsUAiV1WNl+QukFSskqHVI2spcKiVIEJEqhq3thoSVRRJLllN6TFXU2eUav2wMcQkh6/T7GGqQMykSNHKU1UiuiJA4nZFVHYfvKLGlMMB1kqSnDsaLee5LqtJG00w0ZBrv7PHn/fY6/8BqvfPEW/St3sHqnBvAm4F9wfwuPjVLhCCjVshNlpanVssBaWyFRY53DOYO1BmfDOahFPg1pFUIEdtbp0ElThsMRcRRhTTi0z5QlkY6w9YEPHtzYYmLL2NhqAcmGKpRSweFdm0BCBhbLLGrgnaGDRXvLCMFoNMT4MaYs6HZ7GFMgpSBOwquTyip/VQgR2G3jKXI4F8RGaFgEE0xrdBQxrV4EEw6rCEVWbVjvOckd0fF1bl/vs398BxcfVmammHN318GFmYjYiL/tkFizUlremoDIGpiaOA7qcXhlgqm+Q7b38PlTTF6gla4Of/c479BKEelw1LRzFiFp2tRaN/szBB7pDNPROISV5j5ytrAqedl8ZACgF4JoZ0D56D49oelEESMbtqLHSUjEmk4ndHtd4jhtlJkoikJ/LblZa4vOhfGXiMbnCuHwiDwP4S+lVAOvtJOgtOTgYJfDmzdx6TEeQfuw1Rny5nEwr/C8ABKds0Hm2uAVqV1vXqoAJFU7AmYanXOmQmQc0gifPg4HLCQKU1FcW8bgPcaG0FOQQdX2AILdZo1BOR0WhVsO3yzGMtsyu3HN3XqFeHyOG02gyFFCYJUAZ/AqpiwKTk5OEGLmiaq3v7W18baDv5aL1hqkkigVVa9Z8uiWphvHMYOdPgf7EYfHx7jODZoU+BXenrbyuK2jfbNig8O5sDyMsXjKmVdPiuo872rfIsGdFUWaKKr3bJTsDQY8k54kiWfuLiURlfsrLwpUpENf3uCruGWkU4wJ548jBJ045nwynSEf5hSrtumxiFCSHsXhLYrpO+x3OnQrD4txBaPSI9MUYw2j8ZA4SsJbBSou1Eae975i/b5hnTVX8i6c5xrH8WwcUpB2Yo4OIvaPr+N6t9bYgzNErkbg5g05F9iJgPRBa8POWGrVQeNLFbrlnhMoVU04H6POHnGUCHJviCJNWYQAbBTFuMhxPjwn7aQNq3TVdm4hZFAOTInA048jzsfgmdlq7cm2g7Q1V2gHbZODI+599CH3H50QN3k8JcY59q4ccuv2XYTweG8pSotxwQ5UVbKyEKLxqRpTIgToykXnK14YVR4fU5Zorel2Eo6vxOwd38T1b+KFWrIaFilt8e9tssAvjic6hxUSpcNEDCVo3bCS2suBWDTGPY8+epeOzTi4ecTH9x9TTCI6+0fBlefD9rU8y7AmsGAlJUkchZxSa3HeE3dSyjwHU6KVoLQL54LXE/cBwe3V3AZKlKR87o03+fhHbyEJx7dYa/DOYkrL2clT4jhmPB6TZ1lQwHpdBoMBg529YPZUG4WiJJ5RO2CNwztbacdh8XVTwY1rPfauv4rrXgPkHAJXscnt45SXQaIzCCQIXzl1PU5bgmpe+04rTVHOnOBSKry3jJ/cpxNrrh7sEyvJex8+xPV3UJ1O0LoEIHzYhJqXCCCOQoKw94KyKCo/rEQ6w163w8k0Dx6eudlD+20wc+EwZuw17na58coXGD5+gJSCSPWa0z6SOMaWOQ8+/ojh8BznPSqOuXVtn6/+3M9Tlo7njx8wOj2lKEpANppoYKuCSEckqeBwR3J07Yjkyiu4ZH9JW6m1zsZMWlNmSP1Eik3FiyvzIOx/n3ncvQ8KCW72yjzvIYplOBZzMkbkBcJ5rh9fIx+N+fjkETuHR+RZgXcWrYImWlpL7BPyfBoiEji8sSRxGl7vJxVX+gNEUjDNc4oibxSl5hUKvhWyQjSpKm2nRdzrMzg6ZvL8CVEcoaOoMX36gx1++mCfjz74gPc/eB+852ivy+DgOjLucuXWq2Tjc04ffcSze+8xHGVYC5GSdBLF4W7EwdEh3cM7qP4xqGgOnm2E1T9flPq2RmLoxFWbYwTWGVzhkMZitcXbCBe5YM+5oGXGsa2cxgoZpzx5+3vsaknv1k0G3Q7+/kOm56c4GYAXRXF41gQtr/aggEQKhfNgbJAxEs/R3i4ZkrzIKfKcIsvDuQCmXIo8LAaTQ1o+RJ0+nR1DOTnHeUscJ4DCOEev1+f1L71Bt9fjow/f59qtuwidhhOlpKI72KfbP+Dq7deYnDwkHz1DSUWnv0M6OECmuyD0PGI8y69u2KLMmvgEvtOmASHwhL36IWvaBe9MpWY7G76NNeFkYmuwZcHeK2/w9u9/i8m3vsX54wcUUjE8PcE+ecjh3S8Ex3Kakk2z0IYLURNfOe89ITanowglw3EpiozeYI/+YC/I0spLkuVTsmwSXqJiymCyMNshPOdC9B7V6WGdwUwnRDrClKaal6PXS7lz9/P0OjFHNz5XOTba0PXopMvutVdAvFLFBKtIPjQ7wtbJwNU5qbDMNj8Ft9tMtswaDUrMTEusTQNrC4wpMWVEWeT88Pe/yfnTJ+y99lOY02e8c/qUJw8/4tnpOQOTsHP9LlkVGnLOVcgPMkaKGfCV1qgqKKykBGuwkzM63R5pZ4CvtFljw+kc1piA0OkkhITyPGTEtTVa4fFCIpM+tizJphM6nR7WePAFY+8xqeHWndsM9vYR9UuGW1GGmjsFZDSYCqHeCzPbFjXQ5vGm/erO5oaqshGJ9UBDJ7MIdD0Q7x3OikabNNZQmogoKnDecX52GiL4u4cc3LzD4U9JJqMR3//+9zHWYE1BpIPKjofJZByCpFoHg9zaQH1CYn14m41SGqyjOHtG7+gGKg1hq4i4YZm108CUJXk2ZTodMx6NmE4n5HklS204CIIorU55nAaN1QGlw+Qn7OsYHb+G8I5w4u4s+l7DeeZR8bNkjealwrQrbdRIZxr1YnD4kyJRtrLLqsHU2lJYc7PtXzXwbHV4e9ob0B0M6PR6eA+j0ZQojujv7PHKa69jrSdJ0ko5CUdlOm/wleM6joInJTKmUZpMaVCRJvYhJjh9/oj+0U20jhpNb3G3U3+wE95lZUqKomA6mTAenTM8O2M0HIJ3GGcRZoIrR3S0Z68Xc3R8jb3bX0L1roa26nmv1ChbR6q0/g/e+Xl5uG5Py3rl5mKkXrArakaF4UzTKszS0ghnKyhkdpmyDB6MyiPT7XYZ9AdEUYjDZdMp3TRmMjphsHvAeDTGA+PRCNuJw+KwHhMH6oyiCOtmJoWrZHJRFHScwzrYuXoDFcczvtSMv3JvKYWOIjqdLjs7u3h3jLWGbDplPB4xPT+jn2qUHZN0u3R2j1Bxr9l+QBNLbQN7Hl3t4us7olVTzCOw/m4oe00RYmlaS+UCJKrgP23x/noi9X6MGrmVXMeJmnpn9pDSIagaRTHdbo/9/T3eefstiukJ4+EpSafHeJohxA62NJSlpdvtkiQJw+EQNVGNQzlJE/AxSiuKIsf5M85MQbp7SNztoaN4ZVphDTghRIh8aE2SdtjZ24cbt6iDsC31AyEkXhJs5XqOM57JahTScK3G9Gm1WY9jNqbmiVmthTTHi8pGJGqtKMvabzfv2lo0pMMLtEKWV1Ocx1kzi45XA1ZxzODoJmm/h+T7DM/PMUXJ2ZkPRrf1SKUorSHSGiFBeA9OUuTBl5sqFaLmPqcscvLJOMT8dIyKEw6v34aWI3oGtBW/6zlUAVlRUU0ty9oHdQnETObNWpoBvZ2ttoCcGfVdZBteTi5uRGIUVfko1dEidf6MEGJeILdU92YYVR5nnmVkk2nl1ZHBlRZF2DznxIA+uMtO/Bjl7/Hw2RkjNAcH4TXwCEG/38dYB0JinEFXMb3cA0mCqA56sNZiJ2OKsqSTJKTZGd2DI+TBjTkALoFrCakLGueKenMIXKy4AfafpqutXTYisZN2moE5N+/qahDJzIiuBxWQSkh18CHOFnyMNgRVCQcYPXn6DKqVq7pHHLnHnE0sZbWfXypFlmVYZ+l0u2H7mzeQgdUh/SFJ03DeXNW+lpLJeEQqDEmkMfvXkFIvA3tlWY3AtbWXELuIkHlWugphqxH4KWqnvd4gpOBJQVEUc4lRDdXVxvTCwIQgHBMGlMagshxijybCKU+/36N88GjmQ0QQda+yI58xLUqMLRHWzLnStNYgg+kRvDtBE3a1V6ayAYyxDLOC4vkp8uCc4Oe0JGlK0u0vYWkx8fkiI/vFAD9jpRe1t86Jv65cgMReFfCUSDFpgp7td2UgwVs/x2IFQTOVQlAa08iXYJQbhAmbTYW3OB8c3EIKrJDIzhVi85iyyNBRwnQ6xuGq+GWIkiBDu7ryFgEhM0CGLPVON2WYRrh+Smd4j0hBjEO7CJm+hlPpEqAWAbZorrxYWZSdqxG9qp/L9LkRiWnaCdH7CjgeT57lDfXV4rtmkUjReFC8CMixxuB8CATXCUXeObyANIrIyiqwqirbU8Yk+9fQ+Rm5y9FRBwipj0IIEpIq5AP5dEwcSXppRLcb0+2HQ4zitBPigAjQHWSUhtcDClX5bGeA+jRk0icvP0aZGMdJk5JRZegjPORFUSUyVTRZsTMpRBOaEXViFVW+CpXM0gprwuF7g/6A4nyI1ipQexOLVBBdoV+OKItJdXy0phd32e9odgeeXkeTJpo0SdA6wssYF/WQ6Q4iHeDiHkLHCKHwQuCFqkyEWRho2VsyK9tQ4ZKCt3CvAs26pzeBfmEsm+9fYGLUuTDVRpo6QWo8Ii/yRompB11TYOMLlAKsq9IQIS8y8gyiSCOFZ3+3zyjPiZM4+EWZab8CIO3QxbJPTieG3X6fQb9HknaQOsVFKRPVRcVdorRP3OmHMwKqDD0hZLXFwQMO78NKXAf0LUyyBeAuuiEveuLHQ/EXnmNTAzWkCFb7LaREjIZkeXXOqK92AlWzkNUB6kp4yukJTCFG08EQRxItDYmUTMWAvb09ojgOoSsZ8kqjSKN1RBxHxFFCkiTEkQ4n92uN1iFfRyoVkom1CpSvdJXvUxvtDnztMltfZnJwW7DNlKBlpWTbNuoypxIu3/2kxn5DFULg/SzvtHmVqw9bwpwE6asNpoAXEi8VR1d2IR2yt6Po9HeJOjvotI9OuggZI5zkVcImFVUhSKqArBC9UJUzvMrwVhIlZIj2N26thR3MiBVgqXI7hZ/zyVwkC+dvLyL64mMzL4b/ZkVn27JdKEpKBB6h4iZNUeuIJI4ZjyfhNUFNYrFsXGT6zufQSqJ1hIoiIh2hlawO9KgPvq32VMgQBJbV+37rpCtRubtk8OPNO7s8UCsmokLqspXePBf+FCu/W7Nu9bA9MGdxy4sWxyILXqchB2r/VCiRujkhGkBKqYIftNNjd7cMSGyxJFkddSKruqJK+wcQ3iH8LNlJKgVVCj5SIAkp+m1QykqJWlTBm13EsrWVrvZxUrHRymZdRYEXa6Wb2Nu83XcZTbftfptvK8yg5i6tXje2dyElzuRi3VZY8VpHKKWJ42QuBWL+E1guPhxg5D0IX1GiINiHWlGfkTPnj21GEeTa7K2FLSS0IivNc0LOalZvk9s0v2Wgr0PCIiDn/75Mwu9q4qoBHOY0j+BPYOwLUcuSQEl1XEwIWXGui11IgYpB+Cry4WeyDKlYlGnLReKr166JajftbC1Vz3hA1OObAaJZ4XOjWSyLBvnKGWy4v1B7a81GrPldj2meF20qFwSFZQseLbnS6rwxnJfCKW13XLgnpWpkVmhyxUEKK4FQrU4B1VFRCB9YfEgB8lRMl4rEgz3IbHPNYtyzHnvNwmoWvFy2cactU+XmIO+s3Vm99kkbmxC8XDYnSq14fk4uhQvUaSViRb16H/+qiHaDzoV+VnkwPcwBOuwuCIio1KNQTwja7xEKG1dqRM7WiPd+QQlZpcysY7WLiJ3Va7PV1W3Mtz/bl7+q/nZUvcWhta0mG3Ojkn+1rV8D1K/ydMwGGa7N9qHPB01XeE1maF6Yj2g6nrUhqI/TmrcLa6VhPTCXlZJt5WL7mljzexMlh3qh30WWuf3J/xckSknq5KgG1K2GZzKyRWGyJafabTWaUfswo0Vgz9PzIkeqrTxf3QzUKZvv9cBvU0rNbZepZ7Hup1GWNdHV99fd2waPF5sYDVxXe9rnkBpGOycf5ylzkwJD3dHaOvV1uUZuzi+3y5X141pWfLYLE82ocT1FrWa58/7YTyoT2/3I2YpaFTJZp8OtM2hX1GSRxdX9tf+e1WVN3dnElyjZz3+37y/ae6ueX+xv9RwW+2zPfREpbWVm/l5bEbsIkRcjUcwk0xwCG8WgGnyjnywHNBdZ16a/L2I/69pYqMF2cm090DcxjNXa5+rxtuv6RpOef262qOYPCL6Yc4Wyxav3JOGFW/P2XB1Nr222dTC/iAoXBznHni9A5LaCf1Xdi0NFcy1sNabF+222ePFY12nCF5ft9mJAszRXeWbqPmdadUWZzaPba1qLfWxbd9W413W5vHBaw17bZaDuZba+Qqv2fmVbMy04PLvIamsZuGw/b4bdBUj0tTVAbQwu5lI27GeOpc4meJGfcr6t1aNY8gytGe0qVrzOrSbEPPIWx7B5/awyi+YRus4RvmlhrhMTFy3mC/bsz8tDnG9S+2dDr6Exr5XWiu3CFOb/asTreqBvhcBKOC+aClt7wC5VPlmjm7w5i9ebDPaLRnTZ2NXL8g9fufyLoV+Wf+jKSyR+BspLJH4GykskfgbKSyR+BspLJH4Gyv8PRMwuZkQ8LZ8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["## TEST!\n","test_and_visualize_model(model, phase = 'real_test') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSiJYn2JO8Th"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1345,"status":"ok","timestamp":1641787821995,"user":{"displayName":"HYUNWOO YOO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04434741534059157516"},"user_tz":-540},"id":"TTop7GS0Ky-G","outputId":"96523f18-7a15-4b74-e299-a0ca94943196"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(  \"/content/drive/MyDrive/model/image_class/president_model.pt\" ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZm_7LuwKzCU"},"outputs":[],"source":[]},{"cell_type":"code","source":["## TEST!\n","test_and_visualize_model(model, phase = 'real_test')  ##president_model (from 210109) #test done : loss/acc : 1.46 / 60.4"],"metadata":{"id":"ZMqbiP1G0rnK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txpxk-yPLmLf"},"outputs":[],"source":[]},{"cell_type":"code","source":["## TEST!\n","\n","model.load_state_dict(torch.load(  \"/content/drive/MyDrive/model/image_class/complete/image_model.pt\" ))\n","\n","test_and_visualize_model(model, phase = 'real_test')  ##image_model (from 210109)\n","\n","\n","\n","# test done : loss/acc : 1.44 / 60.9\n","#  dcg_mean : 1.13\n","#  MAP@K    : 0.72"],"metadata":{"id":"lBb5eRnP0zQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POeZzGrtMGZ_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WqEzoFLLmR8"},"outputs":[],"source":["## TEST!\n","test_and_visualize_model(model, phase = 'real_test')  ##image_model_210110 #test done : loss/acc : 1.55 / 57.8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CeRINZh1aRC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5sIQWxLiaj-l"},"outputs":[],"source":["torch.save(model.state_dict(),\"drive/MyDrive/model/image_class/image_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjIYRGsVfkxN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPX7zh7VwfvoVYf1oiWOYmW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ae742debf36e46b9959f80d17905c3bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_491ce6f0bbe94bc1a96bedff398c1156","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bafb0098355b4ad685817835d3f0fbee","IPY_MODEL_2f3f7be9fb7e4b32b73ab4d456cfbe95","IPY_MODEL_5c683f3988b749f098f352813d2963ab"]}},"491ce6f0bbe94bc1a96bedff398c1156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bafb0098355b4ad685817835d3f0fbee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2f601e9d16e4516972d594ded243a2d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e68a728b1a214015a1b498c86f015a96"}},"2f3f7be9fb7e4b32b73ab4d456cfbe95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b11419d2bacf42e5ae69f959f050d956","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":21388428,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":21388428,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a311e4701afe437bab2297a05908ad40"}},"5c683f3988b749f098f352813d2963ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7f7b1dff71d94d9c9698fb412991cfe7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20.4M/20.4M [00:00&lt;00:00, 116MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81b4f8da046240d5ab6d3dd0c14196b3"}},"f2f601e9d16e4516972d594ded243a2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e68a728b1a214015a1b498c86f015a96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b11419d2bacf42e5ae69f959f050d956":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a311e4701afe437bab2297a05908ad40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f7b1dff71d94d9c9698fb412991cfe7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81b4f8da046240d5ab6d3dd0c14196b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}