
학습데이터는 sparse한 벡터형태의 데이터와 2개의 시간데이터, 4개의 숫자데이터로 7가지 필드로 구성됨  
각 필드들은 하나의 단일 unit의 feature들이라기 보다는 두개 이상의 unit의 feature들로 보여짐  

약 20가지 라벨로 구성되어 있음  
위에 나타난 것처럼 label은 종류별로 불균등하게 분포하고 있음  

***모델-train.sparse**  

feature들이 독립적일 때 성능이 좋은 트리모델 기반의 random forest모델로 학습을 진행함

이 모델은 Random Bootstrapping으로 불균형한 분포에 어느정도 균형을 주는 효과가 있음

***결과-train.sparse**

주어진 학습데이터 중 20%를 샘플링해서 테스트 데이터로, 나머지 80%를 학습 데이터로 하여 비교 실험 진행  

|                    | LogisticRegression | MLP    | RandomForest | XGB    | LGB    | CB     |
|:------------------:|:------------------:|:------:|:------------:|:------:|:------:|:------:|
| Accuracy           | 0.3102             | 0.6168 | **0.9837**   | 0.8915 | 0.5001 | 0.7608 |
| F1-score(weighted) | 0.4397             | 0.6554 | **0.9838**   | 0.9014 | 0.4825 | 0.7612 |
| F1-score(micro)    | 0.3102             | 0.6168 | **0.9837**   | 0.8915 | 0.5001 | 0.7607 |

전체 학습데이터를 이용하여 kfold cross validation (k=10) 실험 진행  

|                  | LogisticRegression | MLP     | RandomForest | XGB     | LGB     | CB     |
|:----------------:|:------------------:|:-------:|:------------:|:-------:|:-------:|:------:|
| Average Accuracy | 0.31069            | 0.62701 | **0.92906**  | 0.88708 | 0.51560 | 0.6954 |

***시간 및 추가 비교**

80%데이터로 학습 소요 시간 비교    

|                    | LogisticRegression | MLP     | RandomForest | XGB     | LGB    | CB     |
|:------------------:|:------------------:|:-------:|:------------:|:-------:|:------:|:------:|
| Training time(sec) | **11.185**         | 169.088 | 17.719       | 322.018 | 80.199 | 31.135 |

kfold(k=10) cross validation test

|                     | LogisticRegression | MLP     | RandomForest10 | RandomForest800 | XGB     | XGB1000    | LGB    | CB     | CB1000  |
|:-------------------:|:------------------:|:-------:|:--------------:|:---------------:|:-------:|:----------:|:------:|:------:|:-------:|
| F1-score(weighted)  | 0.4410             | 0.6574  | 0.9029         | 0.9322          | 0.8971  | **0.9513** | 0.5915 | 0.6966 | 0.9481  |
| F1-score(macro)     | 0.0463             | 0.3596  | 0.7564         | 0.8138          | 0.8647  | **0.9298** | 0.3488 | 0.5499 | 0.9177  |
| F1-score(micro=acc) | 0.3107             | 0.6236  | 0.8981         | 0.9292          | 0.8867  | **0.9498** | 0.5749 | 0.6954 | 0.9463  |
| Avg Train time(sec) | 12.812             | 183.858 | **2.183**      | 185.708         | 321.955 | 3075.126   | 70.566 | 31.328 | 310.612 |

(LightGradinetBoost는 tree 수 늘릴 수록 성능 오히려 떨어져서 LGB800제외)


dense의 경우 벡터형태의 데이터로 100 이상의 필드로 구성됨  
각 필드들은 하나의 단일 unit의 feature로 추정됨(100을 넘는 차원의 벡터 형태)  


label의 가지수와 분포는 sparse한 데이터와 일치함    

***모델-train.dense**  

feature들이 하나의 unit을 이루는 형태이므로 딥러닝 모델로 학습을 진행함

***결과-train.dense**

sparse data와 마찮가지로 주어진 학습데이터 중 20%를 샘플링해서 테스트 데이터로, 나머지 80%를 학습 데이터로 하여 비교 실험 진행  

|                    | LogisticRegression | MLP    | RandomForest | XGB    | LGB    | CB     |
|:------------------:|:------------------:|:------:|:------------:|:------:|:------:|:------:|
| Accuracy           | 0.9642             | 0.9838 | **0.9907**   | 0.9768 | 0.8584 | 0.9808 |
| F1-score(weighted) | 0.9662             | 0.9838 | **0.9907**   | 0.9772 | 0.8574 | 0.9809 |
| F1-score(micro)    | 0.9642             | 0.9838 | **0.9907**   | 0.9768 | 0.8584 | 0.9808 |

전체 학습데이터를 이용하여 kfold cross validation (k=10) 실험 진행  

|                  | LogisticRegression | MLP         | RandomForest | XGB     | LGB     | CB     |
|:----------------:|:------------------:|:-----------:|:------------:|:-------:|:-------:|:------:|
| Average Accuracy | 0.96646            | **0.98373** | 0.95980      | 0.96814 | 0.85555 | 0.9665 |

***시간 및 추가 비교**

kfold(k=10) cross validation test

|                     | LogisticRegression | MLP        | RandomForest | RandomForest800 | XGB      | LGB     | CB      | CB800      |
|:-------------------:|:------------------:|:----------:|:------------:|:---------------:|:--------:|:-------:|:-------:|:----------:|
| F1-score(weighted)  | 0.9684             | **0.9840** | 0.9601       | 0.9774          | 0.9695   | 0.8401  | 0.9669  | 0.9839     |
| F1-score(macro)     | 0.8406             | 0.9053     | 0.8495       | 0.8882          | 0.8768   | 0.6440  | 0.8697  | **0.9150** |
| F1-score(micro=acc) | 0.9666             | **0.9841** | 0.9586       | 0.9765          | 0.9686   | 0.8433  | 0.9665  | 0.9836     |
| Avg Train time(sec) | **13.375**         | 545.064    | 18.892       | 1505.108        | 2053.631 | 236.701 | 444.404 | 3458.683   |

MLP 비교 ReLu+Xavier+Adam, ELU+He+Nadam

|                     | R+X+A    | R+X+N    | R+H+A | R+H+N    | E+X+A    | E+X+N      | E+H+A | E+H+N      | E+H+RmsProp  |
|:-------------------:|:--------:|:--------:|:-----:|:--------:|:--------:|:----------:|:-----:|:----------:|:------------:|
| F1-score(weighted)  | 0.9834   | 0.9833   | 0     | 0.9836   | 0.9831   | **0.9840** | 0     | 0.9835     | 0.9826       |
| F1-score(macro)     | 0.8971   | 0.8998   | 0     | 0.8975   | 0.8994   | 0.9053     | 0     | **0.9060** | 0.8971       |
| F1-score(micro=acc) | 0.9836   | 0.9834   | 0     | 0.9838   | 0.9832   | **0.9841** | 0     | 0.9836     | 0.9829       |
| Avg Train time(sec) | 6665.756 | 9921.465 | 0     | 9754.647 | 4372.170 | 5450.641   | 0     | 6657.727   | **3930.952** |

```python

```
